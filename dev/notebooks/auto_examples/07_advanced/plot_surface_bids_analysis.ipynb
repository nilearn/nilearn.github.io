{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Surface-based dataset first and second level analysis of a dataset\n\nFull step-by-step example of fitting a :term:`GLM`\n(first and second level analysis) in a 10-subjects dataset\nand visualizing the results.\n\nMore specifically:\n\n#. Download an :term:`fMRI` :term:`BIDS` dataset\n   with two language conditions to contrast.\n\n#. Project the data to a standard mesh, fsaverage5,\n   also known as the Freesurfer template :term:`mesh`\n   downsampled to about 10k nodes per hemisphere.\n\n#. Run the first level model objects.\n\n#. Fit a second level model on the fitted first level models.\n\nNotice that in this case the preprocessed :term:`bold<BOLD>` images\nwere already normalized to the same :term:`MNI` space.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetch example :term:`BIDS` dataset\nWe download a simplified :term:`BIDS` dataset\nmade available for illustrative purposes.\nIt contains only the necessary information\nto run a statistical analysis using Nilearn.\nThe raw data subject folders only contain bold.json and events.tsv files,\nwhile the derivatives folder includes the preprocessed files preproc.nii\nand the confounds.tsv files.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import fetch_language_localizer_demo_dataset\n\ndata = fetch_language_localizer_demo_dataset(legacy_output=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is the location of the dataset on disk.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data.data_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subject level models\nFrom the dataset directory we automatically obtain\nthe FirstLevelModel objects\nwith their subject_id filled from the :term:`BIDS` dataset.\nAlong, we also obtain:\n\n- a list with the Nifti image associated with each run\n\n- a list of events read from events.tsv in the :term:`BIDS` dataset\n\n- a list of confounder motion regressors\n  since in this case a confounds.tsv file is available\n  in the :term:`BIDS` dataset.\n\nTo get the first level models we only have to specify the dataset directory\nand the ``task_label`` as specified in the file names.\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.glm.first_level import first_level_from_bids\n\nmodels, run_imgs, events, confounds = first_level_from_bids(\n    dataset_path=data.data_dir,\n    task_label=\"languagelocalizer\",\n    space_label=\"\",\n    img_filters=[(\"desc\", \"preproc\")],\n    n_jobs=2,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Project :term:`fMRI` data to the surface, fit the GLM and compute contrasts\n\nThe projection function simply takes the :term:`fMRI` data and the mesh.\nNote that those correspond spatially, as they are both in same space.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>Note that here we pass ALL the confounds when we fit the model.\n   In this case we can do this because our regressors only include\n   the motion realignment parameters.\n   For most preprocessed BIDS dataset,\n   you would have to carefully choose which confounds to include.\n\n   When working with a typical BIDS derivative dataset\n   generated by fmriprep,\n   the :obj:`~nilearn.glm.first_level.first_level_from_bids` function\n   allows you to indirectly pass arguments to\n   :obj:`~nilearn.interfaces.fmriprep.load_confounds`,\n   so you can selectively load specific subsets of confounds\n   to implement certain denoising strategies.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\nfrom nilearn.datasets import load_fsaverage, load_fsaverage_data\nfrom nilearn.surface import SurfaceImage\n\nfsaverage5 = load_fsaverage()\n\n# let's get the fsaverage curvature data image\n# to use as background for the GLM report.\ncurvature = load_fsaverage_data(mesh_type=\"inflated\", data_type=\"curvature\")\n\nthreshold = 1.96\n\n# Empty lists in which we are going to store activation values.\nz_scores = []\nz_scores_left = []\nz_scores_right = []\nfor i, (first_level_glm, fmri_img, confound, event) in enumerate(\n    zip(models, run_imgs, confounds, events, strict=False)\n):\n    print(f\"Running GLM on {Path(fmri_img[0]).relative_to(data.data_dir)}\")\n\n    image = SurfaceImage.from_volume(\n        mesh=fsaverage5[\"pial\"],\n        volume_img=fmri_img[0],\n    )\n\n    # Fit GLM.\n    # Pass events and all confounds\n    first_level_glm.fit(\n        run_imgs=image,\n        events=event[0],\n        confounds=confound[0],\n    )\n\n    # Compute contrast between 'language' and 'string' events\n    z_scores.append(\n        first_level_glm.compute_contrast(\n            \"language-string\", stat_type=\"t\", output_type=\"z_score\"\n        )\n    )\n\n    # Let's only generate a report for the first subject\n    if i == 1:\n        report_flm = first_level_glm.generate_report(\n            contrasts=\"language-string\",\n            threshold=threshold,\n            height_control=None,\n            alpha=0.001,\n            bg_img=curvature,\n            title=\"surface based subject-level model\",\n        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View the GLM report of the first subject\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "report_flm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or in a separate browser window\nreport_flm.open_in_browser()\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save the report to disk\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "output_dir = Path.cwd() / \"results\" / \"plot_surface_bids_analysis\"\noutput_dir.mkdir(exist_ok=True, parents=True)\nreport_flm.save_as_html(output_dir / \"report_flm.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Group level model\n\nIndividual activation maps have been accumulated in the ``z_score``.\nWe can now use them in a one-sample t-test at the group level model\nby passing them as input\nto :class:`~nilearn.glm.second_level.SecondLevelModel`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\nfrom nilearn.glm.second_level import SecondLevelModel\n\nsecond_level_glm = SecondLevelModel()\ndesign_matrix = pd.DataFrame([1] * len(z_scores), columns=[\"intercept\"])\nsecond_level_glm.fit(second_level_input=z_scores, design_matrix=design_matrix)\n\nreport_slm = second_level_glm.generate_report(\n    contrasts=[\"intercept\"],\n    threshold=threshold,\n    height_control=None,\n    alpha=0.001,\n    bg_img=curvature,\n    title=\"surface based group-level model\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View the GLM report at the group level.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "report_slm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or in a separate browser window\nreport_flm.open_in_browser()\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save it as an html file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "report_slm.save_as_html(output_dir / \"report_slm.html\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}