{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Working with long time series fMRI images\n\nIn this example, we will demonstrate how one can work with large fMRI images\nmore efficiently. Note that fMRI images can be large on-disk due to several\ndifferent factors, including a long acquisition or high-resolution sampling.\nCurrently, this example focuses on memory-efficient interactions with long\ntime series fMRI data. In this case, loading the whole time series into memory\nmay represent a significant computational cost. We will therefore explore\nstrategies to minimize the amount of data that is loaded into memory,\nand we will compare these strategies against a naive usage of\n:class:`~nilearn.maskers.NiftiMasker`.\n\nTo make this more concrete, we will create a large fMRI image with over\n800 time points by concatenating individual subjects in the\n:func:`~nilearn.datasets.fetch_adhd` dataset.\nOur goal is to extract data from several regions of interest (ROIs)\ndefined by a number of binary masks, all in parallel.\n\nWhen using :class:`~nilearn.maskers.NiftiMasker` to extract data from each\nROI in parallel, each parallel process will load the entire fMRI image into\nmemory. This can lead to a significant increase in memory usage and may be\ninfeasible in some computational environments.\n\nWe will thus compare three different methods for this task, each handling\nthe fMRI image in a different way:\n\n1. A naive, unoptimized usage of :class:`~nilearn.maskers.NiftiMasker`.\n2. Masking the fMRI image's data array using numpy indexing.\n3. Using :class:`multiprocessing.shared_memory.SharedMemory`.\n\nFor the first method, there are two ways to input the fMRI image:\n\n1. passing the file path (i.e., the location of the large fMRI image on-disk).\n2. loading image first and passing this in-memory object to joblib.\n\nWhen using file paths, the entire image is loaded into memory for each process,\nand that is exactly the problem we described earlier.\n\nHowever, when the fMRI image is loaded once and then passed to\n:class:`joblib.Parallel` as an in-memory object, the image is not loaded\nmultiple times. We will see that this can already be a significant\nimprovement over the naive usage of :class:`~nilearn.maskers.NiftiMasker` with\nfile paths.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a large fMRI image\nHere we will create a \"large\" fMRI image by fetching 6 subjects'\nfMRI images via the :func:`~nilearn.datasets.fetch_adhd`\nfunction, concatenating them and then saving to a file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\nfrom nilearn.datasets import fetch_adhd\nfrom nilearn.image import concat_imgs\n\nN_SUBJECTS = 6\nN_REGIONS = 4\n\n\ndef create_large_fmri(n_subjects):\n    fmri_data = fetch_adhd(n_subjects=n_subjects)\n    fmri_img = concat_imgs(fmri_data.func)\n    n_timepoints = fmri_img.shape[-1]\n\n    output_dir = Path.cwd() / \"results\" / \"plot_mask_large_fmri\"\n    output_dir.mkdir(parents=True, exist_ok=True)\n    print(f\"Large fmri file will be saved to:\\n{output_dir}\")\n\n    fmri_path = output_dir / \"large_fmri.nii.gz\"\n    fmri_img.to_filename(fmri_path)\n\n    return fmri_path, n_timepoints\n\n\nfmri_path, n_timepoints = create_large_fmri(N_SUBJECTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a set of binary masks\nWe will now create 4 binary masks from a brain atlas. Here we will use the\nmultiscale functional brain parcellations via the\n:func:`~nilearn.datasets.fetch_atlas_basc_multiscale_2015` function.\nWe will fetch a 64-region version of this atlas and then create separate\nbinary masks for the first 4 regions.\n\nIn this case, the atlas and the fMRI image have different resolutions.\nSo we will resample the atlas to the fMRI image. It is important to do that\nbecause only :class:`~nilearn.maskers.NiftiMasker` can handle the resampling\nof the mask to the fMRI image but other methods considered here will not.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import fetch_atlas_basc_multiscale_2015\nfrom nilearn.image import load_img, new_img_like, resample_to_img\n\n\ndef create_masks(fmri_path, n_regions):\n    atlas_path = fetch_atlas_basc_multiscale_2015(resolution=64).maps\n    atlas_img = load_img(atlas_path)\n\n    resampled_atlas = resample_to_img(\n        atlas_img, fmri_path, interpolation=\"nearest\", copy_header=True\n    )\n\n    mask_paths = []\n    output_dir = Path.cwd() / \"results\" / \"plot_mask_large_fmri\"\n    for idx in range(1, n_regions + 1):\n        mask = resampled_atlas.get_fdata() == idx\n        mask = new_img_like(\n            ref_niimg=fmri_path,\n            data=mask,\n            affine=resampled_atlas.affine,\n            copy_header=True,\n        )\n        path = output_dir / f\"mask_{idx}.nii.gz\"\n        mask.to_filename(path)\n        mask_paths.append(path)\n\n    return mask_paths\n\n\nmask_paths = create_masks(fmri_path, N_REGIONS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mask the fMRI image using NiftiMasker\nLet's first mask the fMRI image using :class:`~nilearn.maskers.NiftiMasker`.\nThis is the most user-friendly way to extract data from an fMRI image as it\nmakes it easy to standardize, smooth, detrend, etc. the data.\n\nWe will first wrap the :func:`nilearn.maskers.NiftiMasker.fit_transform`\nwithin a function so that it is more readable and easier to use.\nWe will then define another function that would mask the fMRI image using\nmultiple masks in parallel using the :mod:`joblib` package. As mentioned\nearlier, this could further be done in two ways: directly using file paths\nas input or first loading the images in-memory and passing them as input.\n\nSo we will define two functions for each case.\n\nWe can then track the memory usage of these functions via the\n``memory_profiler`` package.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from joblib import Parallel, delayed\n\nfrom nilearn.maskers import NiftiMasker\n\n\ndef nifti_masker_single(fmri, mask):\n    return NiftiMasker(mask_img=mask).fit_transform(fmri)\n\n\ndef nifti_masker_parallel_path(fmri_path, mask_paths):\n    Parallel(n_jobs=N_REGIONS)(\n        delayed(nifti_masker_single)(fmri_path, mask_path)\n        for mask_path in mask_paths\n    )\n\n\ndef nifti_masker_parallel_inmemory(fmri_path, mask_paths):\n    fmri_img = load_img(fmri_path)\n    mask_imgs = [load_img(mask) for mask in mask_paths]\n    Parallel(n_jobs=N_REGIONS)(\n        delayed(nifti_masker_single)(fmri_img, mask) for mask in mask_imgs\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's also create a dictionary to store the memory usage for each method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from memory_profiler import memory_usage\n\nnifti_masker = {\"path\": [], \"in_memory\": []}\n\nnifti_masker[\"path\"] = memory_usage(\n    (nifti_masker_parallel_path, (fmri_path, mask_paths)),\n    max_usage=True,\n    include_children=True,\n    multiprocess=True,\n)\nnifti_masker[\"in_memory\"] = memory_usage(\n    (nifti_masker_parallel_inmemory, (fmri_path, mask_paths)),\n    max_usage=True,\n    include_children=True,\n    multiprocess=True,\n)\n\nprint(\n    f\"Peak memory usage with NiftiMasker, {N_REGIONS} jobs in parallel:\\n\"\n    f\"- with file paths: {nifti_masker['path']} MiB\\n\"\n    f\"- with in-memory images: {nifti_masker['in_memory']} MiB\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Masking using numpy indexing\nNow let's see how we can mask the fMRI image using numpy indexing. This\ncould be more efficient than the NiftiMasker when we simply need to mask\nthe fMRI image with binary masks and don't need to standardize, smooth, etc.\nthe image.\n\nAs before we will first define a function that would mask the data array\nof the fMRI image using a single mask. We will then define another function\nthat would iterate over multiple masks in parallel and mask the data array\nof the fMRI image using each mask.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\n\ndef numpy_masker_single(fmri, mask):\n    return fmri[mask]\n\n\ndef numpy_masker_parallel(fmri_path, mask_paths):\n    fmri_data = load_img(fmri_path).get_fdata()\n    masks = [load_img(mask).get_fdata().astype(bool) for mask in mask_paths]\n    Parallel(n_jobs=N_REGIONS)(\n        delayed(numpy_masker_single)(fmri_data, mask) for mask in masks\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's measure the memory usage\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "numpy_masker = memory_usage(\n    (numpy_masker_parallel, (fmri_path, mask_paths)),\n    max_usage=True,\n    include_children=True,\n    multiprocess=True,\n)\n\nprint(\n    f\"Peak memory usage with numpy indexing, {N_REGIONS} jobs in parallel:\\n\"\n    f\"{numpy_masker} MiB\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Masking using numpy indexing in parallel with shared memory\nFinally, let's see how we can combine numpy indexing and shared memory from\nthe :mod:`multiprocessing` module, and if that makes the masking more\nmemory-efficient.\n\nFor this method, we would have to load the fMRI image into shared memory\nthat can be accessed by multiple processes. This way, each process can\naccess the data directly from the shared memory without loading the entire\nimage into memory again.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from multiprocessing.shared_memory import SharedMemory\n\n\ndef numpy_masker_shared_parallel(fmri_path, mask_paths):\n    fmri_array = load_img(fmri_path).get_fdata()\n    shm = SharedMemory(create=True, size=fmri_array.nbytes)\n    shared_array = np.ndarray(\n        fmri_array.shape, dtype=fmri_array.dtype, buffer=shm.buf\n    )\n    np.copyto(shared_array, fmri_array)\n    del fmri_array\n    masks = [load_img(mask).get_fdata().astype(bool) for mask in mask_paths]\n    Parallel(n_jobs=N_REGIONS)(\n        delayed(numpy_masker_single)(shared_array, mask) for mask in masks\n    )\n    # cleanup\n    shm.close()\n    shm.unlink()\n\n\nnumpy_masker_shared = memory_usage(\n    (numpy_masker_shared_parallel, (fmri_path, mask_paths)),\n    max_usage=True,\n    include_children=True,\n    multiprocess=True,\n)\nprint(\n    f\"Peak memory usage with numpy indexing and shared memory, \"\n    f\"{N_REGIONS} jobs in parallel:\\n\"\n    f\"{numpy_masker_shared} MiB\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the memory usage for each method to compare them.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\nplt.bar(\n    [\n        \"NiftiMasker,\\nwith path\",\n        \"NiftiMasker,\\nwith in-memory\\nimage\",\n        \"Numpy indexing\",\n        \"Numpy indexing,\\nwith\\nSharedMemory\",\n    ],\n    [\n        nifti_masker[\"path\"],\n        nifti_masker[\"in_memory\"],\n        numpy_masker,\n        numpy_masker_shared,\n    ],\n    color=[\n        (0.12156862745098039, 0.4666666666666667, 0.7058823529411765),\n        (0.6823529411764706, 0.7803921568627451, 0.9098039215686274),\n        (1.0, 0.4980392156862745, 0.054901960784313725),\n        (0.17254901960784313, 0.6274509803921569, 0.17254901960784313),\n    ],\n)\nplt.ylabel(\"Peak memory usage (MiB)\")\nplt.title(\n    f\"Memory usage comparison for masking a 4D fMRI image with \\n\"\n    f\"{n_timepoints} volumes across {N_REGIONS} jobs in parallel\"\n)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\nSo overall we can see that there are much more memory-efficient ways to\nextract ROIs in parallel from large fMRI images than simply\nusing :class:`~nilearn.maskers.NiftiMasker` with file paths.\n\nThe two methods that standout both use numpy indexing and involve\nloading the fMRI image prior to masking. In fact, loading the fMRI image\nprior is generally better than using file paths even with\n:class:`~nilearn.maskers.NiftiMasker`.\n\nSo if your goal is to simply extract data from an fMRI image, numpy indexing\nis much more memory-efficient than using\n:class:`~nilearn.maskers.NiftiMasker`.\n\nHowever, if you also need to standardize, smooth, detrend, etc. the data,\nthen using :class:`~nilearn.maskers.NiftiMasker` with in-memory images is\nthe most user-friendly way to run all these operations in the appropriate\norder while still being relatively memory-efficient.\n\nFinally, it should be noted that the differences in memory usage between\nthe methods can be more significant when working with even larger images\nand/or more jobs/regions in parallel. You can try increasing the\n``N_SUBJECTS`` and ``N_REGIONS`` variables at the beginning of this example\nto see how the memory usage changes for each method.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}