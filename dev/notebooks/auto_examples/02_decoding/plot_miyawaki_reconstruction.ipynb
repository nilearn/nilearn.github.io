{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Reconstruction of visual stimuli from Miyawaki et al. 2008\n\nThis example reproduces the experiment presented in :footcite:t:`Miyawaki2008`.\n\nIt reconstructs 10x10 binary images from functional MRI data. Random images\nare used as training set and structured images are used for reconstruction.\n\nThe code is a bit elaborate as the example uses, as the original article,\na multiscale prediction on the images seen by the subject.\n\n.. seealso::\n\n    For an encoding approach for the same dataset, see\n    `sphx_glr_auto_examples_02_decoding_plot_miyawaki_encoding.py`\n\n.. include:: ../../../examples/masker_note.rst\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import sys\nimport time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## First we load the Miyawaki dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn import datasets\nfrom nilearn.plotting import show\n\nsys.stderr.write(\"Fetching dataset...\")\nt0 = time.time()\n\nmiyawaki_dataset = datasets.fetch_miyawaki2008()\n\n# print basic information on the dataset\nprint(\n    \"First functional nifti image (4D) is located \"\n    f\"at: {miyawaki_dataset.func[0]}\"\n)\n\nX_random_filenames = miyawaki_dataset.func[12:]\nX_figure_filenames = miyawaki_dataset.func[:12]\ny_random_filenames = miyawaki_dataset.label[12:]\ny_figure_filenames = miyawaki_dataset.label[:12]\ny_shape = (10, 10)\n\nsys.stderr.write(f\" Done ({time.time() - t0:.2f}s).\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Then we prepare and mask the data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom nilearn.maskers import MultiNiftiMasker\n\nsys.stderr.write(\"Preprocessing data...\")\nt0 = time.time()\n\n# Load and mask fMRI data\nmasker = MultiNiftiMasker(\n    mask_img=miyawaki_dataset.mask, detrend=True, standardize=False, n_jobs=2\n)\nmasker.fit()\nX_train = masker.transform(X_random_filenames)\nX_test = masker.transform(X_figure_filenames)\n\ny_train = [\n    np.reshape(\n        np.loadtxt(y, dtype=int, delimiter=\",\"), (-1, *y_shape), order=\"F\"\n    )\n    for y in y_random_filenames\n]\ny_test = [\n    np.reshape(\n        np.loadtxt(y, dtype=int, delimiter=\",\"), (-1, *y_shape), order=\"F\"\n    )\n    for y in y_figure_filenames\n]\nX_train = np.vstack([x[2:] for x in X_train])\ny_train = np.vstack([y[:-2] for y in y_train]).astype(float)\nX_test = np.vstack([x[2:] for x in X_test])\ny_test = np.vstack([y[:-2] for y in y_test]).astype(float)\n\nn_features = X_train.shape[1]\n\n\ndef flatten(list_of_2d_array):\n    flattened = [array.ravel() for array in list_of_2d_array]\n    return flattened\n\n\n# Build the design matrix for multiscale computation\n# Matrix is squared, y_rows == y_cols\ny_cols = y_shape[1]\n\n# Original data\ndesign_matrix = np.eye(100)\n\n# Example of matrix used for multiscale (sum pixels vertically)\n#\n# 0.5 *\n#\n# 1 1 0 0 0 0 0 0 0 0\n# 0 1 1 0 0 0 0 0 0 0\n# 0 0 1 1 0 0 0 0 0 0\n# 0 0 0 1 1 0 0 0 0 0\n# 0 0 0 0 1 1 0 0 0 0\n# 0 0 0 0 0 1 1 0 0 0\n# 0 0 0 0 0 0 1 1 0 0\n# 0 0 0 0 0 0 0 1 1 0\n# 0 0 0 0 0 0 0 0 1 1\n\nheight_tf = (np.eye(y_cols) + np.eye(y_cols, k=1))[: y_cols - 1] * 0.5\nwidth_tf = height_tf.T\n\nyt_tall = [np.dot(height_tf, m) for m in y_train]\nyt_large = [np.dot(m, width_tf) for m in y_train]\nyt_big = [np.dot(height_tf, np.dot(m, width_tf)) for m in y_train]\n\n# Add it to the training set\ny_train = [\n    np.r_[y.ravel(), t.ravel(), l.ravel(), b.ravel()]\n    for y, t, l, b in zip(y_train, yt_tall, yt_large, yt_big)\n]\n\ny_test = np.asarray(flatten(y_test))\ny_train = np.asarray(y_train)\n\n# Remove rest period\nX_train = X_train[y_train[:, 0] != -1]\ny_train = y_train[y_train[:, 0] != -1]\nX_test = X_test[y_test[:, 0] != -1]\ny_test = y_test[y_test[:, 0] != -1]\n\nsys.stderr.write(f\" Done ({time.time() - t0:.2f}s).\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## We define our prediction function\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sys.stderr.write(\"Training classifiers... \\r\")\nt0 = time.time()\n\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.linear_model import OrthogonalMatchingPursuit\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n# Create as many OrthogonalMatchingPursuit as voxels to predict\nclfs = []\nn_clfs = y_train.shape[1]\nfor i in range(y_train.shape[1]):\n    sys.stderr.write(\n        f\"Training classifiers {int(i + 1):03}/{int(n_clfs)}... \\r\"\n    )\n\n    clf = Pipeline(\n        [\n            (\"selection\", SelectKBest(f_classif, k=500)),\n            (\"scl\", StandardScaler()),\n            (\"clf\", OrthogonalMatchingPursuit(n_nonzero_coefs=10)),\n        ]\n    )\n    clf.fit(X_train, y_train[:, i])\n    clfs.append(clf)\n\nsys.stderr.write(\n    f\"Training classifiers {n_clfs:03d}/{n_clfs:d}... \"\n    f\"Done ({(time.time() - t0):.2f}s).\\n\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Here we run the prediction: the decoding itself\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sys.stderr.write(\"Calculating scores and outputs...\")\nt0 = time.time()\n\ny_pred = [clf.predict(X_test) for clf in clfs]\ny_pred = np.asarray(y_pred).T\n\n\n# We need to the multi scale reconstruction\ndef split_multi_scale(y, y_shape):\n    \"\"\"Split data into 4 original multi_scale images\"\"\"\n    yw, yh = y_shape\n\n    # Index of original image\n    split_index = [yw * yh]\n    # Index of large image\n    split_index.append(split_index[-1] + (yw - 1) * yh)\n    # Index of tall image\n    split_index.append(split_index[-1] + yw * (yh - 1))\n    # Index of big image\n    split_index.append(split_index[-1] + (yw - 1) * (yh - 1))\n\n    # We split according to computed indices\n    y_preds = np.split(y, split_index, axis=1)\n\n    # y_pred is the original image\n    y_pred = y_preds[0]\n\n    # y_pred_tall is the image with 1x2 patch application. We have to make\n    # some calculus to get it back in original shape\n    height_tf_i = (np.eye(y_cols) + np.eye(y_cols, k=-1))[\n        :, : y_cols - 1\n    ] * 0.5\n    height_tf_i.flat[0] = 1\n    height_tf_i.flat[-1] = 1\n    y_pred_tall = [\n        np.dot(height_tf_i, np.reshape(m, (yw - 1, yh))).flatten()\n        for m in y_preds[1]\n    ]\n    y_pred_tall = np.asarray(y_pred_tall)\n\n    # y_pred_large is the image with 2x1 patch application. We have to make\n    # some calculus to get it back in original shape\n    width_tf_i = (np.eye(y_cols) + np.eye(y_cols, k=1))[: y_cols - 1] * 0.5\n    width_tf_i.flat[0] = 1\n    width_tf_i.flat[-1] = 1\n    y_pred_large = [\n        np.dot(np.reshape(m, (yw, yh - 1)), width_tf_i).flatten()\n        for m in y_preds[2]\n    ]\n    y_pred_large = np.asarray(y_pred_large)\n\n    # y_pred_big is the image with 2x2 patch application. We use previous\n    # matrices to get it back in original shape\n    y_pred_big = [\n        np.dot(np.reshape(m, (yw - 1, yh - 1)), width_tf_i) for m in y_preds[3]\n    ]\n    y_pred_big = [\n        np.dot(height_tf_i, np.reshape(m, (yw - 1, yh))).flatten()\n        for m in y_pred_big\n    ]\n    y_pred_big = np.asarray(y_pred_big)\n\n    return (y_pred, y_pred_tall, y_pred_large, y_pred_big)\n\n\ny_pred, y_pred_tall, y_pred_large, y_pred_big = split_multi_scale(\n    y_pred, y_shape\n)\n\ny_pred = (\n    0.25 * y_pred\n    + 0.25 * y_pred_tall\n    + 0.25 * y_pred_large\n    + 0.25 * y_pred_big\n)\n\nsys.stderr.write(f\" Done ({time.time() - t0:.2f}s).\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Let us quantify our prediction error\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n    accuracy_score,\n    f1_score,\n    precision_score,\n    recall_score,\n)\n\nprint(\"Scores\")\nprint(\"------\")\naccuracy_to_print = np.mean(\n    [accuracy_score(y_test[:, i], y_pred[:, i] > 0.5) for i in range(100)]\n)\nprint(f\"  - Accuracy (percent): {accuracy_to_print:f}\")\n\nprecision_to_print = np.mean(\n    [precision_score(y_test[:, i], y_pred[:, i] > 0.5) for i in range(100)]\n)\nprint(f\"  - Precision: {precision_to_print:f}\")\n\nrecall_to_print = np.mean(\n    [\n        recall_score(y_test[:, i], y_pred[:, i] > 0.5, zero_division=0)\n        for i in range(100)\n    ]\n)\nprint(f\"  - Recall: {recall_to_print:f}\")\n\nf1_score_to_print = np.mean(\n    [f1_score(y_test[:, i], y_pred[:, i] > 0.5) for i in range(100)]\n)\nprint(f\"  - F1-score: {f1_score_to_print:f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And finally, we plot six reconstructed images, to compare with\nground truth\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\nfrom matplotlib import pyplot as plt\n\noutput_dir = Path.cwd() / \"results\" / \"plot_miyawaki_reconstruction\"\noutput_dir.mkdir(exist_ok=True, parents=True)\nprint(f\"Output will be saved to: {output_dir}\")\n\nfor i in range(6):\n    j = 10 * i\n    fig = plt.figure()\n    sp1 = plt.subplot(131)\n    sp1.axis(\"off\")\n    plt.title(\"Stimulus\")\n    sp2 = plt.subplot(132)\n    sp2.axis(\"off\")\n    plt.title(\"Reconstruction\")\n    sp3 = plt.subplot(133)\n    sp3.axis(\"off\")\n    plt.title(\"Binarized\")\n    sp1.imshow(\n        np.reshape(y_test[j], (10, 10)),\n        cmap=\"gray\",\n        interpolation=\"nearest\",\n    )\n    sp2.imshow(\n        np.reshape(y_pred[j], (10, 10)),\n        cmap=\"gray\",\n        interpolation=\"nearest\",\n    )\n    sp3.imshow(\n        np.reshape(y_pred[j] > 0.5, (10, 10)),\n        cmap=\"gray\",\n        interpolation=\"nearest\",\n    )\n    plt.savefig(output_dir / f\"miyawaki2008_reconstruction_{int(i)}.png\")\n\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.22"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}