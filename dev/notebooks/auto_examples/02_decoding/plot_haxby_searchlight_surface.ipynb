{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Cortical surface-based searchlight decoding\n\nThis is a demo for surface-based searchlight decoding,\nas described in :footcite:t:`Chen2011`.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>This example projects results from the Haxby dataset\n    on the fsaverage surface.\n    This is inappropriate\n    given that the Haxby data has not been properly coregistered\n    to allow for such projection.\n    It is done in this example for pedagogical reasons\n    to show \"how to do it\".</p></div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Haxby dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\nfrom nilearn.datasets import fetch_haxby\n\n# We fetch 2nd subject from haxby datasets (which is default)\nhaxby_dataset = fetch_haxby()\n\nfmri_filename = haxby_dataset.func[0]\nlabels = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\ny = labels[\"labels\"]\nrun = labels[\"chunks\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Restrict to faces and houses\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.image import index_img\n\ncondition_mask = y.isin([\"face\", \"house\"])\n\nfmri_img = index_img(fmri_filename, condition_mask)\ny, run = y[condition_mask], run[condition_mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Surface :term:`BOLD` response\nFetch a coarse surface of the left hemisphere only for speed\nand average voxels 5 mm close to the 3d pial surface.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn import neighbors\n\nfrom nilearn.datasets import load_fsaverage\nfrom nilearn.surface import SurfaceImage\n\nfsaverage = load_fsaverage()\nfmri_img_surf = SurfaceImage.from_volume(\n    mesh=fsaverage[\"pial\"], volume_img=fmri_img, radius=5\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Searchlight computation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nfrom nilearn.decoding.searchlight import search_light\n\n# For the sake of speed,\n# we will only run the decoding on one hemisphere\n# in this example.\nhemispheres_to_analyze = [\"left\"]\n# Uncomment the following line if you want to run both hemispheres.\n# hemispheres_to_analyze = [\"left\", \"right\"]\n\n# Let us initialize a result scores dictionary ,\n# to be able to create a SurfaceImage from it later.\nscores = {\n    \"left\": np.zeros(fmri_img_surf.mesh.parts[\"left\"].n_vertices),\n    \"right\": np.zeros(fmri_img_surf.mesh.parts[\"right\"].n_vertices),\n}\n\nfor hemi in hemispheres_to_analyze:\n    print(f\"Running searchlight on {hemi} hemisphere.\")\n\n    # To define the BOLD responses\n    # to be included within each searchlight \"sphere\"\n    # we define an adjacency matrix\n    # based on the inflated surface vertices\n    # such that nearby vertices are concatenated\n    # within the same searchlight.\n    coordinates = fsaverage[\"inflated\"].parts[hemi].coordinates\n    nn = neighbors.NearestNeighbors()\n    adjacency = nn.fit(coordinates).radius_neighbors_graph(coordinates).tolil()\n\n    # Simple linear estimator preceded by a normalization step\n    estimator = make_pipeline(StandardScaler(), RidgeClassifier(alpha=10.0))\n\n    # Define cross-validation scheme\n    cv = KFold(n_splits=3, shuffle=False)\n\n    X = fmri_img_surf.data.parts[hemi].T\n\n    # Cross-validated search light\n    scores[hemi] = search_light(\n        X, y, estimator, adjacency, cv=cv, n_jobs=-1, verbose=1\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import load_fsaverage_data\nfrom nilearn.plotting import plot_surf_stat_map, show\n\nfsaverage_data = load_fsaverage_data(mesh_type=\"inflated\", data_type=\"sulcal\")\n\nscore_img = SurfaceImage(mesh=fsaverage[\"inflated\"], data=scores)\n\nchance = 0.5\nfor hemi in hemispheres_to_analyze:\n    score_img.data.parts[hemi] = score_img.data.parts[hemi] - chance\n\nfor hemi in hemispheres_to_analyze:\n    plot_surf_stat_map(\n        stat_map=score_img,\n        view=\"ventral\",\n        hemi=hemi,\n        threshold=0.1,\n        bg_map=fsaverage_data,\n        title=f\"Accuracy map, {hemi} hemisphere\",\n        cmap=\"bwr\",\n    )\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}