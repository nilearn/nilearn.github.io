{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Single-subject data (two runs) in native space\n\nThe example shows the analysis of an :term:`SPM` dataset,\nwith two conditions: viewing a face image or a scrambled face image.\n\nThis example takes a lot of time because the input are lists of 3D images\nsampled in different positions (encoded by different affine functions).\n\n.. seealso::\n\n    For more information\n    see the `dataset description <spm_multimodal_dataset>`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetch and inspect the data\nFetch the :term:`SPM` multimodal_faces data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import fetch_spm_multimodal_fmri\n\nsubject_data = fetch_spm_multimodal_fmri()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's inspect one of the event files before using them.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\nevents = [subject_data.events1, subject_data.events2]\n\nevents_dataframe = pd.read_csv(events[0], sep=\"\\t\")\nevents_dataframe[\"trial_type\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can confirm there are only 2 conditions in the dataset.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.plotting import plot_event, show\n\nplot_event(events)\n\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resample the images:\nthis is achieved by the ``concat_imgs`` function of Nilearn.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\n\nfrom nilearn.image import concat_imgs, mean_img, resample_img\n\n# Avoid getting too many warnings due to resampling\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    fmri_img = [\n        concat_imgs(subject_data.func1, auto_resample=True),\n        concat_imgs(subject_data.func2, auto_resample=True),\n    ]\naffine, shape = fmri_img[0].affine, fmri_img[0].shape\nprint(\"Resampling the second image (this takes time)...\")\nfmri_img[1] = resample_img(fmri_img[1], affine, shape[:3], copy_header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create mean image for display purposes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mean_image = mean_img(fmri_img, copy_header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit the model\nFit the :term:`GLM` for the 2 runs\nby specifying a FirstLevelModel and then fitting it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Sample at the beginning of each acquisition.\nslice_time_ref = 0.0\n# We use a discrete cosine transform to model signal drifts.\ndrift_model = \"cosine\"\n# The cutoff for the drift model is 0.01 Hz.\nhigh_pass = 0.01\n# The hemodynamic response function\nhrf_model = \"spm + derivative\"\n\nfrom nilearn.glm.first_level import FirstLevelModel\n\nprint(\"Fitting a GLM\")\nfmri_glm = FirstLevelModel(\n    smoothing_fwhm=None,\n    t_r=subject_data.t_r,\n    hrf_model=hrf_model,\n    drift_model=drift_model,\n    high_pass=high_pass,\n)\n\n\nfmri_glm = fmri_glm.fit(fmri_img, events=events)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View the results\nNow we can compute contrast-related statistical maps (in z-scale),\nand plot them.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.plotting import plot_stat_map\n\nprint(\"Computing contrasts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We actually want more interesting contrasts.\nThe simplest contrast just makes the difference\nbetween the two main conditions.\nWe define the two opposite versions to run one-tailed t-tests.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "contrasts = [\"faces - scrambled\", \"scrambled - faces\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's store common parameters for all plots.\n\nWe plot the contrasts values overlaid on the mean fMRI image\nand we will use the z-score values as transparency,\nwith any voxel with | Z-score | > 3 being fully opaque\nand any voxel with 0 < | Z-score | < 1.96 being partly transparent.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_param = {\n    \"vmin\": 0,\n    \"display_mode\": \"z\",\n    \"cut_coords\": 3,\n    \"black_bg\": True,\n    \"bg_img\": mean_image,\n    \"cmap\": \"inferno\",\n    \"transparency_range\": [0, 3],\n}\n\n# Iterate on contrasts to compute and plot them.\nfor contrast_id in contrasts:\n    print(f\"\\tcontrast id: {contrast_id}\")\n\n    results = fmri_glm.compute_contrast(contrast_id, output_type=\"all\")\n\n    plot_stat_map(\n        results[\"stat\"],\n        title=contrast_id,\n        transparency=results[\"z_score\"],\n        **plot_param,\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also define the effects of interest contrast,\na 2-dimensional contrasts spanning the two conditions.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\ncontrasts = np.eye(2)\n\nresults = fmri_glm.compute_contrast(contrasts, output_type=\"all\")\n\nplot_stat_map(\n    results[\"stat\"],\n    title=\"effects of interest\",\n    transparency=results[\"z_score\"],\n    **plot_param,\n)\n\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the resulting maps we observe\nthat the analysis results in wide activity\nfor the 'effects of interest' contrast,\nshowing the implications of large portions of the visual cortex\nin the conditions.\nBy contrast,\nthe differential effect between \"faces\" and \"scrambled\" involves sparser,\nmore anterior and lateral regions.\nIt also displays some responses in the frontal lobe.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}