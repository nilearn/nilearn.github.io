<!doctype html>
<html class="no-js" lang="en" data-content_root="./">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="General bibliography" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://nilearn.github.io/bibliography.html" />
<meta property="og:site_name" content="Nilearn" />
<meta property="og:description" content="The references below are arranged alphabetically by first author. You can download the bib file here. Hunar Abdulrahman and Richard N Henson. Effect of trial-to-trial variability on optimal event-r..." />
<meta property="og:image" content="https://nilearn.github.io/_static/nilearn-logo.png" />
<meta property="og:image:alt" content="Nilearn" />
<meta name="description" content="The references below are arranged alphabetically by first author. You can download the bib file here. Hunar Abdulrahman and Richard N Henson. Effect of trial-to-trial variability on optimal event-r..." />
<link rel="search" title="Search" href="search.html" />

    <link rel="shortcut icon" href="_static/favicon.ico"/><!-- Generated with Sphinx 7.4.7 and Furo 2024.08.06 -->
        <title>General bibliography - Nilearn</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=2da93098" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css?v=452ecd87" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/fontawesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/solid.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/brands.min.css" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: black;
  --admonition-font-size: 100%;
  --admonition-title-font-size: 100%;
  --color-announcement-background: #FBB360;
  --color-announcement-text: #111418;
  --color-admonition-title--note: #448aff;
  --color-admonition-title-background--note: #448aff10;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-announcement-background: #935610;
  --color-announcement-text: #FFFFFF;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-announcement-background: #935610;
  --color-announcement-text: #FFFFFF;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>

<div class="announcement">
  <aside class="announcement-content">
     <p>This is the development documentation of nilearn (0.12.1.dev19+g28cf98721) <a class="sd-sphinx-override sd-badge sd-text-wrap sd-btn-outline-dark reference external" href="https://nilearn.github.io"><span>Switch to stable version (0.12.0)</span></a></p> 
  </aside>
</div>

<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">Nilearn</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="_static/nilearn-transparent.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Nilearn</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="auto_examples/index.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Examples</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/00_tutorials/index.html">Basic tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Basic tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/00_tutorials/plot_3d_and_4d_niimg.html">3D and 4D niimgs: handling and visualizing</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/00_tutorials/plot_decoding_tutorial.html">A introduction tutorial to fMRI decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/00_tutorials/plot_nilearn_101.html">Basic nilearn example: manipulating and looking at data</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/00_tutorials/plot_python_101.html">Basic numerics and plotting with Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/00_tutorials/plot_single_subject_single_run.html">Intro to GLM Analysis: a single-run, single-subject fMRI dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/00_tutorials/plot_surface_101.html">Working with Surface images</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/01_plotting/index.html">Visualization of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Visualization of brain images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_atlas.html">Basic Atlas plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_colormaps.html">Colormaps in Nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_dim_plotting.html">Controlling the contrast of the background when plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_demo_glass_brain.html">Glass brain plotting in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_demo_glass_brain_extensive.html">Glass brain plotting in nilearn (all options)</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_surf_atlas.html">Loading and plotting of a cortical surface atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_3d_map_to_surface_projection.html">Making a surface plot of a 3D statistical map</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_demo_more_plotting.html">More plotting tools from nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_visualization.html">NeuroImaging volumes visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_haxby_masks.html">Plot Haxby masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_transparency.html">Plotting images with transparent thresholding</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_demo_plotting.html">Plotting tools in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_surf_stat_map.html">Seed-based connectivity on the surface</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_surface_projection_strategies.html">Technical point: Illustration of the volume to surface sampling schemes</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_prob_atlas.html">Visualizing 4D probabilistic atlas maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_visualize_megatrawls_netmats.html">Visualizing Megatrawls Network Matrices from Human Connectome Project</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_overlay.html">Visualizing a probabilistic atlas: the default mode in the MSDL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_carpet.html">Visualizing global patterns with a carpet plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_multiscale_parcellations.html">Visualizing multiscale functional brain parcellations</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/02_decoding/index.html">Decoding and predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Decoding and predicting from brain images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_searchlight_surface.html">Cortical surface-based searchlight decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_glm_decoding.html">Decoding of a dataset after GLM fit for signal extraction</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_anova_svm.html">Decoding with ANOVA + SVM: face vs house in the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_frem.html">Decoding with FREM: face vs house vs chair object recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_different_estimators.html">Different classifiers in decoding the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_miyawaki_encoding.html">Encoding models for visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_simulated_data.html">Example of pattern recognition on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_mixed_gambles_frem.html">FREM on Jimura et al “mixed gambles” dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_full_analysis.html">ROI-based decoding analysis in Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_miyawaki_reconstruction.html">Reconstruction of visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_searchlight.html">Searchlight analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_grid_search.html">Setting a parameter by cross-validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_stimuli.html">Show stimuli of Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_multiclass.html">The haxby dataset: different multi-class strategies</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_understand_decoder.html">Understanding <code class="xref py py-class docutils literal notranslate"><span class="pre">Decoder</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_oasis_vbm.html">Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_oasis_vbm_space_net.html">Voxel-Based Morphometry on Oasis dataset with Space-Net prior</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/03_connectivity/index.html">Functional connectivity</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Functional connectivity</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_group_level_connectivity.html">Classification of age groups using functional connectivity</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_data_driven_parcellations.html">Clustering methods to learn a brain parcellation from fMRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_atlas_comparison.html">Comparing connectomes on different reference atlases</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_inverse_covariance_connectome.html">Computing a connectome with sparse inverse covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_simulated_connectome.html">Connectivity structure estimation on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_compare_decomposition.html">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_sphere_based_connectome.html">Extract signals on spheres and plot a connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_signal_extraction.html">Extracting signals from a brain parcellation</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_probabilistic_atlas_extraction.html">Extracting signals of a probabilistic atlas of functional regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_multi_subject_connectome.html">Group Sparse inverse covariance for multi-subject connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html">Producing single subject maps of seed-to-voxel correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html">Regions extraction using dictionary learning and functional connectomes</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/04_glm_first_level/index.html">GLM: First level analysis</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of GLM: First level analysis</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_fir_model.html">Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_adhd_dmn.html">Default Mode Network extraction of ADHD dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_hrf.html">Example of MRI response functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_localizer_surface_analysis.html">Example of surface-based first-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_design_matrix.html">Examples of design matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_bids_features.html">First level analysis of a complete BIDS dataset from openneuro</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_write_events_file.html">Generate an events.tsv file for the NeuroSpin localizer task</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_predictions_residuals.html">Predicted time series and residuals</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_two_runs_model.html">Simple example of two-runs fMRI model fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_spm_multimodal_faces.html">Single-subject data (two runs) in native space</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_first_level_details.html">Understanding parameters of the first-level model</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/05_glm_second_level/index.html">GLM: Second level analysis</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of GLM: Second level analysis</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_second_level_association_test.html">Example of generic design in second-level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_second_level_design_matrix.html">Example of second level design matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html">Second-level fMRI model: one sample test</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_proportion_activated_voxels.html">Second-level fMRI model: true positive proportion in clusters</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_second_level_two_sample_test.html">Second-level fMRI model: two-sample test, unpaired and paired</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_thresholding.html">Statistical testing of a second-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_oasis.html">Voxel-Based Morphometry on OASIS dataset</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/06_manipulating_images/index.html">Manipulating brain image volumes</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Manipulating brain image volumes</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_extract_regions_labels_image.html">Breaking an atlas of labels in separated regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_compare_mean_image.html">Comparing the means of 2 images</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_roi_extraction.html">Computing a Region of Interest (ROI) mask manually</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_nifti_labels_simple.html">Extracting signals from brain regions using the NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_threshold_image.html">Image thresholding</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_negate_image.html">Negating an image with math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_extract_rois_statistical_maps.html">Region Extraction using a t-statistical map (3D)</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_extract_rois_smith_atlas.html">Regions Extraction of Default Mode Networks using Smith Atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_resample_to_template.html">Resample an image to a template</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_nifti_simple.html">Simple example of NiftiMasker use</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_smooth_mean_image.html">Smoothing an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_mask_computation.html">Understanding NiftiMasker and mask computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_affine_transformation.html">Visualization of affine resamplings</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/07_advanced/index.html">Advanced statistical analysis of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of Advanced statistical analysis of brain images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_surface_image_and_maskers.html">A short demo of the surface images &amp; maskers</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_advanced_decoding_scikit.html">Advanced decoding using scikit learn</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_bids_analysis.html">BIDS dataset first and second level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_beta_series.html">Beta-Series Modeling for Task-Based Functional Connectivity and Decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_copy_headers_math_img.html">Copying headers from input images with <code class="docutils literal notranslate"><span class="pre">math_img</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_age_group_prediction_cross_val.html">Functional connectivity predicts age group</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_localizer_simple_analysis.html">Massively univariate analysis of a calculation task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_localizer_mass_univariate_methods.html">Massively univariate analysis of a motor task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_haxby_mass_univariate.html">Massively univariate analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_ica_resting_state.html">Multivariate decompositions: Independent component analysis of fMRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_ica_neurovault.html">NeuroVault cross-study ICA maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_neurovault_meta_analysis.html">NeuroVault meta-analysis of stop-go paradigm studies</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_surface_bids_analysis.html">Surface-based dataset first and second level analysis of a dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_mask_large_fmri.html">Working with long time series fMRI images</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="user_guide.html">User guide</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of User guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="introduction.html">1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#what-is-nilearn">2. What is <code class="docutils literal notranslate"><span class="pre">nilearn</span></code>?</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#using-nilearn-for-the-first-time">3. Using <code class="docutils literal notranslate"><span class="pre">nilearn</span></code> for the first time</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#machine-learning-applications-to-neuroimaging">4. Machine learning applications to Neuroimaging</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="decoding/index.html">5. Decoding and MVPA: predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of 5. Decoding and MVPA: predicting from brain images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_intro.html">5.1. An introduction to decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/estimator_choice.html">5.2. Choosing the right predictive model for neuroimaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/frem.html">5.3. FREM: fast ensembling of regularized models for robust decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/space_net.html">5.4. SpaceNet: decoding with spatial structure for better maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/searchlight.html">5.5. Searchlight : finding voxels containing information</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/going_further.html">5.6. Running scikit-learn functions for more control on the analysis</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="connectivity/index.html">6. Functional connectivity and resting state</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of 6. Functional connectivity and resting state</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="connectivity/functional_connectomes.html">6.1. Extracting times series to build a functional connectome</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="connectivity/connectome_extraction.html">6.2. Connectome extraction: inverse covariance for direct connections</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of 6.2. Connectome extraction: inverse covariance for direct connections</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="developers/group_sparse_covariance.html">6.2.3.1. Group-sparse covariance estimation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/resting_state_networks.html">6.3. Extracting functional brain networks: ICA and related</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/region_extraction.html">6.4. Region Extraction for better brain parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/parcellating.html">6.5. Clustering to parcellate the brain in regions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="plotting/index.html">7. Plotting brain images</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="glm/index.html">8. Analyzing fMRI using GLMs</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of 8. Analyzing fMRI using GLMs</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="glm/glm_intro.html">8.1. An introduction to GLMs in fMRI statistical analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="glm/first_level_model.html">8.2. First level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="glm/second_level_model.html">8.3. Second level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="glm/meaning_difference.html">8.4. Difference in meanings between different toolboxes</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="manipulating_images/index.html">9. Manipulation brain volumes with nilearn</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of 9. Manipulation brain volumes with nilearn</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/input_output.html">9.1. Input and output: neuroimaging data representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/manipulating_images.html">9.2. Manipulating images: resampling, smoothing, masking, ROIs…</a></li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/masker_objects.html">9.3. From neuroimaging volumes to data matrices: the masker objects</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="building_blocks/index.html">10. Advanced usage: manual pipelines and scaling up</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of 10. Advanced usage: manual pipelines and scaling up</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manual_pipeline.html">10.1. Building your own neuroimaging machine-learning pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/neurovault.html">10.2. Downloading statistical maps from the Neurovault repository</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="modules/index.html">API References</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of API References</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="modules/connectome.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.connectome</span></code>: Functional Connectivity</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of nilearn.connectome: Functional Connectivity</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.connectome.ConnectivityMeasure.html">nilearn.connectome.ConnectivityMeasure</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.connectome.GroupSparseCovariance.html">nilearn.connectome.GroupSparseCovariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.connectome.GroupSparseCovarianceCV.html">nilearn.connectome.GroupSparseCovarianceCV</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.connectome.sym_matrix_to_vec.html">nilearn.connectome.sym_matrix_to_vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.connectome.vec_to_sym_matrix.html">nilearn.connectome.vec_to_sym_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.connectome.group_sparse_covariance.html">nilearn.connectome.group_sparse_covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.connectome.cov_to_corr.html">nilearn.connectome.cov_to_corr</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.connectome.prec_to_partial.html">nilearn.connectome.prec_to_partial</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="modules/datasets.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.datasets</span></code>: Automatic Dataset Fetching</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of nilearn.datasets: Automatic Dataset Fetching</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_icbm152_2009.html">nilearn.datasets.fetch_icbm152_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_icbm152_brain_gm_mask.html">nilearn.datasets.fetch_icbm152_brain_gm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_surf_fsaverage.html">nilearn.datasets.fetch_surf_fsaverage</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.load_fsaverage.html">nilearn.datasets.load_fsaverage</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.load_fsaverage_data.html">nilearn.datasets.load_fsaverage_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.load_mni152_brain_mask.html">nilearn.datasets.load_mni152_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.load_mni152_gm_mask.html">nilearn.datasets.load_mni152_gm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.load_mni152_gm_template.html">nilearn.datasets.load_mni152_gm_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.load_mni152_template.html">nilearn.datasets.load_mni152_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.load_mni152_wm_mask.html">nilearn.datasets.load_mni152_wm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.load_mni152_wm_template.html">nilearn.datasets.load_mni152_wm_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/icbm152_2009.html">ICBM 152 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/fsaverage.html">fsaverage template</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/fsaverage3.html">fsaverage3 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/fsaverage4.html">fsaverage4 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/fsaverage5.html">fsaverage5 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/fsaverage6.html">fsaverage6 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_aal.html">nilearn.datasets.fetch_atlas_aal</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_basc_multiscale_2015.html">nilearn.datasets.fetch_atlas_basc_multiscale_2015</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_destrieux_2009.html">nilearn.datasets.fetch_atlas_destrieux_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_harvard_oxford.html">nilearn.datasets.fetch_atlas_harvard_oxford</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_juelich.html">nilearn.datasets.fetch_atlas_juelich</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_pauli_2017.html">nilearn.datasets.fetch_atlas_pauli_2017</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_schaefer_2018.html">nilearn.datasets.fetch_atlas_schaefer_2018</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_surf_destrieux.html">nilearn.datasets.fetch_atlas_surf_destrieux</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_talairach.html">nilearn.datasets.fetch_atlas_talairach</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_yeo_2011.html">nilearn.datasets.fetch_atlas_yeo_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_coords_dosenbach_2010.html">nilearn.datasets.fetch_coords_dosenbach_2010</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_coords_power_2011.html">nilearn.datasets.fetch_coords_power_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_coords_seitzman_2018.html">nilearn.datasets.fetch_coords_seitzman_2018</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_allen_2011.html">nilearn.datasets.fetch_atlas_allen_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_craddock_2012.html">nilearn.datasets.fetch_atlas_craddock_2012</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_difumo.html">nilearn.datasets.fetch_atlas_difumo</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_harvard_oxford.html">nilearn.datasets.fetch_atlas_harvard_oxford</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_juelich.html">nilearn.datasets.fetch_atlas_juelich</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_msdl.html">nilearn.datasets.fetch_atlas_msdl</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_pauli_2017.html">nilearn.datasets.fetch_atlas_pauli_2017</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_atlas_smith_2009.html">nilearn.datasets.fetch_atlas_smith_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/craddock_2012.html">Craddock 2012 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/difumo_atlases.html">DiFuMo atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/msdl_atlas.html">MSDL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/dosenbach_2010.html">Dosenbach 2010 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/power_2011.html">Power 2011 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/seitzman_2018.html">Seitzman 2018 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/aal.html">AAL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/allen_rsn_2011.html">Allen 2011 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/basc_multiscale_2015.html">BASC multiscale atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/destrieux_surface.html">Destrieux atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/harvard_oxford.html">Harvard Oxford atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/juelich.html">Juelich atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/pauli_2017.html">Pauli 2007 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/schaefer_2018.html">Schaefer 2018 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/smith_2009.html">Smith 2009 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/talairach_atlas.html">Talairach atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/yeo_2011.html">Yeo 2011 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_abide_pcp.html">nilearn.datasets.fetch_abide_pcp</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_adhd.html">nilearn.datasets.fetch_adhd</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_bids_langloc_dataset.html">nilearn.datasets.fetch_bids_langloc_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_development_fmri.html">nilearn.datasets.fetch_development_fmri</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_ds000030_urls.html">nilearn.datasets.fetch_ds000030_urls</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_fiac_first_level.html">nilearn.datasets.fetch_fiac_first_level</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_haxby.html">nilearn.datasets.fetch_haxby</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_language_localizer_demo_dataset.html">nilearn.datasets.fetch_language_localizer_demo_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_localizer_first_level.html">nilearn.datasets.fetch_localizer_first_level</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_miyawaki2008.html">nilearn.datasets.fetch_miyawaki2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_spm_auditory.html">nilearn.datasets.fetch_spm_auditory</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_spm_multimodal_fmri.html">nilearn.datasets.fetch_spm_multimodal_fmri</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_surf_nki_enhanced.html">nilearn.datasets.fetch_surf_nki_enhanced</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.load_nki.html">nilearn.datasets.load_nki</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/ABIDE_pcp.html">ABIDE PCP dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/adhd.html">ADHD dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/bids_langloc.html">BIDS language localizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/development_fmri.html">development fMRI dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/fiac.html">fiac first level dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/haxby2001.html">Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/language_localizer_demo.html">language localizer demo dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/localizer_first_level.html">localizer first level dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/miyawaki2008.html">Miyawaki 2008 dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/spm_auditory.html">SPM auditory dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/spm_multimodal.html">SPM multimodal dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/nki_enhanced_surface.html">NKI enhanced surface dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/brainomics_localizer.html">Brainomics Localizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_localizer_button_task.html">nilearn.datasets.fetch_localizer_button_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_localizer_calculation_task.html">nilearn.datasets.fetch_localizer_calculation_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_localizer_contrasts.html">nilearn.datasets.fetch_localizer_contrasts</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_megatrawls_netmats.html">nilearn.datasets.fetch_megatrawls_netmats</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_mixed_gambles.html">nilearn.datasets.fetch_mixed_gambles</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_oasis_vbm.html">nilearn.datasets.fetch_oasis_vbm</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_neurovault_auditory_computation_task.html">nilearn.datasets.fetch_neurovault_auditory_computation_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_neurovault_motor_task.html">nilearn.datasets.fetch_neurovault_motor_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/Megatrawls.html">MegaTrawls Network Matrices HCP</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/mixed_gambles.html">Mixed gambles statistical maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/oasis1.html">OASIS volume based morphometry maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_neurovault.html">nilearn.datasets.fetch_neurovault</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_neurovault_ids.html">nilearn.datasets.fetch_neurovault_ids</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.fetch_openneuro_dataset.html">nilearn.datasets.fetch_openneuro_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.get_data_dirs.html">nilearn.datasets.get_data_dirs</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.patch_openneuro_dataset.html">nilearn.datasets.patch_openneuro_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.select_from_index.html">nilearn.datasets.select_from_index</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.datasets.load_sample_motor_activation_image.html">nilearn.datasets.load_sample_motor_activation_image</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/description/neurovault.html">Neurovault statistical maps</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="modules/decoding.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decoding</span></code>: Decoding</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of nilearn.decoding: Decoding</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.decoding.Decoder.html">nilearn.decoding.Decoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.decoding.DecoderRegressor.html">nilearn.decoding.DecoderRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.decoding.FREMClassifier.html">nilearn.decoding.FREMClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.decoding.FREMRegressor.html">nilearn.decoding.FREMRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.decoding.SpaceNetClassifier.html">nilearn.decoding.SpaceNetClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.decoding.SpaceNetRegressor.html">nilearn.decoding.SpaceNetRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.decoding.SearchLight.html">nilearn.decoding.SearchLight</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="modules/decomposition.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decomposition</span></code>: Multivariate Decompositions</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of nilearn.decomposition: Multivariate Decompositions</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.decomposition.CanICA.html">nilearn.decomposition.CanICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.decomposition.DictLearning.html">nilearn.decomposition.DictLearning</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="modules/glm.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.glm</span></code>: Generalized Linear Models</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of nilearn.glm: Generalized Linear Models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.Contrast.html">nilearn.glm.Contrast</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.FContrastResults.html">nilearn.glm.FContrastResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.TContrastResults.html">nilearn.glm.TContrastResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.ARModel.html">nilearn.glm.ARModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.OLSModel.html">nilearn.glm.OLSModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.LikelihoodModelResults.html">nilearn.glm.LikelihoodModelResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.RegressionResults.html">nilearn.glm.RegressionResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.SimpleRegressionResults.html">nilearn.glm.SimpleRegressionResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.compute_contrast.html">nilearn.glm.compute_contrast</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.compute_fixed_effects.html">nilearn.glm.compute_fixed_effects</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.expression_to_contrast_vector.html">nilearn.glm.expression_to_contrast_vector</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.fdr_threshold.html">nilearn.glm.fdr_threshold</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.cluster_level_inference.html">nilearn.glm.cluster_level_inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.threshold_stats_img.html">nilearn.glm.threshold_stats_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.first_level.FirstLevelModel.html">nilearn.glm.first_level.FirstLevelModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.first_level.check_design_matrix.html">nilearn.glm.first_level.check_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.first_level.compute_regressor.html">nilearn.glm.first_level.compute_regressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.first_level.first_level_from_bids.html">nilearn.glm.first_level.first_level_from_bids</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.first_level.glover_dispersion_derivative.html">nilearn.glm.first_level.glover_dispersion_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.first_level.glover_hrf.html">nilearn.glm.first_level.glover_hrf</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.first_level.glover_time_derivative.html">nilearn.glm.first_level.glover_time_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.first_level.make_first_level_design_matrix.html">nilearn.glm.first_level.make_first_level_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.first_level.mean_scaling.html">nilearn.glm.first_level.mean_scaling</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.first_level.run_glm.html">nilearn.glm.first_level.run_glm</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.first_level.spm_dispersion_derivative.html">nilearn.glm.first_level.spm_dispersion_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.first_level.spm_hrf.html">nilearn.glm.first_level.spm_hrf</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.first_level.spm_time_derivative.html">nilearn.glm.first_level.spm_time_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.second_level.SecondLevelModel.html">nilearn.glm.second_level.SecondLevelModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.second_level.make_second_level_design_matrix.html">nilearn.glm.second_level.make_second_level_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.glm.second_level.non_parametric_inference.html">nilearn.glm.second_level.non_parametric_inference</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="modules/image.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.image</span></code>: Image Processing and Resampling Utilities</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle navigation of nilearn.image: Image Processing and Resampling Utilities</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.binarize_img.html">nilearn.image.binarize_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.clean_img.html">nilearn.image.clean_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.concat_imgs.html">nilearn.image.concat_imgs</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.coord_transform.html">nilearn.image.coord_transform</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.copy_img.html">nilearn.image.copy_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.crop_img.html">nilearn.image.crop_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.get_data.html">nilearn.image.get_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.high_variance_confounds.html">nilearn.image.high_variance_confounds</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.index_img.html">nilearn.image.index_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.iter_img.html">nilearn.image.iter_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.largest_connected_component_img.html">nilearn.image.largest_connected_component_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.load_img.html">nilearn.image.load_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.math_img.html">nilearn.image.math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.mean_img.html">nilearn.image.mean_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.new_img_like.html">nilearn.image.new_img_like</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.resample_img.html">nilearn.image.resample_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.resample_to_img.html">nilearn.image.resample_to_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.reorder_img.html">nilearn.image.reorder_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.smooth_img.html">nilearn.image.smooth_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.swap_img_hemispheres.html">nilearn.image.swap_img_hemispheres</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.image.threshold_img.html">nilearn.image.threshold_img</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="modules/interfaces.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.interfaces</span></code>: Loading components from interfaces</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle navigation of nilearn.interfaces: Loading components from interfaces</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.interfaces.bids.get_bids_files.html">nilearn.interfaces.bids.get_bids_files</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.interfaces.bids.parse_bids_filename.html">nilearn.interfaces.bids.parse_bids_filename</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.interfaces.bids.save_glm_to_bids.html">nilearn.interfaces.bids.save_glm_to_bids</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.interfaces.fmriprep.load_confounds.html">nilearn.interfaces.fmriprep.load_confounds</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.interfaces.fmriprep.load_confounds_strategy.html">nilearn.interfaces.fmriprep.load_confounds_strategy</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.interfaces.fsl.get_design_from_fslmat.html">nilearn.interfaces.fsl.get_design_from_fslmat</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="modules/maskers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.maskers</span></code>: Extracting Signals from Brain Images</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle navigation of nilearn.maskers: Extracting Signals from Brain Images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.maskers.BaseMasker.html">nilearn.maskers.BaseMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.maskers.NiftiMasker.html">nilearn.maskers.NiftiMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.maskers.MultiNiftiMasker.html">nilearn.maskers.MultiNiftiMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.maskers.NiftiLabelsMasker.html">nilearn.maskers.NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.maskers.MultiNiftiLabelsMasker.html">nilearn.maskers.MultiNiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.maskers.NiftiMapsMasker.html">nilearn.maskers.NiftiMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.maskers.MultiNiftiMapsMasker.html">nilearn.maskers.MultiNiftiMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.maskers.NiftiSpheresMasker.html">nilearn.maskers.NiftiSpheresMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.maskers.SurfaceLabelsMasker.html">nilearn.maskers.SurfaceLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.maskers.SurfaceMasker.html">nilearn.maskers.SurfaceMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.maskers.SurfaceMapsMasker.html">nilearn.maskers.SurfaceMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated_reports/masker_reports_examples.html">Examples masker reports</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="modules/masking.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.masking</span></code>: Data Masking Utilities</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><div class="visually-hidden">Toggle navigation of nilearn.masking: Data Masking Utilities</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.masking.compute_epi_mask.html">nilearn.masking.compute_epi_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.masking.compute_multi_epi_mask.html">nilearn.masking.compute_multi_epi_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.masking.compute_brain_mask.html">nilearn.masking.compute_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.masking.compute_multi_brain_mask.html">nilearn.masking.compute_multi_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.masking.compute_background_mask.html">nilearn.masking.compute_background_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.masking.compute_multi_background_mask.html">nilearn.masking.compute_multi_background_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.masking.intersect_masks.html">nilearn.masking.intersect_masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.masking.apply_mask.html">nilearn.masking.apply_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.masking.unmask.html">nilearn.masking.unmask</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="modules/mass_univariate.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.mass_univariate</span></code>: Mass-Univariate Analysis</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><div class="visually-hidden">Toggle navigation of nilearn.mass_univariate: Mass-Univariate Analysis</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.mass_univariate.permuted_ols.html">nilearn.mass_univariate.permuted_ols</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="modules/plotting.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.plotting</span></code>: Plotting Brain Data</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><div class="visually-hidden">Toggle navigation of nilearn.plotting: Plotting Brain Data</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.find_cut_slices.html">nilearn.plotting.find_cut_slices</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.find_xyz_cut_coords.html">nilearn.plotting.find_xyz_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.find_parcellation_cut_coords.html">nilearn.plotting.find_parcellation_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.find_probabilistic_atlas_cut_coords.html">nilearn.plotting.find_probabilistic_atlas_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_anat.html">nilearn.plotting.plot_anat</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_carpet.html">nilearn.plotting.plot_carpet</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_connectome.html">nilearn.plotting.plot_connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_contrast_matrix.html">nilearn.plotting.plot_contrast_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_design_matrix.html">nilearn.plotting.plot_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_design_matrix_correlation.html">nilearn.plotting.plot_design_matrix_correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_epi.html">nilearn.plotting.plot_epi</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_event.html">nilearn.plotting.plot_event</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_glass_brain.html">nilearn.plotting.plot_glass_brain</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_img.html">nilearn.plotting.plot_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_img_on_surf.html">nilearn.plotting.plot_img_on_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_markers.html">nilearn.plotting.plot_markers</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_matrix.html">nilearn.plotting.plot_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_prob_atlas.html">nilearn.plotting.plot_prob_atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_roi.html">nilearn.plotting.plot_roi</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_stat_map.html">nilearn.plotting.plot_stat_map</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_surf.html">nilearn.plotting.plot_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_surf_contours.html">nilearn.plotting.plot_surf_contours</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_surf_roi.html">nilearn.plotting.plot_surf_roi</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.plot_surf_stat_map.html">nilearn.plotting.plot_surf_stat_map</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.show.html">nilearn.plotting.show</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.view_surf.html">nilearn.plotting.view_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.view_img_on_surf.html">nilearn.plotting.view_img_on_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.view_connectome.html">nilearn.plotting.view_connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.view_markers.html">nilearn.plotting.view_markers</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.view_img.html">nilearn.plotting.view_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.img_comparison.plot_bland_altman.html">nilearn.plotting.img_comparison.plot_bland_altman</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.img_comparison.plot_img_comparison.html">nilearn.plotting.img_comparison.plot_img_comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.PlotlySurfaceFigure.html">nilearn.plotting.displays.PlotlySurfaceFigure</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.BaseAxes.html">nilearn.plotting.displays.BaseAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.CutAxes.html">nilearn.plotting.displays.CutAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.GlassBrainAxes.html">nilearn.plotting.displays.GlassBrainAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.OrthoProjector.html">nilearn.plotting.displays.OrthoProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.LZRYProjector.html">nilearn.plotting.displays.LZRYProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.LYRZProjector.html">nilearn.plotting.displays.LYRZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.LYRProjector.html">nilearn.plotting.displays.LYRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.LZRProjector.html">nilearn.plotting.displays.LZRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.LRProjector.html">nilearn.plotting.displays.LRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.LProjector.html">nilearn.plotting.displays.LProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.RProjector.html">nilearn.plotting.displays.RProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.XZProjector.html">nilearn.plotting.displays.XZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.YZProjector.html">nilearn.plotting.displays.YZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.YXProjector.html">nilearn.plotting.displays.YXProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.XProjector.html">nilearn.plotting.displays.XProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.YProjector.html">nilearn.plotting.displays.YProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.ZProjector.html">nilearn.plotting.displays.ZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.BaseSlicer.html">nilearn.plotting.displays.BaseSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.OrthoSlicer.html">nilearn.plotting.displays.OrthoSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.MosaicSlicer.html">nilearn.plotting.displays.MosaicSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.TiledSlicer.html">nilearn.plotting.displays.TiledSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.XSlicer.html">nilearn.plotting.displays.XSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.XZSlicer.html">nilearn.plotting.displays.XZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.YXSlicer.html">nilearn.plotting.displays.YXSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.YZSlicer.html">nilearn.plotting.displays.YZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.YSlicer.html">nilearn.plotting.displays.YSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.ZSlicer.html">nilearn.plotting.displays.ZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.get_projector.html">nilearn.plotting.displays.get_projector</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.plotting.displays.get_slicer.html">nilearn.plotting.displays.get_slicer</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="modules/regions.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.regions</span></code>: Operating on Regions</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><div class="visually-hidden">Toggle navigation of nilearn.regions: Operating on Regions</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.regions.RegionExtractor.html">nilearn.regions.RegionExtractor</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.regions.Parcellations.html">nilearn.regions.Parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.regions.ReNA.html">nilearn.regions.ReNA</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.regions.HierarchicalKMeans.html">nilearn.regions.HierarchicalKMeans</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.regions.connected_regions.html">nilearn.regions.connected_regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.regions.connected_label_regions.html">nilearn.regions.connected_label_regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.regions.img_to_signals_labels.html">nilearn.regions.img_to_signals_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.regions.signals_to_img_labels.html">nilearn.regions.signals_to_img_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.regions.img_to_signals_maps.html">nilearn.regions.img_to_signals_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.regions.signals_to_img_maps.html">nilearn.regions.signals_to_img_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.regions.recursive_neighbor_agglomeration.html">nilearn.regions.recursive_neighbor_agglomeration</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="modules/reporting.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.reporting</span></code>: Reporting Functions</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" role="switch" type="checkbox"/><label for="toctree-checkbox-30"><div class="visually-hidden">Toggle navigation of nilearn.reporting: Reporting Functions</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.reporting.HTMLReport.html">nilearn.reporting.HTMLReport</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.reporting.get_clusters_table.html">nilearn.reporting.get_clusters_table</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.reporting.make_glm_report.html">nilearn.reporting.make_glm_report</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated_reports/glm_reports_examples.html">Examples of GLM reports</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="modules/signal.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.signal</span></code>: Preprocessing Time Series</a><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" role="switch" type="checkbox"/><label for="toctree-checkbox-31"><div class="visually-hidden">Toggle navigation of nilearn.signal: Preprocessing Time Series</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.signal.butterworth.html">nilearn.signal.butterworth</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.signal.clean.html">nilearn.signal.clean</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.signal.high_variance_confounds.html">nilearn.signal.high_variance_confounds</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="modules/surface.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.surface</span></code>: Manipulating Surface Data</a><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" role="switch" type="checkbox"/><label for="toctree-checkbox-32"><div class="visually-hidden">Toggle navigation of nilearn.surface: Manipulating Surface Data</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.surface.FileMesh.html">nilearn.surface.FileMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.surface.InMemoryMesh.html">nilearn.surface.InMemoryMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.surface.PolyData.html">nilearn.surface.PolyData</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.surface.PolyMesh.html">nilearn.surface.PolyMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.surface.SurfaceImage.html">nilearn.surface.SurfaceImage</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.surface.SurfaceMesh.html">nilearn.surface.SurfaceMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.surface.load_surf_data.html">nilearn.surface.load_surf_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.surface.load_surf_mesh.html">nilearn.surface.load_surf_mesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/generated/nilearn.surface.vol_to_surf.html">nilearn.surface.vol_to_surf</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="development.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="ci.html">Continuous integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="maintenance.html">Maintenance</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html">What’s new</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">Team</a></li>
<li class="toctree-l1"><a class="reference internal" href="versions.html">Versions</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nilearn/nilearn">GitHub Repository</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="https://github.com/nilearn/nilearn/blob/main/doc/bibliography.rst?plain=true" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>

<div class="edit-this-page">
  <a class="muted-link"
     href="https://github.com/nilearn/nilearn/edit/main/doc/bibliography.rst"
     title="Edit this page"
     target="_blank">
    <svg aria-hidden="true" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
         fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <path d="M4 20h4l10.5 -10.5a1.5 1.5 0 0 0 -4 -4l-10.5 10.5v4" />
      <line x1="13.5" y1="6.5" x2="17.5" y2="10.5" />
    </svg>
    <span class="visually-hidden">Edit this page</span>
  </a>
</div><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="general-bibliography">
<span id="id1"></span><h1>General bibliography<a class="headerlink" href="#general-bibliography" title="Link to this heading">¶</a></h1>
<p>The references below are arranged alphabetically by first author.
You can download the bib file <a class="reference download internal" download="" href="_downloads/33e59b5ca9ec342068223d604c3f8d55/references.bib"><code class="xref download docutils literal notranslate"><span class="pre">here</span></code></a>.</p>
<div class="docutils container" id="id2">
<ol class="arabic simple" start="1">
<li id="id3"><p>Hunar Abdulrahman and Richard N Henson. Effect of trial-to-trial variability on optimal event-related fmri design: implications for beta-series correlation and multi-voxel pattern analysis. <em>NeuroImage</em>, 125:756–766, 2016.</p></li>
<li id="id4"><p>Alexandre Abraham, Elvis Dohmatob, Bertrand Thirion, Dimitris Samaras, and Gael Varoquaux. Region segmentation for sparse decompositions: better brain parcellations from rest fMRI. Sparsity Techniques in Medical Imaging, September 2014. URL: <a class="reference external" href="https://inria.hal.science/hal-01093944">https://inria.hal.science/hal-01093944</a>.</p></li>
<li id="id6"><p>Elena Allen, Erik Erhardt, Eswar Damaraju, William Gruner, Judith Segall, Rogers Silva, Martin Havlicek, Srinivas Rachakonda, Jill Fries, Ravi Kalyanam, Andrew Michael, Arvind Caprihan, Jessica Turner, Tom Eichele, Steven Adelsheim, Angela Bryan, Juan Bustillo, Vincent Clark, Sarah Feldstein Ewing, Francesca Filbey, Corey Ford, Kent Hutchison, Rex Jung, Kent Kiehl, Piyadasa Kodituwakku, Yuko Komesu, Andrew Mayer, Godfrey Pearlson, John Phillips, Joseph Sadek, Michael Stevens, Ursina Teuscher, Robert Thoma, and Vince Calhoun. A baseline for the multivariate comparison of resting-state networks. <em>Frontiers in Systems Neuroscience</em>, 5:2, 2011. <a class="reference external" href="https://doi.org/10.3389/fnsys.2011.00002">doi:10.3389/fnsys.2011.00002</a>.</p></li>
<li id="id7"><p>Elena A Allen, Erik B Erhardt, and Vince D Calhoun. Data visualization in the neurosciences: overcoming the curse of dimensionality. <em>Neuron</em>, 2011. <a class="reference external" href="https://doi.org/10.1016/j.neuron.2012.05.001">doi:10.1016/j.neuron.2012.05.001</a>.</p></li>
<li id="id8"><p>Katrin Amunts, Hartmut Mohlberg, Sebastian Bludau, and Karl Zilles. Julich-Brain: A 3D probabilistic atlas of the human brain’s cytoarchitecture. <em>Science</em>, 369(6506):988–992, August 2020. <a class="reference external" href="https://doi.org/10.1126/science.abb4588">doi:10.1126/science.abb4588</a>.</p></li>
<li id="id9"><p>Marti J. Anderson and John Robinson. Permutation tests for linear models. <em>Australian &amp; New Zealand Journal of Statistics</em>, 43(1):75–88, 2001. <a class="reference external" href="https://doi.org/10.1111/1467-842X.00156">doi:10.1111/1467-842X.00156</a>.</p></li>
<li id="id5"><p>Luca Baldassarre, Janaina Mourao-Miranda, and Massimiliano Pontil. The civet image-processing environment: a fully automated comprehensive pipeline for anatomical neuroimaging research. In <em>Proceedings of the 12th Annual Meeting of the Human Brain Mapping Organization</em>. 2006.</p></li>
<li id="id10"><p>Luca Baldassarre, Janaina Mourao-Miranda, and Massimiliano Pontil. Structured sparsity models for brain decoding from fmri data. In <em>2012 Second International Workshop on Pattern Recognition in NeuroImaging</em>, volume, 5–8. 2012. <a class="reference external" href="https://doi.org/10.1109/PRNI.2012.31">doi:10.1109/PRNI.2012.31</a>.</p></li>
<li id="id11"><p>Yashar Behzadi, Khaled Restom, Joy Liau, and Thomas T. Liu. A component based noise correction method (compcor) for bold and perfusion based fmri. <em>NeuroImage</em>, 37(1):90–101, 2007. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2007.04.042">doi:10.1016/j.neuroimage.2007.04.042</a>.</p></li>
<li id="id12"><p>Pierre Bellec. Mining the hierarchy of resting-state brain networks: selection of representative clusters in a multiscale structure. In <em>2013 International Workshop on Pattern Recognition in Neuroimaging</em>, volume, 54–57. 06 2013. <a class="reference external" href="https://doi.org/10.1109/PRNI.2013.23">doi:10.1109/PRNI.2013.23</a>.</p></li>
<li id="id13"><p>Pierre Bellec, Pedro Rosa-Neto, Oliver C. Lyttelton, Habib Benali, and Alan C. Evans. Multi-level bootstrap analysis of stable clusters in resting-state fmri. <em>NeuroImage</em>, 51(3):1126–1139, 2010. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2010.02.082">doi:10.1016/j.neuroimage.2010.02.082</a>.</p></li>
<li id="id14"><p>Alexander Bowring, Camille Maumet, and Thomas E Nichols. Exploring the impact of analysis software on task fmri results. <em>Human brain mapping</em>, 40(11):3362–3384, 2019.</p></li>
<li id="id15"><p>G. Chen, P. A. Taylor, J. Stoddard, R. W. Cox, P. A. Bandettini, and L. Pessoa. Sources of information waste in neuroimaging: mishandling structures, thinking dichotomously, and over-reducing data. <em>Aperture Neuro</em>, 2022. <a class="reference external" href="https://doi.org/10.52294/ApertureNeuro.2022.2.ZRJI8542">doi:10.52294/ApertureNeuro.2022.2.ZRJI8542</a>.</p></li>
<li id="id16"><p>Yi Chen, Praneeth Namburi, Lloyd T. Elliott, Jakob Heinzle, Chun Siong Soon, Michael W.L. Chee, and John-Dylan Haynes. Cortical surface-based searchlight decoding. <em>NeuroImage</em>, 56(2):582–592, 2011. Multivariate Decoding and Brain Reading. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2010.07.035">doi:10.1016/j.neuroimage.2010.07.035</a>.</p></li>
<li id="id17"><p>Rastko Ciric, Daniel H. Wolf, Jonathan D. Power, David R. Roalf, Graham L. Baum, Kosha Ruparel, Russell T. Shinohara, Mark A. Elliott, Simon B. Eickhoff, Christos Davatzikos, Ruben C. Gur, Raquel E. Gur, Danielle S. Bassett, and Theodore D. Satterthwaite. Benchmarking of participant-level confound regression strategies for the control of motion artifact in studies of functional connectivity. <em>NeuroImage</em>, 154(1):174–187, 2017. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2017.03.020">doi:10.1016/j.neuroimage.2017.03.020</a>.</p></li>
<li id="id18"><p>Josh M Cisler, Keith Bush, and J Scott Steele. A comparison of statistical methods for detecting context-modulated functional connectivity in fmri. <em>Neuroimage</em>, 84:1042–1052, 2014.</p></li>
<li id="id19"><p>Alex Clarke and Lorraine K. Tyler. Object-specific semantic coding in human perirhinal cortex. <em>Journal of Neuroscience</em>, 34(14):4766–4775, 2014. <a class="reference external" href="https://doi.org/10.1523/JNEUROSCI.2828-13.2014">doi:10.1523/JNEUROSCI.2828-13.2014</a>.</p></li>
<li id="id20"><p>D. Louis Collins and Alan C. Evans. Animal: validation and applications of nonlinear registration-based segmentation. <em>International journal of pattern recognition and artificial intelligence</em>, 11(08):1271–1294, 1997.</p></li>
<li id="id22"><p>D. Louis Collins, Alex P. Zijdenbos, Wim F. C. Baaré, and Alan C. Evans. Animal+insect: improved cortical structure segmentation. In Attila Kuba, Martin Šáamal, and Andrew Todd-Pokropek, editors, <em>Information Processing in Medical Imaging</em>, 210–223. Berlin, Heidelberg, 1999. Springer Berlin Heidelberg.</p></li>
<li id="id21"><p>D.L. Collins, A.P. Zijdenbos, V. Kollokian, J.G. Sled, N.J. Kabani, C.J. Holmes, and A.C. Evans. Design and construction of a realistic digital brain phantom. <em>IEEE Transactions on Medical Imaging</em>, 17(3):463–468, 1998. <a class="reference external" href="https://doi.org/10.1109/42.712135">doi:10.1109/42.712135</a>.</p></li>
<li id="id23"><p>R. Cameron Craddock, G.Andrew James, Paul E. Holtzheimer III, Xiaoping P. Hu, and Helen S. Mayberg. A whole brain fmri atlas generated via spatially constrained spectral clustering. <em>Human Brain Mapping</em>, 33(8):1914–1928, 2012. <a class="reference external" href="https://doi.org/10.1002/hbm.21333">doi:10.1002/hbm.21333</a>.</p></li>
<li id="id24"><p>Kamalaker Dadi, Mehdi Rahim, Alexandre Abraham, Darya Chyzhyk, Michael Milham, Bertrand Thirion, and Gaël Varoquaux. Benchmarking functional connectome-based predictive models for resting-state fmri. <em>NeuroImage</em>, 192:115–134, 2019. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2019.02.062">doi:10.1016/j.neuroimage.2019.02.062</a>.</p></li>
<li id="id25"><p>Kamalaker Dadi, Gaël Varoquaux, Antonia Machlouzarides-Shalit, Krzysztof J. Gorgolewski, Demian Wassermann, Bertrand Thirion, and Arthur Mensch. Fine-grain atlases of functional modes for fmri analysis. <em>NeuroImage</em>, 221:117126, 2020. URL: <a class="reference external" href="https://inria.hal.science/hal-02904869">https://inria.hal.science/hal-02904869</a>, <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2020.117126">doi:10.1016/j.neuroimage.2020.117126</a>.</p></li>
<li id="id26"><p>Anders M. Dale, Bruce Fischl, and Martin I. Sereno. Cortical surface-based analysis: i. segmentation and surface reconstruction. <em>NeuroImage</em>, 9(2):179–194, 1999. <a class="reference external" href="https://doi.org/10.1006/nimg.1998.0395">doi:10.1006/nimg.1998.0395</a>.</p></li>
<li id="id27"><p>Russell Davidson and James G. MacKinnon. <em>Econometric theory and methods</em>. Oxford Univ. Press, New York, NY [u.a.], 2004. ISBN 978-0-19-512372-2.</p></li>
<li id="id28"><p>Ghislaine Dehaene-Lambertz, Stanislas Dehaene, Jean-Luc Anton, Aurelie Campagne, Philippe Ciuciu, Guillaume P Dehaene, Isabelle Denghien, Antoinette Jobert, Denis LeBihan, Mariano Sigman, and others. Functional segregation of cortical language areas by sentence repetition. <em>Human brain mapping</em>, 27(5):360–371, 2006. URL: <a class="reference external" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC6871319/">https://pmc.ncbi.nlm.nih.gov/articles/PMC6871319/</a>.</p></li>
<li id="id29"><p>Rahul S Desikan, Florent Ségonne, Bruce Fischl, Brian T Quinn, Bradford C Dickerson, Deborah Blacker, Randy L Buckner, Anders M Dale, R Paul Maguire, Bradley T Hyman, and others. An automated labeling system for subdividing the human cerebral cortex on mri scans into gyral based regions of interest. <em>Neuroimage</em>, 31(3):968–980, 2006.</p></li>
<li id="id31"><p>C Destrieux, B Fischl, AM Dale, and E Halgren. A sulcal depth-based anatomical parcellation of the cerebral cortex. <em>NeuroImage</em>, 47(Supplement 1):S151, 2009. <a class="reference external" href="https://doi.org/10.1016/S1053-8119(09)71561-7">doi:10.1016/S1053-8119(09)71561-7</a>.</p></li>
<li id="id30"><p>Christophe Destrieux, Bruce Fischl, Anders Dale, and Eric Halgren. Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature. <em>NeuroImage</em>, 53(1):1–15, 2010. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2010.06.010">doi:10.1016/j.neuroimage.2010.06.010</a>.</p></li>
<li id="id32"><p>Elvis Dohmatob, Michael Eickenberg, Bertrand Thirion, and Gaël Varoquaux. Speeding-up model-selection in GraphNet via early-stopping and univariate feature-screening. In <em>PRNI</em>. Stanford, United States, June 2015. URL: <a class="reference external" href="https://inria.hal.science/hal-01147731">https://inria.hal.science/hal-01147731</a>.</p></li>
<li id="id33"><p>Elvis Dohmatob, Alexandre Gramfort, Bertrand Thirion, and Gaël Varoquaux. Benchmarking solvers for TV-l1 least-squares and logistic regression in brain imaging. In <em>PRNI 2014 - 4th International Workshop on Pattern Recognition in NeuroImaging</em>. Tübingen, Germany, June 2014. IEEE. URL: <a class="reference external" href="https://inria.hal.science/hal-00991743">https://inria.hal.science/hal-00991743</a>.</p></li>
<li id="id34"><p>Nico U. F. Dosenbach, Binyam Nardos, Alexander L. Cohen, Damien A. Fair, Jonathan D. Power, Jessica A. Church, Steven M. Nelson, Gagan S. Wig, Alecia C. Vogel, Christina N. Lessov-Schlaggar, Kelly Anne Barnes, Joseph W. Dubis, Eric Feczko, Rebecca S. Coalson, John R. Pruett, Deanna M. Barch, Steven E. Petersen, and Bradley L. Schlaggar. Prediction of individual brain maturity using fmri. <em>Science</em>, 329(5997):1358–1361, 2010. <a class="reference external" href="https://doi.org/10.1126/science.1194144">doi:10.1126/science.1194144</a>.</p></li>
<li id="id35"><p>John Duchi, Stephen Gould, and Daphne Koller. Projected subgradient methods for learning sparse gaussians. <em>arXiv</em>, 06 2012. <a class="reference external" href="https://arxiv.org/abs/1206.3249">arXiv:1206.3249</a>.</p></li>
<li id="id36"><p>Joset A. Etzel, Jeffrey M. Zacks, and Todd S. Braver. Searchlight analysis: promise, pitfalls, and potential. <em>NeuroImage</em>, 78:261–269, 2013. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2013.03.041">doi:10.1016/j.neuroimage.2013.03.041</a>.</p></li>
<li id="id37"><p>Nicola Filippini, Bradley J. MacIntosh, Morgan G. Hough, Guy M. Goodwin, Giovanni B. Frisoni, Stephen M. Smith, Paul M. Matthews, Christian F. Beckmann, and Clare E. Mackay. Distinct patterns of brain activity in young carriers of the apoe-ε4 allele. <em>Proceedings of the National Academy of Sciences</em>, 106(17):7209–7214, 2009. <a class="reference external" href="https://doi.org/10.1073/pnas.0811879106">doi:10.1073/pnas.0811879106</a>.</p></li>
<li id="id40"><p>Bruce Fischl, Martin I. Sereno, and Anders M. Dale. Cortical surface-based analysis: ii: inflation, flattening, and a surface-based coordinate system. <em>NeuroImage</em>, 9(2):195–207, 1999. <a class="reference external" href="https://doi.org/10.1006/nimg.1998.0396">doi:10.1006/nimg.1998.0396</a>.</p></li>
<li id="id39"><p>Bruce Fischl, Martin I. Sereno, Roger B.H. Tootell, and Anders M. Dale. High-resolution intersubject averaging and a coordinate system for the cortical surface. <em>Human Brain Mapping</em>, 8(4):272–284, 1999. <a class="reference external" href="https://doi.org/10.1002/(SICI)1097-0193(1999)8:4&lt;272::AID-HBM10&gt;3.0.CO;2-4">doi:10.1002/(SICI)1097-0193(1999)8:4&lt;272::AID-HBM10&gt;3.0.CO;2-4</a>.</p></li>
<li id="id38"><p>Bruce Fischl, André van der Kouwe, Christophe Destrieux, Eric Halgren, Florent Ségonne, David H. Salat, Evelina Busa, Larry J. Seidman, Jill Goldstein, David Kennedy, Verne Caviness, Nikos Makris, Bruce Rosen, and Anders M. Dale. Automatically Parcellating the Human Cerebral Cortex. <em>Cerebral Cortex</em>, 14(1):11–22, 01 2004. <a class="reference external" href="https://doi.org/10.1093/cercor/bhg087">doi:10.1093/cercor/bhg087</a>.</p></li>
<li id="id41"><p>R.A. Fisher. <em>The design of experiments. 1935</em>. Oliver and Boyd, Edinburgh, 1935.</p></li>
<li id="id42"><p>P. Thomas Fletcher and Sarang Joshi. Riemannian geometry for the statistical analysis of diffusion tensor data. <em>Signal Processing</em>, 87(2):250–262, 2007. Tensor Signal Processing. <a class="reference external" href="https://doi.org/10.1016/j.sigpro.2005.12.018">doi:10.1016/j.sigpro.2005.12.018</a>.</p></li>
<li id="id43"><p>Vladimir Fonov, Alan C. Evans, Kelly Botteron, C. Robert Almli, Robert C. McKinstry, and D. Louis Collins. Unbiased average age-appropriate atlases for pediatric studies. <em>NeuroImage</em>, 54(1):313–327, 2011. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2010.07.033">doi:10.1016/j.neuroimage.2010.07.033</a>.</p></li>
<li id="id44"><p>VS Fonov, AC Evans, RC McKinstry, CR Almli, and DL Collins. Unbiased nonlinear average age-appropriate brain templates from birth to adulthood. <em>NeuroImage</em>, 47(Supplement 1):S102, 2009. <a class="reference external" href="https://doi.org/10.1016/S1053-8119(09)70884-5">doi:10.1016/S1053-8119(09)70884-5</a>.</p></li>
<li id="id45"><p>Michael D. Fox, Abraham Z. Snyder, Justin L Vincent, Maurizio Corbetta, David C. Van Essen, and Marcus E. Raichle. The human brain is intrinsically organized into dynamic, anticorrelated functional networks. <em>Proceedings of the National Academy of Sciences</em>, 102(27):9673–9678, July 2005. <a class="reference external" href="https://doi.org/10.1073/pnas.0504136102">doi:10.1073/pnas.0504136102</a>.</p></li>
<li id="id46"><p>Jean A Frazier, Sufen Chiu, Janis L Breeze, Nikos Makris, Nicholas Lange, David N Kennedy, Martha R Herbert, Eileen K Bent, Vamsi K Koneru, Megan E Dieterich, and others. Structural brain magnetic resonance imaging of limbic and thalamic volumes in pediatric bipolar disorder. <em>American Journal of Psychiatry</em>, 162(7):1256–1265, 2005.</p></li>
<li id="id47"><p>David Freedman and David Lane. A nonstochastic interpretation of reported significance levels. <em>Journal of Business &amp; Economic Statistics</em>, 1(4):292–298, 1983. <a class="reference external" href="https://doi.org/10.1080/07350015.1983.10509354">doi:10.1080/07350015.1983.10509354</a>.</p></li>
<li id="id48"><p>J. Friedman, T. Hastie, and R. Tibshirani. Sparse inverse covariance estimation with the graphical lasso. <em>Biostatistics</em>, 9(3):432–441, July 2008. <a class="reference external" href="https://doi.org/10.1093/biostatistics/kxm045">doi:10.1093/biostatistics/kxm045</a>.</p></li>
<li id="id49"><p>K. J. Friston, A. P. Holmes, K. J. Worsley, J.-P. Poline, C. D. Frith, and R. S. J. Frackowiak. Statistical parametric maps in functional imaging: a general linear approach. <em>Human Brain Mapping</em>, 2(4):189–210, 1994. <a class="reference external" href="https://doi.org/10.1002/hbm.460020402">doi:10.1002/hbm.460020402</a>.</p></li>
<li id="id50"><p>Federico Giove, Tommaso Gili, Vittorio Iacovella, Emiliano Macaluso, and Bruno Maraviglia. Images-based suppression of unwanted global signals in resting-state functional connectivity studies. <em>Magnetic Resonance Imaging</em>, 27(8):1058–1064, October 2009. <a class="reference external" href="https://doi.org/10.1016/j.mri.2009.06.004">doi:10.1016/j.mri.2009.06.004</a>.</p></li>
<li id="id51"><p>Jill M Goldstein, Larry J Seidman, Nikos Makris, Todd Ahern, Liam M O’Brien, Verne S Caviness Jr, David N Kennedy, Stephen V Faraone, and Ming T Tsuang. Hypothalamic abnormalities in schizophrenia: sex effects and genetic vulnerability. <em>Biological psychiatry</em>, 61(8):935–945, 2007.</p></li>
<li id="id52"><p>Krzysztof J. Gorgolewski, Gael Varoquaux, Gabriel Rivera, Yannick Schwarz, Satrajit S. Ghosh, Camille Maumet, Vanessa V. Sochat, Thomas E. Nichols, Russell A. Poldrack, Jean-Baptiste Poline, Tal Yarkoni, and Daniel S. Margulies. Neurovault.org: a web-based repository for collecting and sharing unthresholded statistical maps of the human brain. <em>Frontiers in Neuroinformatics</em>, 9:8, 2015. <a class="reference external" href="https://doi.org/10.3389/fninf.2015.00008">doi:10.3389/fninf.2015.00008</a>.</p></li>
<li id="id53"><p>Alexandre Gramfort, Bertrand Thirion, and Gaël Varoquaux. Identifying predictive regions from fMRI with TV-L1 prior. In <em>Pattern Recognition in Neuroimaging (PRNI)</em>. Philadelphia, United States, June 2013. IEEE. URL: <a class="reference external" href="https://inria.hal.science/hal-00839984">https://inria.hal.science/hal-00839984</a>.</p></li>
<li id="id54"><p>William H. Greene. <em>Econometric Analysis</em>. Pearson Education, fifth edition, 2003. ISBN 0-13-066189-9. URL: <a class="reference external" href="https://pages.stern.nyu.edu/~wgreene/Text/econometricanalysis.htm">https://pages.stern.nyu.edu/~wgreene/Text/econometricanalysis.htm</a>.</p></li>
<li id="id55"><p>Logan Grosenick, Brad Klingenberg, Kiefer Katovich, Brian Knutson, and Jonathan E. Taylor. Interpretable whole-brain prediction analysis with graphnet. <em>NeuroImage</em>, 72:304–321, 2013. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2012.12.062">doi:10.1016/j.neuroimage.2012.12.062</a>.</p></li>
<li id="id56"><p>James V. Haxby, M. Ida Gobbini, Maura L. Furey, Alumit Ishai, Jennifer L. Schouten, and Pietro Pietrini. Distributed and overlapping representations of faces and objects in ventral temporal cortex. <em>Science</em>, 293(5539):2425–2430, 2001. <a class="reference external" href="https://doi.org/10.1126/science.1063736">doi:10.1126/science.1063736</a>.</p></li>
<li id="id57"><p>R.N. Henson, Y. Goshen-Gottstein, T. Ganel, L.J. Otten, A. Quayle, and M.D. Rugg. Electrophysiological and Haemodynamic Correlates of Face Perception, Recognition and Priming. <em>Cerebral Cortex</em>, 13(7):793–805, 07 2003. <a class="reference external" href="https://doi.org/10.1093/cercor/13.7.793">doi:10.1093/cercor/13.7.793</a>.</p></li>
<li id="id58"><p>Jean Honorio, Tommi Jaakkola, and Dimitris Samaras. On the statistical efficiency of l1,p multi-task learning of gaussian graphical models. <em>arXiv</em>, 10 2012. <a class="reference external" href="https://arxiv.org/abs/1207.4255">arXiv:1207.4255</a>.</p></li>
<li id="id59"><p>Andres Hoyos-Idrobo, Gael Varoquaux, Jonas Kahn, and Bertrand Thirion. Recursive nearest agglomeration (rena): fast clustering for approximation of structured signals. <em>IEEE Trans. Pattern Anal. Mach. Intell.</em>, 41(3):669–681, 3 2019. <a class="reference external" href="https://doi.org/10.1109/TPAMI.2018.2815524">doi:10.1109/TPAMI.2018.2815524</a>.</p></li>
<li id="id60"><p>Andrés Hoyos-Idrobo, Gaël Varoquaux, Yannick Schwartz, and Bertrand Thirion. Frem – scalable and stable decoding with fast regularized ensemble of models. <em>NeuroImage</em>, 180:160–172, 2018. New advances in encoding and decoding of brain signals. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2017.10.005">doi:10.1016/j.neuroimage.2017.10.005</a>.</p></li>
<li id="id61"><p>Koji Jimura and Russell A. Poldrack. Analyses of regional-average activation and multivoxel pattern information tell complementary stories. <em>Neuropsychologia</em>, 50(4):544–552, 2012. Multivoxel pattern analysis and cognitive theories. <a class="reference external" href="https://doi.org/10.1016/j.neuropsychologia.2011.11.007">doi:10.1016/j.neuropsychologia.2011.11.007</a>.</p></li>
<li id="id62"><p>Thorsten Kahnt, Marcus Grueschow, Oliver Speck, and John-Dylan Haynes. Perceptual learning and decision-making in human medial frontal cortex. <em>Neuron</em>, 70(3):549–559, 2011. <a class="reference external" href="https://doi.org/10.1016/j.neuron.2011.02.054">doi:10.1016/j.neuron.2011.02.054</a>.</p></li>
<li id="id63"><p>André Knops, Bertrand Thirion, Edward M. Hubbard, Vincent Michel, and Stanislas Dehaene. Recruitment of an Area Involved in Eye Movements During Mental Arithmetic. <em>Science</em>, 324(5934):1583–1585, June 2009. <a class="reference external" href="https://doi.org/10.1126/science.1171599">doi:10.1126/science.1171599</a>.</p></li>
<li id="id64"><p>Nikolaus Kriegeskorte, Rainer Goebel, and Peter Bandettini. Information-based functional brain mapping. <em>Proceedings of the National Academy of Sciences</em>, 103(10):3863–3868, 2006. <a class="reference external" href="https://doi.org/10.1073/pnas.0600244103">doi:10.1073/pnas.0600244103</a>.</p></li>
<li id="id65"><p>Angela R. Laird, P. Mickle Fox, Simon B. Eickhoff, Jessica A. Turner, Kimberly L. Ray, D. Reese McKay, David C. Glahn, Christian F. Beckmann, Stephen M. Smith, and Peter T. Fox. Behavioral Interpretations of Intrinsic Connectivity Networks. <em>Journal of Cognitive Neuroscience</em>, 23(12):4022–4037, 12 2011. <a class="reference external" href="https://doi.org/10.1162/jocn_a_00077">doi:10.1162/jocn_a_00077</a>.</p></li>
<li id="id67"><p>J.L. Lancaster, L.H. Rainey, J.L. Summerlin, C.S. Freitas, P.T. Fox, A.C. Evans, A.W. Toga, and J.C. Mazziotta. Automated labeling of the human brain: a preliminary report on the development and evaluation of a forward-transform method. <em>Human Brain Mapping</em>, 5(4):238–242, 1997. <a class="reference external" href="https://doi.org/10.1002/(SICI)1097-0193(1997)5:4&lt;238::AID-HBM6&gt;3.0.CO;2-4">doi:10.1002/(SICI)1097-0193(1997)5:4&lt;238::AID-HBM6&gt;3.0.CO;2-4</a>.</p></li>
<li id="id66"><p>Jack L. Lancaster, Marty G. Woldorff, Lawrence M. Parsons, Mario Liotti, Catarina S. Freitas, Lacy Rainey, Peter V. Kochunov, Dan Nickerson, Shawn A. Mikiten, and Peter T. Fox. Automated talairach atlas labels for functional brain mapping. <em>Human Brain Mapping</em>, 10(3):120–131, 2000. <a class="reference external" href="https://doi.org/10.1002/1097-0193(200007)10:3&lt;120::AID-HBM30&gt;3.0.CO;2-8">doi:10.1002/1097-0193(200007)10:3&lt;120::AID-HBM30&gt;3.0.CO;2-8</a>.</p></li>
<li id="id68"><p>Martin A. Lindquist, Stephan Geuter, Tor D. Wager, and Brian S. Caffo. Modular preprocessing pipelines can reintroduce artifacts into fmri data. <em>bioRxiv</em>, 2018. <a class="reference external" href="https://doi.org/10.1101/407676">doi:10.1101/407676</a>.</p></li>
<li id="id69"><p>Hesheng Liu, Steven M. Stufflebeam, Jorge Sepulcre, Trey Hedden, and Randy L. Buckner. Evidence from intrinsic activity that asymmetry of the human brain is controlled by multiple factors. <em>Proceedings of the National Academy of Sciences</em>, 106(48):20499–20503, December 2009. <a class="reference external" href="https://doi.org/10.1073/pnas.0908073106">doi:10.1073/pnas.0908073106</a>.</p></li>
<li id="id70"><p>Nikos Makris, Jill M. Goldstein, David Kennedy, Steven M. Hodge, Verne S. Caviness, Stephen V. Faraone, Ming T. Tsuang, and Larry J. Seidman. Decreased volume of left and total anterior insular lobule in schizophrenia. <em>Schizophrenia Research</em>, 83(2-3):155–171, April 2006. <a class="reference external" href="https://doi.org/10.1016/j.schres.2005.11.020">doi:10.1016/j.schres.2005.11.020</a>.</p></li>
<li id="id71"><p>Daniel S. Marcus, Tracy H. Wang, Jamie Parker, John G. Csernansky, John C. Morris, and Randy L. Buckner. Open Access Series of Imaging Studies (OASIS): Cross-sectional MRI Data in Young, Middle Aged, Nondemented, and Demented Older Adults. <em>Journal of Cognitive Neuroscience</em>, 19(9):1498–1507, 09 2007. <a class="reference external" href="https://doi.org/10.1162/jocn.2007.19.9.1498">doi:10.1162/jocn.2007.19.9.1498</a>.</p></li>
<li id="id72"><p>Arthur Mensch, Gael Varoquaux, and Bertrand Thirion. Compressed online dictionary learning for fast resting-state fmri decomposition. In <em>2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)</em>, volume, 1282–1285. 2016. <a class="reference external" href="https://doi.org/10.1109/ISBI.2016.7493501">doi:10.1109/ISBI.2016.7493501</a>.</p></li>
<li id="id73"><p>Vincent Michel, Alexandre Gramfort, Gaël Varoquaux, Evelyn Eger, and Bertrand Thirion. Total variation regularization for fMRI-based prediction of behaviour. <em>IEEE Transactions on Medical Imaging</em>, 30(7):1328 – 1340, February 2011. URL: <a class="reference external" href="https://inria.hal.science/inria-00563468">https://inria.hal.science/inria-00563468</a>, <a class="reference external" href="https://doi.org/10.1109/TMI.2011.2113378">doi:10.1109/TMI.2011.2113378</a>.</p></li>
<li id="id74"><p>Vincent Michel, Alexandre Gramfort, Gaël Varoquaux, Evelyn Eger, Christine Keribin, and Bertrand Thirion. A supervised clustering approach for fmri-based inference of brain states. <em>Pattern Recognition</em>, 45(6):2041–2049, 2012. Brain Decoding. <a class="reference external" href="https://doi.org/10.1016/j.patcog.2011.04.006">doi:10.1016/j.patcog.2011.04.006</a>.</p></li>
<li id="id75"><p>Yoichi Miyawaki, Hajime Uchida, Okito Yamashita, Masa-aki Sato, Yusuke Morito, Hiroki C. Tanabe, Norihiro Sadato, and Yukiyasu Kamitani. Visual image reconstruction from human brain activity using a combination of multiscale local image decoders. <em>Neuron</em>, 60(5):915–929, 2008. <a class="reference external" href="https://doi.org/10.1016/j.neuron.2008.11.004">doi:10.1016/j.neuron.2008.11.004</a>.</p></li>
<li id="id76"><p>Douglas C. Montgomery, Elizabeth A. Peck, and Geoffrey G. Vining. <em>Introduction to Linear Regression Analysis (4th ed.)</em>. Wiley &amp; Sons, 2006. ISBN 0471754951.</p></li>
<li id="id77"><p>Janaina Mourão-Miranda, Leticia Oliveira, Cecile D. Ladouceur, Andre Marquand, Michael Brammer, Boris Birmaher, David Axelson, and Mary L. Phillips. Pattern Recognition and Functional Neuroimaging Help to Discriminate Healthy Adolescents at Risk for Mood Disorders from Low Risk Adolescents. <em>PLoS ONE</em>, 7(2):e29482, February 2012. <a class="reference external" href="https://doi.org/10.1371/journal.pone.0029482">doi:10.1371/journal.pone.0029482</a>.</p></li>
<li id="id78"><p>Jeanette A Mumford, Benjamin O Turner, F Gregory Ashby, and Russell A Poldrack. Deconvolving bold activation in event-related designs for multivoxel pattern classification analyses. <em>Neuroimage</em>, 59(3):2636–2643, 2012.</p></li>
<li id="id79"><p>Thomas Naselaris, Kendrick N. Kay, Shinji Nishimoto, and Jack L. Gallant. Encoding and decoding in fmri. <em>NeuroImage</em>, 56(2):400–410, May 2011. 20691790[pmid]. URL: <a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/20691790">https://pubmed.ncbi.nlm.nih.gov/20691790</a>, <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2010.07.073">doi:10.1016/j.neuroimage.2010.07.073</a>.</p></li>
<li id="id80"><p>Jared Nielsen, Brandon Zielinski, P Fletcher, Andrew Alexander, Nicholas Lange, Erin Bigler, Janet Lainhart, and Jeffrey Anderson. Multisite functional connectivity mri classification of autism: abide results. <em>Frontiers in Human Neuroscience</em>, 7:599, 2013. <a class="reference external" href="https://doi.org/10.3389/fnhum.2013.00599">doi:10.3389/fnhum.2013.00599</a>.</p></li>
<li id="id81"><p>Kate Nooner, Stanley Colcombe, Russell Tobe, Maarten Mennes, Melissa Benedict, Alexis Moreno, Laura Panek, Shaquanna Brown, Stephen Zavitz, Qingyang Li, Sharad Sikka, David Gutman, Saroja Bangaru, Rochelle Tziona Schlachter, Stephanie Kamiel, Ayesha Anwar, Caitlin Hinz, Michelle Kaplan, Anna Rachlin, Samantha Adelsberg, Brian Cheung, Ranjit Khanuja, Chaogan Yan, Cameron Craddock, Vincent Calhoun, William Courtney, Margaret King, Dylan Wood, Christine Cox, Clare Kelly, Adriana DiMartino, Eva Petkova, Philip Reiss, Nancy Duan, Dawn Thompsen, Bharat Biswal, Barbara Coffey, Matthew Hoptman, Daniel Javitt, Nunzio Pomara, John Sidtis, Harold Koplewicz, Francisco Castellanos, Bennett Leventhal, and Michael Milham. The nki-rockland sample: a model for accelerating the pace of discovery science in psychiatry. <em>Frontiers in Neuroscience</em>, 6:152, 2012. <a class="reference external" href="https://doi.org/10.3389/fnins.2012.00152">doi:10.3389/fnins.2012.00152</a>.</p></li>
<li id="id92"><p>Jill X. O'Reilly, Christian F. Beckmann, Valentina Tomassini, Narender Ramnani, and Heidi Johansen-Berg. Distinct and Overlapping Functional Zones in the Cerebellum Defined by Resting State Functional Connectivity. <em>Cerebral Cortex</em>, 20(4):953–965, 08 2009. <a class="reference external" href="https://doi.org/10.1093/cercor/bhp157">doi:10.1093/cercor/bhp157</a>.</p></li>
<li id="id83"><p>Linden Parkes, Ben Fulcher, Murat Yücel, and Alex Fornito. An evaluation of the efficacy, reliability, and sensitivity of motion correction strategies for resting-state functional MRI. <em>NeuroImage</em>, 171:415–436, May 2018. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2017.12.073">doi:10.1016/j.neuroimage.2017.12.073</a>.</p></li>
<li id="id84"><p>Wolfgang M. Pauli, Amanda N. Nili, and J. Michael Tyszka. A high-resolution probabilistic in vivo atlas of human subcortical brain nuclei. <em>Scientific Data</em>, 5(1):180063, Apr 2018. <a class="reference external" href="https://doi.org/10.1038/sdata.2018.63">doi:10.1038/sdata.2018.63</a>.</p></li>
<li id="id85"><p>Philippe Pinel, Bertrand Thirion, Sébastien Meriaux, Antoinette Jobert, Julien Serres, Denis Le Bihan, Jean-Baptiste Poline, and Stanislas Dehaene. Fast reproducible identification and large-scale databasing of individual functional cognitive networks. <em>BMC Neuroscience</em>, 2007.</p></li>
<li id="id86"><p>R.A. Poldrack, E. Congdon, W. Triplett, K.J. Gorgolewski, K.H. Karlsgodt, J.A. Mumford, F.W. Sabb, N.B. Freimer, E.D. London, T.D. Cannon, and R.M. Bilder. A phenome-wide examination of neural and cognitive function. <em>Scientific Data</em>, 3(1):160110, December 2016. <a class="reference external" href="https://doi.org/10.1038/sdata.2016.110">doi:10.1038/sdata.2016.110</a>.</p></li>
<li id="id87"><p>Jonathan D. Power. A simple but useful way to assess fmri scan qualities. <em>NeuroImage</em>, 154:150–158, 2017. Cleaning up the fMRI time series: Mitigating noise with advanced acquisition and correction strategies. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2016.08.009">doi:10.1016/j.neuroimage.2016.08.009</a>.</p></li>
<li id="id89"><p>Jonathan D. Power, Kelly A. Barnes, Abraham Z. Snyder, Bradley L. Schlaggar, and Steven E. Petersen. Spurious but systematic correlations in functional connectivity MRI networks arise from subject motion. <em>NeuroImage</em>, 59(3):2142–2154, 2012. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2011.10.018">doi:10.1016/j.neuroimage.2011.10.018</a>.</p></li>
<li id="id90"><p>Jonathan D. Power, Alexander L. Cohen, Steven M. Nelson, Gagan S. Wig, Kelly Anne Barnes, Jessica A. Church, Alecia C. Vogel, Timothy O. Laumann, Fran M. Miezin, Bradley L. Schlaggar, and Steven E. Petersen. Functional network organization of the human brain. <em>Neuron</em>, 72(4):665–678, Nov 2011. <a class="reference external" href="https://doi.org/10.1016/j.neuron.2011.09.006">doi:10.1016/j.neuron.2011.09.006</a>.</p></li>
<li id="id88"><p>Jonathan D. Power, Anish Mitra, Timothy O. Laumann, Abraham Z. Snyder, Bradley L. Schlaggar, and Steven E. Petersen. Methods to detect, characterize, and remove motion artifact in resting state fMRI. <em>NeuroImage</em>, 84:320–341, 2014. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2013.08.048">doi:10.1016/j.neuroimage.2013.08.048</a>.</p></li>
<li id="id91"><p>Raimon H. R. Pruim, Maarten Mennes, Daan van Rooij, Alberto Llera, Jan K. Buitelaar, and Christian F. Beckmann. ICA-AROMA: a robust ICA-based strategy for removing motion artifacts from fMRI data. <em>Neuroimage</em>, 112:267–277, 2015. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2015.02.064">doi:10.1016/j.neuroimage.2015.02.064</a>.</p></li>
<li id="id93"><p>Hilary Richardson, Grace Lisandrelli, Alexa Riobueno-Naylor, and Rebecca Saxe. Development of the social brain from age three to twelve years. <em>Nature communications</em>, 9(1):1–12, 2018.</p></li>
<li id="id94"><p>Jesse Rissman, Adam Gazzaley, and Mark D'Esposito. Measuring functional connectivity during distinct stages of a cognitive task. <em>Neuroimage</em>, 23(2):752–763, 2004.</p></li>
<li id="id95"><p>Jonathan D. Rosenblatt, Livio Finos, Wouter D. Weeda, Aldo Solari, and Jelle J. Goeman. All-resolutions inference for brain imaging. <em>NeuroImage</em>, 181:786–796, November 2018. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2018.07.060">doi:10.1016/j.neuroimage.2018.07.060</a>.</p></li>
<li id="id96"><p>Alexander Schaefer, Ru Kong, Evan M Gordon, Timothy O Laumann, Xi-Nian Zuo, Avram J Holmes, Simon B Eickhoff, and B T Thomas Yeo. Local-Global Parcellation of the Human Cerebral Cortex from Intrinsic Functional Connectivity MRI. <em>Cerebral Cortex</em>, 28(9):3095–3114, 07 2017. <a class="reference external" href="https://doi.org/10.1093/cercor/bhx179">doi:10.1093/cercor/bhx179</a>.</p></li>
<li id="id97"><p>Benjamin A. Seitzman, Caterina Gratton, Scott Marek, Ryan V. Raut, Nico U.F. Dosenbach, Bradley L. Schlaggar, Steven E. Petersen, and Deanna J. Greene. A set of functionally-defined brain regions with improved representation of the subcortex and cerebellum. <em>NeuroImage</em>, 206:116290, 2020. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2019.116290">doi:10.1016/j.neuroimage.2019.116290</a>.</p></li>
<li id="id98"><p>Zarrar Shehzad, A. M. Clare Kelly, Philip T. Reiss, Dylan G. Gee, Kristin Gotimer, Lucina Q. Uddin, Sang Han Lee, Daniel S. Margulies, Amy Krain Roy, Bharat B. Biswal, Eva Petkova, F. Xavier Castellanos, and Michael P. Milham. The Resting Brain: Unconstrained yet Reliable. <em>Cerebral Cortex</em>, 19(10):2209–2229, 02 2009. <a class="reference external" href="https://doi.org/10.1093/cercor/bhn256">doi:10.1093/cercor/bhn256</a>.</p></li>
<li id="id102"><p>SM Smith, MF Glasser, E Robinson, G Salimi-Khorshidi, E Duff, DC Van Essen, MW Woolrich, M Jenkinson, and CF Beckmann. Methods for network modelling from high quality rfmri data. In <em>OHBM 2014 Annual Meeting</em>. 2014.</p></li>
<li id="id103"><p>Stephen M Smith and Thomas E Nichols. Threshold-free cluster enhancement: addressing problems of smoothing, threshold dependence and localisation in cluster inference. <em>Neuroimage</em>, 44(1):83–98, 2009. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2008.03.061">doi:10.1016/j.neuroimage.2008.03.061</a>.</p></li>
<li id="id100"><p>Stephen M Smith, Thomas E Nichols, Diego Vidaurre, Anderson M Winkler, Timothy EJ Behrens, Matthew F Glasser, Kamil Ugurbil, Deanna M Barch, David C Van Essen, and Karla L Miller. A positive-negative mode of population covariation links brain connectivity, demographics and behavior. <em>Nature neuroscience</em>, 18(11):1565–1567, 2015.</p></li>
<li id="id104"><p>Stephen M. Smith, Peter T. Fox, Karla L. Miller, David C. Glahn, P. Mickle Fox, Clare E. Mackay, Nicola Filippini, Kate E. Watkins, Roberto Toro, Angela R. Laird, and Christian F. Beckmann. Correspondence of the brain\textquoteright s functional architecture during activation and rest. <em>Proceedings of the National Academy of Sciences</em>, 106(31):13040–13045, 2009. <a class="reference external" href="https://doi.org/10.1073/pnas.0905267106">doi:10.1073/pnas.0905267106</a>.</p></li>
<li id="id99"><p>Stephen M. Smith, Karla L. Miller, Gholamreza Salimi-Khorshidi, Matthew Webster, Christian F. Beckmann, Thomas E. Nichols, Joseph D. Ramsey, and Mark W. Woolrich. Network modelling methods for FMRI. <em>NeuroImage</em>, 54(2):875–891, January 2011. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2010.08.063">doi:10.1016/j.neuroimage.2010.08.063</a>.</p></li>
<li id="id101"><p>Stephen M. Smith, Diego Vidaurre, Matthew F. Glasser, Anderson M. Winkler, Paul McCarthy, Emma Claire Robinson, Xu Chen, William Horton, Mark Jenkinson, Eugene P. Duff, Christian F. Beckmann, Mark W. Woolrich, Daniel S. Marcus, Deanna M. Barch, Kâmil Uğurbil, Thomas E. Nichols, and David C. Van Essen. Hcp beta-release of the functional connectivity megatrawl. In <em>humanconnectome</em>. 2015.</p></li>
<li id="id105"><p>B. Sundermann, B. Pfleiderer, A. McLeod, and C. Mathys. Seeing more than the tip of the iceberg: approaches to subthreshold effects in functional magnetic resonance imaging of the brain. <em>Clinical Neuroradiology</em>, 2023. <a class="reference external" href="https://doi.org/10.1007/s00062-024-01422-2">doi:10.1007/s00062-024-01422-2</a>.</p></li>
<li id="id106"><p>P. A. Taylor, R. C. Reynolds, V. Calhoun, J. Gonzalez-Castillo, D. A. Handwerker, P. A. Bandettini, A. F. Mejia, and G Chen. Highlight results, don't hide them: enhance interpretation, reduce biases and improve reproducibility. <em>Neuroimage</em>, 2023. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2023.120138">doi:10.1016/j.neuroimage.2023.120138</a>.</p></li>
<li id="id107"><p>Bertrand Thirion, Gaël Varoquaux, Elvis Dohmatob, and Jean-Baptiste Poline. Which fmri clustering gives good brain parcellations? <em>Frontiers in Neuroscience</em>, 2014. <a class="reference external" href="https://doi.org/10.3389/fnins.2014.00167">doi:10.3389/fnins.2014.00167</a>.</p></li>
<li id="id121"><p>B. T. Thomas Yeo, Fenna M. Krienen, Jorge Sepulcre, Mert R. Sabuncu, Danial Lashkari, Marisa Hollinshead, Joshua L. Roffman, Jordan W. Smoller, Lilla Zöllei, Jonathan R. Polimeni, Bruce Fischl, Hesheng Liu, and Randy L. Buckner. The organization of the human cerebral cortex estimated by intrinsic functional connectivity. <em>Journal of Neurophysiology</em>, 106(3):1125–1165, 2011. PMID: 21653723. <a class="reference external" href="https://doi.org/10.1152/jn.00338.2011">doi:10.1152/jn.00338.2011</a>.</p></li>
<li id="id108"><p>Benjamin O Turner, Jeanette A Mumford, Russell A Poldrack, and F Gregory Ashby. Spatiotemporal activity estimation for multivoxel pattern analysis with rapid event-related designs. <em>NeuroImage</em>, 62(3):1429–1438, 2012.</p></li>
<li id="id109"><p>N. Tzourio-Mazoyer, B. Landeau, D. Papathanassiou, F. Crivello, O. Etard, N. Delcroix, B. Mazoyer, and M. Joliot. Automated anatomical labeling of activations in spm using a macroscopic anatomical parcellation of the mni mri single-subject brain. <em>NeuroImage</em>, 15(1):273–289, 2002. <a class="reference external" href="https://doi.org/10.1006/nimg.2001.0978">doi:10.1006/nimg.2001.0978</a>.</p></li>
<li id="id114"><p>Gael Varoquaux, Flore Baronnet, Andreas Kleinschmidt, Pierre Fillard, and Bertrand Thirion. Detection of brain functional-connectivity difference in post-stroke patients using group-level covariance modeling. In Tianzi Jiang, Nassir Navab, Josien P. W. Pluim, and Max A. Viergever, editors, <em>Medical image computing and computer-assisted intervention - MICCAI 2010</em>, Lecture notes in computer science, 200–208. Berlin, Heidelberg, 2010. Springer. <a class="reference external" href="https://doi.org/10/cn2h9c">doi:10/cn2h9c</a>.</p></li>
<li id="id111"><p>Gael Varoquaux, Alexandre Gramfort, Fabian Pedregosa, Vincent Michel, and Bertrand Thirion. Multi-subject dictionary learning to segment an atlas of brain spontaneous activity. In <em>Information Processing in Medical Imaging</em>, 562–573. Berlin, Heidelberg, 2011. Springer Berlin Heidelberg.</p></li>
<li id="id112"><p>Gael Varoquaux, Alexandre Gramfort, Jean Baptiste Poline, and Bertrand Thirion. Brain covariance selection: better individual functional connectivity models using population prior. <em>Advances in neural information processing systems</em>, 2010. URL: <a class="reference external" href="https://inria.hal.science/inria-00512451">https://inria.hal.science/inria-00512451</a>, <a class="reference external" href="https://arxiv.org/abs/1008.5071">arXiv:1008.5071</a>.</p></li>
<li id="id115"><p>Gael Varoquaux, Sepideh Sadaghiani, Philippe Pinel, Andreas Kleinschmidt, Jean-Baptiste Poline, and Bertrand Thirion. A group model for stable multi-subject ica on fmri datasets. <em>NeuroImage</em>, 51(1):288–299, 2010. URL: <a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/20153834">https://pubmed.ncbi.nlm.nih.gov/20153834</a>, <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2010.02.010">doi:10.1016/j.neuroimage.2010.02.010</a>.</p></li>
<li id="id113"><p>Gaël Varoquaux, Alexandre Gramfort, Jean-Baptiste Poline, and Bertrand Thirion. Brain covariance selection: better individual functional connectivity models using population prior. <em>Advances in neural information processing systems</em>, 2010.</p></li>
<li id="id117"><p>Gaël Varoquaux, Alexandre Gramfort, and Bertrand Thirion. Small-sample brain mapping: sparse recovery on spatially correlated designs with randomization and clustering. <em>arXiv</em>, 2012. <a class="reference external" href="https://arxiv.org/abs/1206.6447">arXiv:1206.6447</a>.</p></li>
<li id="id118"><p>Gaël Varoquaux, Pradeep Reddy Raamana, Denis A Engemann, Andrés Hoyos-Idrobo, Yannick Schwartz, and Bertrand Thirion. Assessing and tuning brain decoders: cross-validation, caveats, and guidelines. <em>NeuroImage</em>, 145:166–179, 2017. <a class="reference external" href="https://arxiv.org/abs/1606.05201">arXiv:1606.05201</a>.</p></li>
<li id="id110"><p>Gaël Varoquaux and R. Cameron Craddock. Learning and comparing functional connectomes across subjects. <em>NeuroImage</em>, 80:405–415, 2013. Mapping the Connectome. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2013.04.007">doi:10.1016/j.neuroimage.2013.04.007</a>.</p></li>
<li id="id116"><p>Gaël Varoquaux, Merlin Keller, Jean-Baptiste Poline, Philippe Ciuciu, and Bertrand Thirion. Ica-based sparse features recovery from fmri datasets. In <em>2010 IEEE International Symposium on Biomedical Imaging: From Nano to Macro</em>, volume, 1177–1180. 2010. <a class="reference external" href="https://doi.org/10.1109/ISBI.2010.5490204">doi:10.1109/ISBI.2010.5490204</a>.</p></li>
<li id="id119"><p>Anderson M. Winkler, Gerard R. Ridgway, Matthew A. Webster, Stephen M. Smith, and Thomas E. Nichols. Permutation inference for the general linear model. <em>NeuroImage</em>, 92:381–397, 2014. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2014.01.060">doi:10.1016/j.neuroimage.2014.01.060</a>.</p></li>
<li id="id120"><p>Tal Yarkoni, Russell A Poldrack, Thomas E Nichols, David C Van Essen, and Tor D Wager. Large-scale automated synthesis of human functional neuroimaging data. <em>Nature methods</em>, 8(8):665–670, 2011.</p></li>
<li id="id122"><p>Andrew Zalesky, Alex Fornito, and Ed Bullmore. On the use of correlation as a measure of network connectivity. <em>Neuroimage</em>, 60(4):2096–2106, 2012.</p></li>
<li id="id124"><p>Xi-Nian Zuo, Clare Kelly, Jonathan S. Adelstein, Donald F. Klein, F. Xavier Castellanos, and Michael P. Milham. Reliable intrinsic connectivity networks: test–retest evaluation using ica and dual regression approach. <em>NeuroImage</em>, 49(3):2163–2177, 2010. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2009.10.080">doi:10.1016/j.neuroimage.2009.10.080</a>.</p></li>
<li id="id123"><p>Xi-Nian Zuo, Adriana Di Martino, Clare Kelly, Zarrar E. Shehzad, Dylan G. Gee, Donald F. Klein, F. Xavier Castellanos, Bharat B. Biswal, and Michael P. Milham. The oscillating brain: complex and reliable. <em>NeuroImage</em>, 49(2):1432–1445, 2010. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2009.09.037">doi:10.1016/j.neuroimage.2009.09.037</a>.</p></li>
<li id="id82"><p>Dimitri Papadopoulos Orfanos, Vincent Michel, Yannick Schwartz, Philippe Pinel, Antonio Moreno, Denis Le Bihan, and Vincent Frouin. The brainomics/localizer database. <em>NeuroImage</em>, 144:309–314, 2017. Data Sharing Part II. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2015.09.052">doi:10.1016/j.neuroimage.2015.09.052</a>.</p></li>
</ol>
</div>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; The nilearn developers
- Code and documentation distributed under BSD license.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link fa-brands fa-solid fa-github fa-2x" href="https://github.com/nilearn/nilearn" aria-label="GitHub"></a>
              <a class="muted-link fa-brands fa-solid fa-bluesky fa-2x" href="https://bsky.app/profile/nilearn.bsky.social" aria-label="Bluesky"></a>
              <a class="muted-link fa-brands fa-solid fa-mastodon fa-2x" href="https://fosstodon.org/@nilearn" aria-label="Mastodon"></a>
              <a class="muted-link fa-brands fa-solid fa-discord fa-2x" href="https://discord.com/invite/SsQABEJHkZ" aria-label="Discord"></a>
              <a class="muted-link fa-brands fa-solid fa-youtube fa-2x" href="https://www.youtube.com/channel/UCU6BMAi2zOhNFnDkbdevmPw" aria-label="Youtube"></a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script src="_static/documentation_options.js?v=5929fcd5"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=4ea706d9"></script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    </body>
</html>