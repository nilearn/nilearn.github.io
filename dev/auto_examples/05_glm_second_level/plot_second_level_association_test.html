<!doctype html>
<html class="no-js" lang="en" data-content_root="../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Example of generic design in second-level models" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://nilearn.github.io/auto_examples/05_glm_second_level/plot_second_level_association_test.html" />
<meta property="og:site_name" content="Nilearn" />
<meta property="og:description" content="This example shows the results obtained in a group analysis using a more complex contrast than a one- or two-sample t test. We use the [left button press (auditory cue)] task from the Localizer dat..." />
<meta property="og:image" content="https://nilearn.github.io/_static/nilearn-logo.png" />
<meta property="og:image:alt" content="Nilearn" />
<meta name="description" content="This example shows the results obtained in a group analysis using a more complex contrast than a one- or two-sample t test. We use the [left button press (auditory cue)] task from the Localizer dat..." />
<link rel="search" title="Search" href="../../search.html" /><link rel="next" title="Example of second level design matrix" href="plot_second_level_design_matrix.html" /><link rel="prev" title="GLM: Second level analysis" href="index.html" />
        <link rel="prefetch" href="../../_static/nilearn-transparent.png" as="image" />

    <link rel="shortcut icon" href="../../_static/favicon.ico"/><!-- Generated with Sphinx 8.1.3 and Furo 2025.07.19 -->
        <title>Example of generic design in second-level models - Nilearn</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=2da93098" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=25af2a20" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=8dab3a3b" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=452ecd87" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/fontawesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/solid.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/brands.min.css" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: black;
  --admonition-font-size: 100%;
  --admonition-title-font-size: 100%;
  --color-announcement-background: #FBB360;
  --color-announcement-text: #111418;
  --color-admonition-title--note: #448aff;
  --color-admonition-title-background--note: #448aff10;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-announcement-background: #935610;
  --color-announcement-text: #FFFFFF;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-announcement-background: #935610;
  --color-announcement-text: #FFFFFF;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>

<div class="announcement">
  <aside class="announcement-content">
     <p>This is the development documentation of nilearn (0.12.2.dev38+g4daf178b4) <a class="sd-sphinx-override sd-badge sd-text-wrap sd-btn-outline-dark reference external" href="https://nilearn.github.io"><span>Switch to stable version (0.12.1)</span></a></p> 
  </aside>
</div>

<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">Nilearn</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../../_static/nilearn-transparent.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Nilearn</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quickstart</a></li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../index.html">Examples</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Examples</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../00_tutorials/index.html">Basic tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Basic tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_3d_and_4d_niimg.html">3D and 4D niimgs: handling and visualizing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_decoding_tutorial.html">A introduction tutorial to fMRI decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_nilearn_101.html">Basic nilearn example: manipulating and looking at data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_python_101.html">Basic numerics and plotting with Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_single_subject_single_run.html">Intro to GLM Analysis: a single-run, single-subject fMRI dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_surface_101.html">Working with Surface images</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../01_plotting/index.html">Visualization of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Visualization of brain images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_atlas.html">Basic Atlas plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_colormaps.html">Colormaps in Nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_dim_plotting.html">Controlling the contrast of the background when plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_demo_glass_brain.html">Glass brain plotting in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_demo_glass_brain_extensive.html">Glass brain plotting in nilearn (all options)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_surf_atlas.html">Loading and plotting of a cortical surface atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_3d_map_to_surface_projection.html">Making a surface plot of a 3D statistical map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_demo_more_plotting.html">More plotting tools from nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_visualization.html">NeuroImaging volumes visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_haxby_masks.html">Plot Haxby masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_transparency.html">Plotting images with transparent thresholding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_demo_plotting.html">Plotting tools in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_surf_stat_map.html">Seed-based connectivity on the surface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_surface_projection_strategies.html">Technical point: Illustration of the volume to surface sampling schemes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_prob_atlas.html">Visualizing 4D probabilistic atlas maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_visualize_megatrawls_netmats.html">Visualizing Megatrawls Network Matrices from Human Connectome Project</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_overlay.html">Visualizing a probabilistic atlas: the default mode in the MSDL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_carpet.html">Visualizing global patterns with a carpet plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_multiscale_parcellations.html">Visualizing multiscale functional brain parcellations</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../02_decoding/index.html">Decoding and predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Decoding and predicting from brain images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_searchlight_surface.html">Cortical surface-based searchlight decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_glm_decoding.html">Decoding of a dataset after GLM fit for signal extraction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_anova_svm.html">Decoding with ANOVA + SVM: face vs house in the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_frem.html">Decoding with FREM: face vs house vs chair object recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_different_estimators.html">Different classifiers in decoding the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_miyawaki_encoding.html">Encoding models for visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_simulated_data.html">Example of pattern recognition on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_mixed_gambles_frem.html">FREM on Jimura et al “mixed gambles” dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_full_analysis.html">ROI-based decoding analysis in Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_miyawaki_reconstruction.html">Reconstruction of visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_searchlight.html">Searchlight analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_grid_search.html">Setting a parameter by cross-validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_stimuli.html">Show stimuli of Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_multiclass.html">The haxby dataset: different multi-class strategies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_understand_decoder.html">Understanding <code class="xref py py-class docutils literal notranslate"><span class="pre">Decoder</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_oasis_vbm.html">Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_oasis_vbm_space_net.html">Voxel-Based Morphometry on Oasis dataset with Space-Net prior</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../03_connectivity/index.html">Functional connectivity</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Functional connectivity</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_group_level_connectivity.html">Classification of age groups using functional connectivity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_data_driven_parcellations.html">Clustering methods to learn a brain parcellation from fMRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_atlas_comparison.html">Comparing connectomes on different reference atlases</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_inverse_covariance_connectome.html">Computing a connectome with sparse inverse covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_simulated_connectome.html">Connectivity structure estimation on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_compare_decomposition.html">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_sphere_based_connectome.html">Extract signals on spheres and plot a connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_signal_extraction.html">Extracting signals from a brain parcellation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_probabilistic_atlas_extraction.html">Extracting signals of a probabilistic atlas of functional regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_multi_subject_connectome.html">Group Sparse inverse covariance for multi-subject connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_seed_to_voxel_correlation.html">Producing single subject maps of seed-to-voxel correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_extract_regions_dictlearning_maps.html">Regions extraction using dictionary learning and functional connectomes</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../04_glm_first_level/index.html">GLM: First level analysis</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of GLM: First level analysis</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_fir_model.html">Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_adhd_dmn.html">Default Mode Network extraction of ADHD dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_hrf.html">Example of MRI response functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_localizer_surface_analysis.html">Example of surface-based first-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_design_matrix.html">Examples of design matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_bids_features.html">First level analysis of a complete BIDS dataset from openneuro</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_write_events_file.html">Generate an events.tsv file for the NeuroSpin localizer task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_predictions_residuals.html">Predicted time series and residuals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_two_runs_model.html">Simple example of two-runs fMRI model fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_spm_multimodal_faces.html">Single-subject data (two runs) in native space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_first_level_details.html">Understanding parameters of the first-level model</a></li>
</ul>
</li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="index.html">GLM: Second level analysis</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of GLM: Second level analysis</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">Example of generic design in second-level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_second_level_design_matrix.html">Example of second level design matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_second_level_one_sample_test.html">Second-level fMRI model: one sample test</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_proportion_activated_voxels.html">Second-level fMRI model: true positive proportion in clusters</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_second_level_two_sample_test.html">Second-level fMRI model: two-sample test, unpaired and paired</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_thresholding.html">Statistical testing of a second-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_oasis.html">Voxel-Based Morphometry on OASIS dataset</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../06_manipulating_images/index.html">Manipulating brain image volumes</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Manipulating brain image volumes</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_extract_regions_labels_image.html">Breaking an atlas of labels in separated regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_compare_mean_image.html">Comparing the means of 2 images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_roi_extraction.html">Computing a Region of Interest (ROI) mask manually</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_nifti_labels_simple.html">Extracting signals from brain regions using the NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_threshold_image.html">Image thresholding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_negate_image.html">Negating an image with math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_extract_rois_statistical_maps.html">Region Extraction using a t-statistical map (3D)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_extract_rois_smith_atlas.html">Regions Extraction of Default Mode Networks using Smith Atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_resample_to_template.html">Resample an image to a template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_nifti_simple.html">Simple example of NiftiMasker use</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_smooth_mean_image.html">Smoothing an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_mask_computation.html">Understanding NiftiMasker and mask computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_affine_transformation.html">Visualization of affine resamplings</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../07_advanced/index.html">Advanced statistical analysis of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of Advanced statistical analysis of brain images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_surface_image_and_maskers.html">A short demo of the surface images &amp; maskers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_advanced_decoding_scikit.html">Advanced decoding using scikit learn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_bids_analysis.html">BIDS dataset first and second level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_beta_series.html">Beta-Series Modeling for Task-Based Functional Connectivity and Decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_copy_headers_math_img.html">Copying headers from input images with <code class="docutils literal notranslate"><span class="pre">math_img</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_age_group_prediction_cross_val.html">Functional connectivity predicts age group</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_localizer_simple_analysis.html">Massively univariate analysis of a calculation task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_localizer_mass_univariate_methods.html">Massively univariate analysis of a motor task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_haxby_mass_univariate.html">Massively univariate analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_ica_resting_state.html">Multivariate decompositions: Independent component analysis of fMRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_ica_neurovault.html">NeuroVault cross-study ICA maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_neurovault_meta_analysis.html">NeuroVault meta-analysis of stop-go paradigm studies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_surface_bids_analysis.html">Surface-based dataset first and second level analysis of a dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_mask_large_fmri.html">Working with long time series fMRI images</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../user_guide.html">User guide</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of User guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../introduction.html">1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../introduction.html#what-is-nilearn">2. What is <code class="docutils literal notranslate"><span class="pre">nilearn</span></code>?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../introduction.html#using-nilearn-for-the-first-time">3. Using <code class="docutils literal notranslate"><span class="pre">nilearn</span></code> for the first time</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../introduction.html#machine-learning-applications-to-neuroimaging">4. Machine learning applications to Neuroimaging</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../decoding/index.html">5. Decoding and MVPA: predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of 5. Decoding and MVPA: predicting from brain images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/decoding_intro.html">5.1. An introduction to decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/estimator_choice.html">5.2. Choosing the right predictive model for neuroimaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/frem.html">5.3. FREM: fast ensembling of regularized models for robust decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/space_net.html">5.4. SpaceNet: decoding with spatial structure for better maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/searchlight.html">5.5. Searchlight : finding voxels containing information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/going_further.html">5.6. Running scikit-learn functions for more control on the analysis</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../connectivity/index.html">6. Functional connectivity and resting state</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of 6. Functional connectivity and resting state</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../connectivity/functional_connectomes.html">6.1. Extracting times series to build a functional connectome</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../connectivity/connectome_extraction.html">6.2. Connectome extraction: inverse covariance for direct connections</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of 6.2. Connectome extraction: inverse covariance for direct connections</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../developers/group_sparse_covariance.html">6.2.3.1. Group-sparse covariance estimation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../connectivity/resting_state_networks.html">6.3. Extracting functional brain networks: ICA and related</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../connectivity/region_extraction.html">6.4. Region Extraction for better brain parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../connectivity/parcellating.html">6.5. Clustering to parcellate the brain in regions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../plotting/index.html">7. Plotting brain images</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../glm/index.html">8. Analyzing fMRI using GLMs</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of 8. Analyzing fMRI using GLMs</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../glm/glm_intro.html">8.1. An introduction to GLMs in fMRI statistical analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../glm/first_level_model.html">8.2. First level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../glm/second_level_model.html">8.3. Second level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../glm/meaning_difference.html">8.4. Difference in meanings between different toolboxes</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../manipulating_images/index.html">9. Manipulation brain volumes with nilearn</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of 9. Manipulation brain volumes with nilearn</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../manipulating_images/input_output.html">9.1. Input and output: neuroimaging data representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../manipulating_images/manipulating_images.html">9.2. Manipulating images: resampling, smoothing, masking, ROIs…</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../manipulating_images/masker_objects.html">9.3. From neuroimaging volumes to data matrices: the masker objects</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../building_blocks/index.html">10. Advanced usage: manual pipelines and scaling up</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of 10. Advanced usage: manual pipelines and scaling up</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../building_blocks/manual_pipeline.html">10.1. Building your own neuroimaging machine-learning pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../building_blocks/neurovault.html">10.2. Downloading statistical maps from the Neurovault repository</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../modules/index.html">API References</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of API References</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/connectome.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.connectome</span></code>: Functional Connectivity</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of nilearn.connectome: Functional Connectivity</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.connectome.ConnectivityMeasure.html">nilearn.connectome.ConnectivityMeasure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.connectome.GroupSparseCovariance.html">nilearn.connectome.GroupSparseCovariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.connectome.GroupSparseCovarianceCV.html">nilearn.connectome.GroupSparseCovarianceCV</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.connectome.sym_matrix_to_vec.html">nilearn.connectome.sym_matrix_to_vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.connectome.vec_to_sym_matrix.html">nilearn.connectome.vec_to_sym_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.connectome.group_sparse_covariance.html">nilearn.connectome.group_sparse_covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.connectome.cov_to_corr.html">nilearn.connectome.cov_to_corr</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.connectome.prec_to_partial.html">nilearn.connectome.prec_to_partial</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/datasets.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.datasets</span></code>: Automatic Dataset Fetching</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of nilearn.datasets: Automatic Dataset Fetching</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_icbm152_2009.html">nilearn.datasets.fetch_icbm152_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_icbm152_brain_gm_mask.html">nilearn.datasets.fetch_icbm152_brain_gm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_surf_fsaverage.html">nilearn.datasets.fetch_surf_fsaverage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_fsaverage.html">nilearn.datasets.load_fsaverage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_fsaverage_data.html">nilearn.datasets.load_fsaverage_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_mni152_brain_mask.html">nilearn.datasets.load_mni152_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_mni152_gm_mask.html">nilearn.datasets.load_mni152_gm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_mni152_gm_template.html">nilearn.datasets.load_mni152_gm_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_mni152_template.html">nilearn.datasets.load_mni152_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_mni152_wm_mask.html">nilearn.datasets.load_mni152_wm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_mni152_wm_template.html">nilearn.datasets.load_mni152_wm_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/icbm152_2009.html">ICBM 152 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/fsaverage.html">fsaverage template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/fsaverage3.html">fsaverage3 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/fsaverage4.html">fsaverage4 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/fsaverage5.html">fsaverage5 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/fsaverage6.html">fsaverage6 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_aal.html">nilearn.datasets.fetch_atlas_aal</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_basc_multiscale_2015.html">nilearn.datasets.fetch_atlas_basc_multiscale_2015</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_destrieux_2009.html">nilearn.datasets.fetch_atlas_destrieux_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_harvard_oxford.html">nilearn.datasets.fetch_atlas_harvard_oxford</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_juelich.html">nilearn.datasets.fetch_atlas_juelich</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_pauli_2017.html">nilearn.datasets.fetch_atlas_pauli_2017</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_schaefer_2018.html">nilearn.datasets.fetch_atlas_schaefer_2018</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_surf_destrieux.html">nilearn.datasets.fetch_atlas_surf_destrieux</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_talairach.html">nilearn.datasets.fetch_atlas_talairach</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_yeo_2011.html">nilearn.datasets.fetch_atlas_yeo_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_coords_dosenbach_2010.html">nilearn.datasets.fetch_coords_dosenbach_2010</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_coords_power_2011.html">nilearn.datasets.fetch_coords_power_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_coords_seitzman_2018.html">nilearn.datasets.fetch_coords_seitzman_2018</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_allen_2011.html">nilearn.datasets.fetch_atlas_allen_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_craddock_2012.html">nilearn.datasets.fetch_atlas_craddock_2012</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_difumo.html">nilearn.datasets.fetch_atlas_difumo</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_harvard_oxford.html">nilearn.datasets.fetch_atlas_harvard_oxford</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_juelich.html">nilearn.datasets.fetch_atlas_juelich</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_msdl.html">nilearn.datasets.fetch_atlas_msdl</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_pauli_2017.html">nilearn.datasets.fetch_atlas_pauli_2017</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_smith_2009.html">nilearn.datasets.fetch_atlas_smith_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/craddock_2012.html">Craddock 2012 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/difumo_atlases.html">DiFuMo atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/msdl_atlas.html">MSDL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/dosenbach_2010.html">Dosenbach 2010 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/power_2011.html">Power 2011 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/seitzman_2018.html">Seitzman 2018 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/aal.html">AAL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/allen_rsn_2011.html">Allen 2011 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/basc_multiscale_2015.html">BASC multiscale atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/destrieux_surface.html">Destrieux atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/harvard_oxford.html">Harvard Oxford atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/juelich.html">Juelich atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/pauli_2017.html">Pauli 2007 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/schaefer_2018.html">Schaefer 2018 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/smith_2009.html">Smith 2009 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/talairach_atlas.html">Talairach atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/yeo_2011.html">Yeo 2011 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_abide_pcp.html">nilearn.datasets.fetch_abide_pcp</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_adhd.html">nilearn.datasets.fetch_adhd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_development_fmri.html">nilearn.datasets.fetch_development_fmri</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_ds000030_urls.html">nilearn.datasets.fetch_ds000030_urls</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_fiac_first_level.html">nilearn.datasets.fetch_fiac_first_level</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_haxby.html">nilearn.datasets.fetch_haxby</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_language_localizer_demo_dataset.html">nilearn.datasets.fetch_language_localizer_demo_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_localizer_first_level.html">nilearn.datasets.fetch_localizer_first_level</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_miyawaki2008.html">nilearn.datasets.fetch_miyawaki2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_spm_auditory.html">nilearn.datasets.fetch_spm_auditory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_spm_multimodal_fmri.html">nilearn.datasets.fetch_spm_multimodal_fmri</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_surf_nki_enhanced.html">nilearn.datasets.fetch_surf_nki_enhanced</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_nki.html">nilearn.datasets.load_nki</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/ABIDE_pcp.html">ABIDE PCP dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/adhd.html">ADHD dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/bids_langloc.html">BIDS language localizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/development_fmri.html">development fMRI dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/fiac.html">fiac first level dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/haxby2001.html">Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/language_localizer_demo.html">language localizer demo dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/localizer_first_level.html">localizer first level dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/miyawaki2008.html">Miyawaki 2008 dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/spm_auditory.html">SPM auditory dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/spm_multimodal.html">SPM multimodal dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/nki_enhanced_surface.html">NKI enhanced surface dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/brainomics_localizer.html">Brainomics Localizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_localizer_button_task.html">nilearn.datasets.fetch_localizer_button_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_localizer_calculation_task.html">nilearn.datasets.fetch_localizer_calculation_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_localizer_contrasts.html">nilearn.datasets.fetch_localizer_contrasts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_megatrawls_netmats.html">nilearn.datasets.fetch_megatrawls_netmats</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_mixed_gambles.html">nilearn.datasets.fetch_mixed_gambles</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_oasis_vbm.html">nilearn.datasets.fetch_oasis_vbm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_neurovault_auditory_computation_task.html">nilearn.datasets.fetch_neurovault_auditory_computation_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_neurovault_motor_task.html">nilearn.datasets.fetch_neurovault_motor_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/Megatrawls.html">MegaTrawls Network Matrices HCP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/mixed_gambles.html">Mixed gambles statistical maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/oasis1.html">OASIS volume based morphometry maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_neurovault.html">nilearn.datasets.fetch_neurovault</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_neurovault_ids.html">nilearn.datasets.fetch_neurovault_ids</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_openneuro_dataset.html">nilearn.datasets.fetch_openneuro_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.get_data_dirs.html">nilearn.datasets.get_data_dirs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.patch_openneuro_dataset.html">nilearn.datasets.patch_openneuro_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.select_from_index.html">nilearn.datasets.select_from_index</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_sample_motor_activation_image.html">nilearn.datasets.load_sample_motor_activation_image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/neurovault.html">Neurovault statistical maps</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/decoding.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decoding</span></code>: Decoding</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of nilearn.decoding: Decoding</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decoding.Decoder.html">nilearn.decoding.Decoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decoding.DecoderRegressor.html">nilearn.decoding.DecoderRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decoding.FREMClassifier.html">nilearn.decoding.FREMClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decoding.FREMRegressor.html">nilearn.decoding.FREMRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decoding.SpaceNetClassifier.html">nilearn.decoding.SpaceNetClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decoding.SpaceNetRegressor.html">nilearn.decoding.SpaceNetRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decoding.SearchLight.html">nilearn.decoding.SearchLight</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/decomposition.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decomposition</span></code>: Multivariate Decompositions</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of nilearn.decomposition: Multivariate Decompositions</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decomposition.CanICA.html">nilearn.decomposition.CanICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decomposition.DictLearning.html">nilearn.decomposition.DictLearning</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/exceptions.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.exceptions</span></code>: Exceptions and warnings</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of nilearn.exceptions: Exceptions and warnings</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.exceptions.AllVolumesRemovedError.html">nilearn.exceptions.AllVolumesRemovedError</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.exceptions.DimensionError.html">nilearn.exceptions.DimensionError</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.exceptions.MeshDimensionError.html">nilearn.exceptions.MeshDimensionError</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.exceptions.NotImplementedWarning.html">nilearn.exceptions.NotImplementedWarning</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/glm.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.glm</span></code>: Generalized Linear Models</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle navigation of nilearn.glm: Generalized Linear Models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.Contrast.html">nilearn.glm.Contrast</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.FContrastResults.html">nilearn.glm.FContrastResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.TContrastResults.html">nilearn.glm.TContrastResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.ARModel.html">nilearn.glm.ARModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.OLSModel.html">nilearn.glm.OLSModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.LikelihoodModelResults.html">nilearn.glm.LikelihoodModelResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.RegressionResults.html">nilearn.glm.RegressionResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.SimpleRegressionResults.html">nilearn.glm.SimpleRegressionResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.compute_contrast.html">nilearn.glm.compute_contrast</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.compute_fixed_effects.html">nilearn.glm.compute_fixed_effects</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.expression_to_contrast_vector.html">nilearn.glm.expression_to_contrast_vector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.fdr_threshold.html">nilearn.glm.fdr_threshold</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.cluster_level_inference.html">nilearn.glm.cluster_level_inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.threshold_stats_img.html">nilearn.glm.threshold_stats_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.FirstLevelModel.html">nilearn.glm.first_level.FirstLevelModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.check_design_matrix.html">nilearn.glm.first_level.check_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.compute_regressor.html">nilearn.glm.first_level.compute_regressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.first_level_from_bids.html">nilearn.glm.first_level.first_level_from_bids</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.glover_dispersion_derivative.html">nilearn.glm.first_level.glover_dispersion_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.glover_hrf.html">nilearn.glm.first_level.glover_hrf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.glover_time_derivative.html">nilearn.glm.first_level.glover_time_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.make_first_level_design_matrix.html">nilearn.glm.first_level.make_first_level_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.mean_scaling.html">nilearn.glm.first_level.mean_scaling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.run_glm.html">nilearn.glm.first_level.run_glm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.spm_dispersion_derivative.html">nilearn.glm.first_level.spm_dispersion_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.spm_hrf.html">nilearn.glm.first_level.spm_hrf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.spm_time_derivative.html">nilearn.glm.first_level.spm_time_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html">nilearn.glm.second_level.SecondLevelModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.second_level.make_second_level_design_matrix.html">nilearn.glm.second_level.make_second_level_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.second_level.non_parametric_inference.html">nilearn.glm.second_level.non_parametric_inference</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/image.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.image</span></code>: Image Processing and Resampling Utilities</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle navigation of nilearn.image: Image Processing and Resampling Utilities</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.binarize_img.html">nilearn.image.binarize_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.clean_img.html">nilearn.image.clean_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.concat_imgs.html">nilearn.image.concat_imgs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.coord_transform.html">nilearn.image.coord_transform</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.copy_img.html">nilearn.image.copy_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.crop_img.html">nilearn.image.crop_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.get_data.html">nilearn.image.get_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.high_variance_confounds.html">nilearn.image.high_variance_confounds</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.index_img.html">nilearn.image.index_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.iter_img.html">nilearn.image.iter_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.largest_connected_component_img.html">nilearn.image.largest_connected_component_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.load_img.html">nilearn.image.load_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.math_img.html">nilearn.image.math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.mean_img.html">nilearn.image.mean_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.new_img_like.html">nilearn.image.new_img_like</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.resample_img.html">nilearn.image.resample_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.resample_to_img.html">nilearn.image.resample_to_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.reorder_img.html">nilearn.image.reorder_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.smooth_img.html">nilearn.image.smooth_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.swap_img_hemispheres.html">nilearn.image.swap_img_hemispheres</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.threshold_img.html">nilearn.image.threshold_img</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/interfaces.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.interfaces</span></code>: Loading components from interfaces</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle navigation of nilearn.interfaces: Loading components from interfaces</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.interfaces.bids.get_bids_files.html">nilearn.interfaces.bids.get_bids_files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.interfaces.bids.parse_bids_filename.html">nilearn.interfaces.bids.parse_bids_filename</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.interfaces.bids.save_glm_to_bids.html">nilearn.interfaces.bids.save_glm_to_bids</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.interfaces.fmriprep.load_confounds.html">nilearn.interfaces.fmriprep.load_confounds</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.interfaces.fmriprep.load_confounds_strategy.html">nilearn.interfaces.fmriprep.load_confounds_strategy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.interfaces.fsl.get_design_from_fslmat.html">nilearn.interfaces.fsl.get_design_from_fslmat</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/maskers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.maskers</span></code>: Extracting Signals from Brain Images</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><div class="visually-hidden">Toggle navigation of nilearn.maskers: Extracting Signals from Brain Images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.BaseMasker.html">nilearn.maskers.BaseMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.NiftiMasker.html">nilearn.maskers.NiftiMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.MultiNiftiMasker.html">nilearn.maskers.MultiNiftiMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.NiftiLabelsMasker.html">nilearn.maskers.NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.MultiNiftiLabelsMasker.html">nilearn.maskers.MultiNiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.NiftiMapsMasker.html">nilearn.maskers.NiftiMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.MultiNiftiMapsMasker.html">nilearn.maskers.MultiNiftiMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.NiftiSpheresMasker.html">nilearn.maskers.NiftiSpheresMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.SurfaceLabelsMasker.html">nilearn.maskers.SurfaceLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.SurfaceMasker.html">nilearn.maskers.SurfaceMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.SurfaceMapsMasker.html">nilearn.maskers.SurfaceMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated_reports/masker_reports_examples.html">Examples nifti masker reports</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated_reports/masker_reports_examples.html#examples-surface-masker-reports">Examples surface masker reports</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/masking.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.masking</span></code>: Data Masking Utilities</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><div class="visually-hidden">Toggle navigation of nilearn.masking: Data Masking Utilities</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.compute_epi_mask.html">nilearn.masking.compute_epi_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.compute_multi_epi_mask.html">nilearn.masking.compute_multi_epi_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.compute_brain_mask.html">nilearn.masking.compute_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.compute_multi_brain_mask.html">nilearn.masking.compute_multi_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.compute_background_mask.html">nilearn.masking.compute_background_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.compute_multi_background_mask.html">nilearn.masking.compute_multi_background_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.intersect_masks.html">nilearn.masking.intersect_masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.apply_mask.html">nilearn.masking.apply_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.unmask.html">nilearn.masking.unmask</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/mass_univariate.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.mass_univariate</span></code>: Mass-Univariate Analysis</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><div class="visually-hidden">Toggle navigation of nilearn.mass_univariate: Mass-Univariate Analysis</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.mass_univariate.permuted_ols.html">nilearn.mass_univariate.permuted_ols</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/plotting.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.plotting</span></code>: Plotting Brain Data</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><div class="visually-hidden">Toggle navigation of nilearn.plotting: Plotting Brain Data</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.find_cut_slices.html">nilearn.plotting.find_cut_slices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.find_xyz_cut_coords.html">nilearn.plotting.find_xyz_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.find_parcellation_cut_coords.html">nilearn.plotting.find_parcellation_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.find_probabilistic_atlas_cut_coords.html">nilearn.plotting.find_probabilistic_atlas_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_anat.html">nilearn.plotting.plot_anat</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_carpet.html">nilearn.plotting.plot_carpet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_connectome.html">nilearn.plotting.plot_connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_contrast_matrix.html">nilearn.plotting.plot_contrast_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_design_matrix.html">nilearn.plotting.plot_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_design_matrix_correlation.html">nilearn.plotting.plot_design_matrix_correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_epi.html">nilearn.plotting.plot_epi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_event.html">nilearn.plotting.plot_event</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_glass_brain.html">nilearn.plotting.plot_glass_brain</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_img.html">nilearn.plotting.plot_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_img_on_surf.html">nilearn.plotting.plot_img_on_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_markers.html">nilearn.plotting.plot_markers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_matrix.html">nilearn.plotting.plot_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_prob_atlas.html">nilearn.plotting.plot_prob_atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_roi.html">nilearn.plotting.plot_roi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_stat_map.html">nilearn.plotting.plot_stat_map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_surf.html">nilearn.plotting.plot_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_surf_contours.html">nilearn.plotting.plot_surf_contours</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_surf_roi.html">nilearn.plotting.plot_surf_roi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_surf_stat_map.html">nilearn.plotting.plot_surf_stat_map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.show.html">nilearn.plotting.show</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.view_surf.html">nilearn.plotting.view_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.view_img_on_surf.html">nilearn.plotting.view_img_on_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.view_connectome.html">nilearn.plotting.view_connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.view_markers.html">nilearn.plotting.view_markers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.view_img.html">nilearn.plotting.view_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.img_comparison.plot_bland_altman.html">nilearn.plotting.img_comparison.plot_bland_altman</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.img_comparison.plot_img_comparison.html">nilearn.plotting.img_comparison.plot_img_comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.PlotlySurfaceFigure.html">nilearn.plotting.displays.PlotlySurfaceFigure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.BaseAxes.html">nilearn.plotting.displays.BaseAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.CutAxes.html">nilearn.plotting.displays.CutAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.GlassBrainAxes.html">nilearn.plotting.displays.GlassBrainAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.OrthoProjector.html">nilearn.plotting.displays.OrthoProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.LZRYProjector.html">nilearn.plotting.displays.LZRYProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.LYRZProjector.html">nilearn.plotting.displays.LYRZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.LYRProjector.html">nilearn.plotting.displays.LYRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.LZRProjector.html">nilearn.plotting.displays.LZRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.LRProjector.html">nilearn.plotting.displays.LRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.LProjector.html">nilearn.plotting.displays.LProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.RProjector.html">nilearn.plotting.displays.RProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.XZProjector.html">nilearn.plotting.displays.XZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.YZProjector.html">nilearn.plotting.displays.YZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.YXProjector.html">nilearn.plotting.displays.YXProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.XProjector.html">nilearn.plotting.displays.XProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.YProjector.html">nilearn.plotting.displays.YProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.ZProjector.html">nilearn.plotting.displays.ZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.BaseSlicer.html">nilearn.plotting.displays.BaseSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.OrthoSlicer.html">nilearn.plotting.displays.OrthoSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.MosaicSlicer.html">nilearn.plotting.displays.MosaicSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.TiledSlicer.html">nilearn.plotting.displays.TiledSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.XSlicer.html">nilearn.plotting.displays.XSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.XZSlicer.html">nilearn.plotting.displays.XZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.YXSlicer.html">nilearn.plotting.displays.YXSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.YZSlicer.html">nilearn.plotting.displays.YZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.YSlicer.html">nilearn.plotting.displays.YSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.ZSlicer.html">nilearn.plotting.displays.ZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.get_projector.html">nilearn.plotting.displays.get_projector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.get_slicer.html">nilearn.plotting.displays.get_slicer</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/regions.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.regions</span></code>: Operating on Regions</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" role="switch" type="checkbox"/><label for="toctree-checkbox-30"><div class="visually-hidden">Toggle navigation of nilearn.regions: Operating on Regions</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.RegionExtractor.html">nilearn.regions.RegionExtractor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.Parcellations.html">nilearn.regions.Parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.ReNA.html">nilearn.regions.ReNA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.HierarchicalKMeans.html">nilearn.regions.HierarchicalKMeans</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.connected_regions.html">nilearn.regions.connected_regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.connected_label_regions.html">nilearn.regions.connected_label_regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.img_to_signals_labels.html">nilearn.regions.img_to_signals_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.signals_to_img_labels.html">nilearn.regions.signals_to_img_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.img_to_signals_maps.html">nilearn.regions.img_to_signals_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.signals_to_img_maps.html">nilearn.regions.signals_to_img_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.recursive_neighbor_agglomeration.html">nilearn.regions.recursive_neighbor_agglomeration</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/reporting.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.reporting</span></code>: Reporting Functions</a><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" role="switch" type="checkbox"/><label for="toctree-checkbox-31"><div class="visually-hidden">Toggle navigation of nilearn.reporting: Reporting Functions</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.reporting.HTMLReport.html">nilearn.reporting.HTMLReport</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.reporting.get_clusters_table.html">nilearn.reporting.get_clusters_table</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.reporting.make_glm_report.html">nilearn.reporting.make_glm_report</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated_reports/glm_reports_examples.html">Examples of GLM reports</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/signal.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.signal</span></code>: Preprocessing Time Series</a><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" role="switch" type="checkbox"/><label for="toctree-checkbox-32"><div class="visually-hidden">Toggle navigation of nilearn.signal: Preprocessing Time Series</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.signal.butterworth.html">nilearn.signal.butterworth</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.signal.clean.html">nilearn.signal.clean</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.signal.high_variance_confounds.html">nilearn.signal.high_variance_confounds</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/surface.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.surface</span></code>: Manipulating Surface Data</a><input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" role="switch" type="checkbox"/><label for="toctree-checkbox-33"><div class="visually-hidden">Toggle navigation of nilearn.surface: Manipulating Surface Data</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.FileMesh.html">nilearn.surface.FileMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.InMemoryMesh.html">nilearn.surface.InMemoryMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.PolyData.html">nilearn.surface.PolyData</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.PolyMesh.html">nilearn.surface.PolyMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.SurfaceImage.html">nilearn.surface.SurfaceImage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.SurfaceMesh.html">nilearn.surface.SurfaceMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.load_surf_data.html">nilearn.surface.load_surf_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.load_surf_mesh.html">nilearn.surface.load_surf_mesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.vol_to_surf.html">nilearn.surface.vol_to_surf</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../development.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ci.html">Continuous integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../maintenance.html">Maintenance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html">What’s new</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../authors.html">Team</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../versions.html">Versions</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nilearn/nilearn">GitHub Repository</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="https://github.com/nilearn/nilearn/blob/main/doc/auto_examples/05_glm_second_level/plot_second_level_association_test.rst?plain=true" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>

<div class="edit-this-page">
  <a class="muted-link"
     href="https://github.com/nilearn/nilearn/edit/main/examples/05_glm_second_level/plot_second_level_association_test.py"
     title="Edit this page"
     target="_blank">
    <svg aria-hidden="true" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
         fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <path d="M4 20h4l10.5 -10.5a1.5 1.5 0 0 0 -4 -4l-10.5 10.5v4" />
      <line x1="13.5" y1="6.5" x2="17.5" y2="10.5" />
    </svg>
    <span class="visually-hidden">Edit this page</span>
  </a>
</div><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-05-glm-second-level-plot-second-level-association-test-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code. or to run this example in your browser via Binder</p>
</div>
<section class="sphx-glr-example-title" id="example-of-generic-design-in-second-level-models">
<span id="sphx-glr-auto-examples-05-glm-second-level-plot-second-level-association-test-py"></span><h1>Example of generic design in second-level models<a class="headerlink" href="#example-of-generic-design-in-second-level-models" title="Link to this heading">¶</a></h1>
<p>This example shows the results obtained in a group analysis using a more
complex contrast than a one- or two-sample t test.
We use the [left button press (auditory cue)] task from the Localizer
dataset and seek association between the contrast values and a variate
that measures the speed of pseudo-word reading. No confounding variate
is included in the model.</p>
<p>At first, we need to load the Localizer contrasts.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nilearn.datasets</span><span class="w"> </span><span class="kn">import</span> <a href="../../modules/generated/nilearn.datasets.fetch_localizer_contrasts.html#nilearn.datasets.fetch_localizer_contrasts" title="nilearn.datasets.fetch_localizer_contrasts" class="sphx-glr-backref-module-nilearn-datasets sphx-glr-backref-type-py-function"><span class="n">fetch_localizer_contrasts</span></a>

<a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_samples</span></a> <span class="o">=</span> <span class="mi">94</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch" title="sklearn.utils.Bunch" class="sphx-glr-backref-module-sklearn-utils sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">localizer_dataset</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.datasets.fetch_localizer_contrasts.html#nilearn.datasets.fetch_localizer_contrasts" title="nilearn.datasets.fetch_localizer_contrasts" class="sphx-glr-backref-module-nilearn-datasets sphx-glr-backref-type-py-function"><span class="n">fetch_localizer_contrasts</span></a><span class="p">(</span>
    <span class="p">[</span><span class="s2">&quot;left button press (auditory cue)&quot;</span><span class="p">],</span>
    <span class="n">n_subjects</span><span class="o">=</span><a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_samples</span></a><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[fetch_localizer_contrasts] Dataset found in
/home/runner/nilearn_data/brainomics_localizer
[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d27da3a114a4200190453ab/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d27ebc3114a42001704a18d/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d27f1f0114a42001804603e/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d28092e45253a001c3e597f/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d281a531c5b4a001c9ea662/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d28295aa26b340018087ef4/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d283473a26b34001609ed88/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d284374114a42001605f4d2/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d28590d114a4200160607da/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d285a53114a4200160608be/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d286f35a26b34001908e5c1/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2888ce1c5b4a001b9f789c/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d289b2945253a00193d32ac/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d28a00245253a001c3efac9/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d28bc0145253a00193d53ab/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d28cfd91c5b4a001c9f404d/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d28db3ba26b34001808f444/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d28f0bc1c5b4a001b9fd7f3/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d28ffc245253a00193d7dac/ ...
[fetch_localizer_contrasts]  ...done. (4 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2909cd1c5b4a001b9fe6c5/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2919e2114a42001606b46c/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2928bc45253a001b3cf010/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d293a50a26b34001909682a/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d29492fa26b34001709070f/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d295328114a42001606dd9a/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2c37031c5b4a001ca0da2b/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2c442e114a420017071134/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2c5c431c5b4a001da257a5/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2c6c2645253a001c42460f/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2ec286251f0e001604a189/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2ed2875d2cdc001702b4c5/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d341711a667db0017fc816f/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d34294d835aff001958add9/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2ef8925d2cdc001702e0a5/ ...
[fetch_localizer_contrasts]  ...done. (4 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2f0851251f0e0018044fe4/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2f26e4a667db0017f72ae9/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2f358c251f0e001704a76a/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2f41d2835aff001a52da0c/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2f5acc835aff0018532004/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2f692d835aff00175372e9/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2f7456835aff0017537992/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2f8881a667db0018f6b634/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2f9552251f0e001605bb64/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2faf785d2cdc0017039bb1/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2fbffd835aff0018535ef5/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2fc225a667db001af6222a/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2fdd77835aff00195494d4/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2fe5d5a667db0017f80f32/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d2ff3ea835aff0018538140/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d301049a667db0019f67ca0/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d3021b65d2cdc00190344d6/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d302afe5d2cdc0018030034/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d303ad4835aff001853bca4/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d304f845d2cdc001a032801/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d3058cd835aff001853d4c7/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d306f15a667db0018f78b4d/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d307f8b251f0e00190519ca/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d309cb5251f0e001606fe4b/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d30a667251f0e00190534dc/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d30bb07251f0e001705df42/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d30df37251f0e001705fd72/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d30e232a667db0018f7f2a9/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d30f7ec251f0e001805e3cd/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d3116dca667db0018f81c29/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d312688251f0e0016079f29/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d3134fe5d2cdc001705393d/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d3143f9835aff00195630ce/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d315ac0835aff001754e139/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d3160bc835aff00195649cf/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d317bb2251f0e001608002e/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d318a6c251f0e001905b6ed/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d31962da667db0017fa303d/ ...
[fetch_localizer_contrasts]  ...done. (4 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d31abe45d2cdc0019046202/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d31cdeea667db001af75ab9/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d31dc83835aff001956e6c5/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d31fefea667db0018f8ea9f/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d32072b5d2cdc0018043969/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d3219b4a667db0018f8ff1f/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d3234f3835aff00175590f0/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d323d06251f0e001706f0be/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d324e77251f0e001806e5e7/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d326b70835aff00195762f8/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d32731a5d2cdc001a0472bb/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d3286b7251f0e001906427f/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d3298815d2cdc001804700c/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d32ab6ea667db0017fb59e8/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d32bb275d2cdc001a049841/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d32d901a667db0018f9684f/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d32e9d3835aff001957cd79/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d32f34f835aff001755ee97/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d3306db5d2cdc001706c36f/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d332373251f0e001609acbd/ ...
[fetch_localizer_contrasts]  ...done. (3 seconds, 0 min)

[fetch_localizer_contrasts] Downloading data from
https://osf.io/download/5d332b7e835aff001957feec/ ...
[fetch_localizer_contrasts]  ...done. (2 seconds, 0 min)
</pre></div>
</div>
<p>Let’s print basic information on the dataset.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;First contrast nifti image (3D) is located &quot;</span>
    <span class="sa">f</span><span class="s2">&quot;at: </span><span class="si">{</span><a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">localizer_dataset</span><span class="o">.</span><span class="n">cmaps</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>First contrast nifti image (3D) is located at: /home/runner/nilearn_data/brainomics_localizer/brainomics_data/S01/cmaps_LeftAuditoryClick.nii.gz
</pre></div>
</div>
<p>we also need to load the behavioral variable.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tested_var</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">localizer_dataset</span><span class="o">.</span><span class="n">ext_vars</span></a><span class="p">[</span><span class="s2">&quot;pseudo&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tested_var</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>0     15.0
1     16.0
2     14.0
3     19.0
4     16.0
      ...
89    12.0
90    16.0
91    13.0
92    25.0
93    21.0
Name: pseudo, Length: 94, dtype: float64
</pre></div>
</div>
<p>It is worth to do a quality check and remove subjects with missing values.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">mask_quality_check</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.where.html#numpy.where" title="numpy.where" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">where</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ufunc.html#numpy.ufunc" title="numpy.ufunc" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">np</span><span class="o">.</span><span class="n">logical_not</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ufunc.html#numpy.ufunc" title="numpy.ufunc" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">np</span><span class="o">.</span><span class="n">isnan</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tested_var</span></a><span class="p">)))[</span><span class="mi">0</span><span class="p">]</span>
<a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_samples</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">mask_quality_check</span><span class="o">.</span><span class="n">size</span></a>
<a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">contrast_map_filenames</span></a> <span class="o">=</span> <span class="p">[</span>
    <a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">localizer_dataset</span><span class="o">.</span><span class="n">cmaps</span></a><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">mask_quality_check</span></a>
<span class="p">]</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tested_var</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tested_var</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">mask_quality_check</span></a><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Actual number of subjects after quality check: </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_samples</span></a><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Actual number of subjects after quality check: 89
</pre></div>
</div>
<section id="estimate-second-level-model">
<h2>Estimate second level model<a class="headerlink" href="#estimate-second-level-model" title="Link to this heading">¶</a></h2>
<p>We define the input maps and the design matrix for the second level model
and fit it.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">design_matrix</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.hstack.html#numpy.hstack" title="numpy.hstack" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">hstack</span></a><span class="p">((</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tested_var</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ones_like.html#numpy.ones_like" title="numpy.ones_like" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">ones_like</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tested_var</span></a><span class="p">))),</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fluency&quot;</span><span class="p">,</span> <span class="s2">&quot;intercept&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Fit of the second-level model</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nilearn.glm.second_level</span><span class="w"> </span><span class="kn">import</span> <a href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel" title="nilearn.glm.second_level.SecondLevelModel" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-class"><span class="n">SecondLevelModel</span></a>

<a href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel" title="nilearn.glm.second_level.SecondLevelModel" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel" title="nilearn.glm.second_level.SecondLevelModel" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-class"><span class="n">SecondLevelModel</span></a><span class="p">(</span><span class="n">smoothing_fwhm</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel.fit" title="nilearn.glm.second_level.SecondLevelModel.fit" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">fit</span></a><span class="p">(</span><a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">contrast_map_filenames</span></a><span class="p">,</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">design_matrix</span></a><span class="o">=</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">design_matrix</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<style>#sk-container-id-10 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-10 {
  color: var(--sklearn-color-text);
}

#sk-container-id-10 pre {
  padding: 0;
}

#sk-container-id-10 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-10 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-10 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-10 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-10 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-10 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-10 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-10 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-10 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-10 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-10 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-10 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-10 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-10 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-10 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-10 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-10 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-10 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-10 div.sk-label label.sk-toggleable__label,
#sk-container-id-10 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-10 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-10 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-10 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-10 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-10 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-10 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-10 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-10 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-10 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-10 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-10" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Second Level Model</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-10" type="checkbox" checked><label for="sk-estimator-id-10" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;SecondLevelModel<span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Second Level Model</pre></div> </div></div></div></div>
</div>
<br />
<br /><p>To estimate the <a class="reference internal" href="../../glossary.html#term-contrast"><span class="xref std std-term">contrast</span></a> is very simple.
We can just provide the column name of the design matrix.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">z_map</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel.compute_contrast" title="nilearn.glm.second_level.SecondLevelModel.compute_contrast" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">compute_contrast</span></a><span class="p">(</span><span class="s2">&quot;fluency&quot;</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="s2">&quot;z_score&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We compute the fdr-corrected p = 0.05 threshold for these data.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nilearn.glm</span><span class="w"> </span><span class="kn">import</span> <a href="../../modules/generated/nilearn.glm.threshold_stats_img.html#nilearn.glm.threshold_stats_img" title="nilearn.glm.threshold_stats_img" class="sphx-glr-backref-module-nilearn-glm sphx-glr-backref-type-py-function"><span class="n">threshold_stats_img</span></a>

<a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">_</span></a><span class="p">,</span> <a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">threshold</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.glm.threshold_stats_img.html#nilearn.glm.threshold_stats_img" title="nilearn.glm.threshold_stats_img" class="sphx-glr-backref-module-nilearn-glm sphx-glr-backref-type-py-function"><span class="n">threshold_stats_img</span></a><span class="p">(</span><a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">z_map</span></a><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">height_control</span><span class="o">=</span><span class="s2">&quot;fdr&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Let us plot the second level <a class="reference internal" href="../../glossary.html#term-contrast"><span class="xref std std-term">contrast</span></a> at the computed thresholds.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nilearn.plotting</span><span class="w"> </span><span class="kn">import</span> <a href="../../modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map" title="nilearn.plotting.plot_stat_map" class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"><span class="n">plot_stat_map</span></a><span class="p">,</span> <a href="../../modules/generated/nilearn.plotting.show.html#nilearn.plotting.show" title="nilearn.plotting.show" class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"><span class="n">show</span></a>

<a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cut_coords</span></a> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>

<a href="../../modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map" title="nilearn.plotting.plot_stat_map" class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"><span class="n">plot_stat_map</span></a><span class="p">(</span>
    <a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">z_map</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">threshold</span></a><span class="o">=</span><a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">threshold</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.10/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">title</span></a><span class="o">=</span><span class="s2">&quot;Group-level association between motor activity </span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="s2">&quot;and reading fluency (fdr=0.05)&quot;</span><span class="p">,</span>
    <a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cut_coords</span></a><span class="o">=</span><a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cut_coords</span></a><span class="p">,</span>
    <span class="n">draw_cross</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>

<a href="../../modules/generated/nilearn.plotting.show.html#nilearn.plotting.show" title="nilearn.plotting.show" class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_second_level_association_test_001.png" srcset="../../_images/sphx_glr_plot_second_level_association_test_001.png" alt="plot second level association test" class = "sphx-glr-single-img"/><p>Computing the (corrected) p-values with parametric test to compare with
non parametric test</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nilearn.image</span><span class="w"> </span><span class="kn">import</span> <a href="../../modules/generated/nilearn.image.get_data.html#nilearn.image.get_data" title="nilearn.image.get_data" class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"><span class="n">get_data</span></a><span class="p">,</span> <a href="../../modules/generated/nilearn.image.math_img.html#nilearn.image.math_img" title="nilearn.image.math_img" class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"><span class="n">math_img</span></a>

<a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">p_val</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel.compute_contrast" title="nilearn.glm.second_level.SecondLevelModel.compute_contrast" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">compute_contrast</span></a><span class="p">(</span><span class="s2">&quot;fluency&quot;</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="s2">&quot;p_value&quot;</span><span class="p">)</span>
<a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.uint64" title="numpy.uint64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">n_voxels</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.sum.html#numpy.sum" title="numpy.sum" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">sum</span></a><span class="p">(</span><a href="../../modules/generated/nilearn.image.get_data.html#nilearn.image.get_data" title="nilearn.image.get_data" class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"><span class="n">get_data</span></a><span class="p">(</span><a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span><span class="o">.</span><span class="n">masker_</span><span class="o">.</span><span class="n">mask_img_</span></a><span class="p">))</span>
<span class="c1"># Correcting the p-values for multiple testing and taking negative logarithm</span>
<a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">neg_log_pval</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.image.math_img.html#nilearn.image.math_img" title="nilearn.image.math_img" class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"><span class="n">math_img</span></a><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;-np.log10(np.minimum(1, img * </span><span class="si">{</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.uint64" title="numpy.uint64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">n_voxels</span></a><span class="si">!s}</span><span class="s2">))&quot;</span><span class="p">,</span> <span class="n">img</span><span class="o">=</span><a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">p_val</span></a>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;string&gt;:1: RuntimeWarning: divide by zero encountered in log10
</pre></div>
</div>
<p>Let us plot the (corrected) negative log  p-values for the parametric test</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Since we are plotting negative log p-values and using a threshold equal to 1,</span>
<span class="c1"># it corresponds to corrected p-values lower than 10%, meaning that there</span>
<span class="c1"># is less than 10% probability to make a single false discovery</span>
<span class="c1"># (90% chance that we make no false discoveries at all).</span>
<span class="c1"># This threshold is much more conservative than the previous one.</span>
<a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">threshold</span></a> <span class="o">=</span> <span class="mi">1</span>
<a href="https://docs.python.org/3.10/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">title</span></a> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;Group-level association between motor activity and reading: </span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="s2">&quot;neg-log of parametric corrected p-values (FWER &lt; 10%)&quot;</span>
<span class="p">)</span>
<a href="../../modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map" title="nilearn.plotting.plot_stat_map" class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"><span class="n">plot_stat_map</span></a><span class="p">(</span>
    <a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">neg_log_pval</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cut_coords</span></a><span class="o">=</span><a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cut_coords</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">threshold</span></a><span class="o">=</span><a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">threshold</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.10/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">title</span></a><span class="o">=</span><a href="https://docs.python.org/3.10/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">title</span></a><span class="p">,</span>
    <span class="n">vmin</span><span class="o">=</span><a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">threshold</span></a><span class="p">,</span>
    <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;inferno&quot;</span><span class="p">,</span>
    <span class="n">draw_cross</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<a href="../../modules/generated/nilearn.plotting.show.html#nilearn.plotting.show" title="nilearn.plotting.show" class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_second_level_association_test_002.png" srcset="../../_images/sphx_glr_plot_second_level_association_test_002.png" alt="plot second level association test" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/home/runner/work/nilearn/nilearn/examples/05_glm_second_level/plot_second_level_association_test.py:119: UserWarning: Non-finite values detected. These values will be replaced with zeros.
  plot_stat_map(
</pre></div>
</div>
<p>Computing the (corrected) negative log p-values with permutation test</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nilearn.glm.second_level</span><span class="w"> </span><span class="kn">import</span> <a href="../../modules/generated/nilearn.glm.second_level.non_parametric_inference.html#nilearn.glm.second_level.non_parametric_inference" title="nilearn.glm.second_level.non_parametric_inference" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-function"><span class="n">non_parametric_inference</span></a>

<a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">neg_log_pvals_permuted_ols_unmasked</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.glm.second_level.non_parametric_inference.html#nilearn.glm.second_level.non_parametric_inference" title="nilearn.glm.second_level.non_parametric_inference" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-function"><span class="n">non_parametric_inference</span></a><span class="p">(</span>
    <a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">contrast_map_filenames</span></a><span class="p">,</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">design_matrix</span></a><span class="o">=</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">design_matrix</span></a><span class="p">,</span>
    <span class="n">second_level_contrast</span><span class="o">=</span><span class="s2">&quot;fluency&quot;</span><span class="p">,</span>
    <span class="n">model_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">n_perm</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">two_sided_test</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">smoothing_fwhm</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Let us plot the (corrected) negative log  p-values</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.10/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">title</span></a> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;Group-level association between motor activity and reading: </span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="s2">&quot;neg-log of non-parametric corrected p-values (FWER &lt; 10%)&quot;</span>
<span class="p">)</span>
<a href="../../modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map" title="nilearn.plotting.plot_stat_map" class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"><span class="n">plot_stat_map</span></a><span class="p">(</span>
    <a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">neg_log_pvals_permuted_ols_unmasked</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cut_coords</span></a><span class="o">=</span><a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cut_coords</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">threshold</span></a><span class="o">=</span><a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">threshold</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.10/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">title</span></a><span class="o">=</span><a href="https://docs.python.org/3.10/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">title</span></a><span class="p">,</span>
    <span class="n">vmin</span><span class="o">=</span><a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">threshold</span></a><span class="p">,</span>
    <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;inferno&quot;</span><span class="p">,</span>
    <span class="n">draw_cross</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<a href="../../modules/generated/nilearn.plotting.show.html#nilearn.plotting.show" title="nilearn.plotting.show" class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"><span class="n">show</span></a><span class="p">()</span>

<span class="c1"># The neg-log p-values obtained with non parametric testing are capped at 3</span>
<span class="c1"># since the number of permutations is 1e3.</span>
<span class="c1"># The non parametric test yields a few more discoveries</span>
<span class="c1"># and is then more powerful than the usual parametric procedure.</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_second_level_association_test_003.png" srcset="../../_images/sphx_glr_plot_second_level_association_test_003.png" alt="plot second level association test" class = "sphx-glr-single-img"/><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (4 minutes 21.326 seconds)</p>
<p><strong>Estimated memory usage:</strong>  151 MB</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-05-glm-second-level-plot-second-level-association-test-py">
<div class="binder-badge docutils container">
<a class="reference external image-reference" href="https://mybinder.org/v2/gh/nilearn/nilearn/main?urlpath=lab/tree/notebooks/auto_examples/05_glm_second_level/plot_second_level_association_test.ipynb"><img alt="Launch binder" src="../../_images/binder_badge_logo5.svg" style="width: 150px;" />
</a>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/2b5d485614d16f2dd7cc6203f2cdb7f9/plot_second_level_association_test.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_second_level_association_test.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/22639334ce8d30070c745bfc1e0d1bc8/plot_second_level_association_test.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_second_level_association_test.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/9edf432086e8eedc181d6828392f8027/plot_second_level_association_test.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">plot_second_level_association_test.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="plot_second_level_design_matrix.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Example of second level design matrix</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="index.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">GLM: Second level analysis</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; The nilearn developers
- Code and documentation distributed under BSD license.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link fa-brands fa-solid fa-github fa-2x" href="https://github.com/nilearn/nilearn" aria-label="GitHub"></a>
              <a class="muted-link fa-brands fa-solid fa-bluesky fa-2x" href="https://bsky.app/profile/nilearn.bsky.social" aria-label="Bluesky"></a>
              <a class="muted-link fa-brands fa-solid fa-mastodon fa-2x" href="https://fosstodon.org/@nilearn" aria-label="Mastodon"></a>
              <a class="muted-link fa-brands fa-solid fa-discord fa-2x" href="https://discord.com/invite/SsQABEJHkZ" aria-label="Discord"></a>
              <a class="muted-link fa-brands fa-solid fa-youtube fa-2x" href="https://www.youtube.com/channel/UCU6BMAi2zOhNFnDkbdevmPw" aria-label="Youtube"></a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Example of generic design in second-level models</a><ul>
<li><a class="reference internal" href="#estimate-second-level-model">Estimate second level model</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=4ea706d9"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    </body>
</html>