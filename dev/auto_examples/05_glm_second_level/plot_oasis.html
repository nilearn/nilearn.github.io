<!doctype html>
<html class="no-js" lang="en" data-content_root="../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Voxel-Based Morphometry on OASIS dataset" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://nilearn.github.io/auto_examples/05_glm_second_level/plot_oasis.html" />
<meta property="og:site_name" content="Nilearn" />
<meta property="og:description" content="This example uses voxel-based morphometry ( VBM) to study the relationship between aging, sex, and gray matter density. The data come from the OASIS project. If you use it, you need to agree with t..." />
<meta property="og:image" content="https://nilearn.github.io/_static/nilearn-logo.png" />
<meta property="og:image:alt" content="Nilearn" />
<meta name="description" content="This example uses voxel-based morphometry ( VBM) to study the relationship between aging, sex, and gray matter density. The data come from the OASIS project. If you use it, you need to agree with t..." />
<link rel="search" title="Search" href="../../search.html" /><link rel="next" title="Manipulating brain image volumes" href="../06_manipulating_images/index.html" /><link rel="prev" title="Statistical testing of a second-level analysis" href="plot_thresholding.html" />
        <link rel="prefetch" href="../../_static/nilearn-transparent.png" as="image" />

    <link rel="shortcut icon" href="../../_static/favicon.ico"/><!-- Generated with Sphinx 8.1.3 and Furo 2025.07.19 -->
        <title>Voxel-Based Morphometry on OASIS dataset - Nilearn</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=2da93098" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=25af2a20" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=8dab3a3b" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=452ecd87" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/fontawesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/solid.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/brands.min.css" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: black;
  --admonition-font-size: 100%;
  --admonition-title-font-size: 100%;
  --color-announcement-background: #FBB360;
  --color-announcement-text: #111418;
  --color-admonition-title--note: #448aff;
  --color-admonition-title-background--note: #448aff10;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-announcement-background: #935610;
  --color-announcement-text: #FFFFFF;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-announcement-background: #935610;
  --color-announcement-text: #FFFFFF;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>

<div class="announcement">
  <aside class="announcement-content">
     <p>This is the development documentation of nilearn (0.12.2.dev42+gd442edde6) <a class="sd-sphinx-override sd-badge sd-text-wrap sd-btn-outline-dark reference external" href="https://nilearn.github.io"><span>Switch to stable version (0.12.1)</span></a></p> 
  </aside>
</div>

<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">Nilearn</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../../_static/nilearn-transparent.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Nilearn</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quickstart</a></li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../index.html">Examples</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Examples</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../00_tutorials/index.html">Basic tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Basic tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_3d_and_4d_niimg.html">3D and 4D niimgs: handling and visualizing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_decoding_tutorial.html">A introduction tutorial to fMRI decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_nilearn_101.html">Basic nilearn example: manipulating and looking at data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_python_101.html">Basic numerics and plotting with Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_single_subject_single_run.html">Intro to GLM Analysis: a single-run, single-subject fMRI dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_surface_101.html">Working with Surface images</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../01_plotting/index.html">Visualization of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Visualization of brain images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_atlas.html">Basic Atlas plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_colormaps.html">Colormaps in Nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_dim_plotting.html">Controlling the contrast of the background when plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_demo_glass_brain.html">Glass brain plotting in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_demo_glass_brain_extensive.html">Glass brain plotting in nilearn (all options)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_surf_atlas.html">Loading and plotting of a cortical surface atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_3d_map_to_surface_projection.html">Making a surface plot of a 3D statistical map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_demo_more_plotting.html">More plotting tools from nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_visualization.html">NeuroImaging volumes visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_haxby_masks.html">Plot Haxby masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_transparency.html">Plotting images with transparent thresholding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_demo_plotting.html">Plotting tools in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_surf_stat_map.html">Seed-based connectivity on the surface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_surface_projection_strategies.html">Technical point: Illustration of the volume to surface sampling schemes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_prob_atlas.html">Visualizing 4D probabilistic atlas maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_visualize_megatrawls_netmats.html">Visualizing Megatrawls Network Matrices from Human Connectome Project</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_overlay.html">Visualizing a probabilistic atlas: the default mode in the MSDL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_carpet.html">Visualizing global patterns with a carpet plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_multiscale_parcellations.html">Visualizing multiscale functional brain parcellations</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../02_decoding/index.html">Decoding and predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Decoding and predicting from brain images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_searchlight_surface.html">Cortical surface-based searchlight decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_glm_decoding.html">Decoding of a dataset after GLM fit for signal extraction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_anova_svm.html">Decoding with ANOVA + SVM: face vs house in the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_frem.html">Decoding with FREM: face vs house vs chair object recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_different_estimators.html">Different classifiers in decoding the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_miyawaki_encoding.html">Encoding models for visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_simulated_data.html">Example of pattern recognition on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_mixed_gambles_frem.html">FREM on Jimura et al “mixed gambles” dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_full_analysis.html">ROI-based decoding analysis in Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_miyawaki_reconstruction.html">Reconstruction of visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_searchlight.html">Searchlight analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_grid_search.html">Setting a parameter by cross-validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_stimuli.html">Show stimuli of Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_multiclass.html">The haxby dataset: different multi-class strategies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_understand_decoder.html">Understanding <code class="xref py py-class docutils literal notranslate"><span class="pre">Decoder</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_oasis_vbm.html">Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_oasis_vbm_space_net.html">Voxel-Based Morphometry on Oasis dataset with Space-Net prior</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../03_connectivity/index.html">Functional connectivity</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Functional connectivity</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_group_level_connectivity.html">Classification of age groups using functional connectivity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_data_driven_parcellations.html">Clustering methods to learn a brain parcellation from fMRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_atlas_comparison.html">Comparing connectomes on different reference atlases</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_inverse_covariance_connectome.html">Computing a connectome with sparse inverse covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_simulated_connectome.html">Connectivity structure estimation on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_compare_decomposition.html">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_sphere_based_connectome.html">Extract signals on spheres and plot a connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_signal_extraction.html">Extracting signals from a brain parcellation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_probabilistic_atlas_extraction.html">Extracting signals of a probabilistic atlas of functional regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_multi_subject_connectome.html">Group Sparse inverse covariance for multi-subject connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_seed_to_voxel_correlation.html">Producing single subject maps of seed-to-voxel correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_extract_regions_dictlearning_maps.html">Regions extraction using dictionary learning and functional connectomes</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../04_glm_first_level/index.html">GLM: First level analysis</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of GLM: First level analysis</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_fir_model.html">Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_adhd_dmn.html">Default Mode Network extraction of ADHD dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_hrf.html">Example of MRI response functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_localizer_surface_analysis.html">Example of surface-based first-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_design_matrix.html">Examples of design matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_bids_features.html">First level analysis of a complete BIDS dataset from openneuro</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_write_events_file.html">Generate an events.tsv file for the NeuroSpin localizer task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_predictions_residuals.html">Predicted time series and residuals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_two_runs_model.html">Simple example of two-runs fMRI model fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_spm_multimodal_faces.html">Single-subject data (two runs) in native space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_first_level_details.html">Understanding parameters of the first-level model</a></li>
</ul>
</li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="index.html">GLM: Second level analysis</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of GLM: Second level analysis</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="plot_second_level_association_test.html">Example of generic design in second-level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_second_level_design_matrix.html">Example of second level design matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_second_level_one_sample_test.html">Second-level fMRI model: one sample test</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_proportion_activated_voxels.html">Second-level fMRI model: true positive proportion in clusters</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_second_level_two_sample_test.html">Second-level fMRI model: two-sample test, unpaired and paired</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_thresholding.html">Statistical testing of a second-level analysis</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">Voxel-Based Morphometry on OASIS dataset</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../06_manipulating_images/index.html">Manipulating brain image volumes</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Manipulating brain image volumes</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_extract_regions_labels_image.html">Breaking an atlas of labels in separated regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_compare_mean_image.html">Comparing the means of 2 images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_roi_extraction.html">Computing a Region of Interest (ROI) mask manually</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_nifti_labels_simple.html">Extracting signals from brain regions using the NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_threshold_image.html">Image thresholding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_negate_image.html">Negating an image with math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_extract_rois_statistical_maps.html">Region Extraction using a t-statistical map (3D)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_extract_rois_smith_atlas.html">Regions Extraction of Default Mode Networks using Smith Atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_resample_to_template.html">Resample an image to a template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_nifti_simple.html">Simple example of NiftiMasker use</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_smooth_mean_image.html">Smoothing an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_mask_computation.html">Understanding NiftiMasker and mask computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_affine_transformation.html">Visualization of affine resamplings</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../07_advanced/index.html">Advanced statistical analysis of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of Advanced statistical analysis of brain images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_surface_image_and_maskers.html">A short demo of the surface images &amp; maskers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_advanced_decoding_scikit.html">Advanced decoding using scikit learn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_bids_analysis.html">BIDS dataset first and second level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_beta_series.html">Beta-Series Modeling for Task-Based Functional Connectivity and Decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_copy_headers_math_img.html">Copying headers from input images with <code class="docutils literal notranslate"><span class="pre">math_img</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_age_group_prediction_cross_val.html">Functional connectivity predicts age group</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_localizer_simple_analysis.html">Massively univariate analysis of a calculation task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_localizer_mass_univariate_methods.html">Massively univariate analysis of a motor task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_haxby_mass_univariate.html">Massively univariate analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_ica_resting_state.html">Multivariate decompositions: Independent component analysis of fMRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_ica_neurovault.html">NeuroVault cross-study ICA maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_neurovault_meta_analysis.html">NeuroVault meta-analysis of stop-go paradigm studies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_surface_bids_analysis.html">Surface-based dataset first and second level analysis of a dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../07_advanced/plot_mask_large_fmri.html">Working with long time series fMRI images</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../user_guide.html">User guide</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of User guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../introduction.html">1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../introduction.html#what-is-nilearn">2. What is <code class="docutils literal notranslate"><span class="pre">nilearn</span></code>?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../introduction.html#using-nilearn-for-the-first-time">3. Using <code class="docutils literal notranslate"><span class="pre">nilearn</span></code> for the first time</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../introduction.html#machine-learning-applications-to-neuroimaging">4. Machine learning applications to Neuroimaging</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../decoding/index.html">5. Decoding and MVPA: predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of 5. Decoding and MVPA: predicting from brain images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/decoding_intro.html">5.1. An introduction to decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/estimator_choice.html">5.2. Choosing the right predictive model for neuroimaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/frem.html">5.3. FREM: fast ensembling of regularized models for robust decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/space_net.html">5.4. SpaceNet: decoding with spatial structure for better maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/searchlight.html">5.5. Searchlight : finding voxels containing information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/going_further.html">5.6. Running scikit-learn functions for more control on the analysis</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../connectivity/index.html">6. Functional connectivity and resting state</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of 6. Functional connectivity and resting state</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../connectivity/functional_connectomes.html">6.1. Extracting times series to build a functional connectome</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../connectivity/connectome_extraction.html">6.2. Connectome extraction: inverse covariance for direct connections</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of 6.2. Connectome extraction: inverse covariance for direct connections</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../developers/group_sparse_covariance.html">6.2.3.1. Group-sparse covariance estimation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../connectivity/resting_state_networks.html">6.3. Extracting functional brain networks: ICA and related</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../connectivity/region_extraction.html">6.4. Region Extraction for better brain parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../connectivity/parcellating.html">6.5. Clustering to parcellate the brain in regions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../plotting/index.html">7. Plotting brain images</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../glm/index.html">8. Analyzing fMRI using GLMs</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of 8. Analyzing fMRI using GLMs</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../glm/glm_intro.html">8.1. An introduction to GLMs in fMRI statistical analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../glm/first_level_model.html">8.2. First level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../glm/second_level_model.html">8.3. Second level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../glm/meaning_difference.html">8.4. Difference in meanings between different toolboxes</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../manipulating_images/index.html">9. Manipulation brain volumes with nilearn</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of 9. Manipulation brain volumes with nilearn</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../manipulating_images/input_output.html">9.1. Input and output: neuroimaging data representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../manipulating_images/manipulating_images.html">9.2. Manipulating images: resampling, smoothing, masking, ROIs…</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../manipulating_images/masker_objects.html">9.3. From neuroimaging volumes to data matrices: the masker objects</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../building_blocks/index.html">10. Advanced usage: manual pipelines and scaling up</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of 10. Advanced usage: manual pipelines and scaling up</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../building_blocks/manual_pipeline.html">10.1. Building your own neuroimaging machine-learning pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../building_blocks/neurovault.html">10.2. Downloading statistical maps from the Neurovault repository</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../modules/index.html">API References</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of API References</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/connectome.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.connectome</span></code>: Functional Connectivity</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of nilearn.connectome: Functional Connectivity</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.connectome.ConnectivityMeasure.html">nilearn.connectome.ConnectivityMeasure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.connectome.GroupSparseCovariance.html">nilearn.connectome.GroupSparseCovariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.connectome.GroupSparseCovarianceCV.html">nilearn.connectome.GroupSparseCovarianceCV</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.connectome.sym_matrix_to_vec.html">nilearn.connectome.sym_matrix_to_vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.connectome.vec_to_sym_matrix.html">nilearn.connectome.vec_to_sym_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.connectome.group_sparse_covariance.html">nilearn.connectome.group_sparse_covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.connectome.cov_to_corr.html">nilearn.connectome.cov_to_corr</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.connectome.prec_to_partial.html">nilearn.connectome.prec_to_partial</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/datasets.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.datasets</span></code>: Automatic Dataset Fetching</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of nilearn.datasets: Automatic Dataset Fetching</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_icbm152_2009.html">nilearn.datasets.fetch_icbm152_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_icbm152_brain_gm_mask.html">nilearn.datasets.fetch_icbm152_brain_gm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_surf_fsaverage.html">nilearn.datasets.fetch_surf_fsaverage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_fsaverage.html">nilearn.datasets.load_fsaverage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_fsaverage_data.html">nilearn.datasets.load_fsaverage_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_mni152_brain_mask.html">nilearn.datasets.load_mni152_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_mni152_gm_mask.html">nilearn.datasets.load_mni152_gm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_mni152_gm_template.html">nilearn.datasets.load_mni152_gm_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_mni152_template.html">nilearn.datasets.load_mni152_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_mni152_wm_mask.html">nilearn.datasets.load_mni152_wm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_mni152_wm_template.html">nilearn.datasets.load_mni152_wm_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/icbm152_2009.html">ICBM 152 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/fsaverage.html">fsaverage template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/fsaverage3.html">fsaverage3 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/fsaverage4.html">fsaverage4 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/fsaverage5.html">fsaverage5 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/fsaverage6.html">fsaverage6 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_aal.html">nilearn.datasets.fetch_atlas_aal</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_basc_multiscale_2015.html">nilearn.datasets.fetch_atlas_basc_multiscale_2015</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_destrieux_2009.html">nilearn.datasets.fetch_atlas_destrieux_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_harvard_oxford.html">nilearn.datasets.fetch_atlas_harvard_oxford</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_juelich.html">nilearn.datasets.fetch_atlas_juelich</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_pauli_2017.html">nilearn.datasets.fetch_atlas_pauli_2017</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_schaefer_2018.html">nilearn.datasets.fetch_atlas_schaefer_2018</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_surf_destrieux.html">nilearn.datasets.fetch_atlas_surf_destrieux</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_talairach.html">nilearn.datasets.fetch_atlas_talairach</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_yeo_2011.html">nilearn.datasets.fetch_atlas_yeo_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_coords_dosenbach_2010.html">nilearn.datasets.fetch_coords_dosenbach_2010</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_coords_power_2011.html">nilearn.datasets.fetch_coords_power_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_coords_seitzman_2018.html">nilearn.datasets.fetch_coords_seitzman_2018</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_allen_2011.html">nilearn.datasets.fetch_atlas_allen_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_craddock_2012.html">nilearn.datasets.fetch_atlas_craddock_2012</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_difumo.html">nilearn.datasets.fetch_atlas_difumo</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_harvard_oxford.html">nilearn.datasets.fetch_atlas_harvard_oxford</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_juelich.html">nilearn.datasets.fetch_atlas_juelich</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_msdl.html">nilearn.datasets.fetch_atlas_msdl</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_pauli_2017.html">nilearn.datasets.fetch_atlas_pauli_2017</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_atlas_smith_2009.html">nilearn.datasets.fetch_atlas_smith_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/craddock_2012.html">Craddock 2012 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/difumo_atlases.html">DiFuMo atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/msdl_atlas.html">MSDL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/dosenbach_2010.html">Dosenbach 2010 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/power_2011.html">Power 2011 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/seitzman_2018.html">Seitzman 2018 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/aal.html">AAL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/allen_rsn_2011.html">Allen 2011 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/basc_multiscale_2015.html">BASC multiscale atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/destrieux_surface.html">Destrieux atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/harvard_oxford.html">Harvard Oxford atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/juelich.html">Juelich atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/pauli_2017.html">Pauli 2007 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/schaefer_2018.html">Schaefer 2018 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/smith_2009.html">Smith 2009 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/talairach_atlas.html">Talairach atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/yeo_2011.html">Yeo 2011 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_abide_pcp.html">nilearn.datasets.fetch_abide_pcp</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_adhd.html">nilearn.datasets.fetch_adhd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_development_fmri.html">nilearn.datasets.fetch_development_fmri</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_ds000030_urls.html">nilearn.datasets.fetch_ds000030_urls</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_fiac_first_level.html">nilearn.datasets.fetch_fiac_first_level</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_haxby.html">nilearn.datasets.fetch_haxby</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_language_localizer_demo_dataset.html">nilearn.datasets.fetch_language_localizer_demo_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_localizer_first_level.html">nilearn.datasets.fetch_localizer_first_level</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_miyawaki2008.html">nilearn.datasets.fetch_miyawaki2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_spm_auditory.html">nilearn.datasets.fetch_spm_auditory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_spm_multimodal_fmri.html">nilearn.datasets.fetch_spm_multimodal_fmri</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_surf_nki_enhanced.html">nilearn.datasets.fetch_surf_nki_enhanced</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_nki.html">nilearn.datasets.load_nki</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/ABIDE_pcp.html">ABIDE PCP dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/adhd.html">ADHD dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/bids_langloc.html">BIDS language localizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/development_fmri.html">development fMRI dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/fiac.html">fiac first level dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/haxby2001.html">Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/language_localizer_demo.html">language localizer demo dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/localizer_first_level.html">localizer first level dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/miyawaki2008.html">Miyawaki 2008 dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/spm_auditory.html">SPM auditory dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/spm_multimodal.html">SPM multimodal dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/nki_enhanced_surface.html">NKI enhanced surface dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/brainomics_localizer.html">Brainomics Localizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_localizer_button_task.html">nilearn.datasets.fetch_localizer_button_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_localizer_calculation_task.html">nilearn.datasets.fetch_localizer_calculation_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_localizer_contrasts.html">nilearn.datasets.fetch_localizer_contrasts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_megatrawls_netmats.html">nilearn.datasets.fetch_megatrawls_netmats</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_mixed_gambles.html">nilearn.datasets.fetch_mixed_gambles</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_oasis_vbm.html">nilearn.datasets.fetch_oasis_vbm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_neurovault_auditory_computation_task.html">nilearn.datasets.fetch_neurovault_auditory_computation_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_neurovault_motor_task.html">nilearn.datasets.fetch_neurovault_motor_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/Megatrawls.html">MegaTrawls Network Matrices HCP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/mixed_gambles.html">Mixed gambles statistical maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/oasis1.html">OASIS volume based morphometry maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_neurovault.html">nilearn.datasets.fetch_neurovault</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_neurovault_ids.html">nilearn.datasets.fetch_neurovault_ids</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.fetch_openneuro_dataset.html">nilearn.datasets.fetch_openneuro_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.get_data_dirs.html">nilearn.datasets.get_data_dirs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.patch_openneuro_dataset.html">nilearn.datasets.patch_openneuro_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.select_from_index.html">nilearn.datasets.select_from_index</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.datasets.load_sample_motor_activation_image.html">nilearn.datasets.load_sample_motor_activation_image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/description/neurovault.html">Neurovault statistical maps</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/decoding.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decoding</span></code>: Decoding</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of nilearn.decoding: Decoding</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decoding.Decoder.html">nilearn.decoding.Decoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decoding.DecoderRegressor.html">nilearn.decoding.DecoderRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decoding.FREMClassifier.html">nilearn.decoding.FREMClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decoding.FREMRegressor.html">nilearn.decoding.FREMRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decoding.SpaceNetClassifier.html">nilearn.decoding.SpaceNetClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decoding.SpaceNetRegressor.html">nilearn.decoding.SpaceNetRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decoding.SearchLight.html">nilearn.decoding.SearchLight</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/decomposition.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decomposition</span></code>: Multivariate Decompositions</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of nilearn.decomposition: Multivariate Decompositions</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decomposition.CanICA.html">nilearn.decomposition.CanICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.decomposition.DictLearning.html">nilearn.decomposition.DictLearning</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/exceptions.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.exceptions</span></code>: Exceptions and warnings</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of nilearn.exceptions: Exceptions and warnings</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.exceptions.AllVolumesRemovedError.html">nilearn.exceptions.AllVolumesRemovedError</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.exceptions.DimensionError.html">nilearn.exceptions.DimensionError</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.exceptions.MeshDimensionError.html">nilearn.exceptions.MeshDimensionError</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.exceptions.NotImplementedWarning.html">nilearn.exceptions.NotImplementedWarning</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/glm.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.glm</span></code>: Generalized Linear Models</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle navigation of nilearn.glm: Generalized Linear Models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.Contrast.html">nilearn.glm.Contrast</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.FContrastResults.html">nilearn.glm.FContrastResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.TContrastResults.html">nilearn.glm.TContrastResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.ARModel.html">nilearn.glm.ARModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.OLSModel.html">nilearn.glm.OLSModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.LikelihoodModelResults.html">nilearn.glm.LikelihoodModelResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.RegressionResults.html">nilearn.glm.RegressionResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.SimpleRegressionResults.html">nilearn.glm.SimpleRegressionResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.compute_contrast.html">nilearn.glm.compute_contrast</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.compute_fixed_effects.html">nilearn.glm.compute_fixed_effects</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.expression_to_contrast_vector.html">nilearn.glm.expression_to_contrast_vector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.fdr_threshold.html">nilearn.glm.fdr_threshold</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.cluster_level_inference.html">nilearn.glm.cluster_level_inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.threshold_stats_img.html">nilearn.glm.threshold_stats_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.FirstLevelModel.html">nilearn.glm.first_level.FirstLevelModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.check_design_matrix.html">nilearn.glm.first_level.check_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.compute_regressor.html">nilearn.glm.first_level.compute_regressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.first_level_from_bids.html">nilearn.glm.first_level.first_level_from_bids</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.glover_dispersion_derivative.html">nilearn.glm.first_level.glover_dispersion_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.glover_hrf.html">nilearn.glm.first_level.glover_hrf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.glover_time_derivative.html">nilearn.glm.first_level.glover_time_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.make_first_level_design_matrix.html">nilearn.glm.first_level.make_first_level_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.mean_scaling.html">nilearn.glm.first_level.mean_scaling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.run_glm.html">nilearn.glm.first_level.run_glm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.spm_dispersion_derivative.html">nilearn.glm.first_level.spm_dispersion_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.spm_hrf.html">nilearn.glm.first_level.spm_hrf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.first_level.spm_time_derivative.html">nilearn.glm.first_level.spm_time_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html">nilearn.glm.second_level.SecondLevelModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.second_level.make_second_level_design_matrix.html">nilearn.glm.second_level.make_second_level_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.glm.second_level.non_parametric_inference.html">nilearn.glm.second_level.non_parametric_inference</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/image.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.image</span></code>: Image Processing and Resampling Utilities</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle navigation of nilearn.image: Image Processing and Resampling Utilities</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.binarize_img.html">nilearn.image.binarize_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.clean_img.html">nilearn.image.clean_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.concat_imgs.html">nilearn.image.concat_imgs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.coord_transform.html">nilearn.image.coord_transform</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.copy_img.html">nilearn.image.copy_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.crop_img.html">nilearn.image.crop_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.get_data.html">nilearn.image.get_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.high_variance_confounds.html">nilearn.image.high_variance_confounds</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.index_img.html">nilearn.image.index_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.iter_img.html">nilearn.image.iter_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.largest_connected_component_img.html">nilearn.image.largest_connected_component_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.load_img.html">nilearn.image.load_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.math_img.html">nilearn.image.math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.mean_img.html">nilearn.image.mean_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.new_img_like.html">nilearn.image.new_img_like</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.resample_img.html">nilearn.image.resample_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.resample_to_img.html">nilearn.image.resample_to_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.reorder_img.html">nilearn.image.reorder_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.smooth_img.html">nilearn.image.smooth_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.swap_img_hemispheres.html">nilearn.image.swap_img_hemispheres</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.image.threshold_img.html">nilearn.image.threshold_img</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/interfaces.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.interfaces</span></code>: Loading components from interfaces</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle navigation of nilearn.interfaces: Loading components from interfaces</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.interfaces.bids.get_bids_files.html">nilearn.interfaces.bids.get_bids_files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.interfaces.bids.parse_bids_filename.html">nilearn.interfaces.bids.parse_bids_filename</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.interfaces.bids.save_glm_to_bids.html">nilearn.interfaces.bids.save_glm_to_bids</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.interfaces.fmriprep.load_confounds.html">nilearn.interfaces.fmriprep.load_confounds</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.interfaces.fmriprep.load_confounds_strategy.html">nilearn.interfaces.fmriprep.load_confounds_strategy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.interfaces.fsl.get_design_from_fslmat.html">nilearn.interfaces.fsl.get_design_from_fslmat</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/maskers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.maskers</span></code>: Extracting Signals from Brain Images</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><div class="visually-hidden">Toggle navigation of nilearn.maskers: Extracting Signals from Brain Images</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.BaseMasker.html">nilearn.maskers.BaseMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.NiftiMasker.html">nilearn.maskers.NiftiMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.MultiNiftiMasker.html">nilearn.maskers.MultiNiftiMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.NiftiLabelsMasker.html">nilearn.maskers.NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.MultiNiftiLabelsMasker.html">nilearn.maskers.MultiNiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.NiftiMapsMasker.html">nilearn.maskers.NiftiMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.MultiNiftiMapsMasker.html">nilearn.maskers.MultiNiftiMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.NiftiSpheresMasker.html">nilearn.maskers.NiftiSpheresMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.SurfaceLabelsMasker.html">nilearn.maskers.SurfaceLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.SurfaceMasker.html">nilearn.maskers.SurfaceMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.maskers.SurfaceMapsMasker.html">nilearn.maskers.SurfaceMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated_reports/masker_reports_examples.html">Examples nifti masker reports</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated_reports/masker_reports_examples.html#examples-surface-masker-reports">Examples surface masker reports</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/masking.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.masking</span></code>: Data Masking Utilities</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><div class="visually-hidden">Toggle navigation of nilearn.masking: Data Masking Utilities</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.compute_epi_mask.html">nilearn.masking.compute_epi_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.compute_multi_epi_mask.html">nilearn.masking.compute_multi_epi_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.compute_brain_mask.html">nilearn.masking.compute_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.compute_multi_brain_mask.html">nilearn.masking.compute_multi_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.compute_background_mask.html">nilearn.masking.compute_background_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.compute_multi_background_mask.html">nilearn.masking.compute_multi_background_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.intersect_masks.html">nilearn.masking.intersect_masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.apply_mask.html">nilearn.masking.apply_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.masking.unmask.html">nilearn.masking.unmask</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/mass_univariate.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.mass_univariate</span></code>: Mass-Univariate Analysis</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><div class="visually-hidden">Toggle navigation of nilearn.mass_univariate: Mass-Univariate Analysis</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.mass_univariate.permuted_ols.html">nilearn.mass_univariate.permuted_ols</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/plotting.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.plotting</span></code>: Plotting Brain Data</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><div class="visually-hidden">Toggle navigation of nilearn.plotting: Plotting Brain Data</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.find_cut_slices.html">nilearn.plotting.find_cut_slices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.find_xyz_cut_coords.html">nilearn.plotting.find_xyz_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.find_parcellation_cut_coords.html">nilearn.plotting.find_parcellation_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.find_probabilistic_atlas_cut_coords.html">nilearn.plotting.find_probabilistic_atlas_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_anat.html">nilearn.plotting.plot_anat</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_carpet.html">nilearn.plotting.plot_carpet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_connectome.html">nilearn.plotting.plot_connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_contrast_matrix.html">nilearn.plotting.plot_contrast_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_design_matrix.html">nilearn.plotting.plot_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_design_matrix_correlation.html">nilearn.plotting.plot_design_matrix_correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_epi.html">nilearn.plotting.plot_epi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_event.html">nilearn.plotting.plot_event</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_glass_brain.html">nilearn.plotting.plot_glass_brain</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_img.html">nilearn.plotting.plot_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_img_on_surf.html">nilearn.plotting.plot_img_on_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_markers.html">nilearn.plotting.plot_markers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_matrix.html">nilearn.plotting.plot_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_prob_atlas.html">nilearn.plotting.plot_prob_atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_roi.html">nilearn.plotting.plot_roi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_stat_map.html">nilearn.plotting.plot_stat_map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_surf.html">nilearn.plotting.plot_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_surf_contours.html">nilearn.plotting.plot_surf_contours</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_surf_roi.html">nilearn.plotting.plot_surf_roi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.plot_surf_stat_map.html">nilearn.plotting.plot_surf_stat_map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.show.html">nilearn.plotting.show</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.view_surf.html">nilearn.plotting.view_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.view_img_on_surf.html">nilearn.plotting.view_img_on_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.view_connectome.html">nilearn.plotting.view_connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.view_markers.html">nilearn.plotting.view_markers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.view_img.html">nilearn.plotting.view_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.img_comparison.plot_bland_altman.html">nilearn.plotting.img_comparison.plot_bland_altman</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.img_comparison.plot_img_comparison.html">nilearn.plotting.img_comparison.plot_img_comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.PlotlySurfaceFigure.html">nilearn.plotting.displays.PlotlySurfaceFigure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.BaseAxes.html">nilearn.plotting.displays.BaseAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.CutAxes.html">nilearn.plotting.displays.CutAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.GlassBrainAxes.html">nilearn.plotting.displays.GlassBrainAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.OrthoProjector.html">nilearn.plotting.displays.OrthoProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.LZRYProjector.html">nilearn.plotting.displays.LZRYProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.LYRZProjector.html">nilearn.plotting.displays.LYRZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.LYRProjector.html">nilearn.plotting.displays.LYRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.LZRProjector.html">nilearn.plotting.displays.LZRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.LRProjector.html">nilearn.plotting.displays.LRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.LProjector.html">nilearn.plotting.displays.LProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.RProjector.html">nilearn.plotting.displays.RProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.XZProjector.html">nilearn.plotting.displays.XZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.YZProjector.html">nilearn.plotting.displays.YZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.YXProjector.html">nilearn.plotting.displays.YXProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.XProjector.html">nilearn.plotting.displays.XProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.YProjector.html">nilearn.plotting.displays.YProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.ZProjector.html">nilearn.plotting.displays.ZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.BaseSlicer.html">nilearn.plotting.displays.BaseSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.OrthoSlicer.html">nilearn.plotting.displays.OrthoSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.MosaicSlicer.html">nilearn.plotting.displays.MosaicSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.TiledSlicer.html">nilearn.plotting.displays.TiledSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.XSlicer.html">nilearn.plotting.displays.XSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.XZSlicer.html">nilearn.plotting.displays.XZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.YXSlicer.html">nilearn.plotting.displays.YXSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.YZSlicer.html">nilearn.plotting.displays.YZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.YSlicer.html">nilearn.plotting.displays.YSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.ZSlicer.html">nilearn.plotting.displays.ZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.get_projector.html">nilearn.plotting.displays.get_projector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.plotting.displays.get_slicer.html">nilearn.plotting.displays.get_slicer</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/regions.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.regions</span></code>: Operating on Regions</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" role="switch" type="checkbox"/><label for="toctree-checkbox-30"><div class="visually-hidden">Toggle navigation of nilearn.regions: Operating on Regions</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.RegionExtractor.html">nilearn.regions.RegionExtractor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.Parcellations.html">nilearn.regions.Parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.ReNA.html">nilearn.regions.ReNA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.HierarchicalKMeans.html">nilearn.regions.HierarchicalKMeans</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.connected_regions.html">nilearn.regions.connected_regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.connected_label_regions.html">nilearn.regions.connected_label_regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.img_to_signals_labels.html">nilearn.regions.img_to_signals_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.signals_to_img_labels.html">nilearn.regions.signals_to_img_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.img_to_signals_maps.html">nilearn.regions.img_to_signals_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.signals_to_img_maps.html">nilearn.regions.signals_to_img_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.regions.recursive_neighbor_agglomeration.html">nilearn.regions.recursive_neighbor_agglomeration</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/reporting.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.reporting</span></code>: Reporting Functions</a><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" role="switch" type="checkbox"/><label for="toctree-checkbox-31"><div class="visually-hidden">Toggle navigation of nilearn.reporting: Reporting Functions</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.reporting.HTMLReport.html">nilearn.reporting.HTMLReport</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.reporting.get_clusters_table.html">nilearn.reporting.get_clusters_table</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.reporting.make_glm_report.html">nilearn.reporting.make_glm_report</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated_reports/glm_reports_examples.html">Examples of GLM reports</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/signal.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.signal</span></code>: Preprocessing Time Series</a><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" role="switch" type="checkbox"/><label for="toctree-checkbox-32"><div class="visually-hidden">Toggle navigation of nilearn.signal: Preprocessing Time Series</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.signal.butterworth.html">nilearn.signal.butterworth</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.signal.clean.html">nilearn.signal.clean</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.signal.high_variance_confounds.html">nilearn.signal.high_variance_confounds</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../modules/surface.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.surface</span></code>: Manipulating Surface Data</a><input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" role="switch" type="checkbox"/><label for="toctree-checkbox-33"><div class="visually-hidden">Toggle navigation of nilearn.surface: Manipulating Surface Data</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.FileMesh.html">nilearn.surface.FileMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.InMemoryMesh.html">nilearn.surface.InMemoryMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.PolyData.html">nilearn.surface.PolyData</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.PolyMesh.html">nilearn.surface.PolyMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.SurfaceImage.html">nilearn.surface.SurfaceImage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.SurfaceMesh.html">nilearn.surface.SurfaceMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.load_surf_data.html">nilearn.surface.load_surf_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.load_surf_mesh.html">nilearn.surface.load_surf_mesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../modules/generated/nilearn.surface.vol_to_surf.html">nilearn.surface.vol_to_surf</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../development.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ci.html">Continuous integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../maintenance.html">Maintenance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html">What’s new</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../authors.html">Team</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../versions.html">Versions</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nilearn/nilearn">GitHub Repository</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="https://github.com/nilearn/nilearn/blob/main/doc/auto_examples/05_glm_second_level/plot_oasis.rst?plain=true" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>

<div class="edit-this-page">
  <a class="muted-link"
     href="https://github.com/nilearn/nilearn/edit/main/examples/05_glm_second_level/plot_oasis.py"
     title="Edit this page"
     target="_blank">
    <svg aria-hidden="true" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
         fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <path d="M4 20h4l10.5 -10.5a1.5 1.5 0 0 0 -4 -4l-10.5 10.5v4" />
      <line x1="13.5" y1="6.5" x2="17.5" y2="10.5" />
    </svg>
    <span class="visually-hidden">Edit this page</span>
  </a>
</div><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-05-glm-second-level-plot-oasis-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code. or to run this example in your browser via Binder</p>
</div>
<section class="sphx-glr-example-title" id="voxel-based-morphometry-on-oasis-dataset">
<span id="sphx-glr-auto-examples-05-glm-second-level-plot-oasis-py"></span><h1>Voxel-Based Morphometry on OASIS dataset<a class="headerlink" href="#voxel-based-morphometry-on-oasis-dataset" title="Link to this heading">¶</a></h1>
<p>This example uses voxel-based morphometry (<a class="reference internal" href="../../glossary.html#term-VBM"><span class="xref std std-term">VBM</span></a>) to study the
relationship between aging, sex, and gray matter density.</p>
<p>The data come from the <a class="reference external" href="https://sites.wustl.edu/oasisbrains/">OASIS</a> project.
If you use it, you need to agree with the data usage agreement available
on the website.</p>
<p>It has been run through a standard <a class="reference internal" href="../../glossary.html#term-VBM"><span class="xref std std-term">VBM</span></a> pipeline
(using SPM8 and NewSegment)
to create <a class="reference internal" href="../../glossary.html#term-VBM"><span class="xref std std-term">VBM</span></a> maps, which we study here.</p>
<section id="vbm-analysis-of-aging">
<h2>VBM analysis of aging<a class="headerlink" href="#vbm-analysis-of-aging" title="Link to this heading">¶</a></h2>
<p>We run a standard <a class="reference internal" href="../../glossary.html#term-GLM"><span class="xref std std-term">GLM</span></a> analysis
to study the association between age and gray matter density
from the <a class="reference internal" href="../../glossary.html#term-VBM"><span class="xref std std-term">VBM</span></a> data.
We use only 100 subjects from the OASIS dataset to limit the memory usage.</p>
<p>Note that more power would be obtained from using a larger sample of subjects.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>For more information
see the <a class="reference internal" href="../../modules/description/oasis1.html#oasis-maps"><span class="std std-ref">dataset description</span></a>.</p>
</div>
</section>
<section id="load-oasis-dataset">
<h2>Load Oasis dataset<a class="headerlink" href="#load-oasis-dataset" title="Link to this heading">¶</a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nilearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <a href="../../modules/generated/nilearn.datasets.fetch_icbm152_2009.html#nilearn.datasets.fetch_icbm152_2009" title="nilearn.datasets.fetch_icbm152_2009" class="sphx-glr-backref-module-nilearn-datasets sphx-glr-backref-type-py-function"><span class="n">fetch_icbm152_2009</span></a><span class="p">,</span>
    <a href="../../modules/generated/nilearn.datasets.fetch_icbm152_brain_gm_mask.html#nilearn.datasets.fetch_icbm152_brain_gm_mask" title="nilearn.datasets.fetch_icbm152_brain_gm_mask" class="sphx-glr-backref-module-nilearn-datasets sphx-glr-backref-type-py-function"><span class="n">fetch_icbm152_brain_gm_mask</span></a><span class="p">,</span>
    <a href="../../modules/generated/nilearn.datasets.fetch_oasis_vbm.html#nilearn.datasets.fetch_oasis_vbm" title="nilearn.datasets.fetch_oasis_vbm" class="sphx-glr-backref-module-nilearn-datasets sphx-glr-backref-type-py-function"><span class="n">fetch_oasis_vbm</span></a><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">nilearn.plotting</span><span class="w"> </span><span class="kn">import</span> <a href="../../modules/generated/nilearn.plotting.plot_design_matrix.html#nilearn.plotting.plot_design_matrix" title="nilearn.plotting.plot_design_matrix" class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"><span class="n">plot_design_matrix</span></a><span class="p">,</span> <a href="../../modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map" title="nilearn.plotting.plot_stat_map" class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"><span class="n">plot_stat_map</span></a>

<a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_subjects</span></a> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># more subjects requires more memory</span>

<a href="https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch" title="sklearn.utils.Bunch" class="sphx-glr-backref-module-sklearn-utils sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">oasis_dataset</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.datasets.fetch_oasis_vbm.html#nilearn.datasets.fetch_oasis_vbm" title="nilearn.datasets.fetch_oasis_vbm" class="sphx-glr-backref-module-nilearn-datasets sphx-glr-backref-type-py-function"><span class="n">fetch_oasis_vbm</span></a><span class="p">(</span>
    <a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_subjects</span></a><span class="o">=</span><a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_subjects</span></a><span class="p">,</span>
<span class="p">)</span>
<a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">gray_matter_map_filenames</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">oasis_dataset</span><span class="o">.</span><span class="n">gray_matter_maps</span></a>
<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">age</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">oasis_dataset</span><span class="o">.</span><span class="n">ext_vars</span></a><span class="p">[</span><span class="s2">&quot;age&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[fetch_oasis_vbm] Dataset found in /home/runner/nilearn_data/oasis1
</pre></div>
</div>
<p>Sex is encoded as ‘M’ or ‘F’. Hence, we make it a binary variable.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sex</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">oasis_dataset</span><span class="o">.</span><span class="n">ext_vars</span></a><span class="p">[</span><span class="s2">&quot;mf&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;F&quot;</span>
</pre></div>
</div>
<p>Print basic information on the dataset.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;First gray-matter anatomy image (3D) is located at: &quot;</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">oasis_dataset</span><span class="o">.</span><span class="n">gray_matter_maps</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;First white-matter anatomy image (3D) is located at: &quot;</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">oasis_dataset</span><span class="o">.</span><span class="n">white_matter_maps</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>First gray-matter anatomy image (3D) is located at: /home/runner/nilearn_data/oasis1/OAS1_0001_MR1/mwrc1OAS1_0001_MR1_mpr_anon_fslswapdim_bet.nii.gz
First white-matter anatomy image (3D) is located at: /home/runner/nilearn_data/oasis1/OAS1_0001_MR1/mwrc2OAS1_0001_MR1_mpr_anon_fslswapdim_bet.nii.gz
</pre></div>
</div>
<p>Get a mask image: A mask of the cortex of the ICBM template.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">gm_mask</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.datasets.fetch_icbm152_brain_gm_mask.html#nilearn.datasets.fetch_icbm152_brain_gm_mask" title="nilearn.datasets.fetch_icbm152_brain_gm_mask" class="sphx-glr-backref-module-nilearn-datasets sphx-glr-backref-type-py-function"><span class="n">fetch_icbm152_brain_gm_mask</span></a><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[fetch_icbm152_brain_gm_mask] Dataset found in
/home/runner/nilearn_data/icbm152_2009
</pre></div>
</div>
<p>Resample the mask, since this mask has a different resolution.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nilearn.image</span><span class="w"> </span><span class="kn">import</span> <a href="../../modules/generated/nilearn.image.resample_to_img.html#nilearn.image.resample_to_img" title="nilearn.image.resample_to_img" class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"><span class="n">resample_to_img</span></a>

<a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">mask_img</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.image.resample_to_img.html#nilearn.image.resample_to_img" title="nilearn.image.resample_to_img" class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"><span class="n">resample_to_img</span></a><span class="p">(</span>
    <a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">gm_mask</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">gray_matter_map_filenames</span></a><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;nearest&quot;</span><span class="p">,</span>
    <span class="n">copy_header</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="analyze-data">
<h2>Analyze data<a class="headerlink" href="#analyze-data" title="Link to this heading">¶</a></h2>
<p>First, we create an adequate design matrix with three columns: ‘age’, ‘sex’,
and ‘intercept’.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">intercept</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ones.html#numpy.ones" title="numpy.ones" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">ones</span></a><span class="p">(</span><a href="https://docs.python.org/3.10/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_subjects</span></a><span class="p">)</span>
<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">design_matrix</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span></a><span class="p">(</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.vstack.html#numpy.vstack" title="numpy.vstack" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">vstack</span></a><span class="p">((</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">age</span></a><span class="p">,</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="pandas.core.series.Series" class="sphx-glr-backref-module-pandas-core-series sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sex</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">intercept</span></a><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;age&quot;</span><span class="p">,</span> <span class="s2">&quot;sex&quot;</span><span class="p">,</span> <span class="s2">&quot;intercept&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</pre></div>
</div>
<p>Let’s plot the design matrix.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax1</span></a> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html#matplotlib.pyplot.subplots" title="matplotlib.pyplot.subplots" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.plotting.plot_design_matrix.html#nilearn.plotting.plot_design_matrix" title="nilearn.plotting.plot_design_matrix" class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"><span class="n">plot_design_matrix</span></a><span class="p">(</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">design_matrix</span></a><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html#matplotlib.axes.Axes" title="matplotlib.axes.Axes" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ax1</span></a><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_ylabel.html#matplotlib.axes.Axes.set_ylabel" title="matplotlib.axes.Axes.set_ylabel" class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"><span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span></a><span class="p">(</span><span class="s2">&quot;maps&quot;</span><span class="p">)</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.suptitle.html#matplotlib.figure.Figure.suptitle" title="matplotlib.figure.Figure.suptitle" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-method"><span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span></a><span class="p">(</span><span class="s2">&quot;Second level design matrix&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_oasis_001.png" srcset="../../_images/sphx_glr_plot_oasis_001.png" alt="Second level design matrix" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0.98, &#39;Second level design matrix&#39;)
</pre></div>
</div>
<p>Next, we specify and fit the second-level model when loading the data and
also smooth a little bit to improve statistical behavior.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nilearn.glm.second_level</span><span class="w"> </span><span class="kn">import</span> <a href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel" title="nilearn.glm.second_level.SecondLevelModel" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-class"><span class="n">SecondLevelModel</span></a>

<a href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel" title="nilearn.glm.second_level.SecondLevelModel" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">second_level_model</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel" title="nilearn.glm.second_level.SecondLevelModel" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-class"><span class="n">SecondLevelModel</span></a><span class="p">(</span>
    <span class="n">smoothing_fwhm</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
    <a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">mask_img</span></a><span class="o">=</span><a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">mask_img</span></a><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">minimize_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
<a href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel.fit" title="nilearn.glm.second_level.SecondLevelModel.fit" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-method"><span class="n">second_level_model</span><span class="o">.</span><span class="n">fit</span></a><span class="p">(</span>
    <a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">gray_matter_map_filenames</span></a><span class="p">,</span>
    <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">design_matrix</span></a><span class="o">=</span><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">design_matrix</span></a><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[SecondLevelModel.fit] Fitting second level model. Take a deep breath.
[SecondLevelModel.fit] Loading data from &lt;nibabel.nifti1.Nifti1Image object at
0x7f6110108700&gt;
[SecondLevelModel.fit] Loading mask from &lt;nibabel.nifti1.Nifti1Image object at
0x7f6110108880&gt;
/home/runner/work/nilearn/nilearn/examples/05_glm_second_level/plot_oasis.py:115: UserWarning: [NiftiMasker.fit] Generation of a mask has been requested (imgs != None) while a mask was given at masker creation. Given mask will be used.
  second_level_model.fit(
[SecondLevelModel.fit] Resampling mask
[SecondLevelModel.fit] Finished fit
[SecondLevelModel.fit]
Computation of second level model done in 0.42 seconds.
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<style>#sk-container-id-11 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-11 {
  color: var(--sklearn-color-text);
}

#sk-container-id-11 pre {
  padding: 0;
}

#sk-container-id-11 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-11 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-11 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-11 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-11 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-11 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-11 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-11 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-11 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-11 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-11 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-11 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-11 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-11 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-11 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-11 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-11 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-11 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-11 div.sk-label label.sk-toggleable__label,
#sk-container-id-11 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-11 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-11 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-11 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-11 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-11 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-11 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-11 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-11 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-11 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-11 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-11" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Second Level Model</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-11" type="checkbox" checked><label for="sk-estimator-id-11" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;SecondLevelModel<span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Second Level Model</pre></div> </div></div></div></div>
</div>
<br />
<br /><p>Estimating the <a class="reference internal" href="../../glossary.html#term-contrast"><span class="xref std std-term">contrast</span></a> is very simple.
We can just provide the column name of the design matrix.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">z_map</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel.compute_contrast" title="nilearn.glm.second_level.SecondLevelModel.compute_contrast" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-method"><span class="n">second_level_model</span><span class="o">.</span><span class="n">compute_contrast</span></a><span class="p">(</span>
    <span class="n">second_level_contrast</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">output_type</span><span class="o">=</span><span class="s2">&quot;z_score&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[SecondLevelModel.compute_contrast] Loading data from
&lt;nibabel.nifti1.Nifti1Image object at 0x7f611010bfa0&gt;
[SecondLevelModel.compute_contrast] Smoothing images
[SecondLevelModel.compute_contrast] Extracting region signals
[SecondLevelModel.compute_contrast] Cleaning extracted signals
[SecondLevelModel.compute_contrast] Computing image from signals
</pre></div>
</div>
</section>
<section id="view-results">
<h2>View results<a class="headerlink" href="#view-results" title="Link to this heading">¶</a></h2>
<p>We threshold the second level <a class="reference internal" href="../../glossary.html#term-contrast"><span class="xref std std-term">contrast</span></a>
at FDR-corrected p &lt; 0.05 and plot it.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nilearn.glm</span><span class="w"> </span><span class="kn">import</span> <a href="../../modules/generated/nilearn.glm.threshold_stats_img.html#nilearn.glm.threshold_stats_img" title="nilearn.glm.threshold_stats_img" class="sphx-glr-backref-module-nilearn-glm sphx-glr-backref-type-py-function"><span class="n">threshold_stats_img</span></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">nilearn.plotting</span><span class="w"> </span><span class="kn">import</span> <a href="../../modules/generated/nilearn.plotting.show.html#nilearn.plotting.show" title="nilearn.plotting.show" class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"><span class="n">show</span></a>

<a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">_</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">threshold</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.glm.threshold_stats_img.html#nilearn.glm.threshold_stats_img" title="nilearn.glm.threshold_stats_img" class="sphx-glr-backref-module-nilearn-glm sphx-glr-backref-type-py-function"><span class="n">threshold_stats_img</span></a><span class="p">(</span><a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">z_map</span></a><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">height_control</span><span class="o">=</span><span class="s2">&quot;fdr&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The FDR=.05-corrected threshold is: </span><span class="si">{</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">threshold</span></a><span class="si">:</span><span class="s2">03g</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.figure.html#matplotlib.pyplot.figure" title="matplotlib.pyplot.figure" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<a href="../../modules/generated/nilearn.plotting.displays.ZSlicer.html#nilearn.plotting.displays.ZSlicer" title="nilearn.plotting.displays.ZSlicer" class="sphx-glr-backref-module-nilearn-plotting-displays sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">display</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map" title="nilearn.plotting.plot_stat_map" class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"><span class="n">plot_stat_map</span></a><span class="p">(</span>
    <a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">z_map</span></a><span class="p">,</span>
    <a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">threshold</span></a><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">threshold</span></a><span class="p">,</span>
    <span class="n">display_mode</span><span class="o">=</span><span class="s2">&quot;z&quot;</span><span class="p">,</span>
    <span class="n">cut_coords</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">26</span><span class="p">],</span>
    <span class="n">figure</span><span class="o">=</span><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span>
<span class="p">)</span>
<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.suptitle.html#matplotlib.figure.Figure.suptitle" title="matplotlib.figure.Figure.suptitle" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-method"><span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span></a><span class="p">(</span><span class="s2">&quot;age effect on gray matter density (FDR = .05)&quot;</span><span class="p">)</span>
<a href="../../modules/generated/nilearn.plotting.show.html#nilearn.plotting.show" title="nilearn.plotting.show" class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_oasis_002.png" srcset="../../_images/sphx_glr_plot_oasis_002.png" alt="age effect on gray matter density (FDR = .05)" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>The FDR=.05-corrected threshold is: 2.40175
</pre></div>
</div>
<p>We can also study the effect of sex by computing the contrast, thresholding
it and plot the resulting map.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">z_map</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel.compute_contrast" title="nilearn.glm.second_level.SecondLevelModel.compute_contrast" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-method"><span class="n">second_level_model</span><span class="o">.</span><span class="n">compute_contrast</span></a><span class="p">(</span>
    <span class="n">second_level_contrast</span><span class="o">=</span><span class="s2">&quot;sex&quot;</span><span class="p">,</span>
    <span class="n">output_type</span><span class="o">=</span><span class="s2">&quot;z_score&quot;</span><span class="p">,</span>
<span class="p">)</span>
<a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">_</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">threshold</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.glm.threshold_stats_img.html#nilearn.glm.threshold_stats_img" title="nilearn.glm.threshold_stats_img" class="sphx-glr-backref-module-nilearn-glm sphx-glr-backref-type-py-function"><span class="n">threshold_stats_img</span></a><span class="p">(</span><a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">z_map</span></a><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">height_control</span><span class="o">=</span><span class="s2">&quot;fdr&quot;</span><span class="p">)</span>
<a href="../../modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map" title="nilearn.plotting.plot_stat_map" class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"><span class="n">plot_stat_map</span></a><span class="p">(</span>
    <a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">z_map</span></a><span class="p">,</span>
    <a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">threshold</span></a><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">threshold</span></a><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;sex effect on gray matter density (FDR = .05)&quot;</span><span class="p">,</span>
<span class="p">)</span>
<a href="../../modules/generated/nilearn.plotting.show.html#nilearn.plotting.show" title="nilearn.plotting.show" class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_oasis_003.png" srcset="../../_images/sphx_glr_plot_oasis_003.png" alt="plot oasis" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[SecondLevelModel.compute_contrast] Loading data from
&lt;nibabel.nifti1.Nifti1Image object at 0x7f612ab8c3a0&gt;
[SecondLevelModel.compute_contrast] Smoothing images
[SecondLevelModel.compute_contrast] Extracting region signals
[SecondLevelModel.compute_contrast] Cleaning extracted signals
[SecondLevelModel.compute_contrast] Computing image from signals
</pre></div>
</div>
<p>Note that there does not seem to be any significant effect of sex on
gray matter density on that dataset.</p>
</section>
<section id="saving-model-outputs-to-disk">
<h2>Saving model outputs to disk<a class="headerlink" href="#saving-model-outputs-to-disk" title="Link to this heading">¶</a></h2>
<p>It can be useful to quickly generate a portable, ready-to-view report with
most of the pertinent information.
We can do this by saving the output of the GLM to disk
including an HTML report.
This is easy to do if you have a fitted model and the list of contrasts,
which we do here.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">nilearn.interfaces.bids</span><span class="w"> </span><span class="kn">import</span> <a href="../../modules/generated/nilearn.interfaces.bids.save_glm_to_bids.html#nilearn.interfaces.bids.save_glm_to_bids" title="nilearn.interfaces.bids.save_glm_to_bids" class="sphx-glr-backref-module-nilearn-interfaces-bids sphx-glr-backref-type-py-function"><span class="n">save_glm_to_bids</span></a>

<a href="https://docs.python.org/3.10/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_dir</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.10/library/pathlib.html#pathlib.Path.cwd" title="pathlib.Path.cwd" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-method"><span class="n">Path</span><span class="o">.</span><span class="n">cwd</span></a><span class="p">()</span> <span class="o">/</span> <span class="s2">&quot;results&quot;</span> <span class="o">/</span> <span class="s2">&quot;plot_oasis&quot;</span>
<a href="https://docs.python.org/3.10/library/pathlib.html#pathlib.Path.mkdir" title="pathlib.Path.mkdir" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-method"><span class="n">output_dir</span><span class="o">.</span><span class="n">mkdir</span></a><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<a href="https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch" title="sklearn.utils.Bunch" class="sphx-glr-backref-module-sklearn-utils sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">icbm152_2009</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.datasets.fetch_icbm152_2009.html#nilearn.datasets.fetch_icbm152_2009" title="nilearn.datasets.fetch_icbm152_2009" class="sphx-glr-backref-module-nilearn-datasets sphx-glr-backref-type-py-function"><span class="n">fetch_icbm152_2009</span></a><span class="p">()</span>

<a href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel" title="nilearn.glm.second_level.SecondLevelModel" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">second_level_model</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.interfaces.bids.save_glm_to_bids.html#nilearn.interfaces.bids.save_glm_to_bids" title="nilearn.interfaces.bids.save_glm_to_bids" class="sphx-glr-backref-module-nilearn-interfaces-bids sphx-glr-backref-type-py-function"><span class="n">save_glm_to_bids</span></a><span class="p">(</span>
    <a href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel" title="nilearn.glm.second_level.SecondLevelModel" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">second_level_model</span></a><span class="p">,</span>
    <span class="n">contrasts</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;age&quot;</span><span class="p">,</span> <span class="s2">&quot;sex&quot;</span><span class="p">],</span>
    <span class="n">out_dir</span><span class="o">=</span><a href="https://docs.python.org/3.10/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_dir</span></a> <span class="o">/</span> <span class="s2">&quot;derivatives&quot;</span> <span class="o">/</span> <span class="s2">&quot;nilearn_glm&quot;</span><span class="p">,</span>
    <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;ageEffectOnGM&quot;</span><span class="p">,</span>
    <span class="n">bg_img</span><span class="o">=</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch" title="sklearn.utils.Bunch" class="sphx-glr-backref-module-sklearn-utils sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">icbm152_2009</span></a><span class="p">[</span><span class="s2">&quot;t1&quot;</span><span class="p">],</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">height_control</span><span class="o">=</span><span class="s2">&quot;fdr&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[fetch_icbm152_2009] Dataset found in /home/runner/nilearn_data/icbm152_2009
[save_glm_to_bids] Saving mask...
[save_glm_to_bids] Generating design matrices figures...
[save_glm_to_bids] Generating contrast matrices figures...
[save_glm_to_bids] Saving contrast-level statistical maps...
[SecondLevelModel._make_stat_maps] Loading data from &lt;nibabel.nifti1.Nifti1Image
object at 0x7f6111633220&gt;
[SecondLevelModel._make_stat_maps] Smoothing images
[SecondLevelModel._make_stat_maps] Extracting region signals
[SecondLevelModel._make_stat_maps] Cleaning extracted signals
[SecondLevelModel._make_stat_maps] Computing image from signals
[SecondLevelModel._make_stat_maps] Computing image from signals
[SecondLevelModel._make_stat_maps] Computing image from signals
[SecondLevelModel._make_stat_maps] Computing image from signals
[SecondLevelModel._make_stat_maps] Computing image from signals
[SecondLevelModel._make_stat_maps] Loading data from &lt;nibabel.nifti1.Nifti1Image
object at 0x7f610f233c10&gt;
[SecondLevelModel._make_stat_maps] Smoothing images
[SecondLevelModel._make_stat_maps] Extracting region signals
[SecondLevelModel._make_stat_maps] Cleaning extracted signals
[SecondLevelModel._make_stat_maps] Computing image from signals
[SecondLevelModel._make_stat_maps] Computing image from signals
[SecondLevelModel._make_stat_maps] Computing image from signals
[SecondLevelModel._make_stat_maps] Computing image from signals
[SecondLevelModel._make_stat_maps] Computing image from signals
/home/runner/work/nilearn/nilearn/examples/05_glm_second_level/plot_oasis.py:187: UserWarning: &#39;threshold=3.09&#39; will not be used with &#39;height_control=&#39;fdr&#39;&#39;. &#39;threshold&#39; is only used when &#39;height_control=None&#39;. Set &#39;threshold&#39; to &#39;3.0&#39; to avoid this warning.
  second_level_model = save_glm_to_bids(
/home/runner/work/nilearn/nilearn/examples/05_glm_second_level/plot_oasis.py:187: UserWarning: The given float value must not exceed 2.75855356998246e-06. But, you have given threshold=inf.
  second_level_model = save_glm_to_bids(
/home/runner/work/nilearn/nilearn/examples/05_glm_second_level/plot_oasis.py:187: UserWarning: The given float value must not exceed 0.0. But, you have given threshold=inf.
  second_level_model = save_glm_to_bids(
/home/runner/work/nilearn/nilearn/examples/05_glm_second_level/plot_oasis.py:187: UserWarning: Attention: No clusters with stat higher than inf
  second_level_model = save_glm_to_bids(
/home/runner/work/nilearn/nilearn/examples/05_glm_second_level/plot_oasis.py:187: UserWarning: &#39;threshold=3.09&#39; will not be used with &#39;height_control=&#39;fdr&#39;&#39;. &#39;threshold&#39; is only used when &#39;height_control=None&#39;. Set &#39;threshold&#39; to &#39;3.0&#39; to avoid this warning.
  second_level_model = save_glm_to_bids(
/home/runner/work/nilearn/nilearn/examples/05_glm_second_level/plot_oasis.py:187: UserWarning: The given float value must not exceed 0.00743128949229107. But, you have given threshold=inf.
  second_level_model = save_glm_to_bids(
/home/runner/work/nilearn/nilearn/examples/05_glm_second_level/plot_oasis.py:187: UserWarning: The given float value must not exceed 0.0. But, you have given threshold=inf.
  second_level_model = save_glm_to_bids(
/home/runner/work/nilearn/nilearn/examples/05_glm_second_level/plot_oasis.py:187: UserWarning: Attention: No clusters with stat higher than inf
  second_level_model = save_glm_to_bids(
[save_glm_to_bids] Saving model level statistical maps...
[SecondLevelModel.residuals] Computing image from signals
[SecondLevelModel.r_square] Computing image from signals
[save_glm_to_bids] Generating HTML...
/home/runner/work/nilearn/nilearn/examples/05_glm_second_level/plot_oasis.py:187: UserWarning: &#39;threshold=3.09&#39; will not be used with &#39;height_control=&#39;fdr&#39;&#39;. &#39;threshold&#39; is only used when &#39;height_control=None&#39;. Set &#39;threshold&#39; to &#39;3.0&#39; to avoid this warning.
  second_level_model = save_glm_to_bids(
/home/runner/work/nilearn/nilearn/examples/05_glm_second_level/plot_oasis.py:187: UserWarning: &#39;threshold=3.09&#39; will not be used with &#39;height_control=&#39;fdr&#39;&#39;. &#39;threshold&#39; is only used when &#39;height_control=None&#39;. Set &#39;threshold&#39; to &#39;3.0&#39; to avoid this warning.
  second_level_model = save_glm_to_bids(
/home/runner/work/nilearn/nilearn/examples/05_glm_second_level/plot_oasis.py:187: UserWarning: The given float value must not exceed 3.800631000800836. But, you have given threshold=inf.
  second_level_model = save_glm_to_bids(
/home/runner/work/nilearn/nilearn/examples/05_glm_second_level/plot_oasis.py:187: UserWarning: The given float value must not exceed 0.0. But, you have given threshold=inf.
  second_level_model = save_glm_to_bids(
/home/runner/work/nilearn/nilearn/examples/05_glm_second_level/plot_oasis.py:187: UserWarning: Attention: No clusters with stat higher than inf
  second_level_model = save_glm_to_bids(
/home/runner/work/nilearn/nilearn/examples/05_glm_second_level/plot_oasis.py:187: UserWarning: empty mask
  second_level_model = save_glm_to_bids(
</pre></div>
</div>
<p>View the generated files</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">files</span></a> <span class="o">=</span> <span class="nb">sorted</span><span class="p">((</span><a href="https://docs.python.org/3.10/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_dir</span></a> <span class="o">/</span> <span class="s2">&quot;derivatives&quot;</span> <span class="o">/</span> <span class="s2">&quot;nilearn_glm&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;**/*&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">relative_to</span><span class="p">(</span><a href="https://docs.python.org/3.10/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_dir</span></a><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <a href="https://docs.python.org/3.10/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">files</span></a><span class="p">]))</span>

<span class="c1">#  %%</span>
<span class="c1"># Generate a report and view it.</span>
<span class="c1"># If no new contrast is passed to ``generate_report``,</span>
<span class="c1"># the results saved to disk will be reused to generate the report.</span>

<a href="../../modules/generated/nilearn.reporting.HTMLReport.html#nilearn.reporting.HTMLReport" title="nilearn.reporting.HTMLReport" class="sphx-glr-backref-module-nilearn-reporting sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">report</span></a> <span class="o">=</span> <a href="../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel.generate_report" title="nilearn.glm.second_level.SecondLevelModel.generate_report" class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-method"><span class="n">second_level_model</span><span class="o">.</span><span class="n">generate_report</span></a><span class="p">(</span>
    <span class="n">bg_img</span><span class="o">=</span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch" title="sklearn.utils.Bunch" class="sphx-glr-backref-module-sklearn-utils sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">icbm152_2009</span></a><span class="p">[</span><span class="s2">&quot;t1&quot;</span><span class="p">],</span>
    <span class="n">plot_type</span><span class="o">=</span><span class="s2">&quot;glass&quot;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">height_control</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span>
<a href="../../modules/generated/nilearn.reporting.HTMLReport.html#nilearn.reporting.HTMLReport.save_as_html" title="nilearn.reporting.HTMLReport.save_as_html" class="sphx-glr-backref-module-nilearn-reporting sphx-glr-backref-type-py-method"><span class="n">report</span><span class="o">.</span><span class="n">save_as_html</span></a><span class="p">(</span><a href="https://docs.python.org/3.10/library/pathlib.html#pathlib.PosixPath" title="pathlib.PosixPath" class="sphx-glr-backref-module-pathlib sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_dir</span></a> <span class="o">/</span> <span class="s2">&quot;report.html&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>derivatives/nilearn_glm/dataset_description.json
derivatives/nilearn_glm/group
derivatives/nilearn_glm/group/ageEffectOnGM_contrast-age_clusters.json
derivatives/nilearn_glm/group/ageEffectOnGM_contrast-age_clusters.tsv
derivatives/nilearn_glm/group/ageEffectOnGM_contrast-age_design.png
derivatives/nilearn_glm/group/ageEffectOnGM_contrast-age_stat-effect_statmap.nii.gz
derivatives/nilearn_glm/group/ageEffectOnGM_contrast-age_stat-p_statmap.nii.gz
derivatives/nilearn_glm/group/ageEffectOnGM_contrast-age_stat-t_statmap.nii.gz
derivatives/nilearn_glm/group/ageEffectOnGM_contrast-age_stat-variance_statmap.nii.gz
derivatives/nilearn_glm/group/ageEffectOnGM_contrast-age_stat-z_statmap.nii.gz
derivatives/nilearn_glm/group/ageEffectOnGM_contrast-sex_clusters.json
derivatives/nilearn_glm/group/ageEffectOnGM_contrast-sex_clusters.tsv
derivatives/nilearn_glm/group/ageEffectOnGM_contrast-sex_design.png
derivatives/nilearn_glm/group/ageEffectOnGM_contrast-sex_stat-effect_statmap.nii.gz
derivatives/nilearn_glm/group/ageEffectOnGM_contrast-sex_stat-p_statmap.nii.gz
derivatives/nilearn_glm/group/ageEffectOnGM_contrast-sex_stat-t_statmap.nii.gz
derivatives/nilearn_glm/group/ageEffectOnGM_contrast-sex_stat-variance_statmap.nii.gz
derivatives/nilearn_glm/group/ageEffectOnGM_contrast-sex_stat-z_statmap.nii.gz
derivatives/nilearn_glm/group/ageEffectOnGM_corrdesign.png
derivatives/nilearn_glm/group/ageEffectOnGM_design.png
derivatives/nilearn_glm/group/ageEffectOnGM_design.tsv
derivatives/nilearn_glm/group/ageEffectOnGM_mask.nii.gz
derivatives/nilearn_glm/group/ageEffectOnGM_report.html
derivatives/nilearn_glm/group/ageEffectOnGM_stat-errorts_statmap.nii.gz
derivatives/nilearn_glm/group/ageEffectOnGM_stat-rsquared_statmap.nii.gz
derivatives/nilearn_glm/group/ageEffectOnGM_statmap.json
threshold=3.09 current_default=3.09 old_default=3.09
[SecondLevelModel.generate_report] Generating contrast-level figures...
[SecondLevelModel.generate_report] Generating design matrices figures...
[SecondLevelModel.generate_report] Generating contrast matrices figures...
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (3 minutes 21.340 seconds)</p>
<p><strong>Estimated memory usage:</strong>  1681 MB</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-05-glm-second-level-plot-oasis-py">
<div class="binder-badge docutils container">
<a class="reference external image-reference" href="https://mybinder.org/v2/gh/nilearn/nilearn/main?urlpath=lab/tree/notebooks/auto_examples/05_glm_second_level/plot_oasis.ipynb"><img alt="Launch binder" src="../../_images/binder_badge_logo5.svg" style="width: 150px;" />
</a>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/bc534df441f349d0f6e70283606cb03c/plot_oasis.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_oasis.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/1020ea2b51f8e38daf607e192d4bdc5d/plot_oasis.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_oasis.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/4f6c009516d6956f180d8a05a141b383/plot_oasis.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">plot_oasis.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../06_manipulating_images/index.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Manipulating brain image volumes</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="plot_thresholding.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Statistical testing of a second-level analysis</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; The nilearn developers
- Code and documentation distributed under BSD license.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link fa-brands fa-solid fa-github fa-2x" href="https://github.com/nilearn/nilearn" aria-label="GitHub"></a>
              <a class="muted-link fa-brands fa-solid fa-bluesky fa-2x" href="https://bsky.app/profile/nilearn.bsky.social" aria-label="Bluesky"></a>
              <a class="muted-link fa-brands fa-solid fa-mastodon fa-2x" href="https://fosstodon.org/@nilearn" aria-label="Mastodon"></a>
              <a class="muted-link fa-brands fa-solid fa-discord fa-2x" href="https://discord.com/invite/SsQABEJHkZ" aria-label="Discord"></a>
              <a class="muted-link fa-brands fa-solid fa-youtube fa-2x" href="https://www.youtube.com/channel/UCU6BMAi2zOhNFnDkbdevmPw" aria-label="Youtube"></a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Voxel-Based Morphometry on OASIS dataset</a><ul>
<li><a class="reference internal" href="#vbm-analysis-of-aging">VBM analysis of aging</a></li>
<li><a class="reference internal" href="#load-oasis-dataset">Load Oasis dataset</a></li>
<li><a class="reference internal" href="#analyze-data">Analyze data</a></li>
<li><a class="reference internal" href="#view-results">View results</a></li>
<li><a class="reference internal" href="#saving-model-outputs-to-disk">Saving model outputs to disk</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=4ea706d9"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    </body>
</html>