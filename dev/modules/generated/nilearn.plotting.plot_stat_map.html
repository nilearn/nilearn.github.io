
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta property="og:title" content="8.10.10. nilearn.plotting.plot_stat_map" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://nilearn.github.io/modules/generated/nilearn.plotting.plot_stat_map.html" />
  <meta property="og:site_name" content="Nilearn" />
  <meta property="og:description" content="Examples using nilearn.plotting.plot_stat_map: 3D and 4D niimgs: handling and visualizing 3D and 4D niimgs: handling and visualizing, Intro to GLM Analysis: a single-session, single-subject fMRI da..." />
  <meta property="og:image" content="../../_images/sphx_glr_plot_3d_and_4d_niimg_thumb.png" />
  <meta property="og:image:alt" content="3D and 4D niimgs: handling and visualizing" />
  
    <title>Nilearn: Statistical Analysis for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/nature.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="8.10.11. nilearn.plotting.plot_glass_brain" href="nilearn.plotting.plot_glass_brain.html" />
    <link rel="prev" title="8.10.9. nilearn.plotting.plot_roi" href="nilearn.plotting.plot_roi.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">


<script type="text/javascript">
function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});
</script>
<script type="text/javascript">
function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../../index.html">
      <img src="../../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../../manipulating_images/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Statistics for NeuroImaging in Python</h2>
  </div>
  <div class="search_form">
    <div class="gcse-search" id="cse" style="width: 100%;"></div>
    <script>
      (function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </div>
</div>



<div class=related-wrapper>
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="nilearn.plotting.plot_glass_brain.html" title="8.10.11. nilearn.plotting.plot_glass_brain"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="nilearn.plotting.plot_roi.html" title="8.10.9. nilearn.plotting.plot_roi"
             accesskey="P">previous</a> |</li>
<li><a href="../../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li><a href="../../glossary.html">Glossary</a>|&nbsp;</li>
<li><a href="../../bibliography.html">Bibliography</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../reference.html" accesskey="U"><span class="section-number">8. </span>Reference documentation: all nilearn functions</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Nilearn: Statistical Analysis for NeuroImaging in Python</a></li> 
      </ul>
    </div>
</div>

<div class="devel-alert-banner">
This is documentation for the <em>unstable development version</em> of Nilearn,
the current stable version is available <a href="https://nilearn.github.io/stable/index.html">here</a>.
</div>

  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page is a reference documentation. It only explains the
function signature, and not how to use it. Please refer to the
<a class="reference internal" href="../../user_guide.html#user-guide"><span class="std std-ref">user guide</span></a> for the big picture.</p>
</div>
<section id="nilearn-plotting-plot-stat-map">
<h1><span class="section-number">8.10.10. </span>nilearn.plotting.plot_stat_map<a class="headerlink" href="#nilearn-plotting-plot-stat-map" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="nilearn.plotting.plot_stat_map">
<span class="sig-prename descclassname"><span class="pre">nilearn.plotting.</span></span><span class="sig-name descname"><span class="pre">plot_stat_map</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">stat_map_img</span></em>, <em class="sig-param"><span class="pre">bg_img=&lt;MNI152Template&gt;</span></em>, <em class="sig-param"><span class="pre">cut_coords=None</span></em>, <em class="sig-param"><span class="pre">output_file=None</span></em>, <em class="sig-param"><span class="pre">display_mode='ortho'</span></em>, <em class="sig-param"><span class="pre">colorbar=True</span></em>, <em class="sig-param"><span class="pre">figure=None</span></em>, <em class="sig-param"><span class="pre">axes=None</span></em>, <em class="sig-param"><span class="pre">title=None</span></em>, <em class="sig-param"><span class="pre">threshold=1e-06</span></em>, <em class="sig-param"><span class="pre">annotate=True</span></em>, <em class="sig-param"><span class="pre">draw_cross=True</span></em>, <em class="sig-param"><span class="pre">black_bg='auto'</span></em>, <em class="sig-param"><span class="pre">cmap=&lt;matplotlib.colors.LinearSegmentedColormap</span> <span class="pre">object&gt;</span></em>, <em class="sig-param"><span class="pre">symmetric_cbar='auto'</span></em>, <em class="sig-param"><span class="pre">dim='auto'</span></em>, <em class="sig-param"><span class="pre">vmax=None</span></em>, <em class="sig-param"><span class="pre">resampling_interpolation='continuous'</span></em>, <em class="sig-param"><span class="pre">**kwargs</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/3a2daae2/nilearn/plotting/img_plotting.py#L876"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.plotting.plot_stat_map" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot cuts of an ROI/mask image (by default 3 cuts: Frontal, Axial, and
Lateral)</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>stat_map_img</strong><span class="classifier">Niimg-like object</span></dt><dd><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
The statistical map image</p>
</dd>
<dt><strong>bg_img</strong><span class="classifier">Niimg-like object, optional</span></dt><dd><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">input_output</a>.
The background image to plot on top of.
If nothing is specified, the MNI152 template will be used.
To turn off background image, just pass “bg_img=None”.
Default=MNI152TEMPLATE.</p>
</dd>
<dt><strong>cut_coords</strong><span class="classifier">None, a <a class="reference external" href="https://docs.python.org/3.8/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a>, or <a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>, optional</span></dt><dd><p>The MNI coordinates of the point where the cut is performed.</p>
<blockquote>
<div><ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">display_mode</span></code> is ‘ortho’ or ‘tiled’, this should
be a 3-tuple: <code class="docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">y,</span> <span class="pre">z)</span></code></p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">display_mode</span> <span class="pre">==</span> <span class="pre">'x'</span></code>, ‘y’, or ‘z’, then these are
the coordinates of each cut in the corresponding direction.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">None</span></code> is given, the cuts are calculated automatically.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">display_mode</span></code> is ‘mosaic’, and the number of cuts is the same
for all directions, <code class="docutils literal notranslate"><span class="pre">cut_coords</span></code> can be specified as an integer.
It can also be a length 3 tuple specifying the number of cuts for
every direction if these are different.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <code class="docutils literal notranslate"><span class="pre">display_mode</span></code> is ‘x’, ‘y’ or ‘z’, <code class="docutils literal notranslate"><span class="pre">cut_coords</span></code> can be
an integer, in which case it specifies the number of
cuts to perform.</p>
</div>
</div></blockquote>
</dd>
<dt><strong>output_file</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.8/library/stdtypes.html#str" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code></a>, or None, optional</span></dt><dd><p>The name of an image file to export the plot to. Valid extensions
are .png, .pdf, .svg. If <code class="docutils literal notranslate"><span class="pre">output_file</span></code> is not None, the plot
is saved to a file, and the display is closed.</p>
</dd>
<dt><strong>display_mode</strong><span class="classifier">{‘ortho’, ‘tiled’, ‘mosaic’,’x’,’y’, ‘z’, ‘yx’, ‘xz’, ‘yz’}, optional</span></dt><dd><p>Choose the direction of the cuts:</p>
<blockquote>
<div><ul class="simple">
<li><p>‘x’: sagittal</p></li>
<li><p>‘y’: coronal</p></li>
<li><p>‘z’: axial</p></li>
<li><p>‘ortho’: three cuts are performed in orthogonal
directions</p></li>
<li><p>‘tiled’: three cuts are performed and arranged
in a 2x2 grid</p></li>
<li><p>‘mosaic’: three cuts are performed along
multiple rows and columns</p></li>
</ul>
</div></blockquote>
<p>Default=’ortho’.</p>
</dd>
<dt><strong>colorbar</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#bool" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code></a>, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, display a colorbar on the right of the plots.
Default=True.</p>
</dd>
<dt><strong>figure</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#int" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code></a>, or <a class="reference external" href="https://matplotlib.org/api/figure_api.html#matplotlib.figure.Figure" title="(in Matplotlib v3.4.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">matplotlib.figure.Figure</span></code></a>, or None,  optional</span></dt><dd><p>Matplotlib figure used or its number. If <code class="docutils literal notranslate"><span class="pre">None</span></code> is given, a
new figure is created.</p>
</dd>
<dt><strong>axes</strong><span class="classifier"><a class="reference external" href="https://matplotlib.org/api/axes_api.html#matplotlib.axes.Axes" title="(in Matplotlib v3.4.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">matplotlib.axes.Axes</span></code></a>, or 4 tupleof <a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a>: (xmin, ymin, width, height), optional</span></dt><dd><p>The axes, or the coordinates, in matplotlib figure
space, of the axes used to display the plot.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the complete figure is used.</p>
</dd>
<dt><strong>title</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.8/library/stdtypes.html#str" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code></a>, or None, optional</span></dt><dd><p>The title displayed on the figure.
Default=None.</p>
</dd>
<dt><strong>threshold</strong><span class="classifier">a number, None, or ‘auto’, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">None</span></code> is given, the image is not thresholded.
If a number is given, it is used to threshold the image:
values below the threshold (in absolute value) are plotted
as transparent. If ‘auto’ is given, the threshold is determined
magically by analysis of the image.
Default=1e-6.</p>
</dd>
<dt><strong>annotate</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#bool" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code></a>, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">annotate</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, positions and left/right annotation
are added to the plot. Default=True.</p>
</dd>
<dt><strong>draw_cross</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#bool" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code></a>, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">draw_cross</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, a cross is drawn on the plot to indicate
the cut position. Default=True.</p>
</dd>
<dt><strong>black_bg</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#bool" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code></a>, or ‘auto’, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the background of the image is set to be black.
If you wish to save figures with a black background, you
will need to pass facecolor=’k’, edgecolor=’k’
to <a class="reference external" href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.savefig.html#matplotlib.pyplot.savefig" title="(in Matplotlib v3.4.3)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.savefig</span></code></a>.
Default=’auto’.</p>
</dd>
<dt><strong>cmap</strong><span class="classifier"><a class="reference external" href="https://matplotlib.org/api/_as_gen/matplotlib.colors.Colormap.html#matplotlib.colors.Colormap" title="(in Matplotlib v3.4.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">matplotlib.colors.Colormap</span></code></a>, or <a class="reference external" href="https://docs.python.org/3.8/library/stdtypes.html#str" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code></a>, optional</span></dt><dd><p>The colormap to use. Either a string which is a name of
a matplotlib colormap, or a matplotlib colormap object.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The ccolormap <em>must</em> be symmetrical.</p>
</div>
<p>Default=`plt.cm.cold_hot`.</p>
</dd>
<dt><strong>symmetric_cbar</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#bool" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code></a>, or ‘auto’, optional</span></dt><dd><p>Specifies whether the colorbar should range from <code class="docutils literal notranslate"><span class="pre">-vmax</span></code> to <code class="docutils literal notranslate"><span class="pre">vmax</span></code>
or from <code class="docutils literal notranslate"><span class="pre">vmin</span></code> to <code class="docutils literal notranslate"><span class="pre">vmax</span></code>. Setting to ‘auto’ will select the latter
if the range of the whole image is either positive or negative.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The colormap will always range from <code class="docutils literal notranslate"><span class="pre">-vmax</span></code> to <code class="docutils literal notranslate"><span class="pre">vmax</span></code>.</p>
</div>
<p>Default=’auto’.</p>
</dd>
<dt><strong>dim</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a>, or ‘auto’, optional</span></dt><dd><p>Dimming factor applied to background image. By default, automatic
heuristics are applied based upon the background image intensity.
Accepted float values, where a typical span is between -2 and 2
(-2 = increase contrast; 2 = decrease contrast), but larger values
can be used for a more pronounced effect. 0 means no dimming.
Default=’auto’.</p>
</dd>
<dt><strong>vmax</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a>, optional</span></dt><dd><p>Upper bound of the colormap. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the max of the image is used.
Passed to <a class="reference external" href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html#matplotlib.pyplot.imshow" title="(in Matplotlib v3.4.3)"><code class="xref py py-func docutils literal notranslate"><span class="pre">matplotlib.pyplot.imshow</span></code></a>.</p>
</dd>
<dt><strong>resampling_interpolation</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.8/library/stdtypes.html#str" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code></a>, optional</span></dt><dd><p>Interpolation to use when resampling the image to
the destination space. Can be:</p>
<blockquote>
<div><ul>
<li><p>“continuous”: use 3rd-order spline interpolation</p></li>
<li><p>“nearest”: use nearest-neighbor mapping.</p>
<blockquote>
<div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>“nearest” is faster but can be noisier in some cases.</p>
</div>
</div></blockquote>
</li>
</ul>
</div></blockquote>
<p>Default=’continuous’.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="nilearn.plotting.plot_anat.html#nilearn.plotting.plot_anat" title="nilearn.plotting.plot_anat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.plotting.plot_anat</span></code></a></dt><dd><p>To simply plot anatomical images</p>
</dd>
<dt><a class="reference internal" href="nilearn.plotting.plot_epi.html#nilearn.plotting.plot_epi" title="nilearn.plotting.plot_epi"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.plotting.plot_epi</span></code></a></dt><dd><p>To simply plot raw EPI images</p>
</dd>
<dt><a class="reference internal" href="nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain" title="nilearn.plotting.plot_glass_brain"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.plotting.plot_glass_brain</span></code></a></dt><dd><p>To plot maps in a glass brain</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Arrays should be passed in numpy convention: (x, y, z) ordered.</p>
<p>For visualization, non-finite values found in passed ‘stat_map_img’ or
‘bg_img’ are set to zero.</p>
</dd></dl>

<section id="examples-using-nilearn-plotting-plot-stat-map">
<h2><span class="section-number">8.10.10.1. </span>Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.plotting.plot_stat_map</span></code><a class="headerlink" href="#examples-using-nilearn-plotting-plot-stat-map" title="Permalink to this headline">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="Here we discover how to work with 3D and 4D niimgs."><figure class="align-default" id="id1">
<img alt="3D and 4D niimgs: handling and visualizing" src="../../_images/sphx_glr_plot_3d_and_4d_niimg_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/plot_3d_and_4d_niimg.html#sphx-glr-auto-examples-plot-3d-and-4d-niimg-py"><span class="std std-ref">3D and 4D niimgs: handling and visualizing</span></a></span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this tutorial, we use a General Linear Model (:term:`GLM`) to compare the fMRI signal during..."><figure class="align-default" id="id2">
<img alt="Intro to GLM Analysis: a single-session, single-subject fMRI dataset" src="../../_images/sphx_glr_plot_single_subject_single_run_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/plot_single_subject_single_run.html#sphx-glr-auto-examples-plot-single-subject-single-run-py"><span class="std std-ref">Intro to GLM Analysis: a single-session, single-subject fMRI dataset</span></a></span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="Visualizing a probabilistic atlas requires visualizing the different maps that compose it."><figure class="align-default" id="id3">
<img alt="Visualizing a probabilistic atlas: the default mode in the MSDL atlas" src="../../_images/sphx_glr_plot_overlay_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/01_plotting/plot_overlay.html#sphx-glr-auto-examples-01-plotting-plot-overlay-py"><span class="std std-ref">Visualizing a probabilistic atlas: the default mode in the MSDL atlas</span></a></span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="The dim argument controls the contrast of the background."><figure class="align-default" id="id4">
<img alt="Controlling the contrast of the background when plotting" src="../../_images/sphx_glr_plot_dim_plotting_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/01_plotting/plot_dim_plotting.html#sphx-glr-auto-examples-01-plotting-plot-dim-plotting-py"><span class="std std-ref">Controlling the contrast of the background when plotting</span></a></span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="Nilearn comes with a set of plotting functions for easy visualization of Nifti-like images such..."><figure class="align-default" id="id5">
<img alt="Plotting tools in nilearn" src="../../_images/sphx_glr_plot_demo_plotting_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/01_plotting/plot_demo_plotting.html#sphx-glr-auto-examples-01-plotting-plot-demo-plotting-py"><span class="std std-ref">Plotting tools in nilearn</span></a></span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="project a 3D statistical map onto a cortical mesh using nilearn.surface.vol_to_surf. Display a ..."><figure class="align-default" id="id6">
<img alt="Making a surface plot of a 3D statistical map" src="../../_images/sphx_glr_plot_3d_map_to_surface_projection_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/01_plotting/plot_3d_map_to_surface_projection.html#sphx-glr-auto-examples-01-plotting-plot-3d-map-to-surface-projection-py"><span class="std std-ref">Making a surface plot of a 3D statistical map</span></a></span><a class="headerlink" href="#id6" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we demonstrate how to use plotting options from nilearn essential in visualizi..."><figure class="align-default" id="id7">
<img alt="More plotting tools from nilearn" src="../../_images/sphx_glr_plot_demo_more_plotting_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/01_plotting/plot_demo_more_plotting.html#sphx-glr-auto-examples-01-plotting-plot-demo-more-plotting-py"><span class="std std-ref">More plotting tools from nilearn</span></a></span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we use fast ensembling of regularized models (FREM) to solve a regression prob..."><figure class="align-default" id="id8">
<img alt="FREM on Jimura et al &quot;mixed gambles&quot; dataset." src="../../_images/sphx_glr_plot_mixed_gambles_frem_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_mixed_gambles_frem.html#sphx-glr-auto-examples-02-decoding-plot-mixed-gambles-frem-py"><span class="std std-ref">FREM on Jimura et al “mixed gambles” dataset.</span></a></span><a class="headerlink" href="#id8" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example uses fast ensembling of regularized models (FREM) to decode a face vs house discri..."><figure class="align-default" id="id9">
<img alt="Decoding with FREM: face vs house object recognition" src="../../_images/sphx_glr_plot_haxby_frem_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_frem.html#sphx-glr-auto-examples-02-decoding-plot-haxby-frem-py"><span class="std std-ref">Decoding with FREM: face vs house object recognition</span></a></span><a class="headerlink" href="#id9" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="Predicting age from gray-matter concentration maps from OASIS dataset. Note that age is a conti..."><figure class="align-default" id="id10">
<img alt="Voxel-Based Morphometry on Oasis dataset with Space-Net prior" src="../../_images/sphx_glr_plot_oasis_vbm_space_net_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_oasis_vbm_space_net.html#sphx-glr-auto-examples-02-decoding-plot-oasis-vbm-space-net-py"><span class="std std-ref">Voxel-Based Morphometry on Oasis dataset with Space-Net prior</span></a></span><a class="headerlink" href="#id10" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example does a simple but efficient decoding on the Haxby dataset: using a feature selecti..."><figure class="align-default" id="id11">
<img alt="Decoding with ANOVA + SVM: face vs house in the Haxby dataset" src="../../_images/sphx_glr_plot_haxby_anova_svm_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_anova_svm.html#sphx-glr-auto-examples-02-decoding-plot-haxby-anova-svm-py"><span class="std std-ref">Decoding with ANOVA + SVM: face vs house in the Haxby dataset</span></a></span><a class="headerlink" href="#id11" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="Searchlight analysis requires fitting a classifier a large amount of times. As a result, it is ..."><figure class="align-default" id="id12">
<img alt="Searchlight analysis of face vs house recognition" src="../../_images/sphx_glr_plot_haxby_searchlight_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_searchlight.html#sphx-glr-auto-examples-02-decoding-plot-haxby-searchlight-py"><span class="std std-ref">Searchlight analysis of face vs house recognition</span></a></span><a class="headerlink" href="#id12" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we compare different classifiers on a visual object recognition decoding task."><figure class="align-default" id="id13">
<img alt="Different classifiers in decoding the Haxby dataset" src="../../_images/sphx_glr_plot_haxby_different_estimators_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_different_estimators.html#sphx-glr-auto-examples-02-decoding-plot-haxby-different-estimators-py"><span class="std std-ref">Different classifiers in decoding the Haxby dataset</span></a></span><a class="headerlink" href="#id13" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example uses Voxel-Based Morphometry (VBM) to study the relationship between aging and gra..."><figure class="align-default" id="id14">
<img alt="Voxel-Based Morphometry on Oasis dataset" src="../../_images/sphx_glr_plot_oasis_vbm_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_oasis_vbm.html#sphx-glr-auto-examples-02-decoding-plot-oasis-vbm-py"><span class="std std-ref">Voxel-Based Morphometry on Oasis dataset</span></a></span><a class="headerlink" href="#id14" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example partly reproduces the encoding model presented in     `Visual image reconstruction..."><figure class="align-default" id="id15">
<img alt="Encoding models for visual stimuli from Miyawaki et al. 2008" src="../../_images/sphx_glr_plot_miyawaki_encoding_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_miyawaki_encoding.html#sphx-glr-auto-examples-02-decoding-plot-miyawaki-encoding-py"><span class="std std-ref">Encoding models for visual stimuli from Miyawaki et al. 2008</span></a></span><a class="headerlink" href="#id15" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="Various approaches exist to derive spatial maps or networks from group fmr data. The methods ex..."><figure class="align-default" id="id16">
<img alt="Deriving spatial maps from group fMRI data using ICA and Dictionary Learning" src="../../_images/sphx_glr_plot_compare_decomposition_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_compare_decomposition.html#sphx-glr-auto-examples-03-connectivity-plot-compare-decomposition-py"><span class="std std-ref">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</span></a></span><a class="headerlink" href="#id16" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to produce seed-to-voxel correlation maps for a single subject based on ..."><figure class="align-default" id="id17">
<img alt="Producing single subject maps of seed-to-voxel correlation" src="../../_images/sphx_glr_plot_seed_to_voxel_correlation_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html#sphx-glr-auto-examples-03-connectivity-plot-seed-to-voxel-correlation-py"><span class="std std-ref">Producing single subject maps of seed-to-voxel correlation</span></a></span><a class="headerlink" href="#id17" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use nilearn.regions.RegionExtractor to extract spatially constrained ..."><figure class="align-default" id="id18">
<img alt="Regions extraction using Dictionary Learning and functional connectomes" src="../../_images/sphx_glr_plot_extract_regions_dictlearning_maps_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html#sphx-glr-auto-examples-03-connectivity-plot-extract-regions-dictlearning-maps-py"><span class="std std-ref">Regions extraction using Dictionary Learning and functional connectomes</span></a></span><a class="headerlink" href="#id18" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to run a fixed effects model based on pre-computed statistics. Thi..."><figure class="align-default" id="id19">
<img alt="Example of explicit fixed effects fMRI model fitting" src="../../_images/sphx_glr_plot_fixed_effects_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_fixed_effects.html#sphx-glr-auto-examples-04-glm-first-level-plot-fixed-effects-py"><span class="std std-ref">Example of explicit fixed effects fMRI model fitting</span></a></span><a class="headerlink" href="#id19" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows a full step-by-step workflow of fitting a GLM to data extracted from a seed ..."><figure class="align-default" id="id20">
<img alt="Default Mode Network extraction of AHDH dataset" src="../../_images/sphx_glr_plot_adhd_dmn_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_adhd_dmn.html#sphx-glr-auto-examples-04-glm-first-level-plot-adhd-dmn-py"><span class="std std-ref">Default Mode Network extraction of AHDH dataset</span></a></span><a class="headerlink" href="#id20" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="FIR models are used to estimate the hemodyamic response non-parametrically. The example below s..."><figure class="align-default" id="id21">
<img alt="Analysis of an fMRI dataset with a Finite Impule Response (FIR) model" src="../../_images/sphx_glr_plot_fir_model_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_fir_model.html#sphx-glr-auto-examples-04-glm-first-level-plot-fir-model-py"><span class="std std-ref">Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</span></a></span><a class="headerlink" href="#id21" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="The example shows the analysis of an SPM dataset studying face perception.  The analysis is per..."><figure class="align-default" id="id22">
<img alt="Single-subject data (two sessions) in native space" src="../../_images/sphx_glr_plot_spm_multimodal_faces_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_spm_multimodal_faces.html#sphx-glr-auto-examples-04-glm-first-level-plot-spm-multimodal-faces-py"><span class="std std-ref">Single-subject data (two sessions) in native space</span></a></span><a class="headerlink" href="#id22" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here, we will go through a full step-by-step example of fitting a GLM to experimental data and ..."><figure class="align-default" id="id23">
<img alt="Simple example of two-session fMRI model fitting" src="../../_images/sphx_glr_plot_fiac_analysis_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_fiac_analysis.html#sphx-glr-auto-examples-04-glm-first-level-plot-fiac-analysis-py"><span class="std std-ref">Simple example of two-session fMRI model fitting</span></a></span><a class="headerlink" href="#id23" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we fit a First Level GLM with the minimize_memory-argument set to False. By doing so, the ..."><figure class="align-default" id="id24">
<img alt="Predicted time series and residuals" src="../../_images/sphx_glr_plot_predictions_residuals_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_predictions_residuals.html#sphx-glr-auto-examples-04-glm-first-level-plot-predictions-residuals-py"><span class="std std-ref">Predicted time series and residuals</span></a></span><a class="headerlink" href="#id24" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this tutorial, we study how first-level models are parametrized for fMRI data analysis and c..."><figure class="align-default" id="id25">
<img alt="Understanding parameters of the first-level model" src="../../_images/sphx_glr_plot_first_level_details_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_first_level_details.html#sphx-glr-auto-examples-04-glm-first-level-plot-first-level-details-py"><span class="std std-ref">Understanding parameters of the first-level model</span></a></span><a class="headerlink" href="#id25" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This script showcases the so-called &quot;All resolution inference&quot; procedure, in which the proporti..."><figure class="align-default" id="id26">
<img alt="Second-level fMRI model: true positive proportion in clusters" src="../../_images/sphx_glr_plot_proportion_activated_voxels_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_proportion_activated_voxels.html#sphx-glr-auto-examples-05-glm-second-level-plot-proportion-activated-voxels-py"><span class="std std-ref">Second-level fMRI model: true positive proportion in clusters</span></a></span><a class="headerlink" href="#id26" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="Perform a one-sample t-test on a bunch of images (a.k.a. second-level analysis in fMRI) and thr..."><figure class="align-default" id="id27">
<img alt="Statistical testing of a second-level analysis" src="../../_images/sphx_glr_plot_thresholding_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_thresholding.html#sphx-glr-auto-examples-05-glm-second-level-plot-thresholding-py"><span class="std std-ref">Statistical testing of a second-level analysis</span></a></span><a class="headerlink" href="#id27" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example uses Voxel-Based Morphometry (VBM) to study the relationship between aging, sex an..."><figure class="align-default" id="id28">
<img alt="Voxel-Based Morphometry on Oasis dataset" src="../../_images/sphx_glr_plot_oasis_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_oasis.html#sphx-glr-auto-examples-05-glm-second-level-plot-oasis-py"><span class="std std-ref">Voxel-Based Morphometry on Oasis dataset</span></a></span><a class="headerlink" href="#id28" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows the results obtained in a group analysis using a more complex contrast than ..."><figure class="align-default" id="id29">
<img alt="Example of generic design in second-level models" src="../../_images/sphx_glr_plot_second_level_association_test_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_second_level_association_test.html#sphx-glr-auto-examples-05-glm-second-level-plot-second-level-association-test-py"><span class="std std-ref">Example of generic design in second-level models</span></a></span><a class="headerlink" href="#id29" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="The goal of this example is to illustrate the use of the function nilearn.image.math_img on T-m..."><figure class="align-default" id="id30">
<img alt="Negating an image with math_img" src="../../_images/sphx_glr_plot_negate_image_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_negate_image.html#sphx-glr-auto-examples-06-manipulating-images-plot-negate-image-py"><span class="std std-ref">Negating an image with math_img</span></a></span><a class="headerlink" href="#id30" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="The goal of this example is to illustrate the use of the function nilearn.image.math_img with a..."><figure class="align-default" id="id31">
<img alt="Comparing the means of 2 images" src="../../_images/sphx_glr_plot_compare_mean_image_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_compare_mean_image.html#sphx-glr-auto-examples-06-manipulating-images-plot-compare-mean-image-py"><span class="std std-ref">Comparing the means of 2 images</span></a></span><a class="headerlink" href="#id31" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This simple example shows how to extract regions from Smith atlas resting state networks."><figure class="align-default" id="id32">
<img alt="Regions Extraction of Default Mode Networks using Smith Atlas" src="../../_images/sphx_glr_plot_extract_rois_smith_atlas_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_extract_rois_smith_atlas.html#sphx-glr-auto-examples-06-manipulating-images-plot-extract-rois-smith-atlas-py"><span class="std std-ref">Regions Extraction of Default Mode Networks using Smith Atlas</span></a></span><a class="headerlink" href="#id32" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="The goal of this example is to illustrate the use of the function nilearn.image.resample_to_img..."><figure class="align-default" id="id33">
<img alt="Resample an image to a template" src="../../_images/sphx_glr_plot_resample_to_template_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_resample_to_template.html#sphx-glr-auto-examples-06-manipulating-images-plot-resample-to-template-py"><span class="std std-ref">Resample an image to a template</span></a></span><a class="headerlink" href="#id33" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here is a simple example of automatic mask computation using the nifti masker. The mask is comp..."><figure class="align-default" id="id34">
<img alt="Simple example of NiftiMasker use" src="../../_images/sphx_glr_plot_nifti_simple_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_nifti_simple.html#sphx-glr-auto-examples-06-manipulating-images-plot-nifti-simple-py"><span class="std std-ref">Simple example of NiftiMasker use</span></a></span><a class="headerlink" href="#id34" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to extract regions or separate the regions from a statistical map."><figure class="align-default" id="id35">
<img alt="Region Extraction using a t-statistical map (3D)" src="../../_images/sphx_glr_plot_extract_rois_statistical_maps_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_extract_rois_statistical_maps.html#sphx-glr-auto-examples-06-manipulating-images-plot-extract-rois-statistical-maps-py"><span class="std std-ref">Region Extraction using a t-statistical map (3D)</span></a></span><a class="headerlink" href="#id35" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows manual steps to create and further modify an ROI spatial mask. They represen..."><figure class="align-default" id="id36">
<img alt="Computing a Region of Interest (ROI) mask manually" src="../../_images/sphx_glr_plot_roi_extraction_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_roi_extraction.html#sphx-glr-auto-examples-06-manipulating-images-plot-roi-extraction-py"><span class="std std-ref">Computing a Region of Interest (ROI) mask manually</span></a></span><a class="headerlink" href="#id36" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip=" This example is meant to demonstrate nilearn as a low-level tools used to combine feature extr..."><figure class="align-default" id="id37">
<img alt="Multivariate decompositions: Independent component analysis of fMRI" src="../../_images/sphx_glr_plot_ica_resting_state_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/07_advanced/plot_ica_resting_state.html#sphx-glr-auto-examples-07-advanced-plot-ica-resting-state-py"><span class="std std-ref">Multivariate decompositions: Independent component analysis of fMRI</span></a></span><a class="headerlink" href="#id37" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use the Localizer dataset in a basic analysis. A standard Anova is pe..."><figure class="align-default" id="id38">
<img alt="Massively univariate analysis of a calculation task from the Localizer dataset" src="../../_images/sphx_glr_plot_localizer_simple_analysis_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/07_advanced/plot_localizer_simple_analysis.html#sphx-glr-auto-examples-07-advanced-plot-localizer-simple-analysis-py"><span class="std std-ref">Massively univariate analysis of a calculation task from the Localizer dataset</span></a></span><a class="headerlink" href="#id38" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to download statistical maps from NeuroVault"><figure class="align-default" id="id39">
<img alt="NeuroVault meta-analysis of stop-go paradigm studies." src="../../_images/sphx_glr_plot_neurovault_meta_analysis_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/07_advanced/plot_neurovault_meta_analysis.html#sphx-glr-auto-examples-07-advanced-plot-neurovault-meta-analysis-py"><span class="std std-ref">NeuroVault meta-analysis of stop-go paradigm studies.</span></a></span><a class="headerlink" href="#id39" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows the results obtained in a massively univariate analysis performed at the int..."><figure class="align-default" id="id40">
<img alt="Massively univariate analysis of a motor task from the Localizer dataset" src="../../_images/sphx_glr_plot_localizer_mass_univariate_methods_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/07_advanced/plot_localizer_mass_univariate_methods.html#sphx-glr-auto-examples-07-advanced-plot-localizer-mass-univariate-methods-py"><span class="std std-ref">Massively univariate analysis of a motor task from the Localizer dataset</span></a></span><a class="headerlink" href="#id40" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to download statistical maps from NeuroVault, label them with NeuroSynth..."><figure class="align-default" id="id41">
<img alt="NeuroVault cross-study ICA maps." src="../../_images/sphx_glr_plot_ica_neurovault_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/07_advanced/plot_ica_neurovault.html#sphx-glr-auto-examples-07-advanced-plot-ica-neurovault-py"><span class="std std-ref">NeuroVault cross-study ICA maps.</span></a></span><a class="headerlink" href="#id41" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="A permuted Ordinary Least Squares algorithm is run at each voxel in order to determine whether ..."><figure class="align-default" id="id42">
<img alt="Massively univariate analysis of face vs house recognition" src="../../_images/sphx_glr_plot_haxby_mass_univariate_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/07_advanced/plot_haxby_mass_univariate.html#sphx-glr-auto-examples-07-advanced-plot-haxby-mass-univariate-py"><span class="std std-ref">Massively univariate analysis of face vs house recognition</span></a></span><a class="headerlink" href="#id42" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial opens the box of decoding pipelines to bridge integrated functionalities provided..."><figure class="align-default" id="id43">
<img alt="Advanced decoding using scikit learn" src="../../_images/sphx_glr_plot_advanced_decoding_scikit_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/07_advanced/plot_advanced_decoding_scikit.html#sphx-glr-auto-examples-07-advanced-plot-advanced-decoding-scikit-py"><span class="std std-ref">Advanced decoding using scikit learn</span></a></span><a class="headerlink" href="#id43" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div style='clear:both'></div></section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">8.10.10. nilearn.plotting.plot_stat_map</a><ul>
<li><a class="reference internal" href="#examples-using-nilearn-plotting-plot-stat-map">8.10.10.1. Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.plotting.plot_stat_map</span></code></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="nilearn.plotting.plot_roi.html"
                        title="previous chapter"><span class="section-number">8.10.9. </span>nilearn.plotting.plot_roi</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="nilearn.plotting.plot_glass_brain.html"
                        title="next chapter"><span class="section-number">8.10.11. </span>nilearn.plotting.plot_glass_brain</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
            &copy; The nilearn developers 2010-2021.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 4.2.0.
        <span style="padding-left: 5ex;">
          <a href="../../_sources/modules/generated/nilearn.plotting.plot_stat_map.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>