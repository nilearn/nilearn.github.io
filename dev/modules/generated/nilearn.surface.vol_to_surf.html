
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta property="og:title" content="8.15.3. nilearn.surface.vol_to_surf" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://nilearn.github.io/modules/generated/nilearn.surface.vol_to_surf.html" />
  <meta property="og:site_name" content="Nilearn" />
  <meta property="og:description" content="Examples using nilearn.surface.vol_to_surf: Technical point: Illustration of the volume to surface sampling schemes Technical point: Illustration of the volume to surface sampling schemes, Making a..." />
  <meta property="og:image" content="https://nilearn.github.io/_images/sphx_glr_plot_surface_projection_strategies_thumb.png" />
  <meta property="og:image:alt" content="Technical point: Illustration of the volume to surface sampling schemes" />
  
    <title>Nilearn: Statistical Analysis for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/nature.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="9. Nilearn usage examples" href="../../auto_examples/index.html" />
    <link rel="prev" title="8.15.2. nilearn.surface.load_surf_mesh" href="nilearn.surface.load_surf_mesh.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">


<script type="text/javascript">
function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});
</script>
<script type="text/javascript">
function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../../index.html">
      <img src="../../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../../manipulating_images/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Statistics for NeuroImaging in Python</h2>
  </div>
  <div class="search_form">
    <div class="gcse-search" id="cse" style="width: 100%;"></div>
    <script>
      (function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </div>
</div>



<div class=related-wrapper>
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="../../auto_examples/index.html" title="9. Nilearn usage examples"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="nilearn.surface.load_surf_mesh.html" title="8.15.2. nilearn.surface.load_surf_mesh"
             accesskey="P">previous</a> |</li>
<li><a href="../../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li><a href="../../glossary.html">Glossary</a>|&nbsp;</li>
<li><a href="../../bibliography.html">Bibliography</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../reference.html" accesskey="U"><span class="section-number">8. </span>Reference documentation: all nilearn functions</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Nilearn: Statistical Analysis for NeuroImaging in Python</a></li> 
      </ul>
    </div>
</div>

<div class="devel-alert-banner">
This is documentation for the <em>unstable development version</em> of Nilearn,
the current stable version is available <a href="https://nilearn.github.io/stable/index.html">here</a>.
</div>

  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page is a reference documentation. It only explains the
function signature, and not how to use it. Please refer to the
<a class="reference internal" href="../../user_guide.html#user-guide"><span class="std std-ref">user guide</span></a> for the big picture.</p>
</div>
<section id="nilearn-surface-vol-to-surf">
<h1><span class="section-number">8.15.3. </span>nilearn.surface.vol_to_surf<a class="headerlink" href="#nilearn-surface-vol-to-surf" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="nilearn.surface.vol_to_surf">
<span class="sig-prename descclassname"><span class="pre">nilearn.surface.</span></span><span class="sig-name descname"><span class="pre">vol_to_surf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">surf_mesh</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">radius</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpolation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'linear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kind</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_img</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inner_mesh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/3f0bd9b6/nilearn/surface/surface.py#L468"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.surface.vol_to_surf" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract surface data from a Nifti image.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.4.0.</span></p>
</div>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>img</strong><span class="classifier">Niimg-like object, 3d or 4d.</span></dt><dd><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a></p>
</dd>
<dt><strong>surf_mesh</strong><span class="classifier">str or numpy.ndarray or Mesh</span></dt><dd><p>Either a file containing surface mesh geometry (valid formats
are .gii or Freesurfer specific files such as .orig, .pial,
.sphere, .white, .inflated) or two Numpy arrays organized in a list,
tuple or a namedtuple with the fields “coordinates” and “faces”, or
a Mesh object with “coordinates” and “faces” attributes.</p>
</dd>
<dt><strong>radius</strong><span class="classifier">float, optional</span></dt><dd><p>The size (in mm) of the neighbourhood from which samples are drawn
around each node. Ignored if <cite>inner_mesh</cite> is provided.
Default=3.0.</p>
</dd>
<dt><strong>interpolation</strong><span class="classifier">{‘linear’, ‘nearest’}, optional</span></dt><dd><p>How the image intensity is measured at a sample point.
Default=’linear’.</p>
<ul class="simple">
<li><dl class="simple">
<dt>‘linear’:</dt><dd><p>Use a trilinear interpolation of neighboring voxels.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>‘nearest’:</dt><dd><p>Use the intensity of the nearest voxel.</p>
</dd>
</dl>
</li>
</ul>
<p>For one image, the speed difference is small, ‘linear’ takes about x1.5
more time. For many images, ‘nearest’ scales much better, up to x20
faster.</p>
</dd>
<dt><strong>kind</strong><span class="classifier">{‘auto’, ‘depth’, ‘line’, ‘ball’}, optional</span></dt><dd><p>The strategy used to sample image intensities around each vertex.
Default=’auto’.</p>
<ul class="simple">
<li><dl class="simple">
<dt>‘auto’:</dt><dd><p>Chooses ‘depth’ if <cite>inner_mesh</cite> is provided and ‘line’ otherwise.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>‘depth’:</dt><dd><p><cite>inner_mesh</cite> must be a mesh whose nodes correspond to those in
<cite>surf_mesh</cite>. For example, <cite>inner_mesh</cite> could be a white matter
surface mesh and <cite>surf_mesh</cite> a pial surface mesh. Samples are
placed between each pair of corresponding nodes at the specified
cortical depths (regularly spaced by default, see <cite>depth</cite>
parameter).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>‘line’:</dt><dd><p>Samples are placed along the normal to the mesh, at the positions
specified by <cite>depth</cite>, or by default regularly spaced over the
interval [- <cite>radius</cite>, + <cite>radius</cite>].</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>‘ball’:</dt><dd><p>Samples are regularly spaced inside a ball centered at the mesh
vertex.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt><strong>n_samples</strong><span class="classifier">int or None, optional</span></dt><dd><p>How many samples are drawn around each vertex and averaged. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, use a reasonable default for the chosen sampling strategy
(20 for ‘ball’ or 10 for ‘line’).
For performance reasons, if using <cite>kind</cite> =”ball”, choose <cite>n_samples</cite> in
[10, 20, 40, 80, 160] (default is 20), because cached positions are
available.</p>
</dd>
<dt><strong>mask_img</strong><span class="classifier">Niimg-like object or None, optional</span></dt><dd><p>Samples falling out of this mask or out of the image are ignored.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, don’t apply any mask.</p>
</dd>
<dt><strong>inner_mesh</strong><span class="classifier">str or numpy.ndarray, optional</span></dt><dd><p>Either a file containing a surface mesh or a pair of ndarrays
(coordinates, triangles). If provided this is an inner surface that is
nested inside the one represented by <cite>surf_mesh</cite> – e.g. <cite>surf_mesh</cite> is
a pial surface and <cite>inner_mesh</cite> a white matter surface. In this case
nodes in both meshes must correspond: node i in <cite>surf_mesh</cite> is just
across the gray matter thickness from node i in <cite>inner_mesh</cite>. Image
values for index i are then sampled along the line joining these two
points (if <cite>kind</cite> is ‘auto’ or ‘depth’).</p>
</dd>
<dt><strong>depth</strong><span class="classifier">sequence of floats or None, optional</span></dt><dd><p>The cortical depth of samples. If provided, n_samples is ignored.
When <cite>inner_mesh</cite> is provided, each element of <cite>depth</cite> is a fraction of
the distance from <cite>mesh</cite> to <cite>inner_mesh</cite>: 0 is exactly on the outer
surface, .5 is halfway, 1. is exactly on the inner surface. <cite>depth</cite>
entries can be negative or greater than 1.
When <cite>inner_mesh</cite> is not provided and <cite>kind</cite> is “line”, each element of
<cite>depth</cite> is a fraction of <cite>radius</cite> along the inwards normal at each mesh
node. For example if <cite>radius==1</cite> and <cite>depth==[-.5, 0.]</cite>, for each node
values will be sampled .5 mm outside of the surface and exactly at the
node position.
This parameter is not supported for the “ball” strategy so passing
<cite>depth</cite> when <cite>kind==”ball”</cite> results in a <cite>ValueError</cite>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>texture</strong><span class="classifier">numpy.ndarray, 1d or 2d.</span></dt><dd><p>If 3D image is provided, a 1d vector is returned, containing one value
for each mesh node.
If 4D image is provided, a 2d array is returned, where each row
corresponds to a mesh node.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This function is experimental and details such as the interpolation method
are subject to change.</p>
</div>
<p class="rubric">Notes</p>
<p>This function computes a value for each vertex of the mesh. In order to do
so, it selects a few points in the volume surrounding that vertex,
interpolates the image intensities at these sampling positions, and
averages the results.</p>
<p>Three strategies are available to select these positions.</p>
<blockquote>
<div><ul class="simple">
<li><p>with ‘depth’, data is sampled at various cortical depths between
corresponding nodes of <cite>surface_mesh</cite> and <cite>inner_mesh</cite> (which can be,
for example, a pial surface and a white matter surface).</p></li>
<li><p>‘ball’ uses points regularly spaced in a ball centered at the mesh
vertex. The radius of the ball is controlled by the parameter
<cite>radius</cite>.</p></li>
<li><p>‘line’ starts by drawing the normal to the mesh passing through this
vertex. It then selects a segment of this normal, centered at the
vertex, of length 2 * <cite>radius</cite>. Image intensities are measured at
points regularly spaced on this normal segment, or at positions
determined by <cite>depth</cite>.</p></li>
<li><p>(‘auto’ chooses ‘depth’ if <cite>inner_mesh</cite> is provided and ‘line’
otherwise)</p></li>
</ul>
</div></blockquote>
<p>You can control how many samples are drawn by setting <cite>n_samples</cite>, or their
position by setting <cite>depth</cite>.</p>
<p>Once the sampling positions are chosen, those that fall outside of the 3d
image (or outside of the mask if you provided one) are discarded. If all
sample positions are discarded (which can happen, for example, if the
vertex itself is outside of the support of the image), the projection at
this vertex will be <code class="docutils literal notranslate"><span class="pre">numpy.nan</span></code>.</p>
<p>The 3d image then needs to be interpolated at each of the remaining points.
Two options are available: ‘nearest’ selects the value of the nearest
voxel, and ‘linear’ performs trilinear interpolation of neighbouring
voxels. ‘linear’ may give better results - for example, the projected
values are more stable when resampling the 3d image or applying affine
transformations to it. For one image, the speed difference is small,
‘linear’ takes about x1.5 more time. For many images, ‘nearest’ scales much
better, up to x20 faster.</p>
<p>Once the 3d image has been interpolated at each sample point, the
interpolated values are averaged to produce the value associated to this
particular mesh vertex.</p>
</dd></dl>

<section id="examples-using-nilearn-surface-vol-to-surf">
<h2><span class="section-number">8.15.3.1. </span>Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.surface.vol_to_surf</span></code><a class="headerlink" href="#examples-using-nilearn-surface-vol-to-surf" title="Permalink to this headline">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="In nilearn, nilearn.surface.vol_to_surf allows us to measure values of a 3d volume at the nodes..."><figure class="align-default" id="id1">
<img alt="Technical point: Illustration of the volume to surface sampling schemes" src="../../_images/sphx_glr_plot_surface_projection_strategies_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/01_plotting/plot_surface_projection_strategies.html#sphx-glr-auto-examples-01-plotting-plot-surface-projection-strategies-py"><span class="std std-ref">Technical point: Illustration of the volume to surface sampling schemes</span></a></span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, we will project a 3D statistical map onto a cortical mesh using vol_to_surf, d..."><figure class="align-default" id="id2">
<img alt="Making a surface plot of a 3D statistical map" src="../../_images/sphx_glr_plot_3d_map_to_surface_projection_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/01_plotting/plot_3d_map_to_surface_projection.html#sphx-glr-auto-examples-01-plotting-plot-3d-map-to-surface-projection-py"><span class="std std-ref">Making a surface plot of a 3D statistical map</span></a></span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This is a demo for surface-based searchlight decoding, as described in: Chen, Y., Namburi, P., ..."><figure class="align-default" id="id3">
<img alt="Cortical surface-based searchlight decoding" src="../../_images/sphx_glr_plot_haxby_searchlight_surface_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_searchlight_surface.html#sphx-glr-auto-examples-02-decoding-plot-haxby-searchlight-surface-py"><span class="std std-ref">Cortical surface-based searchlight decoding</span></a></span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="A full step-by-step example of fitting a GLM to experimental data sampled on the cortical surfa..."><figure class="align-default" id="id4">
<img alt="Example of surface-based first-level analysis" src="../../_images/sphx_glr_plot_localizer_surface_analysis_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_localizer_surface_analysis.html#sphx-glr-auto-examples-04-glm-first-level-plot-localizer-surface-analysis-py"><span class="std std-ref">Example of surface-based first-level analysis</span></a></span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip=" Full step-by-step example of fitting a GLM (first and second level analysis) in a 10-subjects ..."><figure class="align-default" id="id5">
<img alt="Surface-based dataset first and second level analysis of a dataset" src="../../_images/sphx_glr_plot_surface_bids_analysis_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/07_advanced/plot_surface_bids_analysis.html#sphx-glr-auto-examples-07-advanced-plot-surface-bids-analysis-py"><span class="std std-ref">Surface-based dataset first and second level analysis of a dataset</span></a></span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div style='clear:both'></div></section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">8.15.3. nilearn.surface.vol_to_surf</a><ul>
<li><a class="reference internal" href="#examples-using-nilearn-surface-vol-to-surf">8.15.3.1. Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.surface.vol_to_surf</span></code></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="nilearn.surface.load_surf_mesh.html"
                        title="previous chapter"><span class="section-number">8.15.2. </span>nilearn.surface.load_surf_mesh</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../../auto_examples/index.html"
                        title="next chapter"><span class="section-number">9. </span>Nilearn usage examples</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
            &copy; The nilearn developers 2010-2021.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 4.2.0.
        <span style="padding-left: 5ex;">
          <a href="../../_sources/modules/generated/nilearn.surface.vol_to_surf.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>