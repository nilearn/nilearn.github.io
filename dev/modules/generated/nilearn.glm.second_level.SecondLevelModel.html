
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta property="og:title" content="8.12.16.1. nilearn.glm.second_level.SecondLevelModel" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://nilearn.github.io/modules/generated/nilearn.glm.second_level.SecondLevelModel.html" />
  <meta property="og:site_name" content="Nilearn" />
  <meta property="og:description" content="Examples using nilearn.glm.second_level.SecondLevelModel: Second-level fMRI model: true positive proportion in clusters Second-level fMRI model: true positive proportion in clusters, Statistical te..." />
  <meta property="og:image" content="../../_images/sphx_glr_plot_proportion_activated_voxels_thumb.png" />
  <meta property="og:image:alt" content="Second-level fMRI model: true positive proportion in clusters" />
  
    <title>Nilearn: Statistical Analysis for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/nature.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="8.12.16.2. nilearn.glm.second_level.make_second_level_design_matrix" href="nilearn.glm.second_level.make_second_level_design_matrix.html" />
    <link rel="prev" title="8.12.15.13. nilearn.glm.first_level.spm_time_derivative" href="nilearn.glm.first_level.spm_time_derivative.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">


<script type="text/javascript">
function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});
</script>
<script type="text/javascript">
function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../../index.html">
      <img src="../../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../../manipulating_images/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Statistics for NeuroImaging in Python</h2>
  </div>
  <div class="search_form">
    <div class="gcse-search" id="cse" style="width: 100%;"></div>
    <script>
      (function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </div>
</div>



<div class=related-wrapper>
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="nilearn.glm.second_level.make_second_level_design_matrix.html" title="8.12.16.2. nilearn.glm.second_level.make_second_level_design_matrix"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="nilearn.glm.first_level.spm_time_derivative.html" title="8.12.15.13. nilearn.glm.first_level.spm_time_derivative"
             accesskey="P">previous</a> |</li>
<li><a href="../../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li><a href="../../glossary.html">Glossary</a>|&nbsp;</li>
<li><a href="../../bibliography.html">Bibliography</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../reference.html" accesskey="U"><span class="section-number">8. </span>Reference documentation: all nilearn functions</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Nilearn: Statistical Analysis for NeuroImaging in Python</a></li> 
      </ul>
    </div>
</div>

<div class="devel-alert-banner">
This is documentation for the <em>unstable development version</em> of Nilearn,
the current stable version is available <a href="https://nilearn.github.io/stable/index.html">here</a>.
</div>

  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page is a reference documentation. It only explains the class
signature, and not how to use it. Please refer to the
<a class="reference internal" href="../../user_guide.html#user-guide"><span class="std std-ref">user guide</span></a> for the big picture.</p>
</div>
<section id="nilearn-glm-second-level-secondlevelmodel">
<h1><span class="section-number">8.12.16.1. </span>nilearn.glm.second_level.SecondLevelModel<a class="headerlink" href="#nilearn-glm-second-level-secondlevelmodel" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="nilearn.glm.second_level.SecondLevelModel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">nilearn.glm.second_level.</span></span><span class="sig-name descname"><span class="pre">SecondLevelModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mask_img</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_affine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smoothing_fwhm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Memory(location=None)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minimize_memory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/3a2daae2/nilearn/glm/second_level/second_level.py#L227"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.glm.second_level.SecondLevelModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of the General Linear Model for multiple subject
fMRI data</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>mask_img</strong><span class="classifier">Niimg-like, NiftiMasker or MultiNiftiMasker object, optional</span></dt><dd><p>Mask to be used on data. If an instance of masker is passed,
then its mask will be used. If no mask is given,
it will be computed automatically by a MultiNiftiMasker with default
parameters. Automatic mask computation assumes first level imgs have
already been masked.</p>
</dd>
<dt><strong>target_affine</strong><span class="classifier">3x3 or 4x4 matrix, optional</span></dt><dd><p>This parameter is passed to <a class="reference internal" href="nilearn.image.resample_img.html#nilearn.image.resample_img" title="nilearn.image.resample_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.image.resample_img</span></code></a>.
Please see the related documentation for details.</p>
</dd>
<dt><strong>target_shape</strong><span class="classifier">3-tuple of integers, optional</span></dt><dd><p>This parameter is passed to <a class="reference internal" href="nilearn.image.resample_img.html#nilearn.image.resample_img" title="nilearn.image.resample_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.image.resample_img</span></code></a>.
Please see the related documentation for details.</p>
</dd>
<dt><strong>smoothing_fwhm</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3.8/library/functions.html#float" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a>, optional.</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">smoothing_fwhm</span></code> is not <code class="docutils literal notranslate"><span class="pre">None</span></code>, it gives
the <a class="reference internal" href="../../glossary.html#term-FWHM"><span class="xref std std-term">full-width at half maximum</span></a> in millimeters
of the spatial smoothing to apply to the signal.</p>
</dd>
<dt><strong>memory</strong><span class="classifier">string, optional</span></dt><dd><p>Path to the directory used to cache the masking process and the glm
fit. By default, no caching is done. Creates instance of joblib.Memory.</p>
</dd>
<dt><strong>memory_level</strong><span class="classifier">integer, optional</span></dt><dd><p>Rough estimator of the amount of memory used by caching. Higher value
means more memory for caching. Default=1.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">integer, optional</span></dt><dd><p>Indicate the level of verbosity. By default, nothing is printed.
If 0 prints nothing. If 1 prints final computation time.
If 2 prints masker computation details. Default=0.</p>
</dd>
<dt><strong>n_jobs</strong><span class="classifier">integer, optional</span></dt><dd><p>The number of CPUs to use to do the computation. -1 means
‘all CPUs’, -2 ‘all CPUs but one’, and so on.
Default=1.</p>
</dd>
<dt><strong>minimize_memory</strong><span class="classifier">boolean, optional</span></dt><dd><p>Gets rid of some variables on the model fit results that are not
necessary for contrast computation and would only be useful for
further inspection of model details. This has an important impact
on memory consumption. Default=True.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This class is experimental.
It may change in any future release of Nilearn.</p>
<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.second_level.SecondLevelModel.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mask_img</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_affine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smoothing_fwhm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Memory(location=None)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minimize_memory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/3a2daae2/nilearn/glm/second_level/second_level.py#L278"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.glm.second_level.SecondLevelModel.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.second_level.SecondLevelModel.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">second_level_input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">design_matrix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/3a2daae2/nilearn/glm/second_level/second_level.py#L297"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.glm.second_level.SecondLevelModel.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the second-level GLM</p>
<ol class="arabic simple">
<li><p>create design matrix</p></li>
<li><p>do a masker job: fMRI_data -&gt; Y</p></li>
<li><p>fit regression to (Y, X)</p></li>
</ol>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>second_level_input: list of `FirstLevelModel` objects or pandas</strong></dt><dd><blockquote>
<div><p>DataFrame or list of Niimg-like objects.</p>
</div></blockquote>
<p>Giving FirstLevelModel objects will allow to easily compute
the second level contrast of arbitrary first level contrasts thanks
to the first_level_contrast argument of the compute_contrast
method. Effect size images will be computed for each model to
contrast at the second level.</p>
<p>If a pandas DataFrame, then they have to contain subject_label,
map_name and effects_map_path. It can contain multiple maps that
would be selected during contrast estimation with the argument
first_level_contrast of the compute_contrast function. The
DataFrame will be sorted based on the subject_label column to avoid
order inconsistencies when extracting the maps. So the rows of the
automatically computed design matrix, if not provided, will
correspond to the sorted subject_label column.</p>
<p>If list of Niimg-like objects then this is taken literally as Y
for the model fit and design_matrix must be provided.</p>
</dd>
<dt><strong>confounds</strong><span class="classifier">pandas DataFrame, optional</span></dt><dd><p>Must contain a subject_label column. All other columns are
considered as confounds and included in the model. If
design_matrix is provided then this argument is ignored.
The resulting second level design matrix uses the same column
names as in the given DataFrame for confounds. At least two columns
are expected, “subject_label” and at least one confound.</p>
</dd>
<dt><strong>design_matrix</strong><span class="classifier">pandas DataFrame, optional</span></dt><dd><p>Design matrix to fit the GLM. The number of rows
in the design matrix must agree with the number of maps derived
from second_level_input.
Ensure that the order of maps given by a second_level_input
list of Niimgs matches the order of the rows in the design matrix.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.second_level.SecondLevelModel.compute_contrast">
<span class="sig-name descname"><span class="pre">compute_contrast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">second_level_contrast</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">first_level_contrast</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">second_level_stat_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'z_score'</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/3a2daae2/nilearn/glm/second_level/second_level.py#L424"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.glm.second_level.SecondLevelModel.compute_contrast" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate different outputs corresponding to
the contrasts provided e.g. z_map, t_map, effects and variance.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>second_level_contrast</strong><span class="classifier">str or array of shape (n_col), optional</span></dt><dd><p>Where <code class="docutils literal notranslate"><span class="pre">n_col</span></code> is the number of columns of the design matrix. The
string can be a formula compatible with <cite>pandas.DataFrame.eval</cite>.
Basically one can use the name of the conditions as they appear in
the design matrix of the fitted model combined with operators +-
and combined with numbers with operators +-<cite>*</cite>/. The default (None)
is accepted if the design matrix has a single column, in which case
the only possible contrast array((1)) is applied; when the design
matrix has multiple columns, an error is raised.</p>
</dd>
<dt><strong>first_level_contrast</strong><span class="classifier">str or array of shape (n_col) with respect to</span></dt><dd><blockquote>
<div><p>FirstLevelModel, optional</p>
</div></blockquote>
<p>In case a list of FirstLevelModel was provided as
second_level_input, we have to provide a contrast to apply to
the first level models to get the corresponding list of images
desired, that would be tested at the second level. In case a
pandas DataFrame was provided as second_level_input this is the
map name to extract from the pandas dataframe map_name column.
It has to be a ‘t’ contrast.</p>
</dd>
<dt><strong>second_level_stat_type</strong><span class="classifier">{‘t’, ‘F’}, optional</span></dt><dd><p>Type of the second level contrast</p>
</dd>
<dt><strong>output_type</strong><span class="classifier">str, optional</span></dt><dd><p>Type of the output map. Can be ‘z_score’, ‘stat’, ‘p_value’,
‘effect_size’, ‘effect_variance’ or ‘all’.
Default=’z-score’.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output_image</strong><span class="classifier">Nifti1Image</span></dt><dd><p>The desired output image(s). If <code class="docutils literal notranslate"><span class="pre">output_type</span> <span class="pre">==</span> <span class="pre">'all'</span></code>, then
the output is a dictionary of images, keyed by the type of image.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.second_level.SecondLevelModel.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">fit_params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.glm.second_level.SecondLevelModel.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to <cite>X</cite> and <cite>y</cite> with optional parameters <cite>fit_params</cite>
and returns a transformed version of <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span></dt><dd><p>Input samples.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None</span></dt><dd><p>Target values (None for unsupervised transformations).</p>
</dd>
<dt><strong>**fit_params</strong><span class="classifier">dict</span></dt><dd><p>Additional fit parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X_new</strong><span class="classifier">ndarray array of shape (n_samples, n_features_new)</span></dt><dd><p>Transformed array.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.second_level.SecondLevelModel.generate_report">
<span class="sig-name descname"><span class="pre">generate_report</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">contrasts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bg_img</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'MNI152TEMPLATE'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3.09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cluster_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">height_control</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'fpr'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_distance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plot_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'slice'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">display_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">report_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(1600,</span> <span class="pre">800)</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/3a2daae2/nilearn/glm/_base.py#L6"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.glm.second_level.SecondLevelModel.generate_report" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns HTMLDocument object
for a report which shows all important aspects of a fitted GLM.
The object can be opened in a browser, displayed in a notebook,
or saved to disk as a standalone HTML file.</p>
<p>The GLM must be fitted and have the computed design matrix(ces).</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>A fitted first or second level model object.</strong></dt><dd></dd>
<dt><strong>contrasts</strong><span class="classifier">Dict[string, ndarray] or String or List[String] or</span></dt><dd><p>ndarray or List[ndarray]</p>
<p>Contrasts information for a first or second level model.</p>
<p>Example:</p>
<blockquote>
<div><p>Dict of contrast names and coefficients,
or list of contrast names
or list of contrast coefficients
or contrast name
or contrast coefficient</p>
<p>Each contrast name must be a string.
Each contrast coefficient must be a list or
numpy array of ints.</p>
</div></blockquote>
<p>Contrasts are passed to <code class="docutils literal notranslate"><span class="pre">contrast_def</span></code> for FirstLevelModel
(<a class="reference internal" href="nilearn.glm.first_level.FirstLevelModel.html#nilearn.glm.first_level.FirstLevelModel.compute_contrast" title="nilearn.glm.first_level.FirstLevelModel.compute_contrast"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.glm.first_level.FirstLevelModel.compute_contrast</span></code></a>)
&amp; second_level_contrast for SecondLevelModel
(<a class="reference internal" href="#nilearn.glm.second_level.SecondLevelModel.compute_contrast" title="nilearn.glm.second_level.SecondLevelModel.compute_contrast"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.glm.second_level.SecondLevelModel.compute_contrast</span></code></a>)</p>
</dd>
<dt><strong>title</strong><span class="classifier">String, optional</span></dt><dd><p>If string, represents the web page’s title and primary heading,
model type is sub-heading.
If None, page titles and headings are autogenerated
using contrast names.</p>
</dd>
<dt><strong>bg_img</strong><span class="classifier">Niimg-like object, optional</span></dt><dd><p>Default is the MNI152 template (Default=’MNI152TEMPLATE’)
See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
The background image for mask and stat maps to be plotted on upon.
To turn off background image, just pass “bg_img=None”.</p>
</dd>
<dt><strong>threshold</strong><span class="classifier">float, optional</span></dt><dd><p>Cluster forming threshold in same scale as <cite>stat_img</cite> (either a
t-scale or z-scale value). Used only if height_control is None.
Default=3.09</p>
</dd>
<dt><strong>alpha</strong><span class="classifier">float, optional</span></dt><dd><p>Number controlling the thresholding (either a p-value or q-value).
Its actual meaning depends on the height_control parameter.
This function translates alpha to a z-scale threshold.
Default=0.001</p>
</dd>
<dt><strong>cluster_threshold</strong><span class="classifier">int, optional</span></dt><dd><p>Cluster size threshold, in voxels.
Default=0</p>
</dd>
<dt><strong>height_control</strong><span class="classifier">string or None, optional</span></dt><dd><p>false positive control meaning of cluster forming
threshold: ‘fpr’ (default) or ‘fdr’ or ‘bonferroni’ or None
Default=’fpr’.</p>
</dd>
<dt><strong>min_distance</strong><span class="classifier">float, optional</span></dt><dd><p>For display purposes only.
Minimum distance between subpeaks in mm. Default=8mm.</p>
</dd>
<dt><strong>plot_type</strong><span class="classifier">String. [‘slice’, ‘glass’], optional</span></dt><dd><p>Specifies the type of plot to be drawn for the statistical maps.
Default=’slice’.</p>
</dd>
<dt><strong>display_mode</strong><span class="classifier">string, optional</span></dt><dd><p>Default is ‘z’ if plot_type is ‘slice’; ‘
ortho’ if plot_type is ‘glass’.</p>
<p>Choose the direction of the cuts:
‘x’ - sagittal, ‘y’ - coronal, ‘z’ - axial,
‘l’ - sagittal left hemisphere only,
‘r’ - sagittal right hemisphere only,
‘ortho’ - three cuts are performed in orthogonal directions.</p>
<p>Possible values are:
‘ortho’, ‘x’, ‘y’, ‘z’, ‘xz’, ‘yx’, ‘yz’,
‘l’, ‘r’, ‘lr’, ‘lzr’, ‘lyr’, ‘lzry’, ‘lyrz’.</p>
</dd>
<dt><strong>report_dims</strong><span class="classifier">Sequence[int, int], optional</span></dt><dd><p>Default is (1600, 800) pixels.
Specifies width, height (in pixels) of report window
within a notebook.
Only applicable when inserting the report into a Jupyter notebook.
Can be set after report creation using report.width, report.height.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>report_text</strong><span class="classifier">HTMLDocument Object</span></dt><dd><p>Contains the HTML code for the GLM Report.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.second_level.SecondLevelModel.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.glm.second_level.SecondLevelModel.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.second_level.SecondLevelModel.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.glm.second_level.SecondLevelModel.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="(in scikit-learn v1.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>). The latter have
parameters of the form <code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s
possible to update each component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Estimator parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">estimator instance</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="examples-using-nilearn-glm-second-level-secondlevelmodel">
<h2><span class="section-number">8.12.16.1.1. </span>Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.glm.second_level.SecondLevelModel</span></code><a class="headerlink" href="#examples-using-nilearn-glm-second-level-secondlevelmodel" title="Permalink to this headline">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="This script showcases the so-called &quot;All resolution inference&quot; procedure, in which the proporti..."><figure class="align-default" id="id1">
<img alt="Second-level fMRI model: true positive proportion in clusters" src="../../_images/sphx_glr_plot_proportion_activated_voxels_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_proportion_activated_voxels.html#sphx-glr-auto-examples-05-glm-second-level-plot-proportion-activated-voxels-py"><span class="std std-ref">Second-level fMRI model: true positive proportion in clusters</span></a></span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="Perform a one-sample t-test on a bunch of images (a.k.a. second-level analysis in fMRI) and thr..."><figure class="align-default" id="id2">
<img alt="Statistical testing of a second-level analysis" src="../../_images/sphx_glr_plot_thresholding_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_thresholding.html#sphx-glr-auto-examples-05-glm-second-level-plot-thresholding-py"><span class="std std-ref">Statistical testing of a second-level analysis</span></a></span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example uses Voxel-Based Morphometry (VBM) to study the relationship between aging, sex an..."><figure class="align-default" id="id3">
<img alt="Voxel-Based Morphometry on Oasis dataset" src="../../_images/sphx_glr_plot_oasis_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_oasis.html#sphx-glr-auto-examples-05-glm-second-level-plot-oasis-py"><span class="std std-ref">Voxel-Based Morphometry on Oasis dataset</span></a></span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="Full step-by-step example of fitting a GLM to perform a second level analysis in experimental d..."><figure class="align-default" id="id4">
<img alt="Second-level fMRI model: two-sample test, unpaired and paired" src="../../_images/sphx_glr_plot_second_level_two_sample_test_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_second_level_two_sample_test.html#sphx-glr-auto-examples-05-glm-second-level-plot-second-level-two-sample-test-py"><span class="std std-ref">Second-level fMRI model: two-sample test, unpaired and paired</span></a></span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="Full step-by-step example of fitting a GLM to perform a second-level analysis (one-sample test)..."><figure class="align-default" id="id5">
<img alt="Second-level fMRI model: one sample test" src="../../_images/sphx_glr_plot_second_level_one_sample_test_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html#sphx-glr-auto-examples-05-glm-second-level-plot-second-level-one-sample-test-py"><span class="std std-ref">Second-level fMRI model: one sample test</span></a></span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows the results obtained in a group analysis using a more complex contrast than ..."><figure class="align-default" id="id6">
<img alt="Example of generic design in second-level models" src="../../_images/sphx_glr_plot_second_level_association_test_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_second_level_association_test.html#sphx-glr-auto-examples-05-glm-second-level-plot-second-level-association-test-py"><span class="std std-ref">Example of generic design in second-level models</span></a></span><a class="headerlink" href="#id6" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip=" Full step-by-step example of fitting a GLM to perform a first and second level analysis in a B..."><figure class="align-default" id="id7">
<img alt="BIDS dataset first and second level analysis" src="../../_images/sphx_glr_plot_bids_analysis_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/07_advanced/plot_bids_analysis.html#sphx-glr-auto-examples-07-advanced-plot-bids-analysis-py"><span class="std std-ref">BIDS dataset first and second level analysis</span></a></span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div style='clear:both'></div></section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">8.12.16.1. nilearn.glm.second_level.SecondLevelModel</a><ul>
<li><a class="reference internal" href="#examples-using-nilearn-glm-second-level-secondlevelmodel">8.12.16.1.1. Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.glm.second_level.SecondLevelModel</span></code></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="nilearn.glm.first_level.spm_time_derivative.html"
                        title="previous chapter"><span class="section-number">8.12.15.13. </span>nilearn.glm.first_level.spm_time_derivative</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="nilearn.glm.second_level.make_second_level_design_matrix.html"
                        title="next chapter"><span class="section-number">8.12.16.2. </span>nilearn.glm.second_level.make_second_level_design_matrix</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
            &copy; The nilearn developers 2010-2021.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 4.2.0.
        <span style="padding-left: 5ex;">
          <a href="../../_sources/modules/generated/nilearn.glm.second_level.SecondLevelModel.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>