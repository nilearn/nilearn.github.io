<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="6.2.3.1. Group-sparse covariance estimation" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://nilearn.github.io/developers/group_sparse_covariance.html" />
<meta property="og:site_name" content="Nilearn" />
<meta property="og:description" content="This page gives technical information on the group_sparse_covariance function and related. This is mainly useful for developers or people that want to know more about implementation. Description: g..." />
<meta property="og:image" content="https://nilearn.github.io/_static/nilearn-logo.png" />
<meta property="og:image:alt" content="Nilearn" />
<meta name="description" content="This page gives technical information on the group_sparse_covariance function and related. This is mainly useful for developers or people that want to know more about implementation. Description: g..." />
<link rel="search" title="Search" href="../search.html"><link rel="next" title="6.3. Extracting functional brain networks: ICA and related" href="../connectivity/resting_state_networks.html"><link rel="prev" title="6.2. Connectome extraction: inverse covariance for direct connections" href="../connectivity/connectome_extraction.html">
        <link rel="prefetch" href="../_static/nilearn-transparent.png" as="image">

    <link rel="shortcut icon" href="../_static/favicon.ico"><!-- Generated with Sphinx 8.1.3 and Furo 2025.09.25 -->
        <title>6.2.3.1. Group-sparse covariance estimation - Nilearn</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=2da93098" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=580074bf" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=54f5008b" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/fontawesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/solid.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/brands.min.css" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: black;
  --admonition-font-size: 100%;
  --admonition-title-font-size: 100%;
  --color-announcement-background: #FBB360;
  --color-announcement-text: #111418;
  --color-admonition-title--note: #448aff;
  --color-admonition-title-background--note: #448aff10;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-announcement-background: #935610;
  --color-announcement-text: #FFFFFF;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-announcement-background: #935610;
  --color-announcement-text: #FFFFFF;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>

<div class="announcement">
  <aside class="announcement-content">
     <p>This is the development documentation of nilearn (0.12.2.dev95+g49854b87d) <a class="sd-sphinx-override sd-badge sd-text-wrap sd-btn-outline-dark reference external" href="https://nilearn.github.io"><span>Switch to stable version (0.12.1)</span></a></p> 
  </aside>
</div>

<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Nilearn</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/nilearn-transparent.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Nilearn</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quickstart</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_examples/index.html">Examples</a><input aria-label="Toggle navigation of Examples" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/00_tutorials/index.html">Basic tutorials</a><input aria-label="Toggle navigation of Basic tutorials" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_3d_and_4d_niimg.html">3D and 4D niimgs: handling and visualizing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_decoding_tutorial.html">A introduction tutorial to fMRI decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_nilearn_101.html">Basic nilearn example: manipulating and looking at data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_python_101.html">Basic numerics and plotting with Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_single_subject_single_run.html">Intro to GLM Analysis: a single-run, single-subject fMRI dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_surface_101.html">Working with Surface images</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/01_plotting/index.html">Visualization of brain images</a><input aria-label="Toggle navigation of Visualization of brain images" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_atlas.html">Basic Atlas plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_colormaps.html">Colormaps in Nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_dim_plotting.html">Controlling the contrast of the background when plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_glass_brain.html">Glass brain plotting in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_glass_brain_extensive.html">Glass brain plotting in nilearn (all options)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_surf_atlas.html">Loading and plotting of a cortical surface atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_3d_map_to_surface_projection.html">Making a surface plot of a 3D statistical map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_more_plotting.html">More plotting tools from nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_visualization.html">NeuroImaging volumes visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_haxby_masks.html">Plot Haxby masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_transparency.html">Plotting images with transparent thresholding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_plotting.html">Plotting tools in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_surf_stat_map.html">Seed-based connectivity on the surface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_surface_projection_strategies.html">Technical point: Illustration of the volume to surface sampling schemes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_prob_atlas.html">Visualizing 4D probabilistic atlas maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_visualize_megatrawls_netmats.html">Visualizing Megatrawls Network Matrices from Human Connectome Project</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_overlay.html">Visualizing a probabilistic atlas: the default mode in the MSDL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_carpet.html">Visualizing global patterns with a carpet plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_multiscale_parcellations.html">Visualizing multiscale functional brain parcellations</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/02_decoding/index.html">Decoding and predicting from brain images</a><input aria-label="Toggle navigation of Decoding and predicting from brain images" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_searchlight_surface.html">Cortical surface-based searchlight decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_glm_decoding.html">Decoding of a dataset after GLM fit for signal extraction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_anova_svm.html">Decoding with ANOVA + SVM: face vs house in the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_frem.html">Decoding with FREM: face vs house vs chair object recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_different_estimators.html">Different classifiers in decoding the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_miyawaki_encoding.html">Encoding models for visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_simulated_data.html">Example of pattern recognition on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_mixed_gambles_frem.html">FREM on Jimura et al “mixed gambles” dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_full_analysis.html">ROI-based decoding analysis in Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_miyawaki_reconstruction.html">Reconstruction of visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_searchlight.html">Searchlight analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_grid_search.html">Setting a parameter by cross-validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_stimuli.html">Show stimuli of Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_multiclass.html">The haxby dataset: different multi-class strategies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_understand_decoder.html">Understanding <code class="xref py py-class docutils literal notranslate"><span class="pre">Decoder</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_oasis_vbm.html">Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_oasis_vbm_space_net.html">Voxel-Based Morphometry on Oasis dataset with Space-Net prior</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/03_connectivity/index.html">Functional connectivity</a><input aria-label="Toggle navigation of Functional connectivity" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_group_level_connectivity.html">Classification of age groups using functional connectivity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_data_driven_parcellations.html">Clustering methods to learn a brain parcellation from fMRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_atlas_comparison.html">Comparing connectomes on different reference atlases</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_inverse_covariance_connectome.html">Computing a connectome with sparse inverse covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_simulated_connectome.html">Connectivity structure estimation on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_compare_decomposition.html">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_sphere_based_connectome.html">Extract signals on spheres and plot a connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_signal_extraction.html">Extracting signals from a brain parcellation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_probabilistic_atlas_extraction.html">Extracting signals of a probabilistic atlas of functional regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_multi_subject_connectome.html">Group Sparse inverse covariance for multi-subject connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html">Producing single subject maps of seed-to-voxel correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html">Regions extraction using dictionary learning and functional connectomes</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/04_glm_first_level/index.html">GLM: First level analysis</a><input aria-label="Toggle navigation of GLM: First level analysis" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_fir_model.html">Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_adhd_dmn.html">Default Mode Network extraction of ADHD dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_hrf.html">Example of MRI response functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_localizer_surface_analysis.html">Example of surface-based first-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_design_matrix.html">Examples of design matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_bids_features.html">First level analysis of a complete BIDS dataset from openneuro</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_write_events_file.html">Generate an events.tsv file for the NeuroSpin localizer task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_predictions_residuals.html">Predicted time series and residuals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_two_runs_model.html">Simple example of two-runs fMRI model fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_spm_multimodal_faces.html">Single-subject data (two runs) in native space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_first_level_details.html">Understanding parameters of the first-level model</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/05_glm_second_level/index.html">GLM: Second level analysis</a><input aria-label="Toggle navigation of GLM: Second level analysis" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_association_test.html">Example of generic design in second-level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_design_matrix.html">Example of second level design matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html">Second-level fMRI model: one sample test</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_proportion_activated_voxels.html">Second-level fMRI model: true positive proportion in clusters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_two_sample_test.html">Second-level fMRI model: two-sample test, unpaired and paired</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_thresholding.html">Statistical testing of a second-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_oasis.html">Voxel-Based Morphometry on OASIS dataset</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/06_manipulating_images/index.html">Manipulating brain image volumes</a><input aria-label="Toggle navigation of Manipulating brain image volumes" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_extract_regions_labels_image.html">Breaking an atlas of labels in separated regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_compare_mean_image.html">Comparing the means of 2 images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_roi_extraction.html">Computing a Region of Interest (ROI) mask manually</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_nifti_labels_simple.html">Extracting signals from brain regions using the NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_threshold_image.html">Image thresholding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_negate_image.html">Negating an image with math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_extract_rois_statistical_maps.html">Region Extraction using a t-statistical map (3D)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_extract_rois_smith_atlas.html">Regions Extraction of Default Mode Networks using Smith Atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_resample_to_template.html">Resample an image to a template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_nifti_simple.html">Simple example of NiftiMasker use</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_smooth_mean_image.html">Smoothing an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_mask_computation.html">Understanding NiftiMasker and mask computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_affine_transformation.html">Visualization of affine resamplings</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/07_advanced/index.html">Advanced statistical analysis of brain images</a><input aria-label="Toggle navigation of Advanced statistical analysis of brain images" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_surface_image_and_maskers.html">A short demo of the surface images &amp; maskers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_advanced_decoding_scikit.html">Advanced decoding using scikit learn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_bids_analysis.html">BIDS dataset first and second level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_beta_series.html">Beta-Series Modeling for Task-Based Functional Connectivity and Decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_copy_headers_math_img.html">Copying headers from input images with <code class="docutils literal notranslate"><span class="pre">math_img</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_age_group_prediction_cross_val.html">Functional connectivity predicts age group</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_localizer_simple_analysis.html">Massively univariate analysis of a calculation task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_localizer_mass_univariate_methods.html">Massively univariate analysis of a motor task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_haxby_mass_univariate.html">Massively univariate analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_ica_resting_state.html">Multivariate decompositions: Independent component analysis of fMRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_ica_neurovault.html">NeuroVault cross-study ICA maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_neurovault_meta_analysis.html">NeuroVault meta-analysis of stop-go paradigm studies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_surface_bids_analysis.html">Surface-based dataset first and second level analysis of a dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_mask_large_fmri.html">Working with long time series fMRI images</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../user_guide.html">User guide</a><input aria-label="Toggle navigation of User guide" checked="" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../introduction.html">1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introduction.html#what-is-nilearn">2. What is <code class="docutils literal notranslate"><span class="pre">nilearn</span></code>?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introduction.html#using-nilearn-for-the-first-time">3. Using <code class="docutils literal notranslate"><span class="pre">nilearn</span></code> for the first time</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introduction.html#machine-learning-applications-to-neuroimaging">4. Machine learning applications to Neuroimaging</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../decoding/index.html">5. Decoding and MVPA: predicting from brain images</a><input aria-label="Toggle navigation of 5. Decoding and MVPA: predicting from brain images" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../decoding/decoding_intro.html">5.1. An introduction to decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/estimator_choice.html">5.2. Choosing the right predictive model for neuroimaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/frem.html">5.3. FREM: fast ensembling of regularized models for robust decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/space_net.html">5.4. SpaceNet: decoding with spatial structure for better maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/searchlight.html">5.5. Searchlight : finding voxels containing information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/going_further.html">5.6. Running scikit-learn functions for more control on the analysis</a></li>
</ul>
</li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="../connectivity/index.html">6. Functional connectivity and resting state</a><input aria-label="Toggle navigation of 6. Functional connectivity and resting state" checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../connectivity/functional_connectomes.html">6.1. Extracting times series to build a functional connectome</a></li>
<li class="toctree-l3 current has-children"><a class="reference internal" href="../connectivity/connectome_extraction.html">6.2. Connectome extraction: inverse covariance for direct connections</a><input aria-label="Toggle navigation of 6.2. Connectome extraction: inverse covariance for direct connections" checked="" class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l4 current current-page"><a class="current reference internal" href="#">6.2.3.1. Group-sparse covariance estimation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../connectivity/resting_state_networks.html">6.3. Extracting functional brain networks: ICA and related</a></li>
<li class="toctree-l3"><a class="reference internal" href="../connectivity/region_extraction.html">6.4. Region Extraction for better brain parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../connectivity/parcellating.html">6.5. Clustering to parcellate the brain in regions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../plotting/index.html">7. Plotting brain images</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../glm/index.html">8. Analyzing fMRI using GLMs</a><input aria-label="Toggle navigation of 8. Analyzing fMRI using GLMs" class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/glm_intro.html">8.1. An introduction to GLMs in fMRI statistical analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/first_level_model.html">8.2. First level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/second_level_model.html">8.3. Second level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/meaning_difference.html">8.4. Difference in meanings between different toolboxes</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../manipulating_images/index.html">9. Manipulation brain volumes with nilearn</a><input aria-label="Toggle navigation of 9. Manipulation brain volumes with nilearn" class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../manipulating_images/input_output.html">9.1. Input and output: neuroimaging data representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../manipulating_images/manipulating_images.html">9.2. Manipulating images: resampling, smoothing, masking, ROIs…</a></li>
<li class="toctree-l3"><a class="reference internal" href="../manipulating_images/masker_objects.html">9.3. From neuroimaging volumes to data matrices: the masker objects</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../building_blocks/index.html">10. Advanced usage: manual pipelines and scaling up</a><input aria-label="Toggle navigation of 10. Advanced usage: manual pipelines and scaling up" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../building_blocks/manual_pipeline.html">10.1. Building your own neuroimaging machine-learning pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../building_blocks/neurovault.html">10.2. Downloading statistical maps from the Neurovault repository</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../modules/index.html">API References</a><input aria-label="Toggle navigation of API References" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/connectome.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.connectome</span></code>: Functional Connectivity</a><input aria-label="Toggle navigation of nilearn.connectome: Functional Connectivity" class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.connectome.ConnectivityMeasure.html">nilearn.connectome.ConnectivityMeasure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.connectome.GroupSparseCovariance.html">nilearn.connectome.GroupSparseCovariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.connectome.GroupSparseCovarianceCV.html">nilearn.connectome.GroupSparseCovarianceCV</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.connectome.sym_matrix_to_vec.html">nilearn.connectome.sym_matrix_to_vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.connectome.vec_to_sym_matrix.html">nilearn.connectome.vec_to_sym_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.connectome.group_sparse_covariance.html">nilearn.connectome.group_sparse_covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.connectome.cov_to_corr.html">nilearn.connectome.cov_to_corr</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.connectome.prec_to_partial.html">nilearn.connectome.prec_to_partial</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/datasets.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.datasets</span></code>: Automatic Dataset Fetching</a><input aria-label="Toggle navigation of nilearn.datasets: Automatic Dataset Fetching" class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_icbm152_2009.html">nilearn.datasets.fetch_icbm152_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_icbm152_brain_gm_mask.html">nilearn.datasets.fetch_icbm152_brain_gm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_surf_fsaverage.html">nilearn.datasets.fetch_surf_fsaverage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_fsaverage.html">nilearn.datasets.load_fsaverage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_fsaverage_data.html">nilearn.datasets.load_fsaverage_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_mni152_brain_mask.html">nilearn.datasets.load_mni152_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_mni152_gm_mask.html">nilearn.datasets.load_mni152_gm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_mni152_gm_template.html">nilearn.datasets.load_mni152_gm_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_mni152_template.html">nilearn.datasets.load_mni152_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_mni152_wm_mask.html">nilearn.datasets.load_mni152_wm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_mni152_wm_template.html">nilearn.datasets.load_mni152_wm_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/icbm152_2009.html">ICBM 152 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/fsaverage.html">fsaverage template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/fsaverage3.html">fsaverage3 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/fsaverage4.html">fsaverage4 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/fsaverage5.html">fsaverage5 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/fsaverage6.html">fsaverage6 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_aal.html">nilearn.datasets.fetch_atlas_aal</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_basc_multiscale_2015.html">nilearn.datasets.fetch_atlas_basc_multiscale_2015</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_destrieux_2009.html">nilearn.datasets.fetch_atlas_destrieux_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_harvard_oxford.html">nilearn.datasets.fetch_atlas_harvard_oxford</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_juelich.html">nilearn.datasets.fetch_atlas_juelich</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_pauli_2017.html">nilearn.datasets.fetch_atlas_pauli_2017</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_schaefer_2018.html">nilearn.datasets.fetch_atlas_schaefer_2018</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_surf_destrieux.html">nilearn.datasets.fetch_atlas_surf_destrieux</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_talairach.html">nilearn.datasets.fetch_atlas_talairach</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_yeo_2011.html">nilearn.datasets.fetch_atlas_yeo_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_coords_dosenbach_2010.html">nilearn.datasets.fetch_coords_dosenbach_2010</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_coords_power_2011.html">nilearn.datasets.fetch_coords_power_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_coords_seitzman_2018.html">nilearn.datasets.fetch_coords_seitzman_2018</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_allen_2011.html">nilearn.datasets.fetch_atlas_allen_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_craddock_2012.html">nilearn.datasets.fetch_atlas_craddock_2012</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_difumo.html">nilearn.datasets.fetch_atlas_difumo</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_harvard_oxford.html">nilearn.datasets.fetch_atlas_harvard_oxford</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_juelich.html">nilearn.datasets.fetch_atlas_juelich</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_msdl.html">nilearn.datasets.fetch_atlas_msdl</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_pauli_2017.html">nilearn.datasets.fetch_atlas_pauli_2017</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_smith_2009.html">nilearn.datasets.fetch_atlas_smith_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/craddock_2012.html">Craddock 2012 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/difumo_atlases.html">DiFuMo atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/msdl_atlas.html">MSDL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/dosenbach_2010.html">Dosenbach 2010 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/power_2011.html">Power 2011 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/seitzman_2018.html">Seitzman 2018 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/aal.html">AAL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/allen_rsn_2011.html">Allen 2011 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/basc_multiscale_2015.html">BASC multiscale atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/destrieux_surface.html">Destrieux atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/harvard_oxford.html">Harvard Oxford atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/juelich.html">Juelich atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/pauli_2017.html">Pauli 2007 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/schaefer_2018.html">Schaefer 2018 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/smith_2009.html">Smith 2009 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/talairach_atlas.html">Talairach atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/yeo_2011.html">Yeo 2011 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_abide_pcp.html">nilearn.datasets.fetch_abide_pcp</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_adhd.html">nilearn.datasets.fetch_adhd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_development_fmri.html">nilearn.datasets.fetch_development_fmri</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_ds000030_urls.html">nilearn.datasets.fetch_ds000030_urls</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_fiac_first_level.html">nilearn.datasets.fetch_fiac_first_level</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_haxby.html">nilearn.datasets.fetch_haxby</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_language_localizer_demo_dataset.html">nilearn.datasets.fetch_language_localizer_demo_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_localizer_first_level.html">nilearn.datasets.fetch_localizer_first_level</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_miyawaki2008.html">nilearn.datasets.fetch_miyawaki2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_spm_auditory.html">nilearn.datasets.fetch_spm_auditory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_spm_multimodal_fmri.html">nilearn.datasets.fetch_spm_multimodal_fmri</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_surf_nki_enhanced.html">nilearn.datasets.fetch_surf_nki_enhanced</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_nki.html">nilearn.datasets.load_nki</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/ABIDE_pcp.html">ABIDE PCP dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/adhd.html">ADHD dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/bids_langloc.html">BIDS language localizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/development_fmri.html">development fMRI dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/fiac.html">fiac first level dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/haxby2001.html">Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/language_localizer_demo.html">language localizer demo dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/localizer_first_level.html">localizer first level dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/miyawaki2008.html">Miyawaki 2008 dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/spm_auditory.html">SPM auditory dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/spm_multimodal.html">SPM multimodal dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/nki_enhanced_surface.html">NKI enhanced surface dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/brainomics_localizer.html">Brainomics Localizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_localizer_button_task.html">nilearn.datasets.fetch_localizer_button_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_localizer_calculation_task.html">nilearn.datasets.fetch_localizer_calculation_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_localizer_contrasts.html">nilearn.datasets.fetch_localizer_contrasts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_megatrawls_netmats.html">nilearn.datasets.fetch_megatrawls_netmats</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_mixed_gambles.html">nilearn.datasets.fetch_mixed_gambles</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_oasis_vbm.html">nilearn.datasets.fetch_oasis_vbm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_neurovault_auditory_computation_task.html">nilearn.datasets.fetch_neurovault_auditory_computation_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_neurovault_motor_task.html">nilearn.datasets.fetch_neurovault_motor_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/Megatrawls.html">MegaTrawls Network Matrices HCP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/mixed_gambles.html">Mixed gambles statistical maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/oasis1.html">OASIS volume based morphometry maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_neurovault.html">nilearn.datasets.fetch_neurovault</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_neurovault_ids.html">nilearn.datasets.fetch_neurovault_ids</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_openneuro_dataset.html">nilearn.datasets.fetch_openneuro_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.get_data_dirs.html">nilearn.datasets.get_data_dirs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.patch_openneuro_dataset.html">nilearn.datasets.patch_openneuro_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.select_from_index.html">nilearn.datasets.select_from_index</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_sample_motor_activation_image.html">nilearn.datasets.load_sample_motor_activation_image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/neurovault.html">Neurovault statistical maps</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/decoding.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decoding</span></code>: Decoding</a><input aria-label="Toggle navigation of nilearn.decoding: Decoding" class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decoding.Decoder.html">nilearn.decoding.Decoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decoding.DecoderRegressor.html">nilearn.decoding.DecoderRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decoding.FREMClassifier.html">nilearn.decoding.FREMClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decoding.FREMRegressor.html">nilearn.decoding.FREMRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decoding.SpaceNetClassifier.html">nilearn.decoding.SpaceNetClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decoding.SpaceNetRegressor.html">nilearn.decoding.SpaceNetRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decoding.SearchLight.html">nilearn.decoding.SearchLight</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/decomposition.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decomposition</span></code>: Multivariate Decompositions</a><input aria-label="Toggle navigation of nilearn.decomposition: Multivariate Decompositions" class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decomposition.CanICA.html">nilearn.decomposition.CanICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decomposition.DictLearning.html">nilearn.decomposition.DictLearning</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/exceptions.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.exceptions</span></code>: Exceptions and warnings</a><input aria-label="Toggle navigation of nilearn.exceptions: Exceptions and warnings" class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.exceptions.MaskWarning.html">nilearn.exceptions.MaskWarning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.exceptions.NotImplementedWarning.html">nilearn.exceptions.NotImplementedWarning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.exceptions.AllVolumesRemovedError.html">nilearn.exceptions.AllVolumesRemovedError</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.exceptions.DimensionError.html">nilearn.exceptions.DimensionError</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.exceptions.MeshDimensionError.html">nilearn.exceptions.MeshDimensionError</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/glm.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.glm</span></code>: Generalized Linear Models</a><input aria-label="Toggle navigation of nilearn.glm: Generalized Linear Models" class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.Contrast.html">nilearn.glm.Contrast</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.FContrastResults.html">nilearn.glm.FContrastResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.TContrastResults.html">nilearn.glm.TContrastResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.ARModel.html">nilearn.glm.ARModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.OLSModel.html">nilearn.glm.OLSModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.LikelihoodModelResults.html">nilearn.glm.LikelihoodModelResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.RegressionResults.html">nilearn.glm.RegressionResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.SimpleRegressionResults.html">nilearn.glm.SimpleRegressionResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.compute_contrast.html">nilearn.glm.compute_contrast</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.compute_fixed_effects.html">nilearn.glm.compute_fixed_effects</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.expression_to_contrast_vector.html">nilearn.glm.expression_to_contrast_vector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.fdr_threshold.html">nilearn.glm.fdr_threshold</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.cluster_level_inference.html">nilearn.glm.cluster_level_inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.threshold_stats_img.html">nilearn.glm.threshold_stats_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.FirstLevelModel.html">nilearn.glm.first_level.FirstLevelModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.check_design_matrix.html">nilearn.glm.first_level.check_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.compute_regressor.html">nilearn.glm.first_level.compute_regressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.first_level_from_bids.html">nilearn.glm.first_level.first_level_from_bids</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.glover_dispersion_derivative.html">nilearn.glm.first_level.glover_dispersion_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.glover_hrf.html">nilearn.glm.first_level.glover_hrf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.glover_time_derivative.html">nilearn.glm.first_level.glover_time_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.make_first_level_design_matrix.html">nilearn.glm.first_level.make_first_level_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.mean_scaling.html">nilearn.glm.first_level.mean_scaling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.run_glm.html">nilearn.glm.first_level.run_glm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.spm_dispersion_derivative.html">nilearn.glm.first_level.spm_dispersion_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.spm_hrf.html">nilearn.glm.first_level.spm_hrf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.spm_time_derivative.html">nilearn.glm.first_level.spm_time_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.second_level.SecondLevelModel.html">nilearn.glm.second_level.SecondLevelModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.second_level.make_second_level_design_matrix.html">nilearn.glm.second_level.make_second_level_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.second_level.non_parametric_inference.html">nilearn.glm.second_level.non_parametric_inference</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/image.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.image</span></code>: Image Processing and Resampling Utilities</a><input aria-label="Toggle navigation of nilearn.image: Image Processing and Resampling Utilities" class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.binarize_img.html">nilearn.image.binarize_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.clean_img.html">nilearn.image.clean_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.concat_imgs.html">nilearn.image.concat_imgs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.coord_transform.html">nilearn.image.coord_transform</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.copy_img.html">nilearn.image.copy_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.crop_img.html">nilearn.image.crop_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.get_data.html">nilearn.image.get_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.high_variance_confounds.html">nilearn.image.high_variance_confounds</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.index_img.html">nilearn.image.index_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.iter_img.html">nilearn.image.iter_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.largest_connected_component_img.html">nilearn.image.largest_connected_component_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.load_img.html">nilearn.image.load_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.math_img.html">nilearn.image.math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.mean_img.html">nilearn.image.mean_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.new_img_like.html">nilearn.image.new_img_like</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.resample_img.html">nilearn.image.resample_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.resample_to_img.html">nilearn.image.resample_to_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.reorder_img.html">nilearn.image.reorder_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.smooth_img.html">nilearn.image.smooth_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.swap_img_hemispheres.html">nilearn.image.swap_img_hemispheres</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.threshold_img.html">nilearn.image.threshold_img</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/interfaces.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.interfaces</span></code>: Loading components from interfaces</a><input aria-label="Toggle navigation of nilearn.interfaces: Loading components from interfaces" class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.interfaces.bids.get_bids_files.html">nilearn.interfaces.bids.get_bids_files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.interfaces.bids.parse_bids_filename.html">nilearn.interfaces.bids.parse_bids_filename</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.interfaces.bids.save_glm_to_bids.html">nilearn.interfaces.bids.save_glm_to_bids</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.interfaces.fmriprep.load_confounds.html">nilearn.interfaces.fmriprep.load_confounds</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.interfaces.fmriprep.load_confounds_strategy.html">nilearn.interfaces.fmriprep.load_confounds_strategy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.interfaces.fsl.get_design_from_fslmat.html">nilearn.interfaces.fsl.get_design_from_fslmat</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/maskers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.maskers</span></code>: Extracting Signals from Brain Images</a><input aria-label="Toggle navigation of nilearn.maskers: Extracting Signals from Brain Images" class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.BaseMasker.html">nilearn.maskers.BaseMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html">nilearn.maskers.NiftiMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiMasker.html">nilearn.maskers.MultiNiftiMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiLabelsMasker.html">nilearn.maskers.NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiLabelsMasker.html">nilearn.maskers.MultiNiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMapsMasker.html">nilearn.maskers.NiftiMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiMapsMasker.html">nilearn.maskers.MultiNiftiMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiSpheresMasker.html">nilearn.maskers.NiftiSpheresMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.SurfaceMasker.html">nilearn.maskers.SurfaceMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.MultiSurfaceMasker.html">nilearn.maskers.MultiSurfaceMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.SurfaceLabelsMasker.html">nilearn.maskers.SurfaceLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.SurfaceMapsMasker.html">nilearn.maskers.SurfaceMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.MultiSurfaceMapsMasker.html">nilearn.maskers.MultiSurfaceMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated_reports/masker_reports_examples.html">Examples nifti masker reports</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated_reports/masker_reports_examples.html#examples-surface-masker-reports">Examples surface masker reports</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/masking.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.masking</span></code>: Data Masking Utilities</a><input aria-label="Toggle navigation of nilearn.masking: Data Masking Utilities" class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.compute_epi_mask.html">nilearn.masking.compute_epi_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.compute_multi_epi_mask.html">nilearn.masking.compute_multi_epi_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.compute_brain_mask.html">nilearn.masking.compute_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.compute_multi_brain_mask.html">nilearn.masking.compute_multi_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.compute_background_mask.html">nilearn.masking.compute_background_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.compute_multi_background_mask.html">nilearn.masking.compute_multi_background_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.intersect_masks.html">nilearn.masking.intersect_masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.apply_mask.html">nilearn.masking.apply_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.unmask.html">nilearn.masking.unmask</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/mass_univariate.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.mass_univariate</span></code>: Mass-Univariate Analysis</a><input aria-label="Toggle navigation of nilearn.mass_univariate: Mass-Univariate Analysis" class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.mass_univariate.permuted_ols.html">nilearn.mass_univariate.permuted_ols</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/plotting.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.plotting</span></code>: Plotting Brain Data</a><input aria-label="Toggle navigation of nilearn.plotting: Plotting Brain Data" class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.find_cut_slices.html">nilearn.plotting.find_cut_slices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.find_xyz_cut_coords.html">nilearn.plotting.find_xyz_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.find_parcellation_cut_coords.html">nilearn.plotting.find_parcellation_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.find_probabilistic_atlas_cut_coords.html">nilearn.plotting.find_probabilistic_atlas_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_anat.html">nilearn.plotting.plot_anat</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_carpet.html">nilearn.plotting.plot_carpet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_connectome.html">nilearn.plotting.plot_connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_contrast_matrix.html">nilearn.plotting.plot_contrast_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_design_matrix.html">nilearn.plotting.plot_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_design_matrix_correlation.html">nilearn.plotting.plot_design_matrix_correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_epi.html">nilearn.plotting.plot_epi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_event.html">nilearn.plotting.plot_event</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_glass_brain.html">nilearn.plotting.plot_glass_brain</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_img.html">nilearn.plotting.plot_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_img_on_surf.html">nilearn.plotting.plot_img_on_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_markers.html">nilearn.plotting.plot_markers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_matrix.html">nilearn.plotting.plot_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_prob_atlas.html">nilearn.plotting.plot_prob_atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_roi.html">nilearn.plotting.plot_roi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_stat_map.html">nilearn.plotting.plot_stat_map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_surf.html">nilearn.plotting.plot_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_surf_contours.html">nilearn.plotting.plot_surf_contours</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_surf_roi.html">nilearn.plotting.plot_surf_roi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_surf_stat_map.html">nilearn.plotting.plot_surf_stat_map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.show.html">nilearn.plotting.show</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.view_surf.html">nilearn.plotting.view_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.view_img_on_surf.html">nilearn.plotting.view_img_on_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.view_connectome.html">nilearn.plotting.view_connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.view_markers.html">nilearn.plotting.view_markers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.view_img.html">nilearn.plotting.view_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.img_comparison.plot_bland_altman.html">nilearn.plotting.img_comparison.plot_bland_altman</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.img_comparison.plot_img_comparison.html">nilearn.plotting.img_comparison.plot_img_comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.PlotlySurfaceFigure.html">nilearn.plotting.displays.PlotlySurfaceFigure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.BaseAxes.html">nilearn.plotting.displays.BaseAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.CutAxes.html">nilearn.plotting.displays.CutAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.GlassBrainAxes.html">nilearn.plotting.displays.GlassBrainAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.OrthoProjector.html">nilearn.plotting.displays.OrthoProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.LZRYProjector.html">nilearn.plotting.displays.LZRYProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.LYRZProjector.html">nilearn.plotting.displays.LYRZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.LYRProjector.html">nilearn.plotting.displays.LYRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.LZRProjector.html">nilearn.plotting.displays.LZRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.LRProjector.html">nilearn.plotting.displays.LRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.LProjector.html">nilearn.plotting.displays.LProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.RProjector.html">nilearn.plotting.displays.RProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.XZProjector.html">nilearn.plotting.displays.XZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.YZProjector.html">nilearn.plotting.displays.YZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.YXProjector.html">nilearn.plotting.displays.YXProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.XProjector.html">nilearn.plotting.displays.XProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.YProjector.html">nilearn.plotting.displays.YProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.ZProjector.html">nilearn.plotting.displays.ZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.BaseSlicer.html">nilearn.plotting.displays.BaseSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.OrthoSlicer.html">nilearn.plotting.displays.OrthoSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.MosaicSlicer.html">nilearn.plotting.displays.MosaicSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.TiledSlicer.html">nilearn.plotting.displays.TiledSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.XSlicer.html">nilearn.plotting.displays.XSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.XZSlicer.html">nilearn.plotting.displays.XZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.YXSlicer.html">nilearn.plotting.displays.YXSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.YZSlicer.html">nilearn.plotting.displays.YZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.YSlicer.html">nilearn.plotting.displays.YSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.ZSlicer.html">nilearn.plotting.displays.ZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.get_projector.html">nilearn.plotting.displays.get_projector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.get_slicer.html">nilearn.plotting.displays.get_slicer</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/regions.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.regions</span></code>: Operating on Regions</a><input aria-label="Toggle navigation of nilearn.regions: Operating on Regions" class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" role="switch" type="checkbox"/><label for="toctree-checkbox-30"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.RegionExtractor.html">nilearn.regions.RegionExtractor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.Parcellations.html">nilearn.regions.Parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.ReNA.html">nilearn.regions.ReNA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.HierarchicalKMeans.html">nilearn.regions.HierarchicalKMeans</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.connected_regions.html">nilearn.regions.connected_regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.connected_label_regions.html">nilearn.regions.connected_label_regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.img_to_signals_labels.html">nilearn.regions.img_to_signals_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.signals_to_img_labels.html">nilearn.regions.signals_to_img_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.img_to_signals_maps.html">nilearn.regions.img_to_signals_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.signals_to_img_maps.html">nilearn.regions.signals_to_img_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.recursive_neighbor_agglomeration.html">nilearn.regions.recursive_neighbor_agglomeration</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/reporting.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.reporting</span></code>: Reporting Functions</a><input aria-label="Toggle navigation of nilearn.reporting: Reporting Functions" class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" role="switch" type="checkbox"/><label for="toctree-checkbox-31"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.reporting.HTMLReport.html">nilearn.reporting.HTMLReport</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.reporting.get_clusters_table.html">nilearn.reporting.get_clusters_table</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.reporting.make_glm_report.html">nilearn.reporting.make_glm_report</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated_reports/glm_reports_examples.html">Examples of GLM reports</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/signal.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.signal</span></code>: Preprocessing Time Series</a><input aria-label="Toggle navigation of nilearn.signal: Preprocessing Time Series" class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" role="switch" type="checkbox"/><label for="toctree-checkbox-32"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.signal.butterworth.html">nilearn.signal.butterworth</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.signal.clean.html">nilearn.signal.clean</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.signal.high_variance_confounds.html">nilearn.signal.high_variance_confounds</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/surface.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.surface</span></code>: Manipulating Surface Data</a><input aria-label="Toggle navigation of nilearn.surface: Manipulating Surface Data" class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" role="switch" type="checkbox"/><label for="toctree-checkbox-33"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.FileMesh.html">nilearn.surface.FileMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.InMemoryMesh.html">nilearn.surface.InMemoryMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.PolyData.html">nilearn.surface.PolyData</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.PolyMesh.html">nilearn.surface.PolyMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.SurfaceImage.html">nilearn.surface.SurfaceImage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.SurfaceMesh.html">nilearn.surface.SurfaceMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.load_surf_data.html">nilearn.surface.load_surf_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.load_surf_mesh.html">nilearn.surface.load_surf_mesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.vol_to_surf.html">nilearn.surface.vol_to_surf</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../development.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ci.html">Continuous integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../maintenance.html">Maintenance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changes/whats_new.html">What’s new</a></li>
<li class="toctree-l1"><a class="reference internal" href="../authors.html">Team</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versions.html">Versions</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nilearn/nilearn">GitHub Repository</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="https://github.com/nilearn/nilearn/blob/main/doc/developers/group_sparse_covariance.rst?plain=true" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>

<div class="edit-this-page">
  <a class="muted-link"
     href="https://github.com/nilearn/nilearn/edit/main/doc/developers/group_sparse_covariance.rst"
     title="Edit this page"
     target="_blank">
    <svg aria-hidden="true" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
         fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <path d="M4 20h4l10.5 -10.5a1.5 1.5 0 0 0 -4 -4l-10.5 10.5v4" />
      <line x1="13.5" y1="6.5" x2="17.5" y2="10.5" />
    </svg>
    <span class="visually-hidden">Edit this page</span>
  </a>
</div><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="group-sparse-covariance-estimation">
<h1><span class="section-number">6.2.3.1. </span>Group-sparse covariance estimation<a class="headerlink" href="#group-sparse-covariance-estimation" title="Link to this heading">¶</a></h1>
<p>This page gives technical information on the
<a class="reference internal" href="../modules/generated/nilearn.connectome.group_sparse_covariance.html#nilearn.connectome.group_sparse_covariance" title="nilearn.connectome.group_sparse_covariance"><code class="xref py py-func docutils literal notranslate"><span class="pre">group_sparse_covariance</span></code></a> function and related. This is mainly
useful for developers or people that want to know more about
implementation.</p>
<section id="description">
<h2><span class="section-number">6.2.3.1.1. </span>Description<a class="headerlink" href="#description" title="Link to this heading">¶</a></h2>
<p><a class="reference internal" href="../modules/generated/nilearn.connectome.group_sparse_covariance.html#nilearn.connectome.group_sparse_covariance" title="nilearn.connectome.group_sparse_covariance"><code class="xref py py-func docutils literal notranslate"><span class="pre">group_sparse_covariance</span></code></a>, and <a class="reference internal" href="../modules/generated/nilearn.connectome.GroupSparseCovariance.html#nilearn.connectome.GroupSparseCovariance" title="nilearn.connectome.GroupSparseCovariance"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupSparseCovariance</span></code></a> are
two different interfaces to an implementation of the algorithm described
in Honorio <em>et al.</em><a class="footnote-reference brackets" href="#footcite-honorio2012" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>.</p>
<p>The goal of the algorithm is to take a set of K covariance matrices as
input, and estimate a set of K sparse precision matrices, using a
penalized maximum-likelihood criterion. The penalization has been
devised to enforce a common sparsity pattern in all precision
matrices. The structure is of a block coordinate descent, with a line
search as innermost loop.</p>
<p>The present implementation relies solely on NumPy, SciPy and Scikit-Learn.
Nilearn contains only Python code.</p>
<p>In addition to the basic algorithm described in the article, several
additions were implemented:</p>
<ul class="simple">
<li><p>computation of bounds for the regularization parameter</p></li>
<li><p>several stopping criteria</p></li>
<li><p>an ad-hoc cross-validation algorithm</p></li>
<li><p>signals synthesis for testing purposes</p></li>
</ul>
<p>These are described in the rest of this page. An overview of the design
choices and the history of the development is also given.</p>
</section>
<section id="numerical-stability">
<h2><span class="section-number">6.2.3.1.2. </span>Numerical stability<a class="headerlink" href="#numerical-stability" title="Link to this heading">¶</a></h2>
<p>The algorithm proved to be rather numerically stable for a wide range
of inputs. It turned out that the condition numbers of the input
matrices do not have any significant effect on numerical stability.
What is relevant is:</p>
<ul class="simple">
<li><p>covariance matrix symmetry: input covariances matrices in
<a class="reference internal" href="../modules/generated/nilearn.connectome.group_sparse_covariance.html#nilearn.connectome.group_sparse_covariance" title="nilearn.connectome.group_sparse_covariance"><code class="xref py py-func docutils literal notranslate"><span class="pre">group_sparse_covariance</span></code></a> must be as symmetric as possible.
This is true in general: a small discrepancy in symmetry tends to be
amplified. For this reason, our functions computing covariances ensure
symmetry.</p></li>
<li><p>covariance matrix normalization: using correlation matrices or
signals with unit variance is mandatory when a large number of
signals is to be processed.</p></li>
<li><p>normalization of the number of samples: the objective to be
optimized contains a sum of terms weighted by the number of samples
available for each subject. The sum of these weights must be
normalized to a small constant number (1 in the current
implementation). Failing to do this leads quickly to instability,
because too large numbers are used in the computation.</p></li>
<li><p>an on-line computation of an inverse is performed in function
<code class="docutils literal notranslate"><span class="pre">_update_submatrix</span></code>. For large problems, this is faster than
computing the full inverse each time, but gives unfortunately less
precision. In particular, symmetry is not always perfect, that’s why
it is enforced at the end on the final result.</p></li>
<li><p>the Newton-Raphson tolerance value has no influence on numerical
stability, unless very large values (like 0.5) are used.</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">debug</span></code> keyword in <a class="reference internal" href="../modules/generated/nilearn.connectome.group_sparse_covariance.html#nilearn.connectome.group_sparse_covariance" title="nilearn.connectome.group_sparse_covariance"><code class="xref py py-func docutils literal notranslate"><span class="pre">group_sparse_covariance</span></code></a> activates a set
of numerical consistency checks (mainly that matrices are s.p.d.) that
can be useful to track down numerical instability problems.</p>
</section>
<section id="execution-time">
<h2><span class="section-number">6.2.3.1.3. </span>Execution time<a class="headerlink" href="#execution-time" title="Link to this heading">¶</a></h2>
<p>The <a class="reference external" href="https://github.com/pyutils/line_profiler">line profiler</a> from
Robert Kern was used to locate execution time bottlenecks. Its
overhead proved not to be negligible (around 50% more execution time
when activated), and not evenly distributed in code lines. Global
execution times have also been measured to ensure that the findings
were valid. As the code in <a class="reference internal" href="../modules/generated/nilearn.connectome.group_sparse_covariance.html#nilearn.connectome.group_sparse_covariance" title="nilearn.connectome.group_sparse_covariance"><code class="xref py py-func docutils literal notranslate"><span class="pre">group_sparse_covariance</span></code></a> is highly
serial, and rather low-level, some lines have to be executed a very
large number of times (10^6 times is easily reached), one of the
bottlenecks is thus the Python interpreter overhead. Optimizing then
boils down to reducing the number of code lines and function calls in
the most executed parts: the Newton-Raphson (line search) loop. It is
for this reason that it has been written inline instead of calling
Scipy’s version (it saves a lot of lines and calls). A lot of small
optimizations of this kind have been done. It is possible that some of
these optimizations give less numerical precision that the naive
operation. But the original author could not tell.</p>
<p>Speed optimization has been performed by checking the wall-clock time
required to get to a given precision, and not the number of
iterations. This is what “fast” means in practice: short overall
execution time. Tuning of the Newton-Raphson (NR) loop gives a good
example of the validity of this approach: the goal was to set the
tolerance on the result. Using a large value reduces the number of
iterations for NR, saving a lot of time. On the other hand, a loose
tolerance increases the number of iterations in the coordinate descent
loop, therefore increasing the overall execution time. Measurement
proved that tight tolerances were leading to faster convergence rates.</p>
<p>Care has been taken to use proper ordering of data in arrays. In
particular, three-dimensional arrays containing precision matrices are
in Fortran order, to get prec[…, k] contiguous for any k. This is
important to avoid copies by lapack/atlas functions, such as matrix
inverse or dot product. It is also consistent with arrays returned by
<code class="docutils literal notranslate"><span class="pre">nibabel.load</span></code>.</p>
<p>An optimization that can be performed, but couldn’t be implemented
short of having proper linalg functions for it is to process only half
of each matrix: all are symmetric. This would improve numerical
stability while saving some execution time. Part of this could be done
with versions of Scipy that weren’t available on the targeted systems
at the time of writing (Ubuntu 10.04 and 12.04).</p>
<p>Memory optimization hasn’t been performed, because all functions
process covariance matrices only, that are quite small compared to the
signals from which they are generated.</p>
</section>
<section id="synthetic-dataset">
<h2><span class="section-number">6.2.3.1.4. </span>Synthetic dataset<a class="headerlink" href="#synthetic-dataset" title="Link to this heading">¶</a></h2>
<p>For testing purposes, a function for synthesis of signals based on
sparse precision matrices has been written:
<code class="docutils literal notranslate"><span class="pre">nilearn._utils.data_gen.generate_group_sparse_gaussian_graphs</span></code>.
Synthesizing such signals is a hard problem that wasn’t solved in the
present implementation. It is hopefully good enough.</p>
<p>This function generates n_subjects time, n_features signals with a
variable number of samples. Every subject has the same number of
features (i.e. signals), for a given subject every signal has the same
number of samples, but between two subjects, the sample number can
differ. This structure is close to what is available in practice.</p>
<p>Here is how signals are generated:</p>
<ul class="simple">
<li><p>a “topology” matrix containing only zero and ones is generated. This
will govern the sparsity pattern of the precision matrices.</p></li>
<li><p>for each subject, a precision matrix is generated by replacing every
1 in the topology matrix by a random positive number, then
multiplying the resulting matrix by its transpose to get a positive
definite matrix. This is a way to get a sparse definite positive
matrix.</p></li>
<li><p>inverting precision matrices gives covariance matrices, that are in
turn used to generate signals.</p></li>
</ul>
<p>The hardest part is generating sparse symmetric positive definite
matrices, while controlling the sparsity level. With the present
scheme, only the location of zeros in the <em>square root</em> of the
precision matrices can be specified. Therefore the final sparsity
level depends not only on the initial sparsity level, but also on the
precise location of zeros. Two different sparsity patterns with the
same number of zeros can lead to two significantly different sparsity
level in precision matrices. In practice, it means that for a given
value of the <code class="docutils literal notranslate"><span class="pre">density</span></code> parameter in
<code class="docutils literal notranslate"><span class="pre">nilearn._utils.data_gen.generate_group_sparse_gaussian_graphs</span></code>,
the actual number of zeros in the precision matrices can fluctuate
widely depending on the random number generation.</p>
<p>The condition number of the precision matrices depends on the range of
numbers used to fill the off-diagonal part. The shorter the range (and
the closer to zero) the lower the condition number.</p>
<p>This generator is useful for debugging and testing. However, the
signals obtained are significantly different from those from
experimental data. Some unrealistic features: each signal has a
perfectly white spectrum (any two samples are decorrelated), and there
is no global additive noise (no confounds whatsoever).</p>
</section>
<section id="stopping-criteria">
<h2><span class="section-number">6.2.3.1.5. </span>Stopping criteria<a class="headerlink" href="#stopping-criteria" title="Link to this heading">¶</a></h2>
<p>As with any iterative algorithm, iteration should be stopped at some
point, which is still mostly an open problem. Several heuristic
techniques have been tested and implemented.</p>
<section id="maximum-number-of-iterations">
<h3><span class="section-number">6.2.3.1.5.1. </span>Maximum number of iterations<a class="headerlink" href="#maximum-number-of-iterations" title="Link to this heading">¶</a></h3>
<p>The simplest way of stopping optimization is to always execute a fixed
number of iterations. This is simple but most of the time gives slow
or bad results. The convergence rate highly depends on the number of
features (size of one covariance matrix), and on the value of the
regularization parameter (high values give fast convergence, and low
values slow convergence). If the requested iteration number is too low,
large or weakly regularized problems will be far from the optimum. On
the other hand, if the requested iteration number is too large, a lot
of time is wasted for almost no gain.</p>
</section>
<section id="duality-gap">
<h3><span class="section-number">6.2.3.1.5.2. </span>Duality gap<a class="headerlink" href="#duality-gap" title="Link to this heading">¶</a></h3>
<p>A better way to stop iteration is to use an upper bound on the duality
gap value, since the problem is convex. This is performed in
<code class="docutils literal notranslate"><span class="pre">group_sparse_covariance_costs</span></code>. The article by Honorio &amp;
Samaras gives the formula for the dual cost, and proves that the
derived bound at optimum is tight (strong duality holds). However, the
dual problem is <em>not</em> solved by this algorithm, thus bounding the
duality gap away from the optimum implies finding a feasible dual
point. This proved to be quite hard in practice, because one has to
compute positive semi-definite matrices under a norm constraint.</p>
<p>What is done is computing an estimate for a dual point using the
formula relating the primal and dual points at optimum. This estimate
does not satisfies in general the norm constraint. It is then
projected on the corresponding ball. Most of the time, this is enough
to ensure the required positive definiteness of another quantity. As
the primal point is coming close to the optimal, the estimate for the
dual point also comes close to the optimal, and the initial estimate
is closer and closer to the norm ball.</p>
<p>But there are cases for which the projection is not enough to get to a
feasible point. No solution to this problem (simultaneous projection
on a norm ball and on a set of positive definite matrices) has been
found. In that case, an easier to compute but non-tight bound is used
instead.</p>
<p>In practice, using the duality gap value to stop iteration leads to
guaranteed uncertainty on the objective value, in any case. No time is
lost on over optimizing rapidly converging problems. However, the
duality gap criterion can lead to prohibitive computation time on
slowly converging cases. In practice, finding a proper value for the
duality gap uncertainty can be tricky, because it is most easily given
as an absolute uncertainty on an objective whose value highly depends
on input data.</p>
</section>
<section id="variation-of-norm-of-estimate">
<h3><span class="section-number">6.2.3.1.5.3. </span>Variation of norm of estimate<a class="headerlink" href="#variation-of-norm-of-estimate" title="Link to this heading">¶</a></h3>
<p>Depending on the application at hand, giving an uncertainty on the
precision matrices instead of the objective can be useful. This is
partly achieved by computing the change of the precision estimate
between two iterations. Optimization is stopped once this value goes
below a threshold. The maximum norm (maximum of the absolute value of
the difference) is used in the current implementation. It ensures that
all coefficients vary less than the threshold when optimization is
stopped.</p>
<p>This technique it is only a way to stop iterating based on the
estimate value instead of the criterion value. It does <em>not</em> ensure a
given uncertainty on the estimate. This has been tested on synthetic
and real <a class="reference internal" href="../glossary.html#term-fMRI"><span class="xref std std-term">fMRI</span></a> data: using two different starting points leads to two
estimates that can differ (in max norm) by more than the threshold
(see next paragraph). However, it has the same property as the duality
gap criterion: quickly converging cases use fewer iterations than
slower cases. From a performance point of view, this is a good thing.</p>
<p>One advantage of this criterion is that the threshold value does not
depend significantly on the input data. Matrix coefficients can be
requested to change less than e.g. 0.1 for any size of the input.</p>
</section>
<section id="initial-estimate-value">
<h3><span class="section-number">6.2.3.1.5.4. </span>Initial estimate value<a class="headerlink" href="#initial-estimate-value" title="Link to this heading">¶</a></h3>
<p>One of the possible way to reduce the computation time of an iterating
algorithm is to start with a initial guess that is as close as
possible to the optimum. In the present case, two initializations were
tested: using a diagonal matrix (with variance of input signals), or
using a Ledoit-Wolf estimate. It turned out that even if the
Ledoit-Wolf initialization allows for starting with a better value for
the objective, the difference with the diagonal matrix initialization
dwindles rather fast. It does not allow any significant speedup
in practice.</p>
<p>Only initialization by the diagonal matrix, as
in the original paper, has been implemented.</p>
</section>
<section id="modifying-the-stopping-criterion">
<h3><span class="section-number">6.2.3.1.5.5. </span>Modifying the stopping criterion<a class="headerlink" href="#modifying-the-stopping-criterion" title="Link to this heading">¶</a></h3>
<p>Modifying the stopping criterion is more complicated than specifying
the initial estimate, since it requires to gain access to the
algorithm internals. This is achieved by a technique close to
aspect-oriented programming: a function can be provided by the user,
that will be called after each iteration, with all internal values as
parameter. If that function returns True, iteration is stopped.
Changing the stopping criterion is thus just a matter of writing a
function and passing it to <a class="reference internal" href="../modules/generated/nilearn.connectome.group_sparse_covariance.html#nilearn.connectome.group_sparse_covariance" title="nilearn.connectome.group_sparse_covariance"><code class="xref py py-func docutils literal notranslate"><span class="pre">group_sparse_covariance</span></code></a>. The same
feature can be used to study the algorithm convergence properties. An
example is the <code class="docutils literal notranslate"><span class="pre">EarlyStopProbe</span></code> class used by the
cross-validation object.</p>
</section>
</section>
<section id="cross-validation-algorithm">
<h2><span class="section-number">6.2.3.1.6. </span>Cross-validation algorithm<a class="headerlink" href="#cross-validation-algorithm" title="Link to this heading">¶</a></h2>
<p>An ad-hoc cross-validation scheme has been implemented in the
<a class="reference internal" href="../modules/generated/nilearn.connectome.GroupSparseCovarianceCV.html#nilearn.connectome.GroupSparseCovarianceCV" title="nilearn.connectome.GroupSparseCovarianceCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupSparseCovarianceCV</span></code></a> class. This implementation is
significantly faster than the “naive” cross-validation scheme.</p>
<p>The cross-validating object performs to distinct tasks: the first one
is to select a value for the regularization parameter, the second is
fitting the precision matrices for the selected parameter. The latter
is identical to what has been described in the previous parts, we thus
focus only on the former.</p>
<section id="principle-of-cross-validation">
<h3><span class="section-number">6.2.3.1.6.1. </span>Principle of cross-validation<a class="headerlink" href="#principle-of-cross-validation" title="Link to this heading">¶</a></h3>
<p>Cross-validation consists in splitting the input samples into two
different sets: train and test. For several values of the
regularization parameter, a model is fit on the train set, and the
generalization performance is assessed on the test set, by computing
the unpenalized criterion (log-likelihood) using the precisions
matrices obtained on the train set with the empirical covariances of
the test set. The chosen regularization parameter is given by the best
criterion on the test set.</p>
<p>The simplest scheme is here to fit many models, for many values of the
regularization parameter alpha, and pick up the best value afterward.
It works in any case, but is very time-consuming. A cleverer scheme
is used, that is very close to that used in the graph lasso
implementation in Scikit-Learn.</p>
</section>
<section id="bounds-on-alpha">
<h3><span class="section-number">6.2.3.1.6.2. </span>Bounds on alpha<a class="headerlink" href="#bounds-on-alpha" title="Link to this heading">¶</a></h3>
<p>The simplest and fastest thing is to get bounds for the value of
alpha. Above a critical value, the optimal precision matrices are
fully sparse (i.e. diagonal). This critical value depends on the input
covariance matrices, and can be obtained by <code class="docutils literal notranslate"><span class="pre">compute_alpha_max</span></code>.
The formula for computing this critical value can be obtained with
techniques presented in Duchi <em>et al.</em><a class="footnote-reference brackets" href="#footcite-duchi2012" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>.</p>
<p>This very same method can be also used for determining a lower
critical value, for which the optimal precision matrices are fully
dense (no zero values). In practice, this critical value is zero if
there is a zero in the input matrices. For this reason, the second
value returned by <code class="docutils literal notranslate"><span class="pre">compute_alpha_max</span></code> is that under which all
coefficients <em>that can be non-zero</em> are non-zero in the optimal
precision matrices.</p>
</section>
<section id="iterative-grid-search">
<h3><span class="section-number">6.2.3.1.6.3. </span>Iterative grid search<a class="headerlink" href="#iterative-grid-search" title="Link to this heading">¶</a></h3>
<p>Getting the regularization parameter optimal value is equivalent to
finding the location of the maximum on the curve log-likelihood vs
regularization parameter. In practice this curve is rather smooth,
with only a single maximum. This can be exploited to reduce the number
of parameter values to try. The strategy used in this implementation
consists of a iterative grid search: the maximum value is searched on
a very loose grid of parameter values (by default, only 4 values are
used), then a tighter grid near the found maximum is computed, and so
on. This allows for a very precise determination of the maximum
location while reducing a lot the required evaluation number. The code
is very close to what is done in
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.covariance.GraphicalLassoCV.html#sklearn.covariance.GraphicalLassoCV" title="(in scikit-learn v1.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.covariance.GraphicalLassoCV</span></code></a>.</p>
</section>
<section id="warm-restart">
<h3><span class="section-number">6.2.3.1.6.4. </span>Warm restart<a class="headerlink" href="#warm-restart" title="Link to this heading">¶</a></h3>
<p>During each step of the grid search, a set of regularization
parameters has to been tested. The straightforward strategy consists of
running independently each fit, each optimization being started with
basically the same initial value (diagonal matrices). Execution time
can be reduced by running all optimizations sequentially, and using
the final result of one as initial value for the next. This goes
faster because it saves part of the optimization trajectory starting
with the second one. However, there is a real gain in execution time
only if the parameter values are ordered from the largest to the
smallest (and not the other way).</p>
<p>The usefulness of this scheme depends on several things. First, using
warm restart does not gives exactly the same result as running
independent optimizations, because optimization paths are not the
same. This is not an issue for cross-validation, since there are many
other larger sources of fluctuations. It has been checked that in
practice, the selected value does not change. Second, using warm
restart forces running all optimization one after another: there is no
parallelism at all. However, this is true only for a given fold: when
n folds are used, n such evaluations can be run in parallel. Thus, the
fact that warm restart gives faster evaluation compared to fixed
initialization depends on the number of folds, and the number of
computation cores. No more cores that the number of folds can be used
at the same time. Thus, if the number of folds is much smaller than
the number of usable cores, warm restart slows down computation (note
that if the goal is energy efficiency, not speed, warm restart is
always a good idea.) This argument is also valid for the iterative
grid search: if many cores are available, the brute-force grid search
is faster than the iterative scheme, just because every point can be
explored simultaneously, without waiting for the previous step to
finish. Many more evaluations are performed, but the overall running
time is limited of by the slowest evaluation. The choice of these
schemes (iterative grid search and warm restart) has been made in the
present implementation because the targeted hardware is a commodity
computer, with a moderate number of cores (4 to 16). More cores (and
memory) will probably be available in future years, these schemes
could be removed easily.</p>
</section>
<section id="stopping-criterion">
<h3><span class="section-number">6.2.3.1.6.5. </span>Stopping criterion<a class="headerlink" href="#stopping-criterion" title="Link to this heading">¶</a></h3>
<p>Finding the regularization parameter optimal value is equivalent to
finding a maximum. But since only the location of the maximum (not its
value) is of interest, any curve that peaks at the same location than
the log-likelihood can be used.</p>
<p>Implicitly, the curve whose maximum is sought is supposed to be
obtained after convergence for any value of alpha. This is never the
case in practice: a stopping criterion has to be used. In the present
implementation, the variation criterion gives results that seem to be
consistent with what would be obtained at convergence (that is: the
log-likelihood-vs-alpha curve seems to be close to convergence). This
can be pushed one step further: any stopping criterion that gives the
<em>same maximum location</em> can be used instead. We stress that only the
location is important: the curve can be anything apart from that.</p>
<p>It was found that stopping iteration just after the log-likelihood has
reached a maximum works in most cases. The obtained log-likelihood vs
alpha curve is different, but its maximum is the same as with the
variation criterion stopping. It is also faster (2 times to 4 times
in our tests).</p>
<p>In more detail: for a given value of alpha, start optimization. After
each step, compute the log-likelihood on the test set. If the current
value is smaller than the previous one, then stop. The variation
criterion is also computed for the rare cases when the log-likelihood
never decreases, and a maximum number of iterations is enforced,
to limit the time spent optimizing in any case.</p>
<p>It is possible to disable the first criterion with <code class="docutils literal notranslate"><span class="pre">the</span>
<span class="pre">early_stopping</span></code> keyword in <a class="reference internal" href="../modules/generated/nilearn.connectome.GroupSparseCovarianceCV.html#nilearn.connectome.GroupSparseCovarianceCV" title="nilearn.connectome.GroupSparseCovarianceCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupSparseCovarianceCV</span></code></a>. In that
case, only the two latter criteria are used. This provides a mean to
test for the validity of the heuristic.</p>
</section>
<section id="references">
<h3><span class="section-number">6.2.3.1.6.6. </span>References<a class="headerlink" href="#references" title="Link to this heading">¶</a></h3>
<div class="docutils container" id="id3">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-honorio2012" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Jean Honorio, Tommi Jaakkola, and Dimitris Samaras. On the statistical efficiency of l1,p multi-task learning of gaussian graphical models. <em>arXiv</em>, 10 2012. <a class="reference external" href="https://arxiv.org/abs/1207.4255">arXiv:1207.4255</a>.</p>
</aside>
<aside class="footnote brackets" id="footcite-duchi2012" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>John Duchi, Stephen Gould, and Daphne Koller. Projected subgradient methods for learning sparse gaussians. <em>arXiv</em>, 06 2012. <a class="reference external" href="https://arxiv.org/abs/1206.3249">arXiv:1206.3249</a>.</p>
</aside>
</aside>
</div>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../connectivity/resting_state_networks.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title"><span class="section-number">6.3. </span>Extracting functional brain networks: ICA and related</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="../connectivity/connectome_extraction.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title"><span class="section-number">6.2. </span>Connectome extraction: inverse covariance for direct connections</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; The nilearn developers
- Code and documentation distributed under BSD license.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link fa-brands fa-solid fa-github fa-2x" href="https://github.com/nilearn/nilearn" aria-label="GitHub"></a>
              <a class="muted-link fa-brands fa-solid fa-bluesky fa-2x" href="https://bsky.app/profile/nilearn.bsky.social" aria-label="Bluesky"></a>
              <a class="muted-link fa-brands fa-solid fa-mastodon fa-2x" href="https://fosstodon.org/@nilearn" aria-label="Mastodon"></a>
              <a class="muted-link fa-brands fa-solid fa-discord fa-2x" href="https://discord.com/invite/SsQABEJHkZ" aria-label="Discord"></a>
              <a class="muted-link fa-brands fa-solid fa-youtube fa-2x" href="https://www.youtube.com/channel/UCU6BMAi2zOhNFnDkbdevmPw" aria-label="Youtube"></a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">6.2.3.1. Group-sparse covariance estimation</a><ul>
<li><a class="reference internal" href="#description">6.2.3.1.1. Description</a></li>
<li><a class="reference internal" href="#numerical-stability">6.2.3.1.2. Numerical stability</a></li>
<li><a class="reference internal" href="#execution-time">6.2.3.1.3. Execution time</a></li>
<li><a class="reference internal" href="#synthetic-dataset">6.2.3.1.4. Synthetic dataset</a></li>
<li><a class="reference internal" href="#stopping-criteria">6.2.3.1.5. Stopping criteria</a><ul>
<li><a class="reference internal" href="#maximum-number-of-iterations">6.2.3.1.5.1. Maximum number of iterations</a></li>
<li><a class="reference internal" href="#duality-gap">6.2.3.1.5.2. Duality gap</a></li>
<li><a class="reference internal" href="#variation-of-norm-of-estimate">6.2.3.1.5.3. Variation of norm of estimate</a></li>
<li><a class="reference internal" href="#initial-estimate-value">6.2.3.1.5.4. Initial estimate value</a></li>
<li><a class="reference internal" href="#modifying-the-stopping-criterion">6.2.3.1.5.5. Modifying the stopping criterion</a></li>
</ul>
</li>
<li><a class="reference internal" href="#cross-validation-algorithm">6.2.3.1.6. Cross-validation algorithm</a><ul>
<li><a class="reference internal" href="#principle-of-cross-validation">6.2.3.1.6.1. Principle of cross-validation</a></li>
<li><a class="reference internal" href="#bounds-on-alpha">6.2.3.1.6.2. Bounds on alpha</a></li>
<li><a class="reference internal" href="#iterative-grid-search">6.2.3.1.6.3. Iterative grid search</a></li>
<li><a class="reference internal" href="#warm-restart">6.2.3.1.6.4. Warm restart</a></li>
<li><a class="reference internal" href="#stopping-criterion">6.2.3.1.6.5. Stopping criterion</a></li>
<li><a class="reference internal" href="#references">6.2.3.1.6.6. References</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=4ea706d9"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    </body>
</html>