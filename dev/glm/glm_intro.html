
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta property="og:title" content="5.1. An introduction to GLMs in fMRI statistical analysis" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://nilearn.github.io/glm/glm_intro.html" />
  <meta property="og:site_name" content="Nilearn" />
  <meta property="og:description" content="Contents: A primer on BOLD-fMRI data analysis. A primer on BOLD-fMRI data analysis: What is fMRI ?: Functional magnetic resonance imaging ( fMRI) is based on the fact that when local neural activit..." />
  <meta property="og:image" content="../_images/stimulation-time-diagram.png" />
  <meta property="og:image:alt" content="Nilearn" />
  
    <title>Nilearn: Statistical Analysis for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/nature.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5.2. First level models" href="first_level_model.html" />
    <link rel="prev" title="5. Analyzing fMRI using GLMs" href="index.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">


<script type="text/javascript">
function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});
</script>
<script type="text/javascript">
function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../index.html">
      <img src="../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../manipulating_images/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../modules/reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Statistics for NeuroImaging in Python</h2>
  </div>
  <div class="search_form">
    <div class="gcse-search" id="cse" style="width: 100%;"></div>
    <script>
      (function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </div>
</div>



<div class=related-wrapper>
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="first_level_model.html" title="5.2. First level models"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="index.html" title="5. Analyzing fMRI using GLMs"
             accesskey="P">previous</a> |</li>
<li><a href="../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../authors.html">About</a>|&nbsp;</li>
<li><a href="../glossary.html">Glossary</a>|&nbsp;</li>
<li><a href="../bibliography.html">Bibliography</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="index.html" accesskey="U"><span class="section-number">5. </span>Analyzing fMRI using GLMs</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Nilearn: Statistical Analysis for NeuroImaging in Python</a></li> 
      </ul>
    </div>
</div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="an-introduction-to-glms-in-fmri-statistical-analysis">
<span id="glm-intro"></span><h1><span class="section-number">5.1. </span>An introduction to GLMs in fMRI statistical analysis<a class="headerlink" href="#an-introduction-to-glms-in-fmri-statistical-analysis" title="Permalink to this headline">¶</a></h1>
<div class="contents local topic" id="contents">
<p class="topic-title"><strong>Contents</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="#a-primer-on-bold-fmri-data-analysis" id="id2">A primer on BOLD-fMRI data analysis</a></p></li>
</ul>
</div>
<section id="a-primer-on-bold-fmri-data-analysis">
<h2><a class="toc-backref" href="#id2"><span class="section-number">5.1.1. </span>A primer on BOLD-fMRI data analysis</a><a class="headerlink" href="#a-primer-on-bold-fmri-data-analysis" title="Permalink to this headline">¶</a></h2>
<section id="what-is-fmri">
<h3><span class="section-number">5.1.1.1. </span>What is fMRI ?<a class="headerlink" href="#what-is-fmri" title="Permalink to this headline">¶</a></h3>
<p>Functional magnetic resonance imaging (<a class="reference internal" href="../glossary.html#term-fMRI"><span class="xref std std-term">fMRI</span></a>) is based on the fact that when local neural activity increases, increases in metabolism and blood flow lead to fluctuations of the relative concentrations of oxyhaemoglobin (the red cells in the blood that carry oxygen) and deoxyhaemoglobin (the same red cells after they have delivered the oxygen). Oxyhaemoglobin and deoxyhaemoglobin have different magnetic properties (diamagnetic and paramagnetic, respectively), and they affect the local magnetic field in different ways. The signal picked up by the MRI scanner is sensitive to these modifications of the local magnetic field. To record cerebral activity during functional sessions, the scanner is tuned to detect this “Blood Oxygen Level Dependent” (<a class="reference internal" href="../glossary.html#term-BOLD"><span class="xref std std-term">BOLD</span></a>) signal.</p>
<p>Brain activity is measured in sessions that span several minutes, during which the participant performs some cognitive task and the scanner acquires brain images, typically every 2 or 3 seconds (the time between two successive image acquisition is called the Repetition time, or <a class="reference internal" href="../glossary.html#term-TR"><span class="xref std std-term">TR</span></a>).</p>
<p>A cerebral MR image provides a 3D image of the brain that can be decomposed into <a class="reference external" href="https://en.wikipedia.org/wiki/Voxel">voxels</a> (the equivalent of pixels, but in 3 dimensions). The series of images acquired during a functional session provides, in each voxel, a time series of positive real number representing the MRI signal, sampled at the <a class="reference internal" href="../glossary.html#term-TR"><span class="xref std std-term">TR</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Before fMRI images can be used to do meaningful comparisons, they must be processed to ensure that the voxels that are being compared represent the same brain regions, irrespective of the variability in size and shape of the brain and its microarchitecture across different subjects in the experiment. The process is called spatial registration or spatial normalization. During this procedure, the voxels of all the brain images are ‘registered’ to correspond to the same region of the brain. Usually, the images (their voxels) are registered to a standard ‘template’ brain image (its voxels). One often used standard template is the MNI152 template from the Montreal Neurological Institute. Once this is done, the coordinates of a voxel are in the same space as the template and can be used to estimate its brain location using brain atlases based on that same template. As previously mentioned, the nilearn package does not perform spatial preprocessing; it only does statistical analyses on the voxel time series. For preprocessing functions, users are referred to <a class="reference external" href="https://nipype.readthedocs.io/en/latest/">Nipype</a> or <a class="reference external" href="https://fmriprep.readthedocs.io/en/stable/">fMRIPrep</a>.</p>
</div>
</section>
<section id="fmri-data-modelling">
<h3><span class="section-number">5.1.1.2. </span>fMRI data modelling<a class="headerlink" href="#fmri-data-modelling" title="Permalink to this headline">¶</a></h3>
<p>One way to analyze times series consists in comparing them to a <em>model</em> built from our knowledge of the events that occurred during the functional session. Events can correspond to actions of the participant (e.g. button presses), presentations of sensory stimui (e.g. sound, images), or hypothesized internal processes (e.g. memorization of a stimulus), …</p>
<blockquote>
<div><figure class="align-default">
<img alt="../_images/stimulation-time-diagram.png" src="../_images/stimulation-time-diagram.png" />
</figure>
</div></blockquote>
<p>One expects that a brain region involved in the processing of a certain type of event (e.g. the auditory cortex for sounds) would show a time course of activation that correlates with the time-diagram of these events. If the fMRI signal directly showed neural activity and did not contain any noise, we could just look at it in various voxels and detect those that conform to the time-diagrams.</p>
<p>But we know from previous measurements that the BOLD signal does not follow the exact time course of stimulus processing and the underlying neural activity. The BOLD response reflects changes in blood flow and concentrations in oxy-deoxy haemoglobin, all together forming a <a class="reference external" href="https://en.wikipedia.org/wiki/Haemodynamic_response">haemodynamic response</a> which is sluggish and long-lasting, as can be seen in the following figure showing the response to an impulsive event (for example, an auditory click played to the participants).</p>
<figure class="align-default">
<img alt="../_images/spm_iHRF.png" src="../_images/spm_iHRF.png" />
</figure>
<p>Using our knowledge of the haemodynamic response, we can build a predicted time course from the time-diagram of the event (the operation is known as  <a class="reference external" href="https://en.wikipedia.org/wiki/Convolution">convolution</a>; simply stated, it measures how the shape of one function’s plot affects the shape of another function’s plot. <strong>Remark:</strong> it assumes linearity of the BOLD response, an assumption that may be wrong in some scenarios). It is this predicted time course, also known as a <em>predictor</em>, that is compared to the actual fMRI signal. If the correlation between the predictor and the signal is higher than expected by chance, the voxel is said to exhibit a significant response to the event type.</p>
<figure class="align-default">
<img alt="../_images/time-course-and-model-fit-in-a-voxel.png" src="../_images/time-course-and-model-fit-in-a-voxel.png" />
</figure>
<p>Correlations are computed separately at each voxel and a correlation map can be produced displaying  the values of correlations (real numbers between -1 and +1) at each voxel. Generally, however, the maps presented in the papers report the significance of the correlations at each voxel, using T, Z or p values for the null hypothesis test of no correlation (see below). For example, the following figure displays a Z-map showing voxels responding to auditory events. Large (positive or negative) values are unlikely to be due to chance alone. The map is thresholded so that only voxels with a p-value less than 1/1000 are coloured.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In this approach, hypothesis tests are conducted in parallel at many voxels, increasing the liklelihood of False Positives. This is known as the Problem of <a class="reference internal" href="#multiple-comparisons">Multiple Comparisons</a>. Some common strategies for dealing with this are discussed later in this page. This issue can be addressed in nilearn using permutations tests.</p>
</div>
<figure class="align-default">
<img alt="../_images/example-spmZ_map.png" src="../_images/example-spmZ_map.png" />
</figure>
<p>In most fMRI experiments, several predictors are needed to fully describe the events occurring during the session – for example, the experimenter may want to distinguish brain activities linked to the perception of auditory stimuli and to button presses. To find the effect specific to each predictor, a multiple  <a class="reference external" href="https://en.wikipedia.org/wiki/Linear_regression">linear regression</a> approach is typically used: all predictors are entered as columns in a <em>design matrix</em> and the software finds the linear combination of these columns that best fits the signal. The weights assigned to each predictor by this linear combination are estimates of the contribution of this predictor to the response in the voxel. One can plot this using effect size maps or, maps showing their statistical significance (how unlikely they are under the null hypothesis of no effect).</p>
<p>In brief, the analysis of fMRI images involves:</p>
<ol class="arabic simple">
<li><p>Describing the paradigm in terms of events grouped by type, occurring at certain times and having specific durations.</p></li>
<li><p>Creating predictors for each type of event, typically using a convolution by the haemodynamic response.</p></li>
<li><p>Assembling these predictors in a design matrix, providing a <em>linear model</em>.</p></li>
<li><p>Estimating the parameters of the model, i.e., the weights associated with each predictor at each voxel, using linear regression.</p></li>
<li><p>Displaying the coefficients or their linear combination, and/or their statistical significance.</p></li>
</ol>
</section>
<section id="fmri-statistical-analysis">
<h3><span class="section-number">5.1.1.3. </span>fMRI statistical analysis<a class="headerlink" href="#fmri-statistical-analysis" title="Permalink to this headline">¶</a></h3>
<p>As explained in the previous section, the basic statistical analysis of fMRI is conceptually a correlation analysis, where one identifies whether a certain combination (contrast) of columns of the design matrix fits a significant proportion of the fMRI signal at a given location.</p>
<p>It can be shown that this is equivalent to studying whether the estimated contrast effect is large with respect to the uncertainty about its exact value. Concretely, we compute the effect size estimate and the uncertainty about its value and divide the two. The resulting number has no physical dimension, it is a statistic – a Student or t-statistic, which we denote by <cite>t</cite>. Next, based on <cite>t</cite>, we want to decide whether the true effect was indeed greater than zero or not.</p>
<p><cite>t</cite> would not necessarily be 0 if the true effect were zero: by chance, noise in the data may be partly explained by the contrast of interest. However, if we assume that the noise is Gaussian and that the model is correctly specified, then we know that <cite>t</cite> should follow a Student distribution with <cite>dof</cite> degrees of freedom, where <cite>dof</cite> is the number of free parameters in the model: in practice, the number of observations (i.e. the number of time points), <cite>n_scans</cite> minus the number of effects modelled (i.e. the number of columns <cite>n_columns</cite>) of the design matrix:</p>
<blockquote>
<div><p><img class="math" src="../_images/math/499002493613ac62a752d5f805fbb1f9e893facd.png" alt="dof = n\_scans - n\_columns"/></p>
</div></blockquote>
<p>With this we can do statistical inference. Given a pre-defined error rate <img class="math" src="../_images/math/2f5aa019312e1bbc969deab8dca8b00f76025404.png" alt="\alpha"/>, we compare the observed <cite>t</cite> to the <img class="math" src="../_images/math/c87d80a9ca1dd2540182b6d20843ecc568241c87.png" alt="(1-\alpha)"/> quantile of the Student distribution with <cite>dof</cite> degrees of freedom. If <cite>t</cite> is greater than this number we can reject the null hypothesis with a <em>p-value</em> <img class="math" src="../_images/math/2f5aa019312e1bbc969deab8dca8b00f76025404.png" alt="\alpha"/>; meaning, if there were no effect, the probability of observing an effect as large as <cite>t</cite> would be less than <img class="math" src="../_images/math/2f5aa019312e1bbc969deab8dca8b00f76025404.png" alt="\alpha"/>.</p>
<blockquote>
<div><figure class="align-default">
<img alt="../_images/student.png" src="../_images/student.png" />
</figure>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A frequent misconception consists in interpreting <img class="math" src="../_images/math/70e890167882143be3c8d9371e4b427448601348.png" alt="1- \alpha"/> as the probability that there is indeed an effect: this is not true! Here we rely on a frequentist approach, that does not support Bayesian interpretation. See e.g. <a class="reference external" href="https://en.wikipedia.org/wiki/Frequentist_inference">https://en.wikipedia.org/wiki/Frequentist_inference</a></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is cumbersome to work with Student distributions, since these always require to specify the degrees of freedom. To avoid this, we can transform <cite>t</cite> to another variable <cite>z</cite> such that comparing <cite>t</cite> to the Student distribution with <cite>dof</cite> degrees of freedom is equivalent to comparing <cite>z</cite> to a standard normal distribution. We call this the z-transform of <cite>t</cite>. We call the <img class="math" src="../_images/math/c87d80a9ca1dd2540182b6d20843ecc568241c87.png" alt="(1-\alpha)"/> quantile of the normal distribution the <em>threshold</em>, since we use this value to declare voxels active or not.</p>
</div>
</section>
<section id="multiple-comparisons">
<span id="id1"></span><h3><span class="section-number">5.1.1.4. </span>Multiple Comparisons<a class="headerlink" href="#multiple-comparisons" title="Permalink to this headline">¶</a></h3>
<dl class="simple">
<dt>A well-known issue that arises here is that of multiple comparisons:</dt><dd><p>when a statistical tests is repeated a large number times, say one for each voxel, i.e. <cite>n_voxels</cite> times, then one can expect that, in the absence of any effect, the number of detections – false detections since there is no effect – will be roughly <img class="math" src="../_images/math/84e4cbe974a8f43192aa21fee564a713f5d1b1df.png" alt="n\_voxels*\alpha"/>. If <img class="math" src="../_images/math/befff685f3ad4a25fe6d0faf8a48e18183d470f6.png" alt="\alpha=.001"/> and <img class="math" src="../_images/math/3b29057dd09798d2669a9a5782924b36b16b6d91.png" alt="n=10^5"/>, the number of false detections will be about 100. The danger is that one may no longer trust the detections, i.e. values of <cite>z</cite> larger than the <img class="math" src="../_images/math/c87d80a9ca1dd2540182b6d20843ecc568241c87.png" alt="(1-\alpha)"/>-quantile of the standard normal distribution.</p>
</dd>
</dl>
<p>The first idea that one might think of is to take a much smaller <img class="math" src="../_images/math/2f5aa019312e1bbc969deab8dca8b00f76025404.png" alt="\alpha"/>: for instance, if we take, <img class="math" src="../_images/math/36526f645a36a408b0caf685b136abf903267333.png" alt="\alpha=\frac{0.05}{n\_voxels}"/> then the expected number of false discoveries is only about 0.05, meaning that there is a 5% chance that a truly inactive voxel is declared active. This correction on the significance is known as Bonferroni procedure. It is fairly accurate when the different tests are independent or close to independent, but becomes conservative if not. The problem with this approach is that a truly activate voxel may not surpass the corresponding threshold, which is typically very high because <cite>n_voxels</cite> is large.</p>
<p>A second possibility is to choose a threshold so that the proportion of true discoveries among the discoveries reaches a certain proportion <cite>0&lt;q&lt;1</cite>; typically <cite>q=0.05</cite>. This means that after statistical inference, one can trust the proportionate <cite>1-q</cite> of the discoveries made. The number <cite>q</cite> is the expected proportion of false discoveries and is known as the <em>false discovery rate</em>. Controlling the false discovery rate is a reasonable compromise in practice. The thresholding that yields this level of control is typically obtained using the so-called <a class="reference external" href="http://www.math.tau.ac.il/~ybenja/MyPapers/benjamini_hochberg1995.pdf">Benjamini-Hochberg</a> procedure.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Note that <cite>q</cite> (as well as <cite>alpha</cite>) are <em>arbitrary</em>. It is recommended to not rely on low values, otherwise the inference is meaningless. Ideally one should use <img class="math" src="../_images/math/36526f645a36a408b0caf685b136abf903267333.png" alt="\alpha=\frac{0.05}{n\_voxels}"/>, or <cite>q=0.05</cite>.</p>
</div>
<p>Note also that supra-threshold sets of voxels are often gathered into connected components (aka <em>clusters</em>), so that only large connected components are retained and isolated supra-threshold voxels are discarded. The rationale is that isolated voxels are unlikely to represent extended brain areas, and are most likely noise. Hence, discarding them most often improves the quality and the reliability of the results.</p>
</section>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">5.1. An introduction to GLMs in fMRI statistical analysis</a><ul>
<li><a class="reference internal" href="#a-primer-on-bold-fmri-data-analysis">5.1.1. A primer on BOLD-fMRI data analysis</a><ul>
<li><a class="reference internal" href="#what-is-fmri">5.1.1.1. What is fMRI ?</a></li>
<li><a class="reference internal" href="#fmri-data-modelling">5.1.1.2. fMRI data modelling</a></li>
<li><a class="reference internal" href="#fmri-statistical-analysis">5.1.1.3. fMRI statistical analysis</a></li>
<li><a class="reference internal" href="#multiple-comparisons">5.1.1.4. Multiple Comparisons</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="index.html"
                        title="previous chapter"><span class="section-number">5. </span>Analyzing fMRI using GLMs</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="first_level_model.html"
                        title="next chapter"><span class="section-number">5.2. </span>First level models</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
            &copy; The nilearn developers 2010-2021.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 4.2.0.
        <span style="padding-left: 5ex;">
          <a href="../_sources/glm/glm_intro.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>