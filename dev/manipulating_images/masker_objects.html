<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="9.3. From neuroimaging volumes to data matrices: the masker objects" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://nilearn.github.io/manipulating_images/masker_objects.html" />
<meta property="og:site_name" content="Nilearn" />
<meta property="og:description" content="This chapter introduces the maskers: objects that go from neuroimaging volumes, on the disk or in memory, to data matrices, eg of time series. The concept of “masker” objects: In any analysis, the ..." />
<meta property="og:image" content="https://nilearn.github.io/manipulating_images/images/niimgs.jpg" />
<meta property="og:image:alt" content="niimgs" />
<meta name="description" content="This chapter introduces the maskers: objects that go from neuroimaging volumes, on the disk or in memory, to data matrices, eg of time series. The concept of “masker” objects: In any analysis, the ..." />
<link rel="search" title="Search" href="../search.html"><link rel="next" title="10. Advanced usage: manual pipelines and scaling up" href="../building_blocks/index.html"><link rel="prev" title="9.2. Manipulating images: resampling, smoothing, masking, ROIs…" href="manipulating_images.html">
        <link rel="prefetch" href="../_static/nilearn-transparent.png" as="image">

    <link rel="shortcut icon" href="../_static/favicon.ico"><!-- Generated with Sphinx 8.1.3 and Furo 2025.09.25 -->
        <title>9.3. From neuroimaging volumes to data matrices: the masker objects - Nilearn</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=2da93098" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=580074bf" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=54f5008b" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/fontawesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/solid.min.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/brands.min.css" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: black;
  --admonition-font-size: 100%;
  --admonition-title-font-size: 100%;
  --color-announcement-background: #FBB360;
  --color-announcement-text: #111418;
  --color-admonition-title--note: #448aff;
  --color-admonition-title-background--note: #448aff10;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-announcement-background: #935610;
  --color-announcement-text: #FFFFFF;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-announcement-background: #935610;
  --color-announcement-text: #FFFFFF;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>

<div class="announcement">
  <aside class="announcement-content">
     <p>This is the development documentation of nilearn (0.12.2.dev98+g02bb81619) <a class="sd-sphinx-override sd-badge sd-text-wrap sd-btn-outline-dark reference external" href="https://nilearn.github.io"><span>Switch to stable version (0.12.1)</span></a></p> 
  </aside>
</div>

<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Nilearn</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/nilearn-transparent.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Nilearn</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quickstart</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_examples/index.html">Examples</a><input aria-label="Toggle navigation of Examples" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/00_tutorials/index.html">Basic tutorials</a><input aria-label="Toggle navigation of Basic tutorials" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_3d_and_4d_niimg.html">3D and 4D niimgs: handling and visualizing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_decoding_tutorial.html">A introduction tutorial to fMRI decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_nilearn_101.html">Basic nilearn example: manipulating and looking at data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_python_101.html">Basic numerics and plotting with Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_single_subject_single_run.html">Intro to GLM Analysis: a single-run, single-subject fMRI dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_surface_101.html">Working with Surface images</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/01_plotting/index.html">Visualization of brain images</a><input aria-label="Toggle navigation of Visualization of brain images" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_atlas.html">Basic Atlas plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_colormaps.html">Colormaps in Nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_dim_plotting.html">Controlling the contrast of the background when plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_glass_brain.html">Glass brain plotting in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_glass_brain_extensive.html">Glass brain plotting in nilearn (all options)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_surf_atlas.html">Loading and plotting of a cortical surface atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_3d_map_to_surface_projection.html">Making a surface plot of a 3D statistical map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_more_plotting.html">More plotting tools from nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_visualization.html">NeuroImaging volumes visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_haxby_masks.html">Plot Haxby masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_transparency.html">Plotting images with transparent thresholding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_plotting.html">Plotting tools in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_surf_stat_map.html">Seed-based connectivity on the surface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_surface_projection_strategies.html">Technical point: Illustration of the volume to surface sampling schemes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_prob_atlas.html">Visualizing 4D probabilistic atlas maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_visualize_megatrawls_netmats.html">Visualizing Megatrawls Network Matrices from Human Connectome Project</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_overlay.html">Visualizing a probabilistic atlas: the default mode in the MSDL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_carpet.html">Visualizing global patterns with a carpet plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_multiscale_parcellations.html">Visualizing multiscale functional brain parcellations</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/02_decoding/index.html">Decoding and predicting from brain images</a><input aria-label="Toggle navigation of Decoding and predicting from brain images" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_searchlight_surface.html">Cortical surface-based searchlight decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_glm_decoding.html">Decoding of a dataset after GLM fit for signal extraction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_anova_svm.html">Decoding with ANOVA + SVM: face vs house in the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_frem.html">Decoding with FREM: face vs house vs chair object recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_different_estimators.html">Different classifiers in decoding the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_miyawaki_encoding.html">Encoding models for visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_simulated_data.html">Example of pattern recognition on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_mixed_gambles_frem.html">FREM on Jimura et al “mixed gambles” dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_full_analysis.html">ROI-based decoding analysis in Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_miyawaki_reconstruction.html">Reconstruction of visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_searchlight.html">Searchlight analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_grid_search.html">Setting a parameter by cross-validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_stimuli.html">Show stimuli of Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_multiclass.html">The haxby dataset: different multi-class strategies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_understand_decoder.html">Understanding <code class="xref py py-class docutils literal notranslate"><span class="pre">Decoder</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_oasis_vbm.html">Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_oasis_vbm_space_net.html">Voxel-Based Morphometry on Oasis dataset with Space-Net prior</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/03_connectivity/index.html">Functional connectivity</a><input aria-label="Toggle navigation of Functional connectivity" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_group_level_connectivity.html">Classification of age groups using functional connectivity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_data_driven_parcellations.html">Clustering methods to learn a brain parcellation from fMRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_atlas_comparison.html">Comparing connectomes on different reference atlases</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_inverse_covariance_connectome.html">Computing a connectome with sparse inverse covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_simulated_connectome.html">Connectivity structure estimation on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_compare_decomposition.html">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_sphere_based_connectome.html">Extract signals on spheres and plot a connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_signal_extraction.html">Extracting signals from a brain parcellation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_probabilistic_atlas_extraction.html">Extracting signals of a probabilistic atlas of functional regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_multi_subject_connectome.html">Group Sparse inverse covariance for multi-subject connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html">Producing single subject maps of seed-to-voxel correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html">Regions extraction using dictionary learning and functional connectomes</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/04_glm_first_level/index.html">GLM: First level analysis</a><input aria-label="Toggle navigation of GLM: First level analysis" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_fir_model.html">Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_adhd_dmn.html">Default Mode Network extraction of ADHD dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_hrf.html">Example of MRI response functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_localizer_surface_analysis.html">Example of surface-based first-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_design_matrix.html">Examples of design matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_bids_features.html">First level analysis of a complete BIDS dataset from openneuro</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_write_events_file.html">Generate an events.tsv file for the NeuroSpin localizer task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_predictions_residuals.html">Predicted time series and residuals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_two_runs_model.html">Simple example of two-runs fMRI model fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_spm_multimodal_faces.html">Single-subject data (two runs) in native space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_first_level_details.html">Understanding parameters of the first-level model</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/05_glm_second_level/index.html">GLM: Second level analysis</a><input aria-label="Toggle navigation of GLM: Second level analysis" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_association_test.html">Example of generic design in second-level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_design_matrix.html">Example of second level design matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html">Second-level fMRI model: one sample test</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_proportion_activated_voxels.html">Second-level fMRI model: true positive proportion in clusters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_two_sample_test.html">Second-level fMRI model: two-sample test, unpaired and paired</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_thresholding.html">Statistical testing of a second-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_oasis.html">Voxel-Based Morphometry on OASIS dataset</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/06_manipulating_images/index.html">Manipulating brain image volumes</a><input aria-label="Toggle navigation of Manipulating brain image volumes" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_extract_regions_labels_image.html">Breaking an atlas of labels in separated regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_compare_mean_image.html">Comparing the means of 2 images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_roi_extraction.html">Computing a Region of Interest (ROI) mask manually</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_nifti_labels_simple.html">Extracting signals from brain regions using the NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_threshold_image.html">Image thresholding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_negate_image.html">Negating an image with math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_extract_rois_statistical_maps.html">Region Extraction using a t-statistical map (3D)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_extract_rois_smith_atlas.html">Regions Extraction of Default Mode Networks using Smith Atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_resample_to_template.html">Resample an image to a template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_nifti_simple.html">Simple example of NiftiMasker use</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_smooth_mean_image.html">Smoothing an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_mask_computation.html">Understanding NiftiMasker and mask computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_affine_transformation.html">Visualization of affine resamplings</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/07_advanced/index.html">Advanced statistical analysis of brain images</a><input aria-label="Toggle navigation of Advanced statistical analysis of brain images" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_surface_image_and_maskers.html">A short demo of the surface images &amp; maskers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_advanced_decoding_scikit.html">Advanced decoding using scikit learn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_bids_analysis.html">BIDS dataset first and second level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_beta_series.html">Beta-Series Modeling for Task-Based Functional Connectivity and Decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_copy_headers_math_img.html">Copying headers from input images with <code class="docutils literal notranslate"><span class="pre">math_img</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_age_group_prediction_cross_val.html">Functional connectivity predicts age group</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_localizer_simple_analysis.html">Massively univariate analysis of a calculation task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_localizer_mass_univariate_methods.html">Massively univariate analysis of a motor task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_haxby_mass_univariate.html">Massively univariate analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_ica_resting_state.html">Multivariate decompositions: Independent component analysis of fMRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_ica_neurovault.html">NeuroVault cross-study ICA maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_neurovault_meta_analysis.html">NeuroVault meta-analysis of stop-go paradigm studies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_surface_bids_analysis.html">Surface-based dataset first and second level analysis of a dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_mask_large_fmri.html">Working with long time series fMRI images</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../user_guide.html">User guide</a><input aria-label="Toggle navigation of User guide" checked="" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../introduction.html">1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introduction.html#what-is-nilearn">2. What is <code class="docutils literal notranslate"><span class="pre">nilearn</span></code>?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introduction.html#using-nilearn-for-the-first-time">3. Using <code class="docutils literal notranslate"><span class="pre">nilearn</span></code> for the first time</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introduction.html#machine-learning-applications-to-neuroimaging">4. Machine learning applications to Neuroimaging</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../decoding/index.html">5. Decoding and MVPA: predicting from brain images</a><input aria-label="Toggle navigation of 5. Decoding and MVPA: predicting from brain images" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../decoding/decoding_intro.html">5.1. An introduction to decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/estimator_choice.html">5.2. Choosing the right predictive model for neuroimaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/frem.html">5.3. FREM: fast ensembling of regularized models for robust decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/space_net.html">5.4. SpaceNet: decoding with spatial structure for better maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/searchlight.html">5.5. Searchlight : finding voxels containing information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/going_further.html">5.6. Running scikit-learn functions for more control on the analysis</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../connectivity/index.html">6. Functional connectivity and resting state</a><input aria-label="Toggle navigation of 6. Functional connectivity and resting state" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../connectivity/functional_connectomes.html">6.1. Extracting times series to build a functional connectome</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../connectivity/connectome_extraction.html">6.2. Connectome extraction: inverse covariance for direct connections</a><input aria-label="Toggle navigation of 6.2. Connectome extraction: inverse covariance for direct connections" class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../developers/group_sparse_covariance.html">6.2.3.1. Group-sparse covariance estimation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../connectivity/resting_state_networks.html">6.3. Extracting functional brain networks: ICA and related</a></li>
<li class="toctree-l3"><a class="reference internal" href="../connectivity/region_extraction.html">6.4. Region Extraction for better brain parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../connectivity/parcellating.html">6.5. Clustering to parcellate the brain in regions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../plotting/index.html">7. Plotting brain images</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../glm/index.html">8. Analyzing fMRI using GLMs</a><input aria-label="Toggle navigation of 8. Analyzing fMRI using GLMs" class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/glm_intro.html">8.1. An introduction to GLMs in fMRI statistical analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/first_level_model.html">8.2. First level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/second_level_model.html">8.3. Second level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/meaning_difference.html">8.4. Difference in meanings between different toolboxes</a></li>
</ul>
</li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="index.html">9. Manipulation brain volumes with nilearn</a><input aria-label="Toggle navigation of 9. Manipulation brain volumes with nilearn" checked="" class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="input_output.html">9.1. Input and output: neuroimaging data representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images.html">9.2. Manipulating images: resampling, smoothing, masking, ROIs…</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">9.3. From neuroimaging volumes to data matrices: the masker objects</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../building_blocks/index.html">10. Advanced usage: manual pipelines and scaling up</a><input aria-label="Toggle navigation of 10. Advanced usage: manual pipelines and scaling up" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../building_blocks/manual_pipeline.html">10.1. Building your own neuroimaging machine-learning pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../building_blocks/neurovault.html">10.2. Downloading statistical maps from the Neurovault repository</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../modules/index.html">API References</a><input aria-label="Toggle navigation of API References" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/connectome.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.connectome</span></code>: Functional Connectivity</a><input aria-label="Toggle navigation of nilearn.connectome: Functional Connectivity" class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.connectome.ConnectivityMeasure.html">nilearn.connectome.ConnectivityMeasure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.connectome.GroupSparseCovariance.html">nilearn.connectome.GroupSparseCovariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.connectome.GroupSparseCovarianceCV.html">nilearn.connectome.GroupSparseCovarianceCV</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.connectome.sym_matrix_to_vec.html">nilearn.connectome.sym_matrix_to_vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.connectome.vec_to_sym_matrix.html">nilearn.connectome.vec_to_sym_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.connectome.group_sparse_covariance.html">nilearn.connectome.group_sparse_covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.connectome.cov_to_corr.html">nilearn.connectome.cov_to_corr</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.connectome.prec_to_partial.html">nilearn.connectome.prec_to_partial</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/datasets.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.datasets</span></code>: Automatic Dataset Fetching</a><input aria-label="Toggle navigation of nilearn.datasets: Automatic Dataset Fetching" class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_icbm152_2009.html">nilearn.datasets.fetch_icbm152_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_icbm152_brain_gm_mask.html">nilearn.datasets.fetch_icbm152_brain_gm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_surf_fsaverage.html">nilearn.datasets.fetch_surf_fsaverage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_fsaverage.html">nilearn.datasets.load_fsaverage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_fsaverage_data.html">nilearn.datasets.load_fsaverage_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_mni152_brain_mask.html">nilearn.datasets.load_mni152_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_mni152_gm_mask.html">nilearn.datasets.load_mni152_gm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_mni152_gm_template.html">nilearn.datasets.load_mni152_gm_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_mni152_template.html">nilearn.datasets.load_mni152_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_mni152_wm_mask.html">nilearn.datasets.load_mni152_wm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_mni152_wm_template.html">nilearn.datasets.load_mni152_wm_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/icbm152_2009.html">ICBM 152 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/fsaverage.html">fsaverage template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/fsaverage3.html">fsaverage3 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/fsaverage4.html">fsaverage4 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/fsaverage5.html">fsaverage5 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/fsaverage6.html">fsaverage6 template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_aal.html">nilearn.datasets.fetch_atlas_aal</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_basc_multiscale_2015.html">nilearn.datasets.fetch_atlas_basc_multiscale_2015</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_destrieux_2009.html">nilearn.datasets.fetch_atlas_destrieux_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_harvard_oxford.html">nilearn.datasets.fetch_atlas_harvard_oxford</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_juelich.html">nilearn.datasets.fetch_atlas_juelich</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_pauli_2017.html">nilearn.datasets.fetch_atlas_pauli_2017</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_schaefer_2018.html">nilearn.datasets.fetch_atlas_schaefer_2018</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_surf_destrieux.html">nilearn.datasets.fetch_atlas_surf_destrieux</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_talairach.html">nilearn.datasets.fetch_atlas_talairach</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_yeo_2011.html">nilearn.datasets.fetch_atlas_yeo_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_coords_dosenbach_2010.html">nilearn.datasets.fetch_coords_dosenbach_2010</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_coords_power_2011.html">nilearn.datasets.fetch_coords_power_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_coords_seitzman_2018.html">nilearn.datasets.fetch_coords_seitzman_2018</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_allen_2011.html">nilearn.datasets.fetch_atlas_allen_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_craddock_2012.html">nilearn.datasets.fetch_atlas_craddock_2012</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_difumo.html">nilearn.datasets.fetch_atlas_difumo</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_harvard_oxford.html">nilearn.datasets.fetch_atlas_harvard_oxford</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_juelich.html">nilearn.datasets.fetch_atlas_juelich</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_msdl.html">nilearn.datasets.fetch_atlas_msdl</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_pauli_2017.html">nilearn.datasets.fetch_atlas_pauli_2017</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_atlas_smith_2009.html">nilearn.datasets.fetch_atlas_smith_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/craddock_2012.html">Craddock 2012 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/difumo_atlases.html">DiFuMo atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/msdl_atlas.html">MSDL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/dosenbach_2010.html">Dosenbach 2010 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/power_2011.html">Power 2011 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/seitzman_2018.html">Seitzman 2018 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/aal.html">AAL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/allen_rsn_2011.html">Allen 2011 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/basc_multiscale_2015.html">BASC multiscale atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/destrieux_surface.html">Destrieux atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/harvard_oxford.html">Harvard Oxford atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/juelich.html">Juelich atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/pauli_2017.html">Pauli 2007 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/schaefer_2018.html">Schaefer 2018 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/smith_2009.html">Smith 2009 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/talairach_atlas.html">Talairach atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/yeo_2011.html">Yeo 2011 atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_abide_pcp.html">nilearn.datasets.fetch_abide_pcp</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_adhd.html">nilearn.datasets.fetch_adhd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_development_fmri.html">nilearn.datasets.fetch_development_fmri</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_ds000030_urls.html">nilearn.datasets.fetch_ds000030_urls</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_fiac_first_level.html">nilearn.datasets.fetch_fiac_first_level</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_haxby.html">nilearn.datasets.fetch_haxby</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_language_localizer_demo_dataset.html">nilearn.datasets.fetch_language_localizer_demo_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_localizer_first_level.html">nilearn.datasets.fetch_localizer_first_level</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_miyawaki2008.html">nilearn.datasets.fetch_miyawaki2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_spm_auditory.html">nilearn.datasets.fetch_spm_auditory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_spm_multimodal_fmri.html">nilearn.datasets.fetch_spm_multimodal_fmri</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_surf_nki_enhanced.html">nilearn.datasets.fetch_surf_nki_enhanced</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_nki.html">nilearn.datasets.load_nki</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/ABIDE_pcp.html">ABIDE PCP dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/adhd.html">ADHD dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/bids_langloc.html">BIDS language localizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/development_fmri.html">development fMRI dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/fiac.html">fiac first level dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/haxby2001.html">Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/language_localizer_demo.html">language localizer demo dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/localizer_first_level.html">localizer first level dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/miyawaki2008.html">Miyawaki 2008 dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/spm_auditory.html">SPM auditory dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/spm_multimodal.html">SPM multimodal dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/nki_enhanced_surface.html">NKI enhanced surface dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/brainomics_localizer.html">Brainomics Localizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_localizer_button_task.html">nilearn.datasets.fetch_localizer_button_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_localizer_calculation_task.html">nilearn.datasets.fetch_localizer_calculation_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_localizer_contrasts.html">nilearn.datasets.fetch_localizer_contrasts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_megatrawls_netmats.html">nilearn.datasets.fetch_megatrawls_netmats</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_mixed_gambles.html">nilearn.datasets.fetch_mixed_gambles</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_oasis_vbm.html">nilearn.datasets.fetch_oasis_vbm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_neurovault_auditory_computation_task.html">nilearn.datasets.fetch_neurovault_auditory_computation_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_neurovault_motor_task.html">nilearn.datasets.fetch_neurovault_motor_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/Megatrawls.html">MegaTrawls Network Matrices HCP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/mixed_gambles.html">Mixed gambles statistical maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/oasis1.html">OASIS volume based morphometry maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_neurovault.html">nilearn.datasets.fetch_neurovault</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_neurovault_ids.html">nilearn.datasets.fetch_neurovault_ids</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_openneuro_dataset.html">nilearn.datasets.fetch_openneuro_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.get_data_dirs.html">nilearn.datasets.get_data_dirs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.patch_openneuro_dataset.html">nilearn.datasets.patch_openneuro_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.select_from_index.html">nilearn.datasets.select_from_index</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.datasets.load_sample_motor_activation_image.html">nilearn.datasets.load_sample_motor_activation_image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/description/neurovault.html">Neurovault statistical maps</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/decoding.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decoding</span></code>: Decoding</a><input aria-label="Toggle navigation of nilearn.decoding: Decoding" class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decoding.Decoder.html">nilearn.decoding.Decoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decoding.DecoderRegressor.html">nilearn.decoding.DecoderRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decoding.FREMClassifier.html">nilearn.decoding.FREMClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decoding.FREMRegressor.html">nilearn.decoding.FREMRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decoding.SpaceNetClassifier.html">nilearn.decoding.SpaceNetClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decoding.SpaceNetRegressor.html">nilearn.decoding.SpaceNetRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decoding.SearchLight.html">nilearn.decoding.SearchLight</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/decomposition.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decomposition</span></code>: Multivariate Decompositions</a><input aria-label="Toggle navigation of nilearn.decomposition: Multivariate Decompositions" class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decomposition.CanICA.html">nilearn.decomposition.CanICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.decomposition.DictLearning.html">nilearn.decomposition.DictLearning</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/exceptions.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.exceptions</span></code>: Exceptions and warnings</a><input aria-label="Toggle navigation of nilearn.exceptions: Exceptions and warnings" class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.exceptions.MaskWarning.html">nilearn.exceptions.MaskWarning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.exceptions.NotImplementedWarning.html">nilearn.exceptions.NotImplementedWarning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.exceptions.AllVolumesRemovedError.html">nilearn.exceptions.AllVolumesRemovedError</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.exceptions.DimensionError.html">nilearn.exceptions.DimensionError</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.exceptions.MeshDimensionError.html">nilearn.exceptions.MeshDimensionError</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/glm.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.glm</span></code>: Generalized Linear Models</a><input aria-label="Toggle navigation of nilearn.glm: Generalized Linear Models" class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.Contrast.html">nilearn.glm.Contrast</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.FContrastResults.html">nilearn.glm.FContrastResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.TContrastResults.html">nilearn.glm.TContrastResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.ARModel.html">nilearn.glm.ARModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.OLSModel.html">nilearn.glm.OLSModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.LikelihoodModelResults.html">nilearn.glm.LikelihoodModelResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.RegressionResults.html">nilearn.glm.RegressionResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.SimpleRegressionResults.html">nilearn.glm.SimpleRegressionResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.compute_contrast.html">nilearn.glm.compute_contrast</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.compute_fixed_effects.html">nilearn.glm.compute_fixed_effects</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.expression_to_contrast_vector.html">nilearn.glm.expression_to_contrast_vector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.fdr_threshold.html">nilearn.glm.fdr_threshold</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.cluster_level_inference.html">nilearn.glm.cluster_level_inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.threshold_stats_img.html">nilearn.glm.threshold_stats_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.FirstLevelModel.html">nilearn.glm.first_level.FirstLevelModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.check_design_matrix.html">nilearn.glm.first_level.check_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.compute_regressor.html">nilearn.glm.first_level.compute_regressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.first_level_from_bids.html">nilearn.glm.first_level.first_level_from_bids</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.glover_dispersion_derivative.html">nilearn.glm.first_level.glover_dispersion_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.glover_hrf.html">nilearn.glm.first_level.glover_hrf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.glover_time_derivative.html">nilearn.glm.first_level.glover_time_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.make_first_level_design_matrix.html">nilearn.glm.first_level.make_first_level_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.mean_scaling.html">nilearn.glm.first_level.mean_scaling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.run_glm.html">nilearn.glm.first_level.run_glm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.spm_dispersion_derivative.html">nilearn.glm.first_level.spm_dispersion_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.spm_hrf.html">nilearn.glm.first_level.spm_hrf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.first_level.spm_time_derivative.html">nilearn.glm.first_level.spm_time_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.second_level.SecondLevelModel.html">nilearn.glm.second_level.SecondLevelModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.second_level.make_second_level_design_matrix.html">nilearn.glm.second_level.make_second_level_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.glm.second_level.non_parametric_inference.html">nilearn.glm.second_level.non_parametric_inference</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/image.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.image</span></code>: Image Processing and Resampling Utilities</a><input aria-label="Toggle navigation of nilearn.image: Image Processing and Resampling Utilities" class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.binarize_img.html">nilearn.image.binarize_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.clean_img.html">nilearn.image.clean_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.concat_imgs.html">nilearn.image.concat_imgs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.coord_transform.html">nilearn.image.coord_transform</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.copy_img.html">nilearn.image.copy_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.crop_img.html">nilearn.image.crop_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.get_data.html">nilearn.image.get_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.high_variance_confounds.html">nilearn.image.high_variance_confounds</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.index_img.html">nilearn.image.index_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.iter_img.html">nilearn.image.iter_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.largest_connected_component_img.html">nilearn.image.largest_connected_component_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.load_img.html">nilearn.image.load_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.math_img.html">nilearn.image.math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.mean_img.html">nilearn.image.mean_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.new_img_like.html">nilearn.image.new_img_like</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.resample_img.html">nilearn.image.resample_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.resample_to_img.html">nilearn.image.resample_to_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.reorder_img.html">nilearn.image.reorder_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.smooth_img.html">nilearn.image.smooth_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.swap_img_hemispheres.html">nilearn.image.swap_img_hemispheres</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.image.threshold_img.html">nilearn.image.threshold_img</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/interfaces.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.interfaces</span></code>: Loading components from interfaces</a><input aria-label="Toggle navigation of nilearn.interfaces: Loading components from interfaces" class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.interfaces.bids.get_bids_files.html">nilearn.interfaces.bids.get_bids_files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.interfaces.bids.parse_bids_filename.html">nilearn.interfaces.bids.parse_bids_filename</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.interfaces.bids.save_glm_to_bids.html">nilearn.interfaces.bids.save_glm_to_bids</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.interfaces.fmriprep.load_confounds.html">nilearn.interfaces.fmriprep.load_confounds</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.interfaces.fmriprep.load_confounds_strategy.html">nilearn.interfaces.fmriprep.load_confounds_strategy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.interfaces.fsl.get_design_from_fslmat.html">nilearn.interfaces.fsl.get_design_from_fslmat</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/maskers.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.maskers</span></code>: Extracting Signals from Brain Images</a><input aria-label="Toggle navigation of nilearn.maskers: Extracting Signals from Brain Images" class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.BaseMasker.html">nilearn.maskers.BaseMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html">nilearn.maskers.NiftiMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiMasker.html">nilearn.maskers.MultiNiftiMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiLabelsMasker.html">nilearn.maskers.NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiLabelsMasker.html">nilearn.maskers.MultiNiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMapsMasker.html">nilearn.maskers.NiftiMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiMapsMasker.html">nilearn.maskers.MultiNiftiMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiSpheresMasker.html">nilearn.maskers.NiftiSpheresMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.SurfaceMasker.html">nilearn.maskers.SurfaceMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.MultiSurfaceMasker.html">nilearn.maskers.MultiSurfaceMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.SurfaceLabelsMasker.html">nilearn.maskers.SurfaceLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.SurfaceMapsMasker.html">nilearn.maskers.SurfaceMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.maskers.MultiSurfaceMapsMasker.html">nilearn.maskers.MultiSurfaceMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated_reports/masker_reports_examples.html">Examples nifti masker reports</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated_reports/masker_reports_examples.html#examples-surface-masker-reports">Examples surface masker reports</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/masking.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.masking</span></code>: Data Masking Utilities</a><input aria-label="Toggle navigation of nilearn.masking: Data Masking Utilities" class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.compute_epi_mask.html">nilearn.masking.compute_epi_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.compute_multi_epi_mask.html">nilearn.masking.compute_multi_epi_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.compute_brain_mask.html">nilearn.masking.compute_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.compute_multi_brain_mask.html">nilearn.masking.compute_multi_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.compute_background_mask.html">nilearn.masking.compute_background_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.compute_multi_background_mask.html">nilearn.masking.compute_multi_background_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.intersect_masks.html">nilearn.masking.intersect_masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.apply_mask.html">nilearn.masking.apply_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.masking.unmask.html">nilearn.masking.unmask</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/mass_univariate.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.mass_univariate</span></code>: Mass-Univariate Analysis</a><input aria-label="Toggle navigation of nilearn.mass_univariate: Mass-Univariate Analysis" class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.mass_univariate.permuted_ols.html">nilearn.mass_univariate.permuted_ols</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/plotting.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.plotting</span></code>: Plotting Brain Data</a><input aria-label="Toggle navigation of nilearn.plotting: Plotting Brain Data" class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.find_cut_slices.html">nilearn.plotting.find_cut_slices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.find_xyz_cut_coords.html">nilearn.plotting.find_xyz_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.find_parcellation_cut_coords.html">nilearn.plotting.find_parcellation_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.find_probabilistic_atlas_cut_coords.html">nilearn.plotting.find_probabilistic_atlas_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_anat.html">nilearn.plotting.plot_anat</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_carpet.html">nilearn.plotting.plot_carpet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_connectome.html">nilearn.plotting.plot_connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_contrast_matrix.html">nilearn.plotting.plot_contrast_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_design_matrix.html">nilearn.plotting.plot_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_design_matrix_correlation.html">nilearn.plotting.plot_design_matrix_correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_epi.html">nilearn.plotting.plot_epi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_event.html">nilearn.plotting.plot_event</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_glass_brain.html">nilearn.plotting.plot_glass_brain</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_img.html">nilearn.plotting.plot_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_img_on_surf.html">nilearn.plotting.plot_img_on_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_markers.html">nilearn.plotting.plot_markers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_matrix.html">nilearn.plotting.plot_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_prob_atlas.html">nilearn.plotting.plot_prob_atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_roi.html">nilearn.plotting.plot_roi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_stat_map.html">nilearn.plotting.plot_stat_map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_surf.html">nilearn.plotting.plot_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_surf_contours.html">nilearn.plotting.plot_surf_contours</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_surf_roi.html">nilearn.plotting.plot_surf_roi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.plot_surf_stat_map.html">nilearn.plotting.plot_surf_stat_map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.show.html">nilearn.plotting.show</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.view_surf.html">nilearn.plotting.view_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.view_img_on_surf.html">nilearn.plotting.view_img_on_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.view_connectome.html">nilearn.plotting.view_connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.view_markers.html">nilearn.plotting.view_markers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.view_img.html">nilearn.plotting.view_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.img_comparison.plot_bland_altman.html">nilearn.plotting.img_comparison.plot_bland_altman</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.img_comparison.plot_img_comparison.html">nilearn.plotting.img_comparison.plot_img_comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.PlotlySurfaceFigure.html">nilearn.plotting.displays.PlotlySurfaceFigure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.BaseAxes.html">nilearn.plotting.displays.BaseAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.CutAxes.html">nilearn.plotting.displays.CutAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.GlassBrainAxes.html">nilearn.plotting.displays.GlassBrainAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.OrthoProjector.html">nilearn.plotting.displays.OrthoProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.LZRYProjector.html">nilearn.plotting.displays.LZRYProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.LYRZProjector.html">nilearn.plotting.displays.LYRZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.LYRProjector.html">nilearn.plotting.displays.LYRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.LZRProjector.html">nilearn.plotting.displays.LZRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.LRProjector.html">nilearn.plotting.displays.LRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.LProjector.html">nilearn.plotting.displays.LProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.RProjector.html">nilearn.plotting.displays.RProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.XZProjector.html">nilearn.plotting.displays.XZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.YZProjector.html">nilearn.plotting.displays.YZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.YXProjector.html">nilearn.plotting.displays.YXProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.XProjector.html">nilearn.plotting.displays.XProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.YProjector.html">nilearn.plotting.displays.YProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.ZProjector.html">nilearn.plotting.displays.ZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.BaseSlicer.html">nilearn.plotting.displays.BaseSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.OrthoSlicer.html">nilearn.plotting.displays.OrthoSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.MosaicSlicer.html">nilearn.plotting.displays.MosaicSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.TiledSlicer.html">nilearn.plotting.displays.TiledSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.XSlicer.html">nilearn.plotting.displays.XSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.XZSlicer.html">nilearn.plotting.displays.XZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.YXSlicer.html">nilearn.plotting.displays.YXSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.YZSlicer.html">nilearn.plotting.displays.YZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.YSlicer.html">nilearn.plotting.displays.YSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.ZSlicer.html">nilearn.plotting.displays.ZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.get_projector.html">nilearn.plotting.displays.get_projector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.plotting.displays.get_slicer.html">nilearn.plotting.displays.get_slicer</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/regions.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.regions</span></code>: Operating on Regions</a><input aria-label="Toggle navigation of nilearn.regions: Operating on Regions" class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" role="switch" type="checkbox"/><label for="toctree-checkbox-30"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.RegionExtractor.html">nilearn.regions.RegionExtractor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.Parcellations.html">nilearn.regions.Parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.ReNA.html">nilearn.regions.ReNA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.HierarchicalKMeans.html">nilearn.regions.HierarchicalKMeans</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.connected_regions.html">nilearn.regions.connected_regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.connected_label_regions.html">nilearn.regions.connected_label_regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.img_to_signals_labels.html">nilearn.regions.img_to_signals_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.signals_to_img_labels.html">nilearn.regions.signals_to_img_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.img_to_signals_maps.html">nilearn.regions.img_to_signals_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.signals_to_img_maps.html">nilearn.regions.signals_to_img_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.regions.recursive_neighbor_agglomeration.html">nilearn.regions.recursive_neighbor_agglomeration</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/reporting.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.reporting</span></code>: Reporting Functions</a><input aria-label="Toggle navigation of nilearn.reporting: Reporting Functions" class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" role="switch" type="checkbox"/><label for="toctree-checkbox-31"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.reporting.HTMLReport.html">nilearn.reporting.HTMLReport</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.reporting.get_clusters_table.html">nilearn.reporting.get_clusters_table</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.reporting.make_glm_report.html">nilearn.reporting.make_glm_report</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated_reports/glm_reports_examples.html">Examples of GLM reports</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/signal.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.signal</span></code>: Preprocessing Time Series</a><input aria-label="Toggle navigation of nilearn.signal: Preprocessing Time Series" class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" role="switch" type="checkbox"/><label for="toctree-checkbox-32"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.signal.butterworth.html">nilearn.signal.butterworth</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.signal.clean.html">nilearn.signal.clean</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.signal.high_variance_confounds.html">nilearn.signal.high_variance_confounds</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/surface.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.surface</span></code>: Manipulating Surface Data</a><input aria-label="Toggle navigation of nilearn.surface: Manipulating Surface Data" class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" role="switch" type="checkbox"/><label for="toctree-checkbox-33"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.FileMesh.html">nilearn.surface.FileMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.InMemoryMesh.html">nilearn.surface.InMemoryMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.PolyData.html">nilearn.surface.PolyData</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.PolyMesh.html">nilearn.surface.PolyMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.SurfaceImage.html">nilearn.surface.SurfaceImage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.SurfaceMesh.html">nilearn.surface.SurfaceMesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.load_surf_data.html">nilearn.surface.load_surf_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.load_surf_mesh.html">nilearn.surface.load_surf_mesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/generated/nilearn.surface.vol_to_surf.html">nilearn.surface.vol_to_surf</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../development.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ci.html">Continuous integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../maintenance.html">Maintenance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changes/whats_new.html">What’s new</a></li>
<li class="toctree-l1"><a class="reference internal" href="../authors.html">Team</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versions.html">Versions</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nilearn/nilearn">GitHub Repository</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="https://github.com/nilearn/nilearn/blob/main/doc/manipulating_images/masker_objects.rst?plain=true" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>

<div class="edit-this-page">
  <a class="muted-link"
     href="https://github.com/nilearn/nilearn/edit/main/doc/manipulating_images/masker_objects.rst"
     title="Edit this page"
     target="_blank">
    <svg aria-hidden="true" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
         fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <path d="M4 20h4l10.5 -10.5a1.5 1.5 0 0 0 -4 -4l-10.5 10.5v4" />
      <line x1="13.5" y1="6.5" x2="17.5" y2="10.5" />
    </svg>
    <span class="visually-hidden">Edit this page</span>
  </a>
</div><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="from-neuroimaging-volumes-to-data-matrices-the-masker-objects">
<span id="masker-objects"></span><h1><span class="section-number">9.3. </span>From neuroimaging volumes to data matrices: the masker objects<a class="headerlink" href="#from-neuroimaging-volumes-to-data-matrices-the-masker-objects" title="Link to this heading">¶</a></h1>
<p>This chapter introduces the maskers: objects that go from
neuroimaging volumes, on the disk or in memory, to data matrices, eg of
time series.</p>
<section id="the-concept-of-masker-objects">
<h2><span class="section-number">9.3.1. </span>The concept of “masker” objects<a class="headerlink" href="#the-concept-of-masker-objects" title="Link to this heading">¶</a></h2>
<p>In any analysis, the first step is to load the data.
It is often convenient to apply some basic data
transformations and to turn the data in a 2D (samples x features) matrix,
where the samples could be different time points, and the features derived
from different voxels (e.g., restrict analysis to the ventral visual stream),
regions of interest (e.g., extract local signals from spheres/cubes), or
pre-specified networks (e.g., look at data from all voxels of a set of
network nodes). Think of masker objects as swiss-army knives for shaping
the raw neuroimaging data in 3D space into the units of observation
relevant for the research questions at hand.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Masker objects can transform both 3D and 4D image objects :</p>
<ul class="simple">
<li><p>transforming a 3D image produces a 1D (features,) array,</p></li>
<li><p>transforming a 4D image produces a 2D (samples, features) array.</p></li>
</ul>
</div>
<p class="centered">
<strong><a class="reference internal" href="../_images/niimgs.jpg"><img alt="niimgs" src="../_images/niimgs.jpg" style="width: 367.0px; height: 163.5px;" /></a>  <span style="padding: .5em; font-size: 400%">&rarr;</span>  <a class="reference internal" href="../_images/feature_array.jpg"><img alt="arrays" src="../_images/feature_array.jpg" style="width: 115.14999999999999px; height: 167.29999999999998px;" /></a></strong></p><p>“masker” objects (found in module <a class="reference internal" href="../modules/maskers.html#module-nilearn.maskers" title="nilearn.maskers"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.maskers</span></code></a>)
simplify these “data folding” steps that often precede the
statistical analysis.</p>
<p>Note that the masker objects may not cover all the image transformations
for specific tasks. Users who want to make some specific processing may
have to call <a class="reference internal" href="manipulating_images.html#preprocessing-functions"><span class="std std-ref">specific functions</span></a>
(modules <a class="reference internal" href="../modules/signal.html#module-nilearn.signal" title="nilearn.signal"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.signal</span></code></a>, <a class="reference internal" href="../modules/masking.html#module-nilearn.masking" title="nilearn.masking"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.masking</span></code></a>).</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<aside class="topic">
<p class="topic-title"><strong>Advanced: Design philosophy of “Maskers”</strong></p>
<p>The design of these classes is similar to <a class="reference external" href="https://scikit-learn.org">scikit-learn</a>‘s transformers. First, objects are
initialized with some parameters guiding the transformation
(unrelated to the data). Then the <cite>fit()</cite> method should be called,
possibly specifying some data-related information (such as number of
images to process), to perform some initial computation (e.g.,
fitting a mask based on the data). Finally, <cite>transform()</cite> can be
called, with the data as argument, to perform some computation on
data themselves (e.g., extracting time series from images).</p>
</aside>
</section>
<section id="niftimasker-applying-a-mask-to-load-time-series">
<span id="nifti-masker"></span><h2><span class="section-number">9.3.2. </span><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a>: applying a mask to load time-series<a class="headerlink" href="#niftimasker-applying-a-mask-to-load-time-series" title="Link to this heading">¶</a></h2>
<p><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> is a powerful tool to load images and
extract <a class="reference internal" href="../glossary.html#term-voxel"><span class="xref std std-term">voxel</span></a> signals in the area defined by the mask.
It applies some basic preprocessing
steps with commonly used parameters as defaults.
But it is <em>very important</em> to look at your data to see the effects
of the preprocessings and validate them.</p>
<aside class="topic">
<p class="topic-title"><strong>Advanced: scikit-learn Pipelines</strong></p>
<p><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> is a <a class="reference external" href="https://scikit-learn.org">scikit-learn</a> compliant
transformer so that you can directly plug it
into a <a class="extlink-sklearn reference external" href="https://scikit-learn.org/stable//modules/pipeline.html">scikit-learn pipeline</a>.</p>
</aside>
<section id="custom-data-loading-loading-only-the-first-100-time-points">
<h3><span class="section-number">9.3.2.1. </span>Custom data loading: loading only the first 100 time points<a class="headerlink" href="#custom-data-loading-loading-only-the-first-100-time-points" title="Link to this heading">¶</a></h3>
<p>Suppose we want to restrict a dataset to the first 100 frames. Below, we load
a movie-watching dataset with <a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_development_fmri.html#nilearn.datasets.fetch_development_fmri" title="nilearn.datasets.fetch_development_fmri"><code class="xref py py-func docutils literal notranslate"><span class="pre">fetch_development_fmri()</span></code></a>, restrict it to 100 frames and
build a new niimg object that we can give to the masker. Although
possible, there is no need to save your data to a file to pass it to a
<a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a>. Simply use <a class="reference internal" href="../modules/generated/nilearn.image.index_img.html#nilearn.image.index_img" title="nilearn.image.index_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.image.index_img</span></code></a> to apply a
slice and create a <a class="reference internal" href="input_output.html#niimg"><span class="std std-ref">Niimg</span></a> in memory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">fetch_development_fmri</span><span class="p">(</span><span class="n">n_subjects</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">epi_filename</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">func</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Restrict to 100 frames to speed up computation</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">nilearn.image</span><span class="w"> </span><span class="kn">import</span> <span class="n">index_img</span>

<span class="n">epi_img</span> <span class="o">=</span> <span class="n">index_img</span><span class="p">(</span><span class="n">epi_filename</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>

</pre></div>
</div>
</section>
<section id="controlling-how-the-mask-is-computed-from-the-data">
<h3><span class="section-number">9.3.2.2. </span>Controlling how the mask is computed from the data<a class="headerlink" href="#controlling-how-the-mask-is-computed-from-the-data" title="Link to this heading">¶</a></h3>
<p>In this section, we show how the masker object can compute a mask
automatically for subsequent statistical analysis.
On some datasets, the default algorithm may however perform poorly.
This is why it is very important to
<strong>always look at your data</strong> before and after feature
engineering using masker objects.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The full example described in this section can be found here:
<a class="reference internal" href="../auto_examples/06_manipulating_images/plot_mask_computation.html"><span class="doc">plot_mask_computation.py</span></a>.
It is also related to this example:
<a class="reference internal" href="../auto_examples/06_manipulating_images/plot_nifti_simple.html"><span class="doc">plot_nifti_simple.py</span></a>.</p>
</div>
<section id="visualizing-the-computed-mask">
<h4><span class="section-number">9.3.2.2.1. </span>Visualizing the computed mask<a class="headerlink" href="#visualizing-the-computed-mask" title="Link to this heading">¶</a></h4>
<p>If a mask is not specified as an argument, <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> will try to
compute one from the provided neuroimaging data.
It is <em>very important</em> to verify the quality of the generated mask by visualization.
This allows to see whether it is suitable for your data and intended analyses.
Alternatively, the mask computation parameters can still be modified.
See the <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> documentation for a complete list of
mask computation parameters.</p>
<p>The mask can be retrieved and visualized from the <code class="docutils literal notranslate"><span class="pre">mask_img_</span></code> attribute
of the masker:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">masker</span> <span class="o">=</span> <span class="n">NiftiMasker</span><span class="p">()</span>
<span class="n">masker</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">miyawaki_filename</span><span class="p">)</span>

<span class="c1"># Plot the generated mask using the mask_img_ attribute</span>
<span class="n">plot_roi</span><span class="p">(</span>
    <span class="n">masker</span><span class="o">.</span><span class="n">mask_img_</span><span class="p">,</span> <span class="n">miyawaki_mean_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Mask from already masked data&quot;</span>
<span class="p">)</span>

<span class="c1"># %%</span>
</pre></div>
</div>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/06_manipulating_images/plot_mask_computation.html"><img alt="../_images/sphx_glr_plot_mask_computation_002.png" src="../_images/sphx_glr_plot_mask_computation_002.png" />
</a>
</figure>
<p>Alternatively, the mask can be visualized using the <code class="docutils literal notranslate"><span class="pre">generate_report</span></code>
method of the masker. The generated report can be viewed in a Jupyter notebook,
opened in a new browser tab using <code class="docutils literal notranslate"><span class="pre">report.open_in_browser()</span></code>,
or saved as a portable HTML file <code class="docutils literal notranslate"><span class="pre">report.save_as_html(output_filepath)</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">masker</span> <span class="o">=</span> <span class="n">NiftiMasker</span><span class="p">(</span><span class="n">mask_strategy</span><span class="o">=</span><span class="s2">&quot;epi&quot;</span><span class="p">)</span>
<span class="n">masker</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">epi_img</span><span class="p">)</span>
<span class="n">report</span> <span class="o">=</span> <span class="n">masker</span><span class="o">.</span><span class="n">generate_report</span><span class="p">()</span>
<span class="n">report</span>

<span class="c1"># %%</span>
</pre></div>
</div>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/06_manipulating_images/plot_mask_computation.html"><img alt="../_images/niftimasker_report.png" src="../_images/niftimasker_report.png" />
</a>
</figure>
</section>
<section id="different-masking-strategies">
<h4><span class="section-number">9.3.2.2.2. </span>Different masking strategies<a class="headerlink" href="#different-masking-strategies" title="Link to this heading">¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">mask_strategy</span></code> argument controls how the mask is computed:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">background</span></code>: detects a continuous background</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">epi</span></code>: suitable for <a class="reference internal" href="../glossary.html#term-EPI"><span class="xref std std-term">EPI</span></a> images</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">whole-brain-template</span></code>: uses an <a class="reference internal" href="../glossary.html#term-MNI"><span class="xref std std-term">MNI</span></a> whole-brain template</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gm-template</span></code>: uses an <a class="reference internal" href="../glossary.html#term-MNI"><span class="xref std std-term">MNI</span></a> grey-matter template</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">wm-template</span></code>: uses an <a class="reference internal" href="../glossary.html#term-MNI"><span class="xref std std-term">MNI</span></a> white-matter template</p></li>
</ul>
</section>
<section id="extra-mask-parameters-opening-cutoff">
<h4><span class="section-number">9.3.2.2.3. </span>Extra mask parameters: opening, cutoff…<a class="headerlink" href="#extra-mask-parameters-opening-cutoff" title="Link to this heading">¶</a></h4>
<p>The underlying function is <a class="reference internal" href="../modules/generated/nilearn.masking.compute_epi_mask.html#nilearn.masking.compute_epi_mask" title="nilearn.masking.compute_epi_mask"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.masking.compute_epi_mask</span></code></a>
called using the <code class="docutils literal notranslate"><span class="pre">mask_args</span></code> argument of the <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a>.
Controlling these arguments set the fine aspects of the mask. See the
functions documentation, or <a class="reference internal" href="../auto_examples/06_manipulating_images/plot_mask_computation.html"><span class="doc">the NiftiMasker example</span></a>.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/06_manipulating_images/plot_mask_computation.html"><img alt="../_images/niftimasker_report_params.png" src="../_images/niftimasker_report_params.png" />
</a>
</figure>
</section>
</section>
<section id="common-data-preparation-steps-smoothing-filtering-resampling">
<span id="masker-preprocessing-steps"></span><h3><span class="section-number">9.3.2.3. </span>Common data preparation steps: smoothing, filtering, resampling<a class="headerlink" href="#common-data-preparation-steps-smoothing-filtering-resampling" title="Link to this heading">¶</a></h3>
<p><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> comes with many parameters that enable data
preparation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">sklearn</span><span class="p">;</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">set_config</span><span class="p">(</span><span class="n">print_changed_only</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">nilearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">maskers</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">masker</span> <span class="o">=</span> <span class="n">maskers</span><span class="o">.</span><span class="n">NiftiMasker</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">masker</span> 
<span class="go">NiftiMasker(clean_args=None, cmap=&#39;gray&#39;, detrend=False, dtype=None, high_pass=None,</span>
<span class="go">      high_variance_confounds=False, low_pass=None, mask_args=None,</span>
<span class="go">      mask_img=None, mask_strategy=&#39;background&#39;,</span>
<span class="go">      memory=None, memory_level=1, reports=True,</span>
<span class="go">      runs=None, smoothing_fwhm=None, standardize=False,</span>
<span class="go">      standardize_confounds=True, t_r=None,</span>
<span class="go">      target_affine=None, target_shape=None, verbose=0)</span>
</pre></div>
</div>
<p>The meaning of each parameter is described in the documentation of
<a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> (click on the name <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a>), here we
comment on the most important.</p>
<aside class="topic">
<p class="topic-title"><strong>`dtype` argument</strong></p>
<p>Forcing your data to have a <code class="docutils literal notranslate"><span class="pre">dtype</span></code> of <strong>float32</strong> can help
save memory and is often a good-enough numerical precision.
You can force this cast by choosing <code class="docutils literal notranslate"><span class="pre">dtype</span></code> to be ‘auto’.
In the future this cast will be the default behavior.</p>
</aside>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>If you do not want to use the <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> to perform these
simple operations on data, note that they can also be manually
accessed in nilearn such as in
<a class="reference internal" href="manipulating_images.html#preprocessing-functions"><span class="std std-ref">corresponding functions</span></a>.</p>
</div>
<section id="smoothing">
<h4><span class="section-number">9.3.2.3.1. </span>Smoothing<a class="headerlink" href="#smoothing" title="Link to this heading">¶</a></h4>
<p><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> can apply Gaussian spatial smoothing to the
neuroimaging data, useful to fight noise or for inter-individual
differences in neuroanatomy. It is achieved by specifying the
<a class="reference internal" href="../glossary.html#term-FWHM"><span class="xref std std-term">full-width half maximum</span></a> (<a class="reference internal" href="../glossary.html#term-FWHM"><span class="xref std std-term">FWHM</span></a>; in millimeter
scale) with the <code class="docutils literal notranslate"><span class="pre">smoothing_fwhm</span></code> parameter. Anisotropic filtering
is also possible by passing 3 scalars <code class="docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">y,</span> <span class="pre">z)</span></code>, the
<a class="reference internal" href="../glossary.html#term-FWHM"><span class="xref std std-term">FWHM</span></a> along the x, y, and z direction.</p>
<p>The underlying function handles properly non-cubic <a class="reference internal" href="../glossary.html#term-voxel"><span class="xref std std-term">voxels</span></a>
by scaling the given widths appropriately.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="../modules/generated/nilearn.image.smooth_img.html#nilearn.image.smooth_img" title="nilearn.image.smooth_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.image.smooth_img</span></code></a></p>
</div>
</section>
<section id="temporal-filtering-and-confound-removal">
<span id="temporal-filtering"></span><h4><span class="section-number">9.3.2.3.2. </span>Temporal Filtering and confound removal<a class="headerlink" href="#temporal-filtering-and-confound-removal" title="Link to this heading">¶</a></h4>
<p><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> can also improve aspects of temporal data
properties, before conversion to <a class="reference internal" href="../glossary.html#term-voxel"><span class="xref std std-term">voxel</span></a> signals.</p>
<ul class="simple">
<li><p><strong>Standardization</strong>. Parameter <code class="docutils literal notranslate"><span class="pre">standardize</span></code>: Signals can be
standardized (scaled to unit variance).</p></li>
<li><p><strong>Frequency filtering</strong>. Low-pass and high-pass filters can be used to
remove artifacts. Parameters: <code class="docutils literal notranslate"><span class="pre">high_pass</span></code> and <code class="docutils literal notranslate"><span class="pre">low_pass</span></code>, specified
in Hz (note that you must specific the sampling rate in seconds with
the <code class="docutils literal notranslate"><span class="pre">t_r</span></code> parameter: <code class="docutils literal notranslate"><span class="pre">loss_pass=.5,</span> <span class="pre">t_r=2.1</span></code>).</p></li>
<li><p><strong>Confound removal</strong>. Two ways of removing confounds are provided: simple
detrending or using prespecified confounds, such as behavioral or movement
information.</p>
<ul>
<li><p>Linear trends can be removed by activating the <code class="docutils literal notranslate"><span class="pre">detrend</span></code> parameter.
This accounts for slow (as opposed to abrupt or transient) changes
in <a class="reference internal" href="../glossary.html#term-voxel"><span class="xref std std-term">voxel</span></a> values along a series of brain images that are unrelated to the
signal of interest (e.g., the neural correlates of cognitive tasks).
It is not activated by default in <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> but is recommended
in almost all scenarios.</p></li>
<li><p>More complex confounds, measured during the acquision, can be removed
by passing them to <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker.transform" title="nilearn.maskers.NiftiMasker.transform"><code class="xref py py-meth docutils literal notranslate"><span class="pre">NiftiMasker.transform</span></code></a>. If the dataset
provides a confounds file, just pass its path to the masker. For
<a class="reference internal" href="../glossary.html#term-fMRIPrep"><span class="xref std std-term">fMRIPrep</span></a> outputs, one can use
<a class="reference internal" href="../modules/generated/nilearn.interfaces.fmriprep.load_confounds.html#nilearn.interfaces.fmriprep.load_confounds" title="nilearn.interfaces.fmriprep.load_confounds"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_confounds</span></code></a> or
<a class="reference internal" href="../modules/generated/nilearn.interfaces.fmriprep.load_confounds_strategy.html#nilearn.interfaces.fmriprep.load_confounds_strategy" title="nilearn.interfaces.fmriprep.load_confounds_strategy"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_confounds_strategy</span></code></a> to select
confound variables with some basic sanity check based on
<a class="reference internal" href="../glossary.html#term-fMRIPrep"><span class="xref std std-term">fMRIPrep</span></a> documentation.</p></li>
</ul>
</li>
</ul>
<aside class="topic green">
<p class="topic-title"><strong>Exercise</strong></p>
<p>You can, more as a training than as an exercise, try to play with
the parameters in
<a class="reference internal" href="../auto_examples/00_tutorials/plot_decoding_tutorial.html#sphx-glr-auto-examples-00-tutorials-plot-decoding-tutorial-py"><span class="std std-ref">A introduction tutorial to fMRI decoding</span></a>.
Try to enable detrending and run the script:
does it have a big impact on the result?</p>
</aside>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please see the usage example of
<a class="reference internal" href="../modules/generated/nilearn.interfaces.fmriprep.load_confounds.html#nilearn.interfaces.fmriprep.load_confounds" title="nilearn.interfaces.fmriprep.load_confounds"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_confounds</span></code></a> and
<a class="reference internal" href="../modules/generated/nilearn.interfaces.fmriprep.load_confounds_strategy.html#nilearn.interfaces.fmriprep.load_confounds_strategy" title="nilearn.interfaces.fmriprep.load_confounds_strategy"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_confounds_strategy</span></code></a> in
<a class="reference internal" href="../auto_examples/03_connectivity/plot_signal_extraction.html"><span class="doc">plot_signal_extraction.py</span></a>.</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="../modules/generated/nilearn.signal.clean.html#nilearn.signal.clean" title="nilearn.signal.clean"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.signal.clean</span></code></a></p>
</div>
</section>
<section id="resampling-resizing-and-changing-resolutions-of-images">
<h4><span class="section-number">9.3.2.3.3. </span>Resampling: resizing and changing resolutions of images<a class="headerlink" href="#resampling-resizing-and-changing-resolutions-of-images" title="Link to this heading">¶</a></h4>
<p><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> and many similar classes enable resampling
(recasting of images into different resolutions and transformations of
brain <a class="reference internal" href="../glossary.html#term-voxel"><span class="xref std std-term">voxel</span></a> data). Two parameters control resampling:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">target_affine</span></code> to resample (resize, rotate…) images in order to match
the spatial configuration defined by the new affine (i.e., matrix
transforming from <a class="reference internal" href="../glossary.html#term-voxel"><span class="xref std std-term">voxel</span></a> space into world space).</p></li>
<li><p>Additionally, a <code class="docutils literal notranslate"><span class="pre">target_shape</span></code> can be used to resize images
(i.e., cropping or padding with zeros) to match an expected data
image dimensions (shape composed of x, y, and z).</p></li>
</ul>
<p>How to combine these parameter to obtain the specific resampling desired
is explained in details in <a class="reference internal" href="manipulating_images.html#resampling"><span class="std std-ref">Resampling images</span></a>.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="../modules/generated/nilearn.image.resample_img.html#nilearn.image.resample_img" title="nilearn.image.resample_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.image.resample_img</span></code></a>, <a class="reference internal" href="../modules/generated/nilearn.image.resample_to_img.html#nilearn.image.resample_to_img" title="nilearn.image.resample_to_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.image.resample_to_img</span></code></a></p>
</div>
</section>
</section>
<section id="inverse-transform-unmasking-data">
<span id="unmasking-step"></span><h3><span class="section-number">9.3.2.4. </span>Inverse transform: unmasking data<a class="headerlink" href="#inverse-transform-unmasking-data" title="Link to this heading">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Inverse transform only performs spatial unmasking.
The data is only brought back into either a 3D or 4D represenetation,
without inverting any signal processing performed by <code class="docutils literal notranslate"><span class="pre">transform</span></code>.</p>
</div>
<p>Once <a class="reference internal" href="../glossary.html#term-voxel"><span class="xref std std-term">voxel</span></a> signals have been processed, the result can be visualized as
images after unmasking (masked-reduced data transformed back into
the original whole-brain space). This step is present in many
<a class="reference external" href="https://matplotlib.org/stable/gallery/index.html#examples-index" title="(in Matplotlib v3.10.7)"><span class="xref std std-ref">examples</span></a> provided in nilearn. Below you will find
an excerpt of <a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_anova_svm.html#sphx-glr-auto-examples-02-decoding-plot-haxby-anova-svm-py"><span class="std std-ref">the example performing Anova-SVM on the Haxby data</span></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># :class:`~nilearn.plotting.plot_stat_map`</span>
<span class="n">weight_img</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">coef_img_</span><span class="p">[</span><span class="s2">&quot;face&quot;</span><span class="p">]</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">nilearn.plotting</span><span class="w"> </span><span class="kn">import</span> <span class="n">plot_stat_map</span><span class="p">,</span> <span class="n">show</span>

<span class="n">plot_stat_map</span><span class="p">(</span><span class="n">weight_img</span><span class="p">,</span> <span class="n">bg_img</span><span class="o">=</span><span class="n">haxby_dataset</span><span class="o">.</span><span class="n">anat</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;SVM weights&quot;</span><span class="p">)</span>

<span class="n">show</span><span class="p">()</span>

<span class="c1"># %%</span>
</pre></div>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Masker objects can inverse-transform both 1D and 2D arrays :</p>
<ul class="simple">
<li><p>inverse-transforming a 2D array produces a 4D (X x Y x Z x samples) image,</p></li>
<li><p>inverse-transforming a 1D array produces a 3D (X x Y x Z) image.</p></li>
</ul>
</div>
<aside class="topic">
<p class="topic-title"><strong>Examples to better understand the NiftiMasker</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_nifti_simple.html#sphx-glr-auto-examples-06-manipulating-images-plot-nifti-simple-py"><span class="std std-ref">Simple example of NiftiMasker use</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_mask_computation.html#sphx-glr-auto-examples-06-manipulating-images-plot-mask-computation-py"><span class="std std-ref">Understanding NiftiMasker and mask computation</span></a></p></li>
</ul>
</aside>
<div class="line-block">
<div class="line"><br /></div>
</div>
</section>
</section>
<section id="extraction-of-signals-from-regions-niftilabelsmasker-niftimapsmasker">
<span id="region"></span><h2><span class="section-number">9.3.3. </span>Extraction of signals from regions: <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiLabelsMasker.html#nilearn.maskers.NiftiLabelsMasker" title="nilearn.maskers.NiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a>, <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMapsMasker.html#nilearn.maskers.NiftiMapsMasker" title="nilearn.maskers.NiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a><a class="headerlink" href="#extraction-of-signals-from-regions-niftilabelsmasker-niftimapsmasker" title="Link to this heading">¶</a></h2>
<p>The purpose of <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiLabelsMasker.html#nilearn.maskers.NiftiLabelsMasker" title="nilearn.maskers.NiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a> and <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMapsMasker.html#nilearn.maskers.NiftiMapsMasker" title="nilearn.maskers.NiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a> is to
compute signals from regions containing many voxels. They make it easy to get
these signals once you have an atlas or a <a class="reference internal" href="../glossary.html#term-parcellation"><span class="xref std std-term">parcellation</span></a> into brain regions.</p>
<section id="regions-definition">
<h3><span class="section-number">9.3.3.1. </span>Regions definition<a class="headerlink" href="#regions-definition" title="Link to this heading">¶</a></h3>
<p>Nilearn understands two different ways of defining regions, which are called
labels and maps, handled by <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiLabelsMasker.html#nilearn.maskers.NiftiLabelsMasker" title="nilearn.maskers.NiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a> and
<a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMapsMasker.html#nilearn.maskers.NiftiMapsMasker" title="nilearn.maskers.NiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a>, respectively.</p>
<ul class="simple">
<li><p>labels: a single region is defined as the set of all the voxels that have a
common label (e.g., anatomical brain region definitions as integers)
in the region definition array. The set of
regions is defined by a single 3D array, containing a voxel-wise
dictionary of label numbers that denote what
region a given <a class="reference internal" href="../glossary.html#term-voxel"><span class="xref std std-term">voxel</span></a> belongs to. This technique has a big advantage: the
required memory load is independent of the number of regions, allowing
for a large number of regions. On the other hand, there are
several disadvantages: regions cannot spatially overlap
and are represented in a binary present/nonpresent coding (no weighting).</p></li>
<li><p>maps: a single region is defined as the set of all the voxels that have a
non-zero weight. A set of regions is thus defined by a set of 3D images (or a
single 4D image), one 3D image per region (as opposed to all regions in a
single 3D image such as for labels, cf. above).
While these defined weighted regions can exhibit spatial
overlap (as opposed to labels), storage cost scales linearly with the
number of regions. Handling a large number (e.g., thousands)
of regions will prove difficult with this data transformation of
whole-brain <a class="reference internal" href="../glossary.html#term-voxel"><span class="xref std std-term">voxel</span></a> data into weighted region-wise data.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These usage are illustrated in the section <a class="reference internal" href="../connectivity/functional_connectomes.html#functional-connectomes"><span class="std std-ref">Extracting times series to build a functional connectome</span></a>.</p>
</div>
</section>
<section id="niftilabelsmasker-usage">
<h3><span class="section-number">9.3.3.2. </span><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiLabelsMasker.html#nilearn.maskers.NiftiLabelsMasker" title="nilearn.maskers.NiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a> Usage<a class="headerlink" href="#niftilabelsmasker-usage" title="Link to this heading">¶</a></h3>
<p>Usage of <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiLabelsMasker.html#nilearn.maskers.NiftiLabelsMasker" title="nilearn.maskers.NiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a> is similar to that of
<a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMapsMasker.html#nilearn.maskers.NiftiMapsMasker" title="nilearn.maskers.NiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a>. The main difference is that it requires a labels image
instead of a set of maps as input.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">background_label</span></code> keyword of <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiLabelsMasker.html#nilearn.maskers.NiftiLabelsMasker" title="nilearn.maskers.NiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a> deserves
some explanation. The voxels that correspond to the brain or a region
of interest in an <a class="reference internal" href="../glossary.html#term-fMRI"><span class="xref std std-term">fMRI</span></a> image do not fill the entire image.
Consequently, in the labels image, there must be a label value that corresponds
to “outside” the brain (for which no signal should be extracted).
By default, this label is set to zero in nilearn (referred to as “background”).
Should some non-zero value encoding be necessary, it is possible
to change the background value with the <code class="docutils literal notranslate"><span class="pre">background_label</span></code> keyword.</p>
<aside class="topic">
<p class="topic-title"><strong>Examples</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/03_connectivity/plot_signal_extraction.html#sphx-glr-auto-examples-03-connectivity-plot-signal-extraction-py"><span class="std std-ref">Extracting signals from a brain parcellation</span></a></p></li>
</ul>
</aside>
</section>
<section id="niftimapsmasker-usage">
<h3><span class="section-number">9.3.3.3. </span><a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMapsMasker.html#nilearn.maskers.NiftiMapsMasker" title="nilearn.maskers.NiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a> Usage<a class="headerlink" href="#niftimapsmasker-usage" title="Link to this heading">¶</a></h3>
<p>This atlas defines its regions using maps. The path to the corresponding
file is given in the <code class="docutils literal notranslate"><span class="pre">maps_img</span></code> argument.</p>
<p>One important thing that happens transparently during the execution of
<a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker.fit_transform" title="nilearn.maskers.NiftiMasker.fit_transform"><code class="xref py py-meth docutils literal notranslate"><span class="pre">NiftiMasker.fit_transform</span></code></a> is resampling. Initially, the images
and the atlas do typically not have the same shape nor the same affine.
Casting them into the same format is required for successful signal extraction
The keyword argument <code class="docutils literal notranslate"><span class="pre">resampling_target</span></code> specifies which format
(i.e., dimensions and affine) the data should be resampled to.
See the reference documentation for <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMapsMasker.html#nilearn.maskers.NiftiMapsMasker" title="nilearn.maskers.NiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a> for every
possible option.</p>
<aside class="topic">
<p class="topic-title"><strong>Examples</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/03_connectivity/plot_probabilistic_atlas_extraction.html#sphx-glr-auto-examples-03-connectivity-plot-probabilistic-atlas-extraction-py"><span class="std std-ref">Extracting signals of a probabilistic atlas of functional regions</span></a></p></li>
</ul>
</aside>
</section>
</section>
<section id="extraction-of-signals-from-regions-for-multiple-subjects-multiniftimasker-multiniftilabelsmasker-multiniftimapsmasker">
<h2><span class="section-number">9.3.4. </span>Extraction of signals from regions for multiple subjects: <a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiMasker.html#nilearn.maskers.MultiNiftiMasker" title="nilearn.maskers.MultiNiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiMasker</span></code></a>, <a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiLabelsMasker.html#nilearn.maskers.MultiNiftiLabelsMasker" title="nilearn.maskers.MultiNiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiLabelsMasker</span></code></a>, <a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiMapsMasker.html#nilearn.maskers.MultiNiftiMapsMasker" title="nilearn.maskers.MultiNiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiMapsMasker</span></code></a><a class="headerlink" href="#extraction-of-signals-from-regions-for-multiple-subjects-multiniftimasker-multiniftilabelsmasker-multiniftimapsmasker" title="Link to this heading">¶</a></h2>
<p>The purpose of <a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiMasker.html#nilearn.maskers.MultiNiftiMasker" title="nilearn.maskers.MultiNiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiMasker</span></code></a>, <a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiLabelsMasker.html#nilearn.maskers.MultiNiftiLabelsMasker" title="nilearn.maskers.MultiNiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiLabelsMasker</span></code></a> and
<a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiMapsMasker.html#nilearn.maskers.MultiNiftiMapsMasker" title="nilearn.maskers.MultiNiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiMapsMasker</span></code></a> is to extend the capabilities of
<a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a>, <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiLabelsMasker.html#nilearn.maskers.NiftiLabelsMasker" title="nilearn.maskers.NiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a> and <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMapsMasker.html#nilearn.maskers.NiftiMapsMasker" title="nilearn.maskers.NiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a>
as to facilitate the computation of <a class="reference internal" href="../glossary.html#term-voxel"><span class="xref std std-term">voxel</span></a> signals in multi-subjects settings.
While <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a>, <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiLabelsMasker.html#nilearn.maskers.NiftiLabelsMasker" title="nilearn.maskers.NiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a> and
<a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMapsMasker.html#nilearn.maskers.NiftiMapsMasker" title="nilearn.maskers.NiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a> work with 3D inputs (single brain volume) or 4D inputs
(sequence of brain volumes in time for one subject), <a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiMasker.html#nilearn.maskers.MultiNiftiMasker" title="nilearn.maskers.MultiNiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiMasker</span></code></a>,
<a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiLabelsMasker.html#nilearn.maskers.MultiNiftiLabelsMasker" title="nilearn.maskers.MultiNiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiLabelsMasker</span></code></a> and <a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiMapsMasker.html#nilearn.maskers.MultiNiftiMapsMasker" title="nilearn.maskers.MultiNiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiMapsMasker</span></code></a>
can also handle list of 3D or 4D image objects.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>MultiMasker objects can transform both 3D, 4D,
as well as list of 3D or 4D image objects :</p>
<ul class="simple">
<li><p>transforming a 3D image produces a 1D (features,) array,</p></li>
<li><p>transforming a 4D image produces a 2D (samples, features) array,</p></li>
<li><p>transforming a list of 3D image produces a list of 1D (features,) array,</p></li>
<li><p>transforming a list of 4D image produces a list of 2D (samples, features) array.</p></li>
</ul>
</div>
<section id="multiniftimasker-usage">
<h3><span class="section-number">9.3.4.1. </span><a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiMasker.html#nilearn.maskers.MultiNiftiMasker" title="nilearn.maskers.MultiNiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiMasker</span></code></a> Usage<a class="headerlink" href="#multiniftimasker-usage" title="Link to this heading">¶</a></h3>
<p><a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiMasker.html#nilearn.maskers.MultiNiftiMasker" title="nilearn.maskers.MultiNiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiMasker</span></code></a> extracts <a class="reference internal" href="../glossary.html#term-voxel"><span class="xref std std-term">voxel</span></a> signals for each subject in the areas defined by the
masks.</p>
<aside class="topic">
<p class="topic-title"><strong>Examples</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/02_decoding/plot_miyawaki_reconstruction.html#sphx-glr-auto-examples-02-decoding-plot-miyawaki-reconstruction-py"><span class="std std-ref">Reconstruction of visual stimuli from Miyawaki et al. 2008</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/02_decoding/plot_miyawaki_encoding.html#sphx-glr-auto-examples-02-decoding-plot-miyawaki-encoding-py"><span class="std std-ref">Encoding models for visual stimuli from Miyawaki et al. 2008</span></a></p></li>
</ul>
</aside>
</section>
<section id="multiniftilabelsmasker-usage">
<h3><span class="section-number">9.3.4.2. </span><a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiLabelsMasker.html#nilearn.maskers.MultiNiftiLabelsMasker" title="nilearn.maskers.MultiNiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiLabelsMasker</span></code></a> Usage<a class="headerlink" href="#multiniftilabelsmasker-usage" title="Link to this heading">¶</a></h3>
<p><a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiLabelsMasker.html#nilearn.maskers.MultiNiftiLabelsMasker" title="nilearn.maskers.MultiNiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiLabelsMasker</span></code></a> extracts signals from regions defined by labels
for each subject.</p>
<aside class="topic">
<p class="topic-title"><strong>Examples</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/03_connectivity/plot_atlas_comparison.html#sphx-glr-auto-examples-03-connectivity-plot-atlas-comparison-py"><span class="std std-ref">Comparing connectomes on different reference atlases</span></a></p></li>
</ul>
</aside>
</section>
<section id="multiniftimapsmasker-usage">
<h3><span class="section-number">9.3.4.3. </span><a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiMapsMasker.html#nilearn.maskers.MultiNiftiMapsMasker" title="nilearn.maskers.MultiNiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiMapsMasker</span></code></a> Usage<a class="headerlink" href="#multiniftimapsmasker-usage" title="Link to this heading">¶</a></h3>
<p><a class="reference internal" href="../modules/generated/nilearn.maskers.MultiNiftiMapsMasker.html#nilearn.maskers.MultiNiftiMapsMasker" title="nilearn.maskers.MultiNiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiMapsMasker</span></code></a> extracts signals regions defined by maps
for each subject.</p>
<aside class="topic">
<p class="topic-title"><strong>Examples</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/03_connectivity/plot_atlas_comparison.html#sphx-glr-auto-examples-03-connectivity-plot-atlas-comparison-py"><span class="std std-ref">Comparing connectomes on different reference atlases</span></a></p></li>
</ul>
</aside>
</section>
</section>
<section id="extraction-of-signals-from-seeds-niftispheresmasker">
<h2><span class="section-number">9.3.5. </span>Extraction of signals from seeds: <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiSpheresMasker.html#nilearn.maskers.NiftiSpheresMasker" title="nilearn.maskers.NiftiSpheresMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiSpheresMasker</span></code></a><a class="headerlink" href="#extraction-of-signals-from-seeds-niftispheresmasker" title="Link to this heading">¶</a></h2>
<p>The purpose of <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiSpheresMasker.html#nilearn.maskers.NiftiSpheresMasker" title="nilearn.maskers.NiftiSpheresMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiSpheresMasker</span></code></a> is to compute signals from
seeds containing voxels in spheres. It makes it easy to get these signals once
you have a list of coordinates.
A single seed is a sphere defined by the radius (in millimeters) and the
coordinates (typically <a class="reference internal" href="../glossary.html#term-MNI"><span class="xref std std-term">MNI</span></a> or TAL) of its center.</p>
<p>Using <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiSpheresMasker.html#nilearn.maskers.NiftiSpheresMasker" title="nilearn.maskers.NiftiSpheresMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiSpheresMasker</span></code></a> needs to define a list of coordinates.
<code class="docutils literal notranslate"><span class="pre">seeds</span></code> argument takes a list of 3D coordinates (tuples) of the spheres centers,
they should be in the same space as the images.
Seeds can overlap spatially and are represented in a binary present/nonpresent
coding (no weighting).
Below is an example of a coordinates list of four seeds from the default mode network:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dmn_coords</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">52</span><span class="p">,</span> <span class="mi">18</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">46</span><span class="p">,</span> <span class="o">-</span><span class="mi">68</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="p">(</span><span class="mi">46</span><span class="p">,</span> <span class="o">-</span><span class="mi">68</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">)]</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">radius</span></code> is an optional argument that takes a real value in millimeters.
If no value is given for the <code class="docutils literal notranslate"><span class="pre">radius</span></code> argument, the single <a class="reference internal" href="../glossary.html#term-voxel"><span class="xref std std-term">voxel</span></a> at the given
seed position is used.</p>
<aside class="topic">
<p class="topic-title"><strong>Examples</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/03_connectivity/plot_sphere_based_connectome.html#sphx-glr-auto-examples-03-connectivity-plot-sphere-based-connectome-py"><span class="std std-ref">Extract signals on spheres and plot a connectome</span></a></p></li>
</ul>
</aside>
</section>
<section id="extraction-of-signals-from-surface-images-surfacemasker-surfacelabelsmasker-surfacemapsmasker-multisurfacemasker">
<h2><span class="section-number">9.3.6. </span>Extraction of signals from surface images <a class="reference internal" href="../modules/generated/nilearn.maskers.SurfaceMasker.html#nilearn.maskers.SurfaceMasker" title="nilearn.maskers.SurfaceMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">SurfaceMasker</span></code></a>, <a class="reference internal" href="../modules/generated/nilearn.maskers.SurfaceLabelsMasker.html#nilearn.maskers.SurfaceLabelsMasker" title="nilearn.maskers.SurfaceLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">SurfaceLabelsMasker</span></code></a>, <a class="reference internal" href="../modules/generated/nilearn.maskers.SurfaceMapsMasker.html#nilearn.maskers.SurfaceMapsMasker" title="nilearn.maskers.SurfaceMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">SurfaceMapsMasker</span></code></a>, <a class="reference internal" href="../modules/generated/nilearn.maskers.MultiSurfaceMasker.html#nilearn.maskers.MultiSurfaceMasker" title="nilearn.maskers.MultiSurfaceMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiSurfaceMasker</span></code></a><a class="headerlink" href="#extraction-of-signals-from-surface-images-surfacemasker-surfacelabelsmasker-surfacemapsmasker-multisurfacemasker" title="Link to this heading">¶</a></h2>
<p>The purpose of <a class="reference internal" href="../modules/generated/nilearn.maskers.SurfaceMasker.html#nilearn.maskers.SurfaceMasker" title="nilearn.maskers.SurfaceMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">SurfaceMasker</span></code></a>, <a class="reference internal" href="../modules/generated/nilearn.maskers.SurfaceLabelsMasker.html#nilearn.maskers.SurfaceLabelsMasker" title="nilearn.maskers.SurfaceLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">SurfaceLabelsMasker</span></code></a>, <a class="reference internal" href="../modules/generated/nilearn.maskers.SurfaceMapsMasker.html#nilearn.maskers.SurfaceMapsMasker" title="nilearn.maskers.SurfaceMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">SurfaceMapsMasker</span></code></a>
is to mirror the capabilities of
<a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a>, <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiLabelsMasker.html#nilearn.maskers.NiftiLabelsMasker" title="nilearn.maskers.NiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a> and <a class="reference internal" href="../modules/generated/nilearn.maskers.NiftiMapsMasker.html#nilearn.maskers.NiftiMapsMasker" title="nilearn.maskers.NiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a>
but to extract data from <a class="reference internal" href="../modules/generated/nilearn.surface.SurfaceImage.html#nilearn.surface.SurfaceImage" title="nilearn.surface.SurfaceImage"><code class="xref py py-class docutils literal notranslate"><span class="pre">SurfaceImage</span></code></a>.</p>
<p>They can perform data extraction from 1D surface data (n_vertices),
2D surface data (n_vertices x samples)
or list of 1D or 2D surface data with the same underlying mesh.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Surface masker objects can transform both 1D, 2D,
as well as list of 1D surface image objects.</p>
<ul class="simple">
<li><p>transforming a 1D image (n_vertices,) produces a 1D array,</p></li>
<li><p>transforming a 2D image (n_vertices, samples) produces a 2D array,</p></li>
<li><p>transforming a list of <code class="docutils literal notranslate"><span class="pre">length==n</span></code> of 1D image (n_vertices,) produces a 2D array (n_vertices, n)</p></li>
</ul>
<p>Multi surface masker objects can transform both 1D, 2D,
as well as list of 1D or 2D surface image objects.</p>
<ul class="simple">
<li><p>transforming a 1D image (n_vertices,) produces a 1D array,</p></li>
<li><p>transforming a 2D image (n_vertices, samples) produces a 2D array,</p></li>
<li><p>transforming a list of <code class="docutils literal notranslate"><span class="pre">length==n</span></code> of images (n_vertices,) produces a list of <code class="docutils literal notranslate"><span class="pre">length==n</span></code> of arrays where the dimension of each array matches that of the input image</p></li>
</ul>
<p>Transforming a 1D image produces a 1D (features,) array.
All other input will produce a 1D (samples, features) array..</p>
<p>Surface masker objects can inverse-transform both 1D and 2D arrays :</p>
<ul class="simple">
<li><p>inverse-transforming a 1D array produces a 1D (n_vertices,) image,</p></li>
<li><p>inverse-transforming a 2D array produces a 2D (n_vertices, samples) image.</p></li>
</ul>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../building_blocks/index.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title"><span class="section-number">10. </span>Advanced usage: manual pipelines and scaling up</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="manipulating_images.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title"><span class="section-number">9.2. </span>Manipulating images: resampling, smoothing, masking, ROIs…</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; The nilearn developers
- Code and documentation distributed under BSD license.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link fa-brands fa-solid fa-github fa-2x" href="https://github.com/nilearn/nilearn" aria-label="GitHub"></a>
              <a class="muted-link fa-brands fa-solid fa-bluesky fa-2x" href="https://bsky.app/profile/nilearn.bsky.social" aria-label="Bluesky"></a>
              <a class="muted-link fa-brands fa-solid fa-mastodon fa-2x" href="https://fosstodon.org/@nilearn" aria-label="Mastodon"></a>
              <a class="muted-link fa-brands fa-solid fa-discord fa-2x" href="https://discord.com/invite/SsQABEJHkZ" aria-label="Discord"></a>
              <a class="muted-link fa-brands fa-solid fa-youtube fa-2x" href="https://www.youtube.com/channel/UCU6BMAi2zOhNFnDkbdevmPw" aria-label="Youtube"></a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">9.3. From neuroimaging volumes to data matrices: the masker objects</a><ul>
<li><a class="reference internal" href="#the-concept-of-masker-objects">9.3.1. The concept of “masker” objects</a></li>
<li><a class="reference internal" href="#niftimasker-applying-a-mask-to-load-time-series">9.3.2. <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code>: applying a mask to load time-series</a><ul>
<li><a class="reference internal" href="#custom-data-loading-loading-only-the-first-100-time-points">9.3.2.1. Custom data loading: loading only the first 100 time points</a></li>
<li><a class="reference internal" href="#controlling-how-the-mask-is-computed-from-the-data">9.3.2.2. Controlling how the mask is computed from the data</a><ul>
<li><a class="reference internal" href="#visualizing-the-computed-mask">9.3.2.2.1. Visualizing the computed mask</a></li>
<li><a class="reference internal" href="#different-masking-strategies">9.3.2.2.2. Different masking strategies</a></li>
<li><a class="reference internal" href="#extra-mask-parameters-opening-cutoff">9.3.2.2.3. Extra mask parameters: opening, cutoff…</a></li>
</ul>
</li>
<li><a class="reference internal" href="#common-data-preparation-steps-smoothing-filtering-resampling">9.3.2.3. Common data preparation steps: smoothing, filtering, resampling</a><ul>
<li><a class="reference internal" href="#smoothing">9.3.2.3.1. Smoothing</a></li>
<li><a class="reference internal" href="#temporal-filtering-and-confound-removal">9.3.2.3.2. Temporal Filtering and confound removal</a></li>
<li><a class="reference internal" href="#resampling-resizing-and-changing-resolutions-of-images">9.3.2.3.3. Resampling: resizing and changing resolutions of images</a></li>
</ul>
</li>
<li><a class="reference internal" href="#inverse-transform-unmasking-data">9.3.2.4. Inverse transform: unmasking data</a></li>
</ul>
</li>
<li><a class="reference internal" href="#extraction-of-signals-from-regions-niftilabelsmasker-niftimapsmasker">9.3.3. Extraction of signals from regions: <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a><ul>
<li><a class="reference internal" href="#regions-definition">9.3.3.1. Regions definition</a></li>
<li><a class="reference internal" href="#niftilabelsmasker-usage">9.3.3.2. <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code> Usage</a></li>
<li><a class="reference internal" href="#niftimapsmasker-usage">9.3.3.3. <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code> Usage</a></li>
</ul>
</li>
<li><a class="reference internal" href="#extraction-of-signals-from-regions-for-multiple-subjects-multiniftimasker-multiniftilabelsmasker-multiniftimapsmasker">9.3.4. Extraction of signals from regions for multiple subjects: <code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiMasker</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiLabelsMasker</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiMapsMasker</span></code></a><ul>
<li><a class="reference internal" href="#multiniftimasker-usage">9.3.4.1. <code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiMasker</span></code> Usage</a></li>
<li><a class="reference internal" href="#multiniftilabelsmasker-usage">9.3.4.2. <code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiLabelsMasker</span></code> Usage</a></li>
<li><a class="reference internal" href="#multiniftimapsmasker-usage">9.3.4.3. <code class="xref py py-class docutils literal notranslate"><span class="pre">MultiNiftiMapsMasker</span></code> Usage</a></li>
</ul>
</li>
<li><a class="reference internal" href="#extraction-of-signals-from-seeds-niftispheresmasker">9.3.5. Extraction of signals from seeds: <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiSpheresMasker</span></code></a></li>
<li><a class="reference internal" href="#extraction-of-signals-from-surface-images-surfacemasker-surfacelabelsmasker-surfacemapsmasker-multisurfacemasker">9.3.6. Extraction of signals from surface images <code class="xref py py-class docutils literal notranslate"><span class="pre">SurfaceMasker</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">SurfaceLabelsMasker</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">SurfaceMapsMasker</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">MultiSurfaceMasker</span></code></a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=4ea706d9"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    </body>
</html>