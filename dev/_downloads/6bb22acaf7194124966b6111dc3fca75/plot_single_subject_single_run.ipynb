{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Intro to GLM Analysis: a single-run, single-subject fMRI dataset\n\nIn this tutorial, we use a General Linear Model (:term:`GLM`) to compare the\n:term:`fMRI` signal during periods of auditory stimulation\nversus periods of rest.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>The analysis described here is performed in the native space,\n    directly on the original :term:`EPI` scans\n    without any spatial or temporal preprocessing.\n    More sensitive results would likely be obtained on the corrected,\n    spatially normalized and smoothed images.</p></div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retrieving the data\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In this tutorial, we load the data using a data downloading\n          function. To input your own data, you will need to provide\n          a list of paths to your own files in the ``subject_data`` variable.\n          These should abide to the Brain Imaging Data Structure\n          (:term:`BIDS`) organization.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import fetch_spm_auditory\n\nsubject_data = fetch_spm_auditory()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspecting the dataset\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "print paths of func image\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subject_data.func[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can display the mean functional image and the subject's anatomy:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.image import mean_img\nfrom nilearn.plotting import plot_anat, plot_img, plot_stat_map, show\n\nfmri_img = subject_data.func\nmean_img = mean_img(subject_data.func[0], copy_header=True)\nplot_img(mean_img, cbar_tick_format=\"%i\")\n\nplot_anat(subject_data.anat, cbar_tick_format=\"%i\")\n\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specifying the experimental paradigm\n\nWe must now provide a description of the experiment, that is,\ndefine the timing of the auditory stimulation and rest periods.\nThis is typically provided in an events.tsv file.\nThe path of this file is provided in the dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\nevents = pd.read_table(subject_data.events)\nevents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performing the :term:`GLM` analysis\n\nIt is now time to create and estimate a ``FirstLevelModel`` object,\nthat will generate the *design matrix*\nusing the information provided by the ``events`` object.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.glm.first_level import FirstLevelModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parameters of the first-level model\n\n* ``t_r=7(s)`` is the time of repetition of acquisitions\n* ``noise_model='ar1'`` specifies the noise covariance model:\n  a lag-1 dependence\n* ``standardize=False`` means that we do not want\n  to rescale the time series to mean 0, variance 1\n* ``hrf_model='spm'`` means that we rely\n  on the :term:`SPM` \"canonical hrf\" model\n  (without time or dispersion derivatives)\n* ``drift_model='cosine'`` means that we model the signal drifts\n  as slow oscillating time functions\n* ``high_pass=0.01`` (Hz) defines the cutoff frequency\n  (inverse of the time period).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fmri_glm = FirstLevelModel(\n    t_r=7,\n    noise_model=\"ar1\",\n    standardize=False,\n    hrf_model=\"spm\",\n    drift_model=\"cosine\",\n    high_pass=0.01,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have specified the model, we can run it on the :term:`fMRI` image\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fmri_glm = fmri_glm.fit(fmri_img, events)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One can inspect the design matrix (rows represent time, and\ncolumns contain the predictors).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "design_matrix = fmri_glm.design_matrices_[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Formally, we have taken the first design matrix, because the model is\nimplictily meant to for multiple runs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.plotting import plot_design_matrix\n\nplot_design_matrix(design_matrix)\n\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save the design matrix image to disk\nfirst create a directory where you want to write the images\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\noutput_dir = Path.cwd() / \"results\" / \"plot_single_subject_single_run\"\noutput_dir.mkdir(exist_ok=True, parents=True)\nprint(f\"Output will be saved to: {output_dir}\")\n\nplot_design_matrix(design_matrix, output_file=output_dir / \"design_matrix.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first column contains the expected response profile of regions which are\nsensitive to the auditory stimulation.\nLet's plot this first column\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nplt.plot(design_matrix[\"listening\"])\nplt.xlabel(\"scan\")\nplt.title(\"Expected Auditory Response\")\n\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detecting voxels with significant effects\n\nTo access the estimated coefficients (Betas of the :term:`GLM` model),\nwe created :term:`contrast` with a single '1' in each of the columns:\nThe role of the :term:`contrast` is to select some columns of the model\n--and potentially weight them-- to study the associated statistics.\nSo in a nutshell, a :term:`contrast`\nis a weighted combination of the estimated effects.\nHere we can define canonical contrasts that just consider\nthe effect of the stimulation in isolation.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Here the baseline is implicit, so passing a value of 1\n      for the first column will give contrast for: ``listening > rest``</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nn_regressors = design_matrix.shape[1]\nactivation = np.zeros(n_regressors)\nactivation[0] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at it: plot the coefficients of the :term:`contrast`,\nindexed by the names of the columns of the design matrix.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.plotting import plot_contrast_matrix\n\nplot_contrast_matrix(contrast_def=activation, design_matrix=design_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below, we compute the :term:`'estimated effect'<Parameter Estimate>`.\nIt is in :term:`BOLD` signal unit, but has no statistical guarantees,\nbecause it does not take into account the associated variance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "eff_map = fmri_glm.compute_contrast(activation, output_type=\"effect_size\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to get statistical significance, we form a t-statistic, and\ndirectly convert it into z-scale. The z-scale means that the values\nare scaled to match a standard Gaussian distribution (mean=0,\nvariance=1), across voxels, if there were no effects in the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z_map = fmri_glm.compute_contrast(activation, output_type=\"z_score\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot thresholded z scores map\n\nWe display it on top of the average functional image of the series\n(could be the anatomical image of the subject).\nWe use arbitrarily a threshold of 3.0 in z-scale.\nWe'll see later how to use corrected thresholds.\nWe will show 3 axial views, with display_mode='z' and cut_coords=3.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotting_config = {\n    \"bg_img\": mean_img,\n    \"display_mode\": \"z\",\n    \"cut_coords\": 3,\n    \"black_bg\": True,\n}\nplot_stat_map(\n    z_map,\n    threshold=3,\n    title=\"listening > rest (|Z|>3)\",\n    figure=plt.figure(figsize=(10, 4)),\n    **plotting_config,\n)\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Notice how the visualizations above shows both 'activated' voxels\n  with Z > 3,\n  as well as 'deactivated' voxels with Z < -3.\n  In the rest of this example we will show only the activate voxels\n  by using one-sided tests.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistical significance testing\n\nOne should worry about the statistical validity of the procedure:\nhere we used an arbitrary\nthreshold of 3.0 but the threshold should provide some guarantees on\nthe risk of false detections (aka type-1 errors in statistics).\nOne suggestion is to control the false positive rate\n(:term:`fpr<FPR correction>`, denoted by alpha)\nat a certain level, e.g. 0.001: this means that there is 0.1% chance\nof declaring an inactive :term:`voxel`, active.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.glm import threshold_stats_img\n\nclean_map, threshold = threshold_stats_img(\n    z_map,\n    alpha=0.001,\n    height_control=\"fpr\",\n    two_sided=False,  # using a one-sided test\n)\n# Let's use a sequential colormap as we will only display positive values.\nplotting_config[\"cmap\"] = \"inferno\"\nplot_stat_map(\n    clean_map,\n    threshold=threshold,\n    title=(\n        f\"listening > rest (Uncorrected p<0.001; threshold: {threshold:.3f})\"\n    ),\n    figure=plt.figure(figsize=(10, 4)),\n    **plotting_config,\n)\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The problem is that with this you expect 0.001 * n_voxels to show up\nwhile they're not active --- tens to hundreds of voxels. A more\nconservative solution is to control the family wise error rate,\ni.e. the probability of making only one false detection, say at\n5%. For that we use the so-called Bonferroni correction.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clean_map, threshold = threshold_stats_img(\n    z_map, alpha=0.05, height_control=\"bonferroni\", two_sided=False\n)\nplot_stat_map(\n    clean_map,\n    threshold=threshold,\n    title=(\n        \"listening > rest (p<0.05 Bonferroni-corrected, \"\n        f\"threshold: {threshold:.3f})\"\n    ),\n    figure=plt.figure(figsize=(10, 4)),\n    **plotting_config,\n)\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is quite conservative indeed!  A popular alternative is to\ncontrol the expected proportion of\nfalse discoveries among detections. This is called the False\ndiscovery rate.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clean_map, threshold = threshold_stats_img(\n    z_map, alpha=0.05, height_control=\"fdr\", two_sided=False\n)\nplot_stat_map(\n    clean_map,\n    threshold=threshold,\n    title=(\n        f\"listening > rest (p<0.05 FDR-corrected; threshold: {threshold:.3f})\"\n    ),\n    figure=plt.figure(figsize=(10, 4)),\n    **plotting_config,\n)\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally people like to discard isolated voxels (aka \"small\nclusters\") from these images. It is possible to generate a\nthresholded map with small clusters removed by providing a\ncluster_threshold argument. Here clusters smaller than 10 voxels\nwill be discarded.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clean_map, threshold = threshold_stats_img(\n    z_map,\n    alpha=0.05,\n    height_control=\"fdr\",\n    cluster_threshold=10,\n    two_sided=False,\n)\nplot_stat_map(\n    clean_map,\n    threshold=threshold,\n    title=(\n        \"listening > rest \"\n        f\"(p<0.05 FDR-corrected; threshold: {threshold:.3f}; \"\n        \"clusters > 10 voxels)\"\n    ),\n    figure=plt.figure(figsize=(10, 4)),\n    **plotting_config,\n)\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can save the effect and zscore maps to the disk.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z_map.to_filename(output_dir / \"listening_gt_rest_z_map.nii.gz\")\neff_map.to_filename(output_dir / \"listening_gt_rest_eff_map.nii.gz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can furthermore extract and report the found positions in a table.\n\n.. seealso::\n\n    This function does not report any named anatomical location\n    for the clusters.\n    To get the names of the location of the clusters\n    according to one or several atlases,\n    we recommend using\n    the [atlasreader package](https://github.com/miykael/atlasreader).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.reporting import get_clusters_table\n\ntable = get_clusters_table(\n    z_map, stat_threshold=threshold, cluster_threshold=20\n)\ntable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This table can be saved for future use.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "table.to_csv(output_dir / \"table.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performing an F-test\n\n\"listening > rest\" is a typical t test: condition versus baseline.\nAnother popular type of test is an F test in which\none seeks whether a certain combination of conditions\n(possibly two-, three- or higher-dimensional)\nexplains a significant proportion of the signal.\nHere one might for instance test which voxels are well\nexplained by the combination of more active or less active than rest.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>As opposed to t-tests, the beta images produced by of F-tests\n   only contain positive values.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify the :term:`contrast` and compute the corresponding map.\nActually, the :term:`contrast` specification is done exactly the same way\nas for t-contrasts.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z_map = fmri_glm.compute_contrast(\n    activation,\n    output_type=\"z_score\",\n    stat_type=\"F\",  # set stat_type to 'F' to perform an F test\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the statistic has been converted to a z-variable,\nwhich makes it easier to represent it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clean_map, threshold = threshold_stats_img(\n    z_map,\n    alpha=0.05,\n    height_control=\"fdr\",\n    cluster_threshold=10,\n    two_sided=False,\n)\nplot_stat_map(\n    clean_map,\n    threshold=threshold,\n    title=\"Effects of interest (fdr=0.05), clusters > 10 voxels\",\n    figure=plt.figure(figsize=(10, 4)),\n    **plotting_config,\n)\nshow()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}