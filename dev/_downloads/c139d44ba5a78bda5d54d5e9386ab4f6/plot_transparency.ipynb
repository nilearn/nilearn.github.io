{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Plotting images with transparent thresholding\n\nStandard thresholding means that any data below a threshold value\nis completely hidden from view.\nHowever, \"transparent thresholding\" allows\nfor the same suprathreshold results to be observed,\nwhile also showing subthreshold information\nwith an opacity that fades with decreasing magnitude\n(:footcite:t:`Allen2012`, :footcite:t:`Chen2022`,\n:footcite:t:`Taylor2023`, :footcite:t:`Sundermann2024`).\n\nThis makes use of the \"alpha\" value that overlays can have\nwhen using some plotting functions (like :func:`matplotlib.pyplot.imshow`).\nThis \"alpha\" value goes from 0 (perfectly transparent) to 1 (perfectly opaque).\n\nConsider having an underlay color $RGB_{U}$\nand overlay color $RGB_{O}$,\nwhere a threshold value T is applied\nand we consider how an element (voxel, node...) with value M is shown.\n\n## \"Opaque\" thresholding\n\nif $\\lvert M \\lvert >= T : alpha=1$,\nmeaning the overlay is shown as: $RGB_{O}$\nelse : $alpha=0$, meaning the underlay is shown as: $RGB_{U}$\n\n## \"Transparent\" thresholding\n\nThe steepness of fading can be linear or quadratic. Linear is shown below.\n\nIf $\\lvert M \\lvert >= T : alpha=1$,\nmeaning the overlay is shown as: $RGB_{O}$.\n\nOtherwise $alpha = (\\lvert M \\lvert /  T)$,\nmerging $RGB_{O}$ and $RGB_{U}$ as:\n\n$RGB_{final} = (1-alpha) * RGB_{U} + alpha * RGB_{O}$.\n\nIn the end, this is just a small tweak for the case of subthreshold data.\nIn that case, alpha is nonzero (rather than simply 0).\n\nAdditionally, a contour can be placed around the suprathreshold regions,\nto further highlight them.\n\nSo, the differences between standard, opaque thresholding\nand the suggested transparent thresholding\nis shown in the rest of this example.\n\n..  admonition:: Benefits\n    :class: important\n\n    Implementing transparent thresholding can help provide\n    more informative results reporting and\n    more accurate interpretations,\n    can facilitate quality control\n    and improve reproducibility checks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nfrom nilearn import datasets\nfrom nilearn.plotting import plot_stat_map, show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the image we will use to demonstrate.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "image = datasets.load_sample_motor_activation_image()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's use some slightly different plotting parameters\nthat should work better with transparency plotting.\nFor example, let's pick a diverging colormap\nthat diverges from black and not from white\nas the default colormap does.\n\n.. TODO switch to ``berlin`` color map when bumping matplotlib\n   as it is not a cyclic color map like ``cold_hot``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vmin = 0.5\nthreshold = 3\nfigure_width = 8\n\nplotting_config = {\n    \"display_mode\": \"ortho\",\n    \"cut_coords\": [5, -26, 21],\n    \"draw_cross\": False,\n    \"vmax\": 8,\n    \"cmap\": \"cold_hot\",\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing transparent and opaque thresholding\n\nHere we use the motor activation image itself to give us the values\nto use for transparency.\nWe can set ``transparency_range`` to ``[0.5, 3]``\nto range of values where transparency will be 'enabled'.\nValues below 0.5 will be fully transparent\nwhile values above 3 will be fully opaque.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotting_config = {\n    \"display_mode\": \"ortho\",\n    \"cut_coords\": [5, -26, 21],\n    \"draw_cross\": False,\n    \"vmax\": 8,\n    \"cmap\": \"cold_hot\",\n}\n\nfig, axes = plt.subplots(\n    4,\n    1,\n    figsize=(figure_width, 17),\n)\n\nplot_stat_map(\n    image,\n    title=\"image without threshold\",\n    axes=axes[0],\n    **plotting_config,\n)\nplot_stat_map(\n    image,\n    title=\"opaque thresholding\",\n    threshold=threshold,\n    axes=axes[1],\n    **plotting_config,\n)\nplot_stat_map(\n    image,\n    title=\"transparent thresholding\",\n    transparency=image,\n    axes=axes[2],\n    **plotting_config,\n)\nplot_stat_map(\n    image,\n    title=\"transparent thresholding with range\",\n    transparency=image,\n    transparency_range=[vmin, threshold],\n    axes=axes[3],\n    **plotting_config,\n)\n\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transparent thresholding and contours\n\nIf you want to visualize the limit where the transparency starts,\nyou can add contours at the right threshold\nby using\nthe :meth:`~nilearn.plotting.displays.BaseSlicer.add_contours` method.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(figsize=(figure_width, 4))\n\ndisplay = plot_stat_map(\n    image,\n    title=\"transparent thresholding with contour\",\n    transparency=image,\n    transparency_range=[vmin, threshold],\n    axes=axes,\n    **plotting_config,\n)\ndisplay.add_contours(\n    image, filled=False, levels=[-threshold, threshold], colors=[\"k\", \"k\"]\n)\n\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transparent masking of part of the data\n\nYou may want to use transparent masking to highlight\nspecific parts of the brain while leaving other parts partly visible.\n\nFor example, you could highlight the gray matter\nand leave values in the rest of the brain partly transparent.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's fetch a beta image of auditory localizer from a single subject.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import fetch_localizer_contrasts\n\nauditory_image = fetch_localizer_contrasts(\n    contrasts=[\"left auditory click\"], verbose=0, n_subjects=1\n)\nauditory_image = auditory_image.cmaps[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The let's create our transparency image\nto leave gray matter opaque and make the white matter\npartly transparent.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom nibabel import Nifti1Image\n\nfrom nilearn.datasets import load_mni152_gm_mask, load_mni152_wm_mask\n\nwhite_matter_image = load_mni152_wm_mask(threshold=0.35)\nwhite_matter_mask = white_matter_image.get_fdata() > 0\n\ngrey_matter_image = load_mni152_gm_mask(threshold=0.6)\ngrey_matter_mask = grey_matter_image.get_fdata() > 0\n\ntransparency_data = np.zeros(grey_matter_image.shape)\ntransparency_data[white_matter_mask] = 0.6\ntransparency_data[grey_matter_mask] = 1\ntransparency_image = Nifti1Image(transparency_data, grey_matter_image.affine)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the plot.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(\n    2,\n    1,\n    figsize=(figure_width, 8),\n)\n\nplotting_config = {\n    \"display_mode\": \"ortho\",\n    \"cut_coords\": [5, -26, 21],\n    \"draw_cross\": False,\n    \"cmap\": \"cold_hot\",\n}\n\ndisplay = plot_stat_map(\n    auditory_image,\n    title=\"auditory localizer - no thresholding\",\n    axes=axes[0],\n    **plotting_config,\n)\n\ndisplay = plot_stat_map(\n    auditory_image,\n    title=\"auditory localizer  - highlight gray matter\",\n    transparency=transparency_image,\n    axes=axes[1],\n    **plotting_config,\n)\n\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The transparency image was automatically resampled to the underlying data.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transparent thresholding with other functions\n\nSeveral plotting functions support transparency including\n:func:`~nilearn.plotting.plot_glass_brain`,\n:func:`~nilearn.plotting.plot_stat_map` and\n:func:`~nilearn.plotting.plot_img`.\n\nSee below an example with ``plot_glass_brain``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.plotting import plot_glass_brain\n\nplotting_config = {\n    \"colorbar\": True,\n    \"cmap\": \"inferno\",\n}\n\nfig, axes = plt.subplots(\n    4,\n    1,\n    figsize=(figure_width, 17),\n)\nplot_glass_brain(\n    image,\n    title=\"image without threshold\",\n    axes=axes[0],\n    **plotting_config,\n)\nplot_glass_brain(\n    image,\n    title=\"opaque thresholding\",\n    threshold=threshold,\n    axes=axes[1],\n    **plotting_config,\n)\nplot_glass_brain(\n    image,\n    title=\"transparent thresholding\",\n    transparency=image,\n    axes=axes[2],\n    **plotting_config,\n)\nplot_glass_brain(\n    image,\n    title=\"transparent thresholding with range\",\n    transparency=image,\n    transparency_range=[vmin, threshold],\n    axes=axes[3],\n    **plotting_config,\n)\n\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transparent thresholding on GLM results\n\nYou can also use different images as 'transparency' layer.\n\nFor example, on the output of a GLM,\nyou can visualize the contrast values and use their z-score as transparency.\n\nWe will show this on a simple block paradigm GLM.\n\n.. seealso::\n\n    For more information\n    see the `dataset description <spm_auditory_dataset>`.\n\nIn the following section we :\n\n- download the data,\n\n- fit the GLM with some smoothing of the data,\n\n- compute the contrast for the only condition present in this dataset,\n\n- compute the mean image of the functional data,\n  to use as underlay for our plots.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import fetch_spm_auditory\nfrom nilearn.glm import threshold_stats_img\nfrom nilearn.glm.first_level import FirstLevelModel\nfrom nilearn.image import mean_img\nfrom nilearn.plotting import plot_stat_map, show\n\nsubject_data = fetch_spm_auditory(verbose=0)\n\nfmri_glm = FirstLevelModel(\n    t_r=7,\n    smoothing_fwhm=4,\n    noise_model=\"ar1\",\n    standardize=False,\n    hrf_model=\"spm\",\n    drift_model=\"cosine\",\n    high_pass=0.01,\n)\n\nfmri_glm = fmri_glm.fit(subject_data.func, subject_data.events)\n\nresults = fmri_glm.compute_contrast(\"listening\", output_type=\"all\")\n\nmean_img = mean_img(subject_data.func[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's set some common configuration for our plots.\n\nWe will look at activations only\nso we set ``vmin`` to 0 and use a sequential colormap (``inferno``).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotting_config = {\n    \"bg_img\": mean_img,\n    \"display_mode\": \"z\",\n    \"cut_coords\": [9, 42, 75],\n    \"black_bg\": True,\n    \"vmin\": 0,\n    \"cmap\": \"inferno\",\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we will:\n\n- have a look at the statistical value for our contrast,\n\n- have a look at their Z score with opaque contrast,\n\n- use the Z score as transparency value,\n\n- finally we will threshold the Z-score to identify the significant clusters\n  (fdr=0.05, 500 voxels)\n  and plot those as contours.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(\n    4,\n    1,\n    figsize=(figure_width, 18),\n)\n\nplot_stat_map(\n    results[\"stat\"],\n    title=\"contrast value\",\n    axes=axes[0],\n    **plotting_config,\n)\nplot_stat_map(\n    results[\"z_score\"],\n    title=\"z-score, opaque threshold\",\n    threshold=3,\n    axes=axes[1],\n    **plotting_config,\n)\nplot_stat_map(\n    results[\"stat\"],\n    title=\"contrast value, z-score as transparency\",\n    axes=axes[2],\n    transparency=results[\"z_score\"],\n    **plotting_config,\n)\ndisplay = plot_stat_map(\n    results[\"stat\"],\n    title=\"contrast value, z-score as transparency, contoured clusters\",\n    axes=axes[3],\n    transparency=results[\"z_score\"],\n    **plotting_config,\n)\nclean_map, threshold = threshold_stats_img(\n    results[\"z_score\"],\n    alpha=0.05,\n    height_control=\"fdr\",\n    cluster_threshold=500,\n    two_sided=False,\n)\ndisplay.add_contours(clean_map, filled=False, levels=[threshold], colors=[\"w\"])\n\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n\n.. footbibliography::\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}