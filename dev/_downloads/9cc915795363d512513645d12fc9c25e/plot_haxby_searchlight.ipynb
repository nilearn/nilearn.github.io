{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Searchlight analysis of face vs house recognition\n\nSearchlight analysis requires fitting a classifier a large amount of\ntimes. As a result, it is an intrinsically slow method. In order to speed\nup computing, in this example, Searchlight is run only on one slice on\nthe :term:`fMRI` (see the generated figures).\n\n.. include:: ../../../examples/masker_note.rst\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Haxby dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\nfrom nilearn.datasets import fetch_haxby\nfrom nilearn.image import get_data, load_img, new_img_like\n\n# We fetch 2nd subject from haxby datasets (which is default)\nhaxby_dataset = fetch_haxby()\n\n# print basic information on the dataset\nprint(f\"Anatomical nifti image (3D) is located at: {haxby_dataset.mask}\")\nprint(f\"Functional nifti image (4D) is located at: {haxby_dataset.func[0]}\")\n\nfmri_filename = haxby_dataset.func[0]\nlabels = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\ny = labels[\"labels\"]\nrun = labels[\"chunks\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Restrict to faces and houses\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.image import index_img\n\ncondition_mask = y.isin([\"face\", \"house\"])\n\nfmri_img = index_img(fmri_filename, condition_mask)\ny, run = y[condition_mask], run[condition_mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare masks\n- mask_img is the original mask\n- process_mask_img is a subset of mask_img, it contains the voxels that\n  should be processed (we only keep the slice z = 29 and the back of the\n  brain to speed up computation)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nmask_img = load_img(haxby_dataset.mask)\n\n# .astype() makes a copy.\nprocess_mask = get_data(mask_img).astype(int)\npicked_slice = 29\nprocess_mask[..., (picked_slice + 1) :] = 0\nprocess_mask[..., :picked_slice] = 0\nprocess_mask[:, 30:] = 0\nprocess_mask_img = new_img_like(mask_img, process_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Searchlight computation\nMake processing parallel\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>As each thread will print its progress, n_jobs > 1 could mess up the\n    information output.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_jobs = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the cross-validation scheme used for validation.\nHere we use a KFold cross-validation on the run, which corresponds to\nsplitting the samples in 4 folds and make 4 runs using each fold as a test\nset once and the others as learning sets\n\nThe radius is the one of the Searchlight sphere that will scan the volume\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n\nimport nilearn.decoding\n\ncv = KFold(n_splits=4)\n\nsearchlight = nilearn.decoding.SearchLight(\n    mask_img,\n    process_mask_img=process_mask_img,\n    radius=5.6,\n    n_jobs=n_jobs,\n    verbose=1,\n    cv=cv,\n)\nsearchlight.fit(fmri_img, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization\n%%\nAfter fitting the searchlight, we can access the searchlight scores\nas a NIfTI image using the `scores_img_` attribute.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores_img = searchlight.scores_img_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the :term:`fMRI` mean image as a surrogate of anatomical data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.image import mean_img\n\nmean_fmri = mean_img(fmri_img, copy_header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because scores are not a zero-center test statistics,\nwe cannot use plot_stat_map\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.plotting import plot_img, plot_stat_map, show\n\nplot_img(\n    scores_img,\n    bg_img=mean_fmri,\n    title=\"Searchlight scores image\",\n    display_mode=\"z\",\n    cut_coords=[-9],\n    vmin=0.2,\n    cmap=\"inferno\",\n    threshold=0.2,\n    black_bg=True,\n    colorbar=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## F-scores computation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import f_classif\n\nfrom nilearn.maskers import NiftiMasker\n\n# For decoding, standardizing is often very important\nnifti_masker = NiftiMasker(\n    mask_img=mask_img,\n    runs=run,\n    standardize=\"zscore_sample\",\n    memory=\"nilearn_cache\",\n    memory_level=1,\n)\nfmri_masked = nifti_masker.fit_transform(fmri_img)\n\n_, p_values = f_classif(fmri_masked, y)\np_values = -np.log10(p_values)\np_values[p_values > 10] = 10\np_unmasked = get_data(nifti_masker.inverse_transform(p_values))\n\n# F_score results\np_ma = np.ma.array(p_unmasked, mask=np.logical_not(process_mask))\nf_score_img = new_img_like(mean_fmri, p_ma)\nplot_stat_map(\n    f_score_img,\n    mean_fmri,\n    title=\"F-scores\",\n    display_mode=\"z\",\n    cut_coords=[-9],\n    cmap=\"inferno\",\n)\n\nshow()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.22"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}