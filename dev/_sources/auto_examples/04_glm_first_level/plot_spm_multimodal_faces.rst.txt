
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/04_glm_first_level/plot_spm_multimodal_faces.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_04_glm_first_level_plot_spm_multimodal_faces.py>`
        to download the full example code or to run this example in your browser via Binder.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_04_glm_first_level_plot_spm_multimodal_faces.py:


Single-subject data (two runs) in native space
==============================================

The example shows the analysis of an :term:`SPM` dataset,
with two conditions: viewing a face image or a scrambled face image.

This example takes a lot of time because the input are lists of 3D images
sampled in different positions (encoded by different affine functions).

.. seealso::

    For more information
    see the :ref:`dataset description <spm_multimodal_dataset>`.

.. GENERATED FROM PYTHON SOURCE LINES 18-21

Fetch and inspect the data
--------------------------
Fetch the :term:`SPM` multimodal_faces data.

.. GENERATED FROM PYTHON SOURCE LINES 21-25

.. code-block:: Python

    from nilearn.datasets import fetch_spm_multimodal_fmri

    subject_data = fetch_spm_multimodal_fmri()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [fetch_spm_multimodal_fmri] Dataset created in 
    /home/runner/nilearn_data/spm_multimodal_fmri
    [fetch_spm_multimodal_fmri] Missing 390 functional scans for session 1.
    [fetch_spm_multimodal_fmri] Data absent, downloading...
    [fetch_spm_multimodal_fmri] Downloading data from 
    https://www.fil.ion.ucl.ac.uk/spm/download/data/mmfaces/multimodal_fmri.zip ...
    [fetch_spm_multimodal_fmri] Downloaded 1875968 of 134263085 bytes (1.4%%,  
    1.2min remaining)
    [fetch_spm_multimodal_fmri] Downloaded 7168000 of 134263085 bytes (5.3%%,   
    35.5s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 11894784 of 134263085 bytes (8.9%%,   
    30.9s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 16850944 of 134263085 bytes (12.6%%,   
    27.9s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 21897216 of 134263085 bytes (16.3%%,   
    25.7s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 27074560 of 134263085 bytes (20.2%%,   
    23.8s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 32276480 of 134263085 bytes (24.0%%,   
    22.2s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 35840000 of 134263085 bytes (26.7%%,   
    22.0s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 39247872 of 134263085 bytes (29.2%%,   
    21.8s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 42459136 of 134263085 bytes (31.6%%,   
    21.7s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 45817856 of 134263085 bytes (34.1%%,   
    21.3s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 49242112 of 134263085 bytes (36.7%%,   
    20.8s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 52699136 of 134263085 bytes (39.3%%,   
    20.2s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 56156160 of 134263085 bytes (41.8%%,   
    19.5s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 59613184 of 134263085 bytes (44.4%%,   
    18.8s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 63102976 of 134263085 bytes (47.0%%,   
    18.1s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 66658304 of 134263085 bytes (49.6%%,   
    17.3s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 70361088 of 134263085 bytes (52.4%%,   
    16.4s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 74301440 of 134263085 bytes (55.3%%,   
    15.4s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 78585856 of 134263085 bytes (58.5%%,   
    14.2s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 83361792 of 134263085 bytes (62.1%%,   
    12.9s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 87638016 of 134263085 bytes (65.3%%,   
    11.8s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 91930624 of 134263085 bytes (68.5%%,   
    10.6s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 96608256 of 134263085 bytes (72.0%%,    
    9.4s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 101564416 of 134263085 bytes (75.6%%,    
    8.1s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 106676224 of 134263085 bytes (79.5%%,    
    6.8s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 111878144 of 134263085 bytes (83.3%%,    
    5.4s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 117121024 of 134263085 bytes (87.2%%,    
    4.1s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 121626624 of 134263085 bytes (90.6%%,    
    3.0s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 124829696 of 134263085 bytes (93.0%%,    
    2.3s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 127524864 of 134263085 bytes (95.0%%,    
    1.6s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 129368064 of 134263085 bytes (96.4%%,    
    1.2s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 131235840 of 134263085 bytes (97.7%%,    
    0.8s remaining)
    [fetch_spm_multimodal_fmri] Downloaded 133185536 of 134263085 bytes (99.2%%,    
    0.3s remaining)
    [fetch_spm_multimodal_fmri]  ...done. (36 seconds, 0 min)

    [fetch_spm_multimodal_fmri] Extracting data from 
    /home/runner/nilearn_data/spm_multimodal_fmri/sub001/multimodal_fmri.zip...
    [fetch_spm_multimodal_fmri] .. done.

    [fetch_spm_multimodal_fmri] Downloading data from 
    https://www.fil.ion.ucl.ac.uk/spm/download/data/mmfaces/multimodal_smri.zip ...
    [fetch_spm_multimodal_fmri] Downloaded 794624 of 6852766 bytes (11.6%%,    7.9s 
    remaining)
    [fetch_spm_multimodal_fmri] Downloaded 2146304 of 6852766 bytes (31.3%%,    4.6s
    remaining)
    [fetch_spm_multimodal_fmri] Downloaded 3661824 of 6852766 bytes (53.4%%,    2.7s
    remaining)
    [fetch_spm_multimodal_fmri] Downloaded 5267456 of 6852766 bytes (76.9%%,    1.3s
    remaining)
    [fetch_spm_multimodal_fmri]  ...done. (6 seconds, 0 min)

    [fetch_spm_multimodal_fmri] Extracting data from 
    /home/runner/nilearn_data/spm_multimodal_fmri/sub001/multimodal_smri.zip...
    [fetch_spm_multimodal_fmri] .. done.





.. GENERATED FROM PYTHON SOURCE LINES 26-27

Let's inspect one of the event files before using them.

.. GENERATED FROM PYTHON SOURCE LINES 27-34

.. code-block:: Python

    import pandas as pd

    events = [subject_data.events1, subject_data.events2]

    events_dataframe = pd.read_csv(events[0], sep="\t")
    events_dataframe["trial_type"].value_counts()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    trial_type
    scrambled    86
    faces        64
    Name: count, dtype: int64



.. GENERATED FROM PYTHON SOURCE LINES 35-37

We can confirm there are only 2 conditions in the dataset.


.. GENERATED FROM PYTHON SOURCE LINES 37-43

.. code-block:: Python

    from nilearn.plotting import plot_event, show

    plot_event(events)

    show()




.. image-sg:: /auto_examples/04_glm_first_level/images/sphx_glr_plot_spm_multimodal_faces_001.png
   :alt: plot spm multimodal faces
   :srcset: /auto_examples/04_glm_first_level/images/sphx_glr_plot_spm_multimodal_faces_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/runner/work/nilearn/nilearn/examples/04_glm_first_level/plot_spm_multimodal_faces.py:41: UserWarning:

    You are using the 'agg' matplotlib backend that is non-interactive.
    No figure will be plotted when calling matplotlib.pyplot.show() or nilearn.plotting.show().
    You can fix this by installing a different backend: for example via
            pip install PyQt6





.. GENERATED FROM PYTHON SOURCE LINES 44-46

Resample the images:
this is achieved by the ``concat_imgs`` function of Nilearn.

.. GENERATED FROM PYTHON SOURCE LINES 46-61

.. code-block:: Python

    import warnings

    from nilearn.image import concat_imgs, mean_img, resample_img

    # Avoid getting too many warnings due to resampling
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        fmri_img = [
            concat_imgs(subject_data.func1, auto_resample=True),
            concat_imgs(subject_data.func2, auto_resample=True),
        ]
    affine, shape = fmri_img[0].affine, fmri_img[0].shape
    print("Resampling the second image (this takes time)...")
    fmri_img[1] = resample_img(fmri_img[1], affine, shape[:3])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Resampling the second image (this takes time)...




.. GENERATED FROM PYTHON SOURCE LINES 62-63

Let's create mean image for display purposes.

.. GENERATED FROM PYTHON SOURCE LINES 63-65

.. code-block:: Python

    mean_image = mean_img(fmri_img)








.. GENERATED FROM PYTHON SOURCE LINES 66-70

Fit the model
-------------
Fit the :term:`GLM` for the 2 runs
by specifying a FirstLevelModel and then fitting it.

.. GENERATED FROM PYTHON SOURCE LINES 70-95

.. code-block:: Python


    # Sample at the beginning of each acquisition.
    slice_time_ref = 0.0
    # We use a discrete cosine transform to model signal drifts.
    drift_model = "cosine"
    # The cutoff for the drift model is 0.01 Hz.
    high_pass = 0.01
    # The hemodynamic response function
    hrf_model = "spm + derivative"

    from nilearn.glm.first_level import FirstLevelModel

    print("Fitting a GLM")
    fmri_glm = FirstLevelModel(
        smoothing_fwhm=None,
        t_r=subject_data.t_r,
        hrf_model=hrf_model,
        drift_model=drift_model,
        high_pass=high_pass,
        verbose=1,
    )


    fmri_glm = fmri_glm.fit(fmri_img, events=events)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Fitting a GLM
    [FirstLevelModel.fit] Loading data from <nibabel.nifti1.Nifti1Image object at 
    0x7fd156dac130>
    [FirstLevelModel.fit] Computing mask
    [FirstLevelModel.fit] Resampling mask
    [FirstLevelModel.fit] Finished fit
    [FirstLevelModel.fit] Computing run 1 out of 2 runs (go take a coffee, a big 
    one).
    [FirstLevelModel.fit] Performing mask computation.
    [FirstLevelModel.fit] Loading data from <nibabel.nifti1.Nifti1Image object at 
    0x7fd156dac130>
    [FirstLevelModel.fit] Extracting region signals
    [FirstLevelModel.fit] Cleaning extracted signals
    [FirstLevelModel.fit] Masking took 0 seconds.
    [FirstLevelModel.fit] Performing GLM computation.
    [FirstLevelModel.fit] GLM took 1 seconds.
    [FirstLevelModel.fit] Computing run 2 out of 2 runs (2 seconds remaining).
    [FirstLevelModel.fit] Performing mask computation.
    [FirstLevelModel.fit] Loading data from <nibabel.nifti1.Nifti1Image object at 
    0x7fd156dadae0>
    [FirstLevelModel.fit] Extracting region signals
    [FirstLevelModel.fit] Cleaning extracted signals
    [FirstLevelModel.fit] Masking took 0 seconds.
    [FirstLevelModel.fit] Performing GLM computation.
    [FirstLevelModel.fit] GLM took 1 seconds.
    [FirstLevelModel.fit] Computation of 2 runs done in 4 seconds.




.. GENERATED FROM PYTHON SOURCE LINES 96-100

View the results
----------------
Now we can compute contrast-related statistical maps (in z-scale),
and plot them.

.. GENERATED FROM PYTHON SOURCE LINES 100-104

.. code-block:: Python

    from nilearn.plotting import plot_stat_map

    print("Computing contrasts")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Computing contrasts




.. GENERATED FROM PYTHON SOURCE LINES 105-110

We actually want more interesting contrasts.
The simplest contrast just makes the difference
between the two main conditions.
We define the two opposite versions to run one-tailed t-tests.


.. GENERATED FROM PYTHON SOURCE LINES 110-113

.. code-block:: Python


    contrasts = ["faces - scrambled", "scrambled - faces"]








.. GENERATED FROM PYTHON SOURCE LINES 114-120

Let's store common parameters for all plots.

We plot the contrasts values overlaid on the mean fMRI image
and we will use the z-score values as transparency,
with any voxel with | Z-score | > 3 being fully opaque
and any voxel with 0 < | Z-score | < 1.96 being partly transparent.

.. GENERATED FROM PYTHON SOURCE LINES 120-143

.. code-block:: Python

    plot_param = {
        "vmin": 0,
        "display_mode": "z",
        "cut_coords": 3,
        "black_bg": True,
        "bg_img": mean_image,
        "cmap": "inferno",
        "transparency_range": [0, 3],
    }

    # Iterate on contrasts to compute and plot them.
    for contrast_id in contrasts:
        print(f"\tcontrast id: {contrast_id}")

        results = fmri_glm.compute_contrast(contrast_id, output_type="all")

        plot_stat_map(
            results["stat"],
            title=contrast_id,
            transparency=results["z_score"],
            **plot_param,
        )




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/04_glm_first_level/images/sphx_glr_plot_spm_multimodal_faces_002.png
         :alt: plot spm multimodal faces
         :srcset: /auto_examples/04_glm_first_level/images/sphx_glr_plot_spm_multimodal_faces_002.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/04_glm_first_level/images/sphx_glr_plot_spm_multimodal_faces_003.png
         :alt: plot spm multimodal faces
         :srcset: /auto_examples/04_glm_first_level/images/sphx_glr_plot_spm_multimodal_faces_003.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

            contrast id: faces - scrambled
    /home/runner/work/nilearn/nilearn/examples/04_glm_first_level/plot_spm_multimodal_faces.py:134: RuntimeWarning:

    The same contrast will be used for all 2 runs. If the design matrices are not the same for all runs, (for example with different column names or column order across runs) you should pass contrast as an expression using the name of the conditions as they appear in the design matrices.

    [FirstLevelModel.compute_contrast] Computing image from signals
    [FirstLevelModel.compute_contrast] Computing image from signals
    [FirstLevelModel.compute_contrast] Computing image from signals
    [FirstLevelModel.compute_contrast] Computing image from signals
    [FirstLevelModel.compute_contrast] Computing image from signals
            contrast id: scrambled - faces
    /home/runner/work/nilearn/nilearn/examples/04_glm_first_level/plot_spm_multimodal_faces.py:134: RuntimeWarning:

    The same contrast will be used for all 2 runs. If the design matrices are not the same for all runs, (for example with different column names or column order across runs) you should pass contrast as an expression using the name of the conditions as they appear in the design matrices.

    [FirstLevelModel.compute_contrast] Computing image from signals
    [FirstLevelModel.compute_contrast] Computing image from signals
    [FirstLevelModel.compute_contrast] Computing image from signals
    [FirstLevelModel.compute_contrast] Computing image from signals
    [FirstLevelModel.compute_contrast] Computing image from signals




.. GENERATED FROM PYTHON SOURCE LINES 144-147

We also define the effects of interest contrast,
a 2-dimensional contrasts spanning the two conditions.


.. GENERATED FROM PYTHON SOURCE LINES 147-162

.. code-block:: Python

    import numpy as np

    contrasts = np.eye(2)

    results = fmri_glm.compute_contrast(contrasts, output_type="all")

    plot_stat_map(
        results["stat"],
        title="effects of interest",
        transparency=results["z_score"],
        **plot_param,
    )

    show()




.. image-sg:: /auto_examples/04_glm_first_level/images/sphx_glr_plot_spm_multimodal_faces_004.png
   :alt: plot spm multimodal faces
   :srcset: /auto_examples/04_glm_first_level/images/sphx_glr_plot_spm_multimodal_faces_004.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/runner/work/nilearn/nilearn/examples/04_glm_first_level/plot_spm_multimodal_faces.py:151: RuntimeWarning:

    The same contrast will be used for all 2 runs. If the design matrices are not the same for all runs, (for example with different column names or column order across runs) you should pass contrast as an expression using the name of the conditions as they appear in the design matrices.

    /home/runner/work/nilearn/nilearn/examples/04_glm_first_level/plot_spm_multimodal_faces.py:151: UserWarning:

    F contrasts should have 20 columns, but it has only 2. The rest of the contrast was padded with zeros.

    /home/runner/work/nilearn/nilearn/examples/04_glm_first_level/plot_spm_multimodal_faces.py:151: UserWarning:

    Running approximate fixed effects on F statistics.

    [FirstLevelModel.compute_contrast] Computing image from signals
    [FirstLevelModel.compute_contrast] Computing image from signals
    [FirstLevelModel.compute_contrast] Computing image from signals
    [FirstLevelModel.compute_contrast] Computing image from signals
    [FirstLevelModel.compute_contrast] Computing image from signals
    /home/runner/work/nilearn/nilearn/examples/04_glm_first_level/plot_spm_multimodal_faces.py:160: UserWarning:

    You are using the 'agg' matplotlib backend that is non-interactive.
    No figure will be plotted when calling matplotlib.pyplot.show() or nilearn.plotting.show().
    You can fix this by installing a different backend: for example via
            pip install PyQt6





.. GENERATED FROM PYTHON SOURCE LINES 163-172

Based on the resulting maps we observe
that the analysis results in wide activity
for the 'effects of interest' contrast,
showing the implications of large portions of the visual cortex
in the conditions.
By contrast,
the differential effect between "faces" and "scrambled" involves sparser,
more anterior and lateral regions.
It also displays some responses in the frontal lobe.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 42.411 seconds)

**Estimated memory usage:**  1035 MB


.. _sphx_glr_download_auto_examples_04_glm_first_level_plot_spm_multimodal_faces.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/nilearn/nilearn/main?urlpath=lab/tree/notebooks/auto_examples/04_glm_first_level/plot_spm_multimodal_faces.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_spm_multimodal_faces.ipynb <plot_spm_multimodal_faces.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_spm_multimodal_faces.py <plot_spm_multimodal_faces.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_spm_multimodal_faces.zip <plot_spm_multimodal_faces.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
