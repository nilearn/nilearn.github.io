
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/04_glm_first_level/plot_spm_multimodal_faces.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_04_glm_first_level_plot_spm_multimodal_faces.py>`
        to download the full example code. or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_04_glm_first_level_plot_spm_multimodal_faces.py:


Single-subject data (two runs) in native space
==============================================

The example shows the analysis of an :term:`SPM` dataset
studying face perception.
The analysis is performed in native space.
Realignment parameters are provided with the input images,
but those have not been resampled to a common space.

The experimental paradigm is simple, with two conditions; viewing a face image
or a scrambled face image, supposedly with the same low-level statistical
properties, to find face-specific responses.

For details on the data, please see :footcite:t:`Henson2003`.

This example takes a lot of time because the input are lists of 3D images
sampled in different positions (encoded by different affine functions).

.. GENERATED FROM PYTHON SOURCE LINES 22-23

Fetch the :term:`SPM` multimodal_faces data.

.. GENERATED FROM PYTHON SOURCE LINES 23-27

.. code-block:: Python

    from nilearn.datasets import fetch_spm_multimodal_fmri

    subject_data = fetch_spm_multimodal_fmri()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [get_dataset_dir] Dataset created in 
    /home/runner/nilearn_data/spm_multimodal_fmri
    [_glob_spm_multimodal_fmri_data] Missing 390 functional scans for session 1.
    [fetch_spm_multimodal_fmri] Data absent, downloading...
    [fetch_single_file] Downloading data from 
    https://www.fil.ion.ucl.ac.uk/spm/download/data/mmfaces/multimodal_fmri.zip ...
    [_chunk_report_] Downloaded 3072000 of 134263085 bytes (2.3%%,   44.8s 
    remaining)
    [_chunk_report_] Downloaded 7168000 of 134263085 bytes (5.3%%,   37.4s 
    remaining)
    [_chunk_report_] Downloaded 11534336 of 134263085 bytes (8.6%%,   33.4s 
    remaining)
    [_chunk_report_] Downloaded 15720448 of 134263085 bytes (11.7%%,   31.2s 
    remaining)
    [_chunk_report_] Downloaded 20275200 of 134263085 bytes (15.1%%,   29.1s 
    remaining)
    [_chunk_report_] Downloaded 24510464 of 134263085 bytes (18.3%%,   27.6s 
    remaining)
    [_chunk_report_] Downloaded 29073408 of 134263085 bytes (21.7%%,   26.1s 
    remaining)
    [_chunk_report_] Downloaded 33349632 of 134263085 bytes (24.8%%,   24.9s 
    remaining)
    [_chunk_report_] Downloaded 38051840 of 134263085 bytes (28.3%%,   23.3s 
    remaining)
    [_chunk_report_] Downloaded 42639360 of 134263085 bytes (31.8%%,   22.0s 
    remaining)
    [_chunk_report_] Downloaded 47923200 of 134263085 bytes (35.7%%,   20.3s 
    remaining)
    [_chunk_report_] Downloaded 53370880 of 134263085 bytes (39.8%%,   18.6s 
    remaining)
    [_chunk_report_] Downloaded 59981824 of 134263085 bytes (44.7%%,   16.5s 
    remaining)
    [_chunk_report_] Downloaded 65839104 of 134263085 bytes (49.0%%,   14.9s 
    remaining)
    [_chunk_report_] Downloaded 71909376 of 134263085 bytes (53.6%%,   13.3s 
    remaining)
    [_chunk_report_] Downloaded 78176256 of 134263085 bytes (58.2%%,   11.7s 
    remaining)
    [_chunk_report_] Downloaded 83468288 of 134263085 bytes (62.2%%,   10.6s 
    remaining)
    [_chunk_report_] Downloaded 88580096 of 134263085 bytes (66.0%%,    9.5s 
    remaining)
    [_chunk_report_] Downloaded 94257152 of 134263085 bytes (70.2%%,    8.2s 
    remaining)
    [_chunk_report_] Downloaded 99753984 of 134263085 bytes (74.3%%,    7.1s 
    remaining)
    [_chunk_report_] Downloaded 104292352 of 134263085 bytes (77.7%%,    6.2s 
    remaining)
    [_chunk_report_] Downloaded 108609536 of 134263085 bytes (80.9%%,    5.3s 
    remaining)
    [_chunk_report_] Downloaded 113442816 of 134263085 bytes (84.5%%,    4.3s 
    remaining)
    [_chunk_report_] Downloaded 118095872 of 134263085 bytes (88.0%%,    3.4s 
    remaining)
    [_chunk_report_] Downloaded 123084800 of 134263085 bytes (91.7%%,    2.3s 
    remaining)
    [_chunk_report_] Downloaded 127795200 of 134263085 bytes (95.2%%,    1.3s 
    remaining)
    [_chunk_report_] Downloaded 132784128 of 134263085 bytes (98.9%%,    0.3s 
    remaining)
    [fetch_single_file]  ...done. (29 seconds, 0 min)

    [uncompress_file] Extracting data from 
    /home/runner/nilearn_data/spm_multimodal_fmri/sub001/multimodal_fmri.zip...
    [uncompress_file] .. done.

    [fetch_single_file] Downloading data from 
    https://www.fil.ion.ucl.ac.uk/spm/download/data/mmfaces/multimodal_smri.zip ...
    [_chunk_report_] Downloaded 3448832 of 6852766 bytes (50.3%%,    1.0s remaining)
    [fetch_single_file]  ...done. (2 seconds, 0 min)

    [uncompress_file] Extracting data from 
    /home/runner/nilearn_data/spm_multimodal_fmri/sub001/multimodal_smri.zip...
    [uncompress_file] .. done.





.. GENERATED FROM PYTHON SOURCE LINES 28-29

Specify timing and design matrix parameters.

.. GENERATED FROM PYTHON SOURCE LINES 29-41

.. code-block:: Python


    # repetition time, in seconds
    t_r = 2.0
    # Sample at the beginning of each acquisition.
    slice_time_ref = 0.0
    # We use a discrete cosine transform to model signal drifts.
    drift_model = "Cosine"
    # The cutoff for the drift model is 0.01 Hz.
    high_pass = 0.01
    # The hemodynamic response function
    hrf_model = "spm + derivative"








.. GENERATED FROM PYTHON SOURCE LINES 42-45

Resample the images.

This is achieved by the concat_imgs function of Nilearn.

.. GENERATED FROM PYTHON SOURCE LINES 45-62

.. code-block:: Python

    import warnings

    from nilearn.image import concat_imgs, mean_img, resample_img

    # Avoid getting too many warnings due to resampling
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        fmri_img = [
            concat_imgs(subject_data.func1, auto_resample=True),
            concat_imgs(subject_data.func2, auto_resample=True),
        ]
    affine, shape = fmri_img[0].affine, fmri_img[0].shape
    print("Resampling the second image (this takes time)...")
    fmri_img[1] = resample_img(
        fmri_img[1], affine, shape[:3], copy_header=True, force_resample=True
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Resampling the second image (this takes time)...




.. GENERATED FROM PYTHON SOURCE LINES 63-64

Let's create mean image for display purposes.

.. GENERATED FROM PYTHON SOURCE LINES 64-66

.. code-block:: Python

    mean_image = mean_img(fmri_img, copy_header=True)








.. GENERATED FROM PYTHON SOURCE LINES 67-68

Make the design matrices.

.. GENERATED FROM PYTHON SOURCE LINES 68-75

.. code-block:: Python

    import numpy as np
    import pandas as pd

    from nilearn.glm.first_level import make_first_level_design_matrix

    design_matrices = []








.. GENERATED FROM PYTHON SOURCE LINES 76-77

Loop over the two runs.

.. GENERATED FROM PYTHON SOURCE LINES 77-95

.. code-block:: Python

    for idx, img in enumerate(fmri_img, start=1):
        # Build experimental paradigm
        n_scans = img.shape[-1]
        events = pd.read_table(subject_data[f"events{idx}"])
        # Define the sampling times for the design matrix
        frame_times = np.arange(n_scans) * t_r
        # Build design matrix with the reviously defined parameters
        design_matrix = make_first_level_design_matrix(
            frame_times,
            events,
            hrf_model=hrf_model,
            drift_model=drift_model,
            high_pass=high_pass,
        )

        # put the design matrices in a list
        design_matrices.append(design_matrix)








.. GENERATED FROM PYTHON SOURCE LINES 96-100

We can specify basic contrasts (to get :term:`beta<Parameter Estimate>`
maps).
We start by specifying canonical :term:`contrast`
that isolate design matrix columns.

.. GENERATED FROM PYTHON SOURCE LINES 100-106

.. code-block:: Python

    contrast_matrix = np.eye(design_matrix.shape[1])
    basic_contrasts = {
        column: contrast_matrix[i]
        for i, column in enumerate(design_matrix.columns)
    }








.. GENERATED FROM PYTHON SOURCE LINES 107-112

We actually want more interesting contrasts. The simplest contrast
just makes the difference between the two main conditions.  We
define the two opposite versions to run one-tailed t-tests.  We also
define the effects of interest contrast, a 2-dimensional contrasts
spanning the two conditions.

.. GENERATED FROM PYTHON SOURCE LINES 112-122

.. code-block:: Python


    contrasts = {
        "faces-scrambled": basic_contrasts["faces"] - basic_contrasts["scrambled"],
        "scrambled-faces": -basic_contrasts["faces"]
        + basic_contrasts["scrambled"],
        "effects_of_interest": np.vstack(
            (basic_contrasts["faces"], basic_contrasts["scrambled"])
        ),
    }








.. GENERATED FROM PYTHON SOURCE LINES 123-125

Fit the :term:`GLM` for the 2 runs
by specifying a FirstLevelModel and then fitting it.

.. GENERATED FROM PYTHON SOURCE LINES 125-131

.. code-block:: Python

    from nilearn.glm.first_level import FirstLevelModel

    print("Fitting a GLM")
    fmri_glm = FirstLevelModel()
    fmri_glm = fmri_glm.fit(fmri_img, design_matrices=design_matrices)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Fitting a GLM




.. GENERATED FROM PYTHON SOURCE LINES 132-134

Now we can compute contrast-related statistical maps (in z-scale), and plot
them.

.. GENERATED FROM PYTHON SOURCE LINES 134-157

.. code-block:: Python

    from nilearn import plotting

    print("Computing contrasts")

    # Iterate on contrasts
    for contrast_id, contrast_val in contrasts.items():
        print(f"\tcontrast id: {contrast_id}")
        # compute the contrasts
        z_map = fmri_glm.compute_contrast(contrast_val, output_type="z_score")
        # plot the contrasts as soon as they're generated
        # the display is overlaid on the mean fMRI image
        # a threshold of 3.0 is used, more sophisticated choices are possible
        plotting.plot_stat_map(
            z_map,
            bg_img=mean_image,
            threshold=3.0,
            display_mode="z",
            cut_coords=3,
            black_bg=True,
            title=contrast_id,
        )
        plotting.show()




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/04_glm_first_level/images/sphx_glr_plot_spm_multimodal_faces_001.png
         :alt: plot spm multimodal faces
         :srcset: /auto_examples/04_glm_first_level/images/sphx_glr_plot_spm_multimodal_faces_001.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/04_glm_first_level/images/sphx_glr_plot_spm_multimodal_faces_002.png
         :alt: plot spm multimodal faces
         :srcset: /auto_examples/04_glm_first_level/images/sphx_glr_plot_spm_multimodal_faces_002.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/04_glm_first_level/images/sphx_glr_plot_spm_multimodal_faces_003.png
         :alt: plot spm multimodal faces
         :srcset: /auto_examples/04_glm_first_level/images/sphx_glr_plot_spm_multimodal_faces_003.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Computing contrasts
            contrast id: faces-scrambled
    /home/runner/work/nilearn/nilearn/examples/04_glm_first_level/plot_spm_multimodal_faces.py:142: UserWarning: One contrast given, assuming it for all 2 runs
      z_map = fmri_glm.compute_contrast(contrast_val, output_type="z_score")
            contrast id: scrambled-faces
    /home/runner/work/nilearn/nilearn/examples/04_glm_first_level/plot_spm_multimodal_faces.py:142: UserWarning: One contrast given, assuming it for all 2 runs
      z_map = fmri_glm.compute_contrast(contrast_val, output_type="z_score")
            contrast id: effects_of_interest
    /home/runner/work/nilearn/nilearn/examples/04_glm_first_level/plot_spm_multimodal_faces.py:142: UserWarning: One contrast given, assuming it for all 2 runs
      z_map = fmri_glm.compute_contrast(contrast_val, output_type="z_score")
    /home/runner/work/nilearn/nilearn/.tox/doc/lib/python3.9/site-packages/nilearn/glm/contrasts.py:166: UserWarning: Running approximate fixed effects on F statistics.
      contrast = contrast_ if contrast is None else contrast + contrast_




.. GENERATED FROM PYTHON SOURCE LINES 158-164

Based on the resulting maps we observe that the analysis results in
wide activity for the 'effects of interest' contrast, showing the
implications of large portions of the visual cortex in the
conditions. By contrast, the differential effect between "faces" and
"scrambled" involves sparser, more anterior and lateral regions. It
also displays some responses in the frontal lobe.

.. GENERATED FROM PYTHON SOURCE LINES 166-170

References
----------

.. footbibliography::


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (2 minutes 13.843 seconds)

**Estimated memory usage:**  974 MB


.. _sphx_glr_download_auto_examples_04_glm_first_level_plot_spm_multimodal_faces.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/nilearn/nilearn/main?urlpath=lab/tree/notebooks/auto_examples/04_glm_first_level/plot_spm_multimodal_faces.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_spm_multimodal_faces.ipynb <plot_spm_multimodal_faces.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_spm_multimodal_faces.py <plot_spm_multimodal_faces.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_spm_multimodal_faces.zip <plot_spm_multimodal_faces.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
