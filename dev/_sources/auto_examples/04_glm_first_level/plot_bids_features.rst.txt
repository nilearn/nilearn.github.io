
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/04_glm_first_level/plot_bids_features.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_04_glm_first_level_plot_bids_features.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_04_glm_first_level_plot_bids_features.py:


First level analysis of a complete BIDS dataset from openneuro
===============================================================


Full step-by-step example of fitting a GLM to perform a first level analysis
in an openneuro :term:`BIDS` dataset. We demonstrate how :term:`BIDS`
derivatives can be exploited to perform a simple one subject analysis with
minimal code. Details about the :term:`BIDS` standard are available at
`http://bids.neuroimaging.io/ <http://bids.neuroimaging.io/>`_.
We also demonstrate how to download individual groups of files from the
Openneuro s3 bucket.

More specifically:

1. Download an :term:`fMRI` :term:`BIDS` dataset with derivatives from openneuro.
2. Extract first level model objects automatically from the :term:`BIDS` dataset.
3. Demonstrate Quality assurance of Nistats estimation against available FSL.
   estimation in the openneuro dataset.
4. Display contrast plot and uncorrected first level statistics table report.



To run this example, you must launch IPython via ``ipython
--matplotlib`` in a terminal, or use the Jupyter notebook.

.. contents:: **Contents**
    :local:
    :depth: 1

.. GENERATED FROM PYTHON SOURCE LINES 32-39

Fetch openneuro BIDS dataset
-----------------------------
We download one subject from the stopsignal task in the ds000030 V4 :term:`BIDS`
dataset available in openneuro.
This dataset contains the necessary information to run a statistical analysis
using Nilearn. The dataset also contains statistical results from a previous
FSL analysis that we can employ for comparison with the Nilearn estimation.

.. GENERATED FROM PYTHON SOURCE LINES 39-57

.. code-block:: default

    from nilearn.datasets import (
        fetch_ds000030_urls,
        fetch_openneuro_dataset,
        select_from_index,
    )

    _, urls = fetch_ds000030_urls()

    exclusion_patterns = ['*group*', '*phenotype*', '*mriqc*',
                          '*parameter_plots*', '*physio_plots*',
                          '*space-fsaverage*', '*space-T1w*',
                          '*dwi*', '*beh*', '*task-bart*',
                          '*task-rest*', '*task-scap*', '*task-task*']
    urls = select_from_index(
        urls, exclusion_filters=exclusion_patterns, n_subjects=1)

    data_dir, _ = fetch_openneuro_dataset(urls=urls)








.. GENERATED FROM PYTHON SOURCE LINES 58-69

Obtain FirstLevelModel objects automatically and fit arguments
---------------------------------------------------------------
From the dataset directory we automatically obtain FirstLevelModel objects
with their subject_id filled from the :term:`BIDS` dataset. Moreover we obtain,
for each model, the list of run images and their respective events and
confound regressors. Those are inferred from the confounds.tsv files
available in the :term:`BIDS` dataset.
To get the first level models we have to specify the dataset directory,
the task_label and the space_label as specified in the file names.
We also have to provide the folder with the desired derivatives, that in this
case were produced by the :term:`fMRIPrep` :term:`BIDS` app.

.. GENERATED FROM PYTHON SOURCE LINES 69-78

.. code-block:: default

    from nilearn.glm.first_level import first_level_from_bids
    task_label = 'stopsignal'
    space_label = 'MNI152NLin2009cAsym'
    derivatives_folder = 'derivatives/fmriprep'
    models, models_run_imgs, models_events, models_confounds = \
        first_level_from_bids(data_dir, task_label, space_label,
                              smoothing_fwhm=5.0,
                              derivatives_folder=derivatives_folder)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/circleci/miniconda3/envs/testenv/lib/python3.8/site-packages/nilearn/glm/first_level/first_level.py:937: UserWarning:

    SliceTimingRef not found in file /home/circleci/nilearn_data/ds000030/ds000030_R1.0.4/uncompressed/sub-10159/func/sub-10159_task-stopsignal_bold.json. It will be assumed that the slice timing reference is 0.0 percent of the repetition time. If it is not the case it will need to be set manually in the generated list of models





.. GENERATED FROM PYTHON SOURCE LINES 79-80

Access the model and model arguments of the subject and process events.

.. GENERATED FROM PYTHON SOURCE LINES 80-92

.. code-block:: default

    model, imgs, events, confounds = (
        models[0], models_run_imgs[0], models_events[0], models_confounds[0])
    subject = 'sub-' + model.subject_label
    model.minimize_memory = False  # override default

    import os
    from nilearn.interfaces.fsl import get_design_from_fslmat
    fsl_design_matrix_path = os.path.join(
        data_dir, 'derivatives', 'task', subject, 'stopsignal.feat', 'design.mat')
    design_matrix = get_design_from_fslmat(
        fsl_design_matrix_path, column_names=None)








.. GENERATED FROM PYTHON SOURCE LINES 93-96

We identify the columns of the Go and StopSuccess conditions of the
design matrix inferred from the FSL file, to use them later for contrast
definition.

.. GENERATED FROM PYTHON SOURCE LINES 96-101

.. code-block:: default

    design_columns = ['cond_%02d' % i for i in range(len(design_matrix.columns))]
    design_columns[0] = 'Go'
    design_columns[4] = 'StopSuccess'
    design_matrix.columns = design_columns








.. GENERATED FROM PYTHON SOURCE LINES 102-105

First level model estimation (one subject)
-------------------------------------------
We fit the first level model for one subject.

.. GENERATED FROM PYTHON SOURCE LINES 105-107

.. code-block:: default

    model.fit(imgs, design_matrices=[design_matrix])






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-6" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>FirstLevelModel(minimize_memory=False, smoothing_fwhm=5.0,
                    subject_label=&#x27;10159&#x27;, t_r=2.0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox" checked><label for="sk-estimator-id-6" class="sk-toggleable__label sk-toggleable__label-arrow">FirstLevelModel</label><div class="sk-toggleable__content"><pre>FirstLevelModel(minimize_memory=False, smoothing_fwhm=5.0,
                    subject_label=&#x27;10159&#x27;, t_r=2.0)</pre></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 108-110

Then we compute the StopSuccess - Go contrast. We can use the column names
of the design matrix.

.. GENERATED FROM PYTHON SOURCE LINES 110-112

.. code-block:: default

    z_map = model.compute_contrast('StopSuccess - Go')








.. GENERATED FROM PYTHON SOURCE LINES 113-115

We show the agreement between the Nilearn estimation and the FSL estimation
available in the dataset.

.. GENERATED FROM PYTHON SOURCE LINES 115-136

.. code-block:: default

    import nibabel as nib
    fsl_z_map = nib.load(
        os.path.join(data_dir, 'derivatives', 'task', subject, 'stopsignal.feat',
                     'stats', 'zstat12.nii.gz'))

    from nilearn import plotting
    import matplotlib.pyplot as plt
    from scipy.stats import norm
    plotting.plot_glass_brain(z_map, colorbar=True, threshold=norm.isf(0.001),
                              title='Nilearn Z map of "StopSuccess - Go" (unc p<0.001)',
                              plot_abs=False, display_mode='ortho')
    plotting.plot_glass_brain(fsl_z_map, colorbar=True, threshold=norm.isf(0.001),
                              title='FSL Z map of "StopSuccess - Go" (unc p<0.001)',
                              plot_abs=False, display_mode='ortho')
    plt.show()

    from nilearn.plotting import plot_img_comparison
    plot_img_comparison([z_map], [fsl_z_map], model.masker_,
                        ref_label='Nilearn', src_label='FSL')
    plt.show()




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/04_glm_first_level/images/sphx_glr_plot_bids_features_001.png
         :alt: plot bids features
         :srcset: /auto_examples/04_glm_first_level/images/sphx_glr_plot_bids_features_001.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/04_glm_first_level/images/sphx_glr_plot_bids_features_002.png
         :alt: plot bids features
         :srcset: /auto_examples/04_glm_first_level/images/sphx_glr_plot_bids_features_002.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/04_glm_first_level/images/sphx_glr_plot_bids_features_003.png
         :alt: Histogram of imgs values
         :srcset: /auto_examples/04_glm_first_level/images/sphx_glr_plot_bids_features_003.png
         :class: sphx-glr-multi-img





.. GENERATED FROM PYTHON SOURCE LINES 137-140

Simple statistical report of thresholded contrast
-----------------------------------------------------
We display the contrast plot and table with cluster information

.. GENERATED FROM PYTHON SOURCE LINES 140-147

.. code-block:: default

    from nilearn.plotting import plot_contrast_matrix
    plot_contrast_matrix('StopSuccess - Go', design_matrix)
    plotting.plot_glass_brain(z_map, colorbar=True, threshold=norm.isf(0.001),
                              plot_abs=False, display_mode='z',
                              figure=plt.figure(figsize=(4, 4)))
    plt.show()




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/04_glm_first_level/images/sphx_glr_plot_bids_features_004.png
         :alt: plot bids features
         :srcset: /auto_examples/04_glm_first_level/images/sphx_glr_plot_bids_features_004.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/04_glm_first_level/images/sphx_glr_plot_bids_features_005.png
         :alt: plot bids features
         :srcset: /auto_examples/04_glm_first_level/images/sphx_glr_plot_bids_features_005.png
         :class: sphx-glr-multi-img





.. GENERATED FROM PYTHON SOURCE LINES 148-150

We can get a latex table from a Pandas Dataframe for display and publication
purposes

.. GENERATED FROM PYTHON SOURCE LINES 150-153

.. code-block:: default

    from nilearn.reporting import get_clusters_table
    print(get_clusters_table(z_map, norm.isf(0.001), 10).to_latex())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/circleci/project/examples/04_glm_first_level/plot_bids_features.py:151: FutureWarning:

    In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.

    \begin{tabular}{llrrrrl}
    \toprule
    {} & Cluster ID &     X &     Y &     Z &  Peak Stat & Cluster Size (mm3) \\
    \midrule
    0  &          1 & -66.0 & -45.0 &  22.0 &   5.307532 &               6300 \\
    1  &         1a & -66.0 & -33.0 &  18.0 &   4.668929 &                    \\
    2  &         1b & -48.0 & -36.0 &  14.0 &   4.534376 &                    \\
    3  &         1c & -57.0 & -48.0 &  10.0 &   4.254210 &                    \\
    4  &          2 & -42.0 &  15.0 &  26.0 &   4.918703 &               2520 \\
    5  &         2a & -51.0 &   9.0 &  34.0 &   4.715845 &                    \\
    6  &         2b & -42.0 &   9.0 &  30.0 &   4.683343 &                    \\
    7  &         2c & -57.0 &  12.0 &  38.0 &   4.587956 &                    \\
    8  &          3 &  57.0 & -27.0 &   2.0 &   4.692869 &                504 \\
    9  &         3a &  66.0 & -27.0 &   2.0 &   3.664250 &                    \\
    10 &          4 &  42.0 &   9.0 &  34.0 &   4.461193 &                540 \\
    11 &          5 &   6.0 &  18.0 &  34.0 &   4.257986 &               2520 \\
    12 &         5a &  -3.0 &  15.0 &  46.0 &   4.078390 &                    \\
    13 &         5b &   0.0 &   0.0 &  38.0 &   3.815609 &                    \\
    14 &         5c &   3.0 &   9.0 &  50.0 &   3.798387 &                    \\
    15 &          6 &   6.0 &   6.0 &  54.0 &   4.208105 &                468 \\
    16 &         6a &   6.0 &   3.0 &  62.0 &   3.348351 &                    \\
    17 &          7 & -45.0 &  21.0 &   2.0 &   4.190472 &                504 \\
    18 &         7a & -54.0 &  21.0 &   6.0 &   3.385929 &                    \\
    19 &          8 &  45.0 & -21.0 &  42.0 &   4.163956 &                432 \\
    20 &          9 &  63.0 & -24.0 &  30.0 &   4.079389 &                360 \\
    21 &         10 & -12.0 &   6.0 &   6.0 &   4.056165 &                792 \\
    22 &        10a &  -9.0 &  -3.0 &  10.0 &   3.726486 &                    \\
    23 &        10b &  -9.0 &   6.0 &  14.0 &   3.710553 &                    \\
    24 &         11 & -27.0 &  45.0 &  18.0 &   4.043724 &                432 \\
    25 &         12 &   3.0 & -24.0 &  30.0 &   3.950054 &                360 \\
    26 &         13 &  12.0 & -72.0 &  22.0 &   3.937283 &                360 \\
    27 &         14 &  33.0 &  42.0 &  34.0 &   3.906274 &                756 \\
    28 &        14a &  30.0 &  45.0 &  26.0 &   3.882906 &                    \\
    29 &         15 &  51.0 & -30.0 &  14.0 &   3.776293 &                648 \\
    \bottomrule
    \end{tabular}





.. GENERATED FROM PYTHON SOURCE LINES 154-158

Generating a report
-------------------
Using the computed FirstLevelModel and contrast information,
we can quickly create a summary report.

.. GENERATED FROM PYTHON SOURCE LINES 158-165

.. code-block:: default


    from nilearn.reporting import make_glm_report

    report = make_glm_report(model=model,
                             contrasts='StopSuccess - Go',
                             )








.. GENERATED FROM PYTHON SOURCE LINES 166-167

We have several ways to access the report:

.. GENERATED FROM PYTHON SOURCE LINES 167-172

.. code-block:: default


    # report  # This report can be viewed in a notebook
    # report.save_as_html('report.html')
    # report.open_in_browser()








.. GENERATED FROM PYTHON SOURCE LINES 173-175

Saving model outputs to disk
----------------------------

.. GENERATED FROM PYTHON SOURCE LINES 175-185

.. code-block:: default

    from nilearn.interfaces.bids import save_glm_to_bids

    save_glm_to_bids(
        model,
        contrasts='StopSuccess - Go',
        contrast_types={'StopSuccess - Go': 't'},
        out_dir='derivatives/nilearn_glm/',
        prefix=subject + '_task-stopsignal',
    )




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/04_glm_first_level/images/sphx_glr_plot_bids_features_006.png
         :alt: plot bids features
         :srcset: /auto_examples/04_glm_first_level/images/sphx_glr_plot_bids_features_006.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/04_glm_first_level/images/sphx_glr_plot_bids_features_007.png
         :alt: plot bids features
         :srcset: /auto_examples/04_glm_first_level/images/sphx_glr_plot_bids_features_007.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/circleci/miniconda3/envs/testenv/lib/python3.8/site-packages/nilearn/interfaces/bids/_utils.py:48: UserWarning:

    Contrast name "StopSuccess - Go" changed to "stopsuccessMinusGo"

    /home/circleci/miniconda3/envs/testenv/lib/python3.8/site-packages/nilearn/interfaces/bids/_utils.py:48: UserWarning:

    Contrast name "StopSuccess - Go" changed to "stopsuccessMinusGo"

    Extracting and saving residuals
    Extracting and saving r_square




.. GENERATED FROM PYTHON SOURCE LINES 186-187

View the generated files

.. GENERATED FROM PYTHON SOURCE LINES 187-190

.. code-block:: default

    from glob import glob

    print('\n'.join(sorted(glob('derivatives/nilearn_glm/*'))))




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    derivatives/nilearn_glm/dataset_description.json
    derivatives/nilearn_glm/sub-10159_task-stopsignal_contrast-stopsuccessMinusGo_design.svg
    derivatives/nilearn_glm/sub-10159_task-stopsignal_contrast-stopsuccessMinusGo_stat-effect_statmap.nii.gz
    derivatives/nilearn_glm/sub-10159_task-stopsignal_contrast-stopsuccessMinusGo_stat-p_statmap.nii.gz
    derivatives/nilearn_glm/sub-10159_task-stopsignal_contrast-stopsuccessMinusGo_stat-t_statmap.nii.gz
    derivatives/nilearn_glm/sub-10159_task-stopsignal_contrast-stopsuccessMinusGo_stat-variance_statmap.nii.gz
    derivatives/nilearn_glm/sub-10159_task-stopsignal_contrast-stopsuccessMinusGo_stat-z_statmap.nii.gz
    derivatives/nilearn_glm/sub-10159_task-stopsignal_design.svg
    derivatives/nilearn_glm/sub-10159_task-stopsignal_design.tsv
    derivatives/nilearn_glm/sub-10159_task-stopsignal_stat-errorts_statmap.nii.gz
    derivatives/nilearn_glm/sub-10159_task-stopsignal_stat-rSquare_statmap.nii.gz
    derivatives/nilearn_glm/sub-10159_task-stopsignal_statmap.json





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  25.014 seconds)

**Estimated memory usage:**  506 MB


.. _sphx_glr_download_auto_examples_04_glm_first_level_plot_bids_features.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/nilearn/nilearn.github.io/main?filepath=examples/auto_examples/04_glm_first_level/plot_bids_features.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_bids_features.py <plot_bids_features.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_bids_features.ipynb <plot_bids_features.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
