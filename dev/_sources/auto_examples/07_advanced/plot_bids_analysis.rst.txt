
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/07_advanced/plot_bids_analysis.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_07_advanced_plot_bids_analysis.py>`
        to download the full example code. or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_07_advanced_plot_bids_analysis.py:


BIDS dataset first and second level analysis
============================================

Full step-by-step example of fitting a :term:`GLM`
to perform a first and second level
analysis in a :term:`BIDS` dataset and visualizing the results.
Details about the :term:`BIDS` standard can be consulted at
`https://bids.neuroimaging.io/ <https://bids.neuroimaging.io/>`_.

More specifically:

1. Download an :term:`fMRI` :term:`BIDS` dataset
   with two language conditions to contrast.
2. Extract first level model objects automatically
   from the :term:`BIDS` dataset.
3. Fit a second level model on the fitted first level models.
   Notice that in this case the preprocessed :term:`bold<BOLD>`
   images were already normalized to the same :term:`MNI` space.

.. note::

      We are only using a subset of participants from the dataset
      to lower the run time of the example.

.. GENERATED FROM PYTHON SOURCE LINES 26-29

.. code-block:: Python


    from nilearn import plotting








.. GENERATED FROM PYTHON SOURCE LINES 30-38

Fetch example :term:`BIDS` dataset
----------------------------------
We download a simplified :term:`BIDS` dataset made available for illustrative
purposes. It contains only the necessary
information to run a statistical analysis using Nilearn. The raw data
subject folders only contain bold.json and events.tsv files, while the
derivatives folder includes the preprocessed files preproc.nii and the
confounds.tsv files.

.. GENERATED FROM PYTHON SOURCE LINES 38-42

.. code-block:: Python

    from nilearn.datasets import fetch_language_localizer_demo_dataset

    data = fetch_language_localizer_demo_dataset(legacy_output=False)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [get_dataset_dir] Dataset created in 
    /home/runner/nilearn_data/fMRI-language-localizer-demo-dataset
    [fetch_single_file] Downloading data from https://osf.io/3dj2a/download ...
    [_chunk_report_] Downloaded 98795520 of 749503182 bytes (13.2%%,    6.6s 
    remaining)
    [_chunk_report_] Downloaded 178757632 of 749503182 bytes (23.9%%,    6.4s 
    remaining)
    [_chunk_report_] Downloaded 244318208 of 749503182 bytes (32.6%%,    6.2s 
    remaining)
    [_chunk_report_] Downloaded 328376320 of 749503182 bytes (43.8%%,    5.1s 
    remaining)
    [_chunk_report_] Downloaded 433094656 of 749503182 bytes (57.8%%,    3.7s 
    remaining)
    [_chunk_report_] Downloaded 517283840 of 749503182 bytes (69.0%%,    2.7s 
    remaining)
    [_chunk_report_] Downloaded 601956352 of 749503182 bytes (80.3%%,    1.7s 
    remaining)
    [_chunk_report_] Downloaded 672751616 of 749503182 bytes (89.8%%,    0.9s 
    remaining)
    [fetch_single_file]  ...done. (10 seconds, 0 min)

    [uncompress_file] Extracting data from 
    /home/runner/nilearn_data/fMRI-language-localizer-demo-dataset/fMRI-language-loc
    alizer-demo-dataset.zip...
    [uncompress_file] .. done.





.. GENERATED FROM PYTHON SOURCE LINES 43-44

Here is the location of the dataset on disk.

.. GENERATED FROM PYTHON SOURCE LINES 44-46

.. code-block:: Python

    print(data.data_dir)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/runner/nilearn_data/fMRI-language-localizer-demo-dataset




.. GENERATED FROM PYTHON SOURCE LINES 47-58

Obtain automatically FirstLevelModel objects and fit arguments
--------------------------------------------------------------
From the dataset directory we automatically obtain
the FirstLevelModel objects
with their subject_id filled from the :term:`BIDS` dataset.
Moreover, we obtain for each model a dictionary with run_imgs,
events and confounder regressors
since in this case a confounds.tsv file is available
in the :term:`BIDS` dataset.
To get the first level models we only have to specify the dataset directory
and the task_label as specified in the file names.

.. GENERATED FROM PYTHON SOURCE LINES 58-76

.. code-block:: Python

    from nilearn.glm.first_level import first_level_from_bids

    task_label = "languagelocalizer"
    (
        models,
        models_run_imgs,
        models_events,
        models_confounds,
    ) = first_level_from_bids(
        data.data_dir,
        task_label,
        img_filters=[("desc", "preproc")],
        n_jobs=2,
        space_label="",
        sub_labels=["01", "02", "05", "08"],  # comment to run all subjects
        smoothing_fwhm=8,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/runner/work/nilearn/nilearn/examples/07_advanced/plot_bids_analysis.py:66: UserWarning: 'StartTime' not found in file /home/runner/nilearn_data/fMRI-language-localizer-demo-dataset/derivatives/sub-01/func/sub-01_task-languagelocalizer_desc-preproc_bold.json.
      ) = first_level_from_bids(




.. GENERATED FROM PYTHON SOURCE LINES 77-81

Quick sanity check on fit arguments
-----------------------------------
Additional checks or information extraction from pre-processed data can
be made here.

.. GENERATED FROM PYTHON SOURCE LINES 83-84

We just expect one run_img per subject.

.. GENERATED FROM PYTHON SOURCE LINES 84-88

.. code-block:: Python

    from pathlib import Path

    print([Path(run).name for run in models_run_imgs[0]])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    ['sub-01_task-languagelocalizer_desc-preproc_bold.nii.gz']




.. GENERATED FROM PYTHON SOURCE LINES 89-92

The only confounds stored are regressors obtained from motion correction. As
we can verify from the column headers of the confounds table corresponding
to the only run_img present.

.. GENERATED FROM PYTHON SOURCE LINES 92-94

.. code-block:: Python

    print(models_confounds[0][0].columns)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Index(['RotX', 'RotY', 'RotZ', 'X', 'Y', 'Z'], dtype='object')




.. GENERATED FROM PYTHON SOURCE LINES 95-98

During this acquisition the subject read blocks of sentences and
consonant strings. So these are our only two conditions in events.
We verify there are 12 blocks for each condition.

.. GENERATED FROM PYTHON SOURCE LINES 98-100

.. code-block:: Python

    print(models_events[0][0]["trial_type"].value_counts())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    trial_type
    language    12
    string      12
    Name: count, dtype: int64




.. GENERATED FROM PYTHON SOURCE LINES 101-108

First level model estimation
----------------------------
Now we simply fit each first level model and plot for each subject the
:term:`contrast` that reveals the language network (language - string).
Notice that we can define a :term:`contrast`
using the names of the conditions specified in the events dataframe.
Sum, subtraction and scalar multiplication are allowed.

.. GENERATED FROM PYTHON SOURCE LINES 110-111

Set the threshold as the z-variate with an uncorrected p-value of 0.001.

.. GENERATED FROM PYTHON SOURCE LINES 111-115

.. code-block:: Python

    from scipy.stats import norm

    p001_unc = norm.isf(0.001)








.. GENERATED FROM PYTHON SOURCE LINES 116-117

Prepare figure for concurrent plot of individual maps.

.. GENERATED FROM PYTHON SOURCE LINES 117-147

.. code-block:: Python

    from math import ceil

    import matplotlib.pyplot as plt
    import numpy as np

    ncols = 2
    nrows = ceil(len(models) / ncols)

    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(8, 4.5))
    axes = np.atleast_2d(axes)
    model_and_args = zip(models, models_run_imgs, models_events, models_confounds)
    for midx, (model, imgs, events, confounds) in enumerate(model_and_args):
        # fit the GLM
        model.fit(imgs, events, confounds)
        # compute the contrast of interest
        zmap = model.compute_contrast("language-string")
        plotting.plot_glass_brain(
            zmap,
            colorbar=True,
            threshold=p001_unc,
            title=f"sub-{model.subject_label}",
            axes=axes[int(midx / ncols), int(midx % ncols)],
            plot_abs=False,
            display_mode="x",
            vmin=-12,
            vmax=12,
        )
    fig.suptitle("subjects z_map language network (unc p<0.001)")
    plotting.show()




.. image-sg:: /auto_examples/07_advanced/images/sphx_glr_plot_bids_analysis_001.png
   :alt: subjects z_map language network (unc p<0.001)
   :srcset: /auto_examples/07_advanced/images/sphx_glr_plot_bids_analysis_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 148-154

Second level model estimation
-----------------------------
We just have to provide the list of fitted FirstLevelModel objects
to the SecondLevelModel object for estimation. We can do this because
all subjects share a similar design matrix (same variables reflected in
column names).

.. GENERATED FROM PYTHON SOURCE LINES 154-158

.. code-block:: Python

    from nilearn.glm.second_level import SecondLevelModel

    second_level_input = models








.. GENERATED FROM PYTHON SOURCE LINES 159-160

Note that we apply a smoothing of 8mm.

.. GENERATED FROM PYTHON SOURCE LINES 160-163

.. code-block:: Python

    second_level_model = SecondLevelModel(smoothing_fwhm=8.0, n_jobs=2)
    second_level_model = second_level_model.fit(second_level_input)








.. GENERATED FROM PYTHON SOURCE LINES 164-168

Computing contrasts at the second level is as simple as at the first level.
Since we are not providing confounders we are performing a one-sample test
at the second level with the images determined by the specified first level
contrast.

.. GENERATED FROM PYTHON SOURCE LINES 168-172

.. code-block:: Python

    zmap = second_level_model.compute_contrast(
        first_level_contrast="language-string"
    )








.. GENERATED FROM PYTHON SOURCE LINES 173-175

The group level :term:`contrast` reveals a left lateralized fronto-temporal
language network.

.. GENERATED FROM PYTHON SOURCE LINES 175-185

.. code-block:: Python

    plotting.plot_glass_brain(
        zmap,
        colorbar=True,
        threshold=p001_unc,
        title="Group language network (unc p<0.001)",
        plot_abs=False,
        display_mode="x",
        figure=plt.figure(figsize=(5, 4)),
    )
    plotting.show()



.. image-sg:: /auto_examples/07_advanced/images/sphx_glr_plot_bids_analysis_002.png
   :alt: plot bids analysis
   :srcset: /auto_examples/07_advanced/images/sphx_glr_plot_bids_analysis_002.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 38.918 seconds)

**Estimated memory usage:**  644 MB


.. _sphx_glr_download_auto_examples_07_advanced_plot_bids_analysis.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/nilearn/nilearn/main?urlpath=lab/tree/notebooks/auto_examples/07_advanced/plot_bids_analysis.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_bids_analysis.ipynb <plot_bids_analysis.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_bids_analysis.py <plot_bids_analysis.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_bids_analysis.zip <plot_bids_analysis.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
