
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/05_glm_second_level/plot_second_level_two_sample_test.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_05_glm_second_level_plot_second_level_two_sample_test.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_05_glm_second_level_plot_second_level_two_sample_test.py:


Second-level fMRI model: two-sample test, unpaired and paired
==============================================================

Full step-by-step example of fitting a GLM to perform a second level analysis
in experimental data and visualizing the results

More specifically:

1. A sample of n=16 visual activity fMRIs are downloaded.

2. An unpaired, two-sample t-test is applied to the brain maps in order to
see the effect of the contrast difference across subjects.

3. A paired, two-sample t-test is applied to the brain maps in order to see
the effect of the contrast difference across subjects, considering subject intercepts

The contrast is between responses to retinotopically distinct
vertical versus horizontal checkerboards. At the individual level,
these stimuli are sometimes used to map the borders of primary visual areas.
At the group level, such a mapping is not possible. Yet, we may
observe some significant effects in these areas.

.. GENERATED FROM PYTHON SOURCE LINES 25-31

.. code-block:: default


    import pandas as pd
    from nilearn import plotting
    from nilearn.datasets import fetch_localizer_contrasts
    import matplotlib.pyplot as plt








.. GENERATED FROM PYTHON SOURCE LINES 32-36

Fetch dataset
--------------
We download a list of left vs right button press contrasts from a
localizer dataset.

.. GENERATED FROM PYTHON SOURCE LINES 36-49

.. code-block:: default

    n_subjects = 16
    sample_vertical = fetch_localizer_contrasts(
        ["vertical checkerboard"], n_subjects,
        get_tmaps=True, legacy_format=False
    )
    sample_horizontal = fetch_localizer_contrasts(
        ["horizontal checkerboard"], n_subjects,
        get_tmaps=True, legacy_format=False
    )

    # Implicitly, there is a one-to-one correspondence between the two samples:
    # the first image of both samples comes from subject S1, the second from subject S2 etc.





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Downloading data from https://osf.io/download/5d27c2c41c5b4a001d9f4e7e/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27ce321c5b4a001aa080fc/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27d3c3114a42001804500a/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27d175a26b340018084d23/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27e5fa1c5b4a001aa09681/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27e900a26b340017083df6/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27f18945253a00193cb2dd/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27f8a845253a001b3c3280/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d2808401c5b4a001d9f83b2/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d280aab45253a001b3c3d51/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d2811fba26b340017085492/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d280d0a114a42001704b6a7/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d282b2345253a001c3e7d09/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d2829f7a26b34001708642d/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28318445253a00193ce6d7/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28399545253a001c3e9288/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d2848581c5b4a001aa10aac/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d2849cc114a42001804994e/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28545ca26b340018089ba7/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d2852861c5b4a001c9ed5bf/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d285cd945253a001a3c8509/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d285c8b45253a00193d0295/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d286e49114a42001904ab90/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d286b6b45253a001c3ec067/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d288af11c5b4a001d9ff0cb/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d2881cd1c5b4a001d9fe799/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d289be945253a001c3ef5e2/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d288c4c114a42001804bfb6/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28a1c91c5b4a001da00bd9/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28ad481c5b4a001aa17d00/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28bb90a26b3400190925d2/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28c24f114a42001904ea5b/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27ccde1c5b4a001d9f5602/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27c7f01c5b4a001c9e778e/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27d9c6114a420019045370/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27d99fa26b340018085146/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27de38a26b340016099771/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27ec4d45253a001c3e3f47/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27fb651c5b4a001d9f7938/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27fb1e1c5b4a001aa0ab78/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d280057a26b340019089965/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27ff2645253a001c3e4fb9/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d2814d145253a001c3e6404/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d280e3945253a001a3c4f15/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28244745253a001b3c4afa/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d2827ff114a420018047f9a/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28309645253a001a3c6a8d/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d282ef61c5b4a001b9f3747/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d284a3445253a001c3ea2d1/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d284636114a42001704e0f6/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28564b1c5b4a001d9fc9d6/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28516e45253a001a3c7e03/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d285b6c1c5b4a001c9edada/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d285cffa26b34001908db9c/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28765645253a001b3c8106/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d287486114a42001804af82/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d287eeb45253a001c3ed1ba/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d287f8f114a4200170503d0/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d2896fb45253a001a3cabe0/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d288e101c5b4a001aa14e0f/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28af541c5b4a001da01caa/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28aa701c5b4a001aa1794c/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28b9af45253a001a3ccb85/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28b579114a42001804e2cd/ ...
     ...done. (1 seconds, 0 min)




.. GENERATED FROM PYTHON SOURCE LINES 50-54

Estimate second level models
------------------------------
We define the input maps and the design matrix for the second level model
and fit it.

.. GENERATED FROM PYTHON SOURCE LINES 54-56

.. code-block:: default

    second_level_input = sample_vertical['cmaps'] + sample_horizontal['cmaps']








.. GENERATED FROM PYTHON SOURCE LINES 57-58

Next, we model the effect of conditions (sample 1 vs sample 2).

.. GENERATED FROM PYTHON SOURCE LINES 58-61

.. code-block:: default

    import numpy as np
    condition_effect = np.hstack(([1] * n_subjects, [- 1] * n_subjects))








.. GENERATED FROM PYTHON SOURCE LINES 62-64

The design matrix for the unpaired test doesn't need any more columns
For the paired test, we include an intercept for each subject.

.. GENERATED FROM PYTHON SOURCE LINES 64-67

.. code-block:: default

    subject_effect = np.vstack((np.eye(n_subjects), np.eye(n_subjects)))
    subjects = [f'S{i:02d}' for i in range(1, n_subjects + 1)]








.. GENERATED FROM PYTHON SOURCE LINES 68-69

We then assemble those into design matrices

.. GENERATED FROM PYTHON SOURCE LINES 69-77

.. code-block:: default

    unpaired_design_matrix = pd.DataFrame(
        condition_effect[:, np.newaxis],
        columns=['vertical vs horizontal'])

    paired_design_matrix = pd.DataFrame(
        np.hstack((condition_effect[:, np.newaxis], subject_effect)),
        columns=['vertical vs horizontal'] + subjects)








.. GENERATED FROM PYTHON SOURCE LINES 78-79

and plot the designs.

.. GENERATED FROM PYTHON SOURCE LINES 79-88

.. code-block:: default

    from nilearn.plotting import plot_design_matrix
    _, (ax_unpaired, ax_paired) = plt.subplots(1,2, gridspec_kw={'width_ratios': [1, 17]})
    plot_design_matrix(unpaired_design_matrix, rescale=False, ax=ax_unpaired)
    plot_design_matrix(paired_design_matrix, rescale=False, ax=ax_paired)
    ax_unpaired.set_title('unpaired design', fontsize=12)
    ax_paired.set_title('paired design', fontsize=12)
    plt.tight_layout()
    plotting.show()




.. image-sg:: /auto_examples/05_glm_second_level/images/sphx_glr_plot_second_level_two_sample_test_001.png
   :alt: unpaired design, paired design
   :srcset: /auto_examples/05_glm_second_level/images/sphx_glr_plot_second_level_two_sample_test_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 89-90

We specify the analysis models and fit them.

.. GENERATED FROM PYTHON SOURCE LINES 90-98

.. code-block:: default

    from nilearn.glm.second_level import SecondLevelModel

    second_level_model_unpaired = SecondLevelModel().fit(
        second_level_input, design_matrix=unpaired_design_matrix)

    second_level_model_paired = SecondLevelModel().fit(
        second_level_input, design_matrix=paired_design_matrix)








.. GENERATED FROM PYTHON SOURCE LINES 99-103

Estimating the contrast is simple. To do so, we provide the column
name of the design matrix. The argument 'output_type' is set to return all
available outputs so that we can compare differences in the effect size,
variance, and z-score.

.. GENERATED FROM PYTHON SOURCE LINES 103-111

.. code-block:: default

    stat_maps_unpaired = second_level_model_unpaired.compute_contrast(
                                                        'vertical vs horizontal',
                                                        output_type='all')

    stat_maps_paired = second_level_model_paired.compute_contrast(
                                                    'vertical vs horizontal',
                                                    output_type='all')








.. GENERATED FROM PYTHON SOURCE LINES 112-115

Plot the results
---------------------------
The two effect_size images are essentially identical

.. GENERATED FROM PYTHON SOURCE LINES 115-118

.. code-block:: default

    (stat_maps_unpaired['effect_size'].get_fdata()
        - stat_maps_paired['effect_size'].get_fdata()).max()





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    9.992007221626409e-16



.. GENERATED FROM PYTHON SOURCE LINES 119-120

But the variance in the unpaired image is larger.

.. GENERATED FROM PYTHON SOURCE LINES 120-130

.. code-block:: default

    plotting.plot_glass_brain(
        stat_maps_unpaired['effect_variance'], colorbar=True, vmin=0, vmax=6,
        title='vertical vs horizontal effect variance, unpaired')

    plotting.plot_glass_brain(
        stat_maps_paired['effect_variance'], colorbar=True, vmin=0, vmax=6,
        title='vertical vs horizontal effect variance, paired')

    plotting.show()




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/05_glm_second_level/images/sphx_glr_plot_second_level_two_sample_test_002.png
         :alt: plot second level two sample test
         :srcset: /auto_examples/05_glm_second_level/images/sphx_glr_plot_second_level_two_sample_test_002.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/05_glm_second_level/images/sphx_glr_plot_second_level_two_sample_test_003.png
         :alt: plot second level two sample test
         :srcset: /auto_examples/05_glm_second_level/images/sphx_glr_plot_second_level_two_sample_test_003.png
         :class: sphx-glr-multi-img





.. GENERATED FROM PYTHON SOURCE LINES 131-133

Together, this makes the z_scores from the paired test larger.
We threshold the second level contrast and plot it.

.. GENERATED FROM PYTHON SOURCE LINES 133-144

.. code-block:: default

    threshold = 3.1  # corresponds to  p < .001, uncorrected
    display = plotting.plot_glass_brain(
        stat_maps_unpaired['z_score'], threshold=threshold, colorbar=True, plot_abs=False,
        title='vertical vs horizontal (unc p<0.001)', vmin=0, vmax=6)

    display = plotting.plot_glass_brain(
        stat_maps_paired['z_score'], threshold=threshold, colorbar=True, plot_abs=False,
        title='vertical vs horizontal (unc p<0.001)', vmin=0, vmax=6)

    plotting.show()




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/05_glm_second_level/images/sphx_glr_plot_second_level_two_sample_test_004.png
         :alt: plot second level two sample test
         :srcset: /auto_examples/05_glm_second_level/images/sphx_glr_plot_second_level_two_sample_test_004.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/05_glm_second_level/images/sphx_glr_plot_second_level_two_sample_test_005.png
         :alt: plot second level two sample test
         :srcset: /auto_examples/05_glm_second_level/images/sphx_glr_plot_second_level_two_sample_test_005.png
         :class: sphx-glr-multi-img





.. GENERATED FROM PYTHON SOURCE LINES 145-147

Unsurprisingly, we see activity in the primary visual cortex, both positive
and negative.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  47.361 seconds)

**Estimated memory usage:**  9 MB


.. _sphx_glr_download_auto_examples_05_glm_second_level_plot_second_level_two_sample_test.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/nilearn/nilearn.github.io/main?filepath=examples/auto_examples/05_glm_second_level/plot_second_level_two_sample_test.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_second_level_two_sample_test.py <plot_second_level_two_sample_test.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_second_level_two_sample_test.ipynb <plot_second_level_two_sample_test.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
