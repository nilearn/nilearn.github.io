
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/05_glm_second_level/plot_oasis.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_05_glm_second_level_plot_oasis.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_05_glm_second_level_plot_oasis.py:

Voxel-Based Morphometry on OASIS dataset
========================================

This example uses voxel-based morphometry (:term:`VBM`) to study the
relationship between aging, sex, and gray matter density.

The data come from the `OASIS <http://www.oasis-brains.org/>`_ project.
If you use it, you need to agree with the data usage agreement available
on the website.

It has been run through a standard VBM pipeline (using SPM8 and NewSegment)
to create :term:`VBM` maps, which we study here.

VBM analysis of aging
---------------------

We run a standard GLM analysis to study the association between age and gray
matter density from the VBM data.
We use only 100 subjects from the OASIS dataset to limit the memory usage.

Note that more power would be obtained from using a larger sample of subjects.

.. GENERATED FROM PYTHON SOURCE LINES 23-30

.. code-block:: default

    # Authors: Bertrand Thirion, <bertrand.thirion@inria.fr>, July 2018
    #          Elvis Dhomatob, <elvis.dohmatob@inria.fr>, Apr. 2014
    #          Virgile Fritsch, <virgile.fritsch@inria.fr>, Apr 2014
    #          Gael Varoquaux, Apr 2014

    n_subjects = 100  # more subjects requires more memory








.. GENERATED FROM PYTHON SOURCE LINES 31-33

Load Oasis dataset
------------------

.. GENERATED FROM PYTHON SOURCE LINES 33-42

.. code-block:: default

    from nilearn import datasets

    oasis_dataset = datasets.fetch_oasis_vbm(
        n_subjects=n_subjects,
        legacy_format=False,
    )
    gray_matter_map_filenames = oasis_dataset.gray_matter_maps
    age = oasis_dataset.ext_vars['age'].astype(float)








.. GENERATED FROM PYTHON SOURCE LINES 43-44

Sex is encoded as 'M' or 'F'. Hence, we make it a binary variable.

.. GENERATED FROM PYTHON SOURCE LINES 44-46

.. code-block:: default

    sex = oasis_dataset.ext_vars['mf'] == 'F'








.. GENERATED FROM PYTHON SOURCE LINES 47-48

Print basic information on the dataset.

.. GENERATED FROM PYTHON SOURCE LINES 48-57

.. code-block:: default

    print(
        'First gray-matter anatomy image (3D) is located at: '
        f'{oasis_dataset.gray_matter_maps[0]}'
    )  # 3D data
    print(
        'First white-matter anatomy image (3D) is located at: '
        f'{oasis_dataset.white_matter_maps[0]}'
    )  # 3D data





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    First gray-matter anatomy image (3D) is located at: /home/circleci/nilearn_data/oasis1/OAS1_0001_MR1/mwrc1OAS1_0001_MR1_mpr_anon_fslswapdim_bet.nii.gz
    First white-matter anatomy image (3D) is located at: /home/circleci/nilearn_data/oasis1/OAS1_0001_MR1/mwrc2OAS1_0001_MR1_mpr_anon_fslswapdim_bet.nii.gz




.. GENERATED FROM PYTHON SOURCE LINES 58-59

Get a mask image: A mask of the cortex of the ICBM template.

.. GENERATED FROM PYTHON SOURCE LINES 59-61

.. code-block:: default

    gm_mask = datasets.fetch_icbm152_brain_gm_mask()








.. GENERATED FROM PYTHON SOURCE LINES 62-63

Resample the mask, since this mask has a different resolution.

.. GENERATED FROM PYTHON SOURCE LINES 63-71

.. code-block:: default

    from nilearn.image import resample_to_img

    mask_img = resample_to_img(
        gm_mask,
        gray_matter_map_filenames[0],
        interpolation='nearest',
    )








.. GENERATED FROM PYTHON SOURCE LINES 72-76

Analyse data
------------
First, we create an adequate design matrix with three columns: 'age', 'sex',
and 'intercept'.

.. GENERATED FROM PYTHON SOURCE LINES 76-85

.. code-block:: default

    import numpy as np
    import pandas as pd

    intercept = np.ones(n_subjects)
    design_matrix = pd.DataFrame(
        np.vstack((age, sex, intercept)).T,
        columns=['age', 'sex', 'intercept'],
    )








.. GENERATED FROM PYTHON SOURCE LINES 86-87

Let's plot the design matrix.

.. GENERATED FROM PYTHON SOURCE LINES 87-93

.. code-block:: default

    from nilearn import plotting

    ax = plotting.plot_design_matrix(design_matrix)
    ax.set_title('Second level design matrix', fontsize=12)
    ax.set_ylabel('maps')




.. image-sg:: /auto_examples/05_glm_second_level/images/sphx_glr_plot_oasis_001.png
   :alt: Second level design matrix
   :srcset: /auto_examples/05_glm_second_level/images/sphx_glr_plot_oasis_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    Text(29.000000000000007, 0.5, 'maps')



.. GENERATED FROM PYTHON SOURCE LINES 94-96

Next, we specify and fit the second-level model when loading the data and
also smooth a little bit to improve statistical behavior.

.. GENERATED FROM PYTHON SOURCE LINES 96-104

.. code-block:: default

    from nilearn.glm.second_level import SecondLevelModel

    second_level_model = SecondLevelModel(smoothing_fwhm=2.0, mask_img=mask_img)
    second_level_model.fit(
        gray_matter_map_filenames,
        design_matrix=design_matrix,
    )






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-7" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>SecondLevelModel(mask_img=&lt;nibabel.nifti1.Nifti1Image object at 0x7fd86c5524c0&gt;,
                     smoothing_fwhm=2.0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" checked><label for="sk-estimator-id-7" class="sk-toggleable__label sk-toggleable__label-arrow">SecondLevelModel</label><div class="sk-toggleable__content"><pre>SecondLevelModel(mask_img=&lt;nibabel.nifti1.Nifti1Image object at 0x7fd86c5524c0&gt;,
                     smoothing_fwhm=2.0)</pre></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 105-107

Estimating the contrast is very simple. We can just provide the column name
of the design matrix.

.. GENERATED FROM PYTHON SOURCE LINES 107-112

.. code-block:: default

    z_map = second_level_model.compute_contrast(
        second_level_contrast=[1, 0, 0],
        output_type='z_score',
    )








.. GENERATED FROM PYTHON SOURCE LINES 113-114

We threshold the second level contrast at FDR-corrected p < 0.05 and plot it.

.. GENERATED FROM PYTHON SOURCE LINES 114-129

.. code-block:: default

    from nilearn.glm import threshold_stats_img

    _, threshold = threshold_stats_img(z_map, alpha=.05, height_control='fdr')
    print(f'The FDR=.05-corrected threshold is: {threshold:03g}')

    display = plotting.plot_stat_map(
        z_map,
        threshold=threshold,
        colorbar=True,
        display_mode='z',
        cut_coords=[-4, 26],
        title='age effect on gray matter density (FDR = .05)',
    )
    plotting.show()




.. image-sg:: /auto_examples/05_glm_second_level/images/sphx_glr_plot_oasis_002.png
   :alt: plot oasis
   :srcset: /auto_examples/05_glm_second_level/images/sphx_glr_plot_oasis_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    The FDR=.05-corrected threshold is: 2.40175




.. GENERATED FROM PYTHON SOURCE LINES 130-132

We can also study the effect of sex by computing the contrast, thresholding
it and plot the resulting map.

.. GENERATED FROM PYTHON SOURCE LINES 132-144

.. code-block:: default

    z_map = second_level_model.compute_contrast(
        second_level_contrast='sex',
        output_type='z_score',
    )
    _, threshold = threshold_stats_img(z_map, alpha=.05, height_control='fdr')
    plotting.plot_stat_map(
        z_map,
        threshold=threshold,
        colorbar=True,
        title='sex effect on gray matter density (FDR = .05)',
    )




.. image-sg:: /auto_examples/05_glm_second_level/images/sphx_glr_plot_oasis_003.png
   :alt: plot oasis
   :srcset: /auto_examples/05_glm_second_level/images/sphx_glr_plot_oasis_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    <nilearn.plotting.displays._slicers.OrthoSlicer object at 0x7fd8587850d0>



.. GENERATED FROM PYTHON SOURCE LINES 145-147

Note that there does not seem to be any significant effect of sex on
gray matter density on that dataset.

.. GENERATED FROM PYTHON SOURCE LINES 149-155

Generating a report
-------------------
It can be useful to quickly generate a portable, ready-to-view report with
most of the pertinent information.
This is easy to do if you have a fitted model and the list of contrasts,
which we do here.

.. GENERATED FROM PYTHON SOURCE LINES 155-164

.. code-block:: default

    from nilearn.reporting import make_glm_report

    icbm152_2009 = datasets.fetch_icbm152_2009()
    report = make_glm_report(
        model=second_level_model,
        contrasts=['age', 'sex'],
        bg_img=icbm152_2009['t1'],
    )








.. GENERATED FROM PYTHON SOURCE LINES 165-166

We have several ways to access the report:

.. GENERATED FROM PYTHON SOURCE LINES 166-170

.. code-block:: default


    # report  # This report can be viewed in a notebook
    # report.save_as_html('report.html')
    # report.open_in_browser()








.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 2 minutes  7.161 seconds)

**Estimated memory usage:**  1173 MB


.. _sphx_glr_download_auto_examples_05_glm_second_level_plot_oasis.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/nilearn/nilearn.github.io/main?filepath=examples/auto_examples/05_glm_second_level/plot_oasis.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_oasis.py <plot_oasis.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_oasis.ipynb <plot_oasis.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
