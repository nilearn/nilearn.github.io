
<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Nilearn: Machine learning for NeuroImaging in Python &mdash; Machine learning for NeuroImaging</title>
    
    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.2.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="top" title="Machine learning for NeuroImaging" href="../index.html" />
    <link rel="up" title="3. Functional connectivity and resting state" href="index.html" />
    <link rel="next" title="4. Image manipulation and visualization" href="../manipulating_visualizing/index.html" />
    <link rel="prev" title="3.4. Parcellating the brain in regions" href="parcellating.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">
<script type="text/javascript">
$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var top = 105 + $('.sphinxsidebarwrapper').offset().top - parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0)),
        sections = {},
        i        = 0,
	url	 = document.URL.replace(/#.*$/, ""),
	current_section = 0;

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50;
    });

    $(window).scroll(function(event) {
	var pos   = $(window).scrollTop();
	// Lock the table of content to a fixed position once we scroll enough
	if(pos > top){
	    //begin to scroll
	    $('.sphinxsidebarwrapper').css("position", "fixed");
	    $('.sphinxsidebarwrapper').css("top", -105);
	}
	else{
	    //lock it back into place
	    $('.sphinxsidebarwrapper').css("position", "relative");
	    $('.sphinxsidebarwrapper').css("top",0);
	}

	// Highlight the current section
	$('a.internal').removeClass('active');
        for(i in sections){
            if(sections[i] > pos){
		break;
            };
	    if($('a.internal[href$="' + i + '"]').is(':visible')){
		current_section = i;
	    };
        }
	$('a.internal[href$="' + current_section + '"]').addClass('active');
    });

});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head>
  <body>
<div id="logo-banner">
  <div class="logo">
    <a href="../index.html">
      <img src="../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../manipulating_visualizing/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../modules/reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Machine learning for Neuro-Imaging in Python</h2>
  </div>
  <div class="search_form">
    <div id="cse" style="width: 100%;"></div>
    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">
      google.load('search', '1', {language : 'en'});
      google.setOnLoadCallback(function() {
      var customSearchControl = new google.search.CustomSearchControl('014136483057745874622:r-npolb1uki');
      customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
      var options = new google.search.DrawOptions();
      options.setAutoComplete(true);
      customSearchControl.draw('cse', options);
      }, true);
    </script>
  </div>
</div>



    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../np-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="../manipulating_visualizing/index.html" title="4. Image manipulation and visualization"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="parcellating.html" title="3.4. Parcellating the brain in regions"
             accesskey="P">previous</a> |</li>
<li><a href="../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../AUTHORS.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li><a href="../user_guide.html" >User guide: table of contents</a> &raquo;</li>
          <li><a href="index.html" accesskey="U">3. Functional connectivity and resting state</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../AUTHORS.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">3.5. Region Extraction for better brain parcellations</a><ul>
<li><a class="reference internal" href="#fetching-resting-state-functional-datasets">3.5.1. Fetching resting state functional datasets</a></li>
<li><a class="reference internal" href="#data-decomposition-using-canonical-ica">3.5.2. Data decomposition using Canonical ICA</a></li>
<li><a class="reference internal" href="#visualization-of-canonical-ica-maps">3.5.3. Visualization of Canonical ICA maps</a></li>
<li><a class="reference internal" href="#region-extraction-with-canica-maps">3.5.4. Region Extraction with CanICA maps</a></li>
<li><a class="reference internal" href="#visualization-of-region-extraction-results">3.5.5. Visualization of Region Extraction results</a></li>
<li><a class="reference internal" href="#computing-functional-connectivity-matrices">3.5.6. Computing functional connectivity matrices</a></li>
<li><a class="reference internal" href="#visualization-of-functional-connectivity-matrices">3.5.7. Visualization of functional connectivity matrices</a></li>
<li><a class="reference internal" href="#validating-results">3.5.8. Validating results</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="parcellating.html"
                        title="previous chapter">3.4. Parcellating the brain in regions</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../manipulating_visualizing/index.html"
                        title="next chapter">4. Image manipulation and visualization</a></p>

<div class="navbar">
</div> <!-- end navbar -->

<script type="text/javascript">$('#searchbox-ml').show(0);</script>
<script type="text/javascript">$('#searchbox-site').show(0);</script>


        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="region-extraction-for-better-brain-parcellations">
<span id="region-extraction"></span><h1>3.5. Region Extraction for better brain parcellations<a class="headerlink" href="#region-extraction-for-better-brain-parcellations" title="Permalink to this headline">¶</a></h1>
<div class="topic">
<p class="topic-title first"><strong>Page summary</strong></p>
<p>This section shows how to use Region Extractor to extract each connected
brain regions/components into a separate brain activation regions and also
shows how to learn functional connectivity interactions between each
separate regions.</p>
</div>
<div class="contents local topic" id="contents">
<p class="topic-title first"><strong>Contents</strong></p>
<ul class="simple">
<li><a class="reference internal" href="#fetching-resting-state-functional-datasets" id="id1">Fetching resting state functional datasets</a></li>
<li><a class="reference internal" href="#data-decomposition-using-canonical-ica" id="id2">Data decomposition using Canonical ICA</a></li>
<li><a class="reference internal" href="#visualization-of-canonical-ica-maps" id="id3">Visualization of Canonical ICA maps</a></li>
<li><a class="reference internal" href="#region-extraction-with-canica-maps" id="id4">Region Extraction with CanICA maps</a></li>
<li><a class="reference internal" href="#visualization-of-region-extraction-results" id="id5">Visualization of Region Extraction results</a></li>
<li><a class="reference internal" href="#computing-functional-connectivity-matrices" id="id6">Computing functional connectivity matrices</a></li>
<li><a class="reference internal" href="#visualization-of-functional-connectivity-matrices" id="id7">Visualization of functional connectivity matrices</a></li>
<li><a class="reference internal" href="#validating-results" id="id8">Validating results</a></li>
</ul>
</div>
<div class="topic">
<p class="topic-title first"><strong>References</strong></p>
<ul class="simple">
<li><a class="reference external" href="https://hal.inria.fr/hal-01093944">Abraham et al. &#8220;Region segmentation for sparse decompositions: better
brain parcellations from rest fMRI&#8221;, Sparsity Techniques in Medical Imaging,
Sep 2014</a></li>
</ul>
</div>
<div class="section" id="fetching-resting-state-functional-datasets">
<h2><a class="toc-backref" href="#id1">3.5.1. Fetching resting state functional datasets</a><a class="headerlink" href="#fetching-resting-state-functional-datasets" title="Permalink to this headline">¶</a></h2>
<p>We use ADHD resting state functional connectivity datasets of 20 subjects,
which is already preprocessed and publicly available at
<a class="reference external" href="http://fcon_1000.projects.nitrc.org/indi/adhd200/">http://fcon_1000.projects.nitrc.org/indi/adhd200/</a>. We use utilities
<a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_adhd.html#nilearn.datasets.fetch_adhd" title="nilearn.datasets.fetch_adhd"><tt class="xref py py-func docutils literal"><span class="pre">fetch_adhd</span></tt></a> implemented in nilearn for automatic fetching of these
datasets.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="n">adhd_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_adhd</span><span class="p">(</span><span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">func_filenames</span> <span class="o">=</span> <span class="n">adhd_dataset</span><span class="o">.</span><span class="n">func</span>
<span class="n">confounds</span> <span class="o">=</span> <span class="n">adhd_dataset</span><span class="o">.</span><span class="n">confounds</span>
</pre></div>
</div>
</div>
<div class="section" id="data-decomposition-using-canonical-ica">
<h2><a class="toc-backref" href="#id2">3.5.2. Data decomposition using Canonical ICA</a><a class="headerlink" href="#data-decomposition-using-canonical-ica" title="Permalink to this headline">¶</a></h2>
<p>Here, we use <a class="reference internal" href="../modules/generated/nilearn.decomposition.CanICA.html#nilearn.decomposition.CanICA" title="nilearn.decomposition.CanICA"><tt class="xref py py-class docutils literal"><span class="pre">CanICA</span></tt></a>, a multi subject model to decompose previously
fetched multi subjects datasets. We do this by setting the parameters in the
object and calling fit on the functional filenames without necessarily
converting each filename to Nifti1Image object.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">nilearn.decomposition</span> <span class="kn">import</span> <span class="n">CanICA</span>

<span class="c"># Initialize canica parameters</span>
<span class="n">canica</span> <span class="o">=</span> <span class="n">CanICA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">smoothing_fwhm</span><span class="o">=</span><span class="mf">6.</span><span class="p">,</span>
                <span class="n">memory</span><span class="o">=</span><span class="s">&quot;nilearn_cache&quot;</span><span class="p">,</span> <span class="n">memory_level</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c"># Fit to the data</span>
<span class="n">canica</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">func_filenames</span><span class="p">)</span>
<span class="c"># ICA maps</span>
<span class="n">components_img</span> <span class="o">=</span> <span class="n">canica</span><span class="o">.</span><span class="n">masker_</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">canica</span><span class="o">.</span><span class="n">components_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-canonical-ica-maps">
<h2><a class="toc-backref" href="#id3">3.5.3. Visualization of Canonical ICA maps</a><a class="headerlink" href="#visualization-of-canonical-ica-maps" title="Permalink to this headline">¶</a></h2>
<p>Showing ICA maps stored in components_img using nilearn plotting utilities.
Here, we use <a class="reference internal" href="../modules/generated/nilearn.plotting.plot_prob_atlas.html#nilearn.plotting.plot_prob_atlas" title="nilearn.plotting.plot_prob_atlas"><tt class="xref py py-func docutils literal"><span class="pre">plot_prob_atlas</span></tt></a> for easy visualization of 4D atlas maps
onto the anatomical standard template. Each ICA map is displayed in different
color and colors are random and automatically picked.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">plotting</span>

<span class="n">plotting</span><span class="o">.</span><span class="n">plot_prob_atlas</span><span class="p">(</span><span class="n">components_img</span><span class="p">,</span> <span class="n">view_type</span><span class="o">=</span><span class="s">&#39;filled_contours&#39;</span><span class="p">,</span>
                         <span class="n">title</span><span class="o">=</span><span class="s">&#39;ICA components&#39;</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference external image-reference" href="../auto_examples/connectivity/plot_extract_regions_canica_maps.html"><img alt="../_images/sphx_glr_plot_extract_regions_canica_maps_0011.png" src="../_images/sphx_glr_plot_extract_regions_canica_maps_0011.png" style="width: 396.0px; height: 156.0px;" /></a>
</div>
<div class="section" id="region-extraction-with-canica-maps">
<h2><a class="toc-backref" href="#id4">3.5.4. Region Extraction with CanICA maps</a><a class="headerlink" href="#region-extraction-with-canica-maps" title="Permalink to this headline">¶</a></h2>
<p>We use object <a class="reference internal" href="../modules/generated/nilearn.regions.RegionExtractor.html#nilearn.regions.RegionExtractor" title="nilearn.regions.RegionExtractor"><tt class="xref py py-class docutils literal"><span class="pre">RegionExtractor</span></tt></a> for extracting brain connected regions
from ICA maps into separated brain activation regions with automatic
thresholding strategy selected as thresholding_strategy=&#8217;ratio_n_voxels&#8217;. We use
thresholding strategy to first get foreground information present in the maps and
then followed by robust region extraction on foreground information using
Random Walker algorithm selected as extractor=&#8217;local_regions&#8217;.</p>
<p>Here, we control foreground extraction using parameter threshold=.5, which
represents the expected proportion of voxels included in the regions
(i.e. with a non-zero value in one of the maps). If you need to keep more
proportion of voxels then threshold should be tweaked according to the maps data.</p>
<p>The parameter min_region_size=1350 mm^3 is to keep the minimum number of extracted
regions. We control the small spurious regions size by thresholding in voxel units
to adapt well to the resolution of the image. Please see the documentation of
nilearn.regions.connected_regions for more details.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># threshold=0.5 indicates that we keep nominal of amount nonzero voxels across all</span>
<span class="c"># maps, less the threshold means that more intense non-voxels will be survived.</span>
<span class="kn">from</span> <span class="nn">nilearn.regions</span> <span class="kn">import</span> <span class="n">RegionExtractor</span>

<span class="n">extractor</span> <span class="o">=</span> <span class="n">RegionExtractor</span><span class="p">(</span><span class="n">components_img</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                            <span class="n">thresholding_strategy</span><span class="o">=</span><span class="s">&#39;ratio_n_voxels&#39;</span><span class="p">,</span>
                            <span class="n">extractor</span><span class="o">=</span><span class="s">&#39;local_regions&#39;</span><span class="p">,</span>
                            <span class="n">standardize</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">min_region_size</span><span class="o">=</span><span class="mi">1350</span><span class="p">)</span>
<span class="c"># Just call fit() to process for regions extraction</span>
<span class="n">extractor</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="c"># Extracted regions are stored in regions_img_</span>
<span class="n">regions_extracted_img</span> <span class="o">=</span> <span class="n">extractor</span><span class="o">.</span><span class="n">regions_img_</span>
<span class="c"># Each region index is stored in index_</span>
<span class="n">regions_index</span> <span class="o">=</span> <span class="n">extractor</span><span class="o">.</span><span class="n">index_</span>
<span class="c"># Total number of regions extracted</span>
<span class="n">n_regions_extracted</span> <span class="o">=</span> <span class="n">regions_extracted_img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-region-extraction-results">
<h2><a class="toc-backref" href="#id5">3.5.5. Visualization of Region Extraction results</a><a class="headerlink" href="#visualization-of-region-extraction-results" title="Permalink to this headline">¶</a></h2>
<p>Showing region extraction results. The same <a class="reference internal" href="../modules/generated/nilearn.plotting.plot_prob_atlas.html#nilearn.plotting.plot_prob_atlas" title="nilearn.plotting.plot_prob_atlas"><tt class="xref py py-func docutils literal"><span class="pre">plot_prob_atlas</span></tt></a> is used
for visualizing extracted regions on a standard template. Each extracted brain
region is assigned a color and as you can see that visual cortex area is extracted
quite nicely into each hemisphere.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">title</span> <span class="o">=</span> <span class="p">(</span><span class="s">&#39;</span><span class="si">%d</span><span class="s"> regions are extracted from </span><span class="si">%d</span><span class="s"> ICA components.&#39;</span>
         <span class="s">&#39;</span><span class="se">\n</span><span class="s">Each separate color of region indicates extracted region&#39;</span>
         <span class="o">%</span> <span class="p">(</span><span class="n">n_regions_extracted</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plotting</span><span class="o">.</span><span class="n">plot_prob_atlas</span><span class="p">(</span><span class="n">regions_extracted_img</span><span class="p">,</span> <span class="n">view_type</span><span class="o">=</span><span class="s">&#39;filled_contours&#39;</span><span class="p">,</span>
                         <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference external image-reference" href="../auto_examples/connectivity/plot_extract_regions_canica_maps.html"><img alt="../_images/sphx_glr_plot_extract_regions_canica_maps_0021.png" src="../_images/sphx_glr_plot_extract_regions_canica_maps_0021.png" style="width: 396.0px; height: 156.0px;" /></a>
</div>
<div class="section" id="computing-functional-connectivity-matrices">
<h2><a class="toc-backref" href="#id6">3.5.6. Computing functional connectivity matrices</a><a class="headerlink" href="#computing-functional-connectivity-matrices" title="Permalink to this headline">¶</a></h2>
<p>Here, we use the object called <a class="reference internal" href="../modules/generated/nilearn.connectome.ConnectivityMeasure.html#nilearn.connectome.ConnectivityMeasure" title="nilearn.connectome.ConnectivityMeasure"><tt class="xref py py-class docutils literal"><span class="pre">ConnectivityMeasure</span></tt></a> to compute
functional connectivity measured between each extracted brain regions. Many different
kinds of measures exists in nilearn such as &#8220;correlation&#8221;, &#8220;partial correlation&#8221;, &#8220;tangent&#8221;,
&#8220;covariance&#8221;, &#8220;precision&#8221;. But, here we show how to compute only correlations by
selecting parameter as kind=&#8217;correlation&#8217; as initialized in the object.</p>
<p>The first step to do is to extract subject specific time series signals using
functional data stored in func_filenames and the second step is to call fit_tranform()
on the time series signals. Here, for each subject we have time series signals of
shape=(176, 23) where 176 is the length of time series and 23 is the number of
extracted regions. Likewise, we have a total of 20 subject specific time series signals.
The third step, we compute the mean correlation across all subjects.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">nilearn.connectome</span> <span class="kn">import</span> <span class="n">ConnectivityMeasure</span>

<span class="n">correlations</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c"># Initializing ConnectivityMeasure object with kind=&#39;correlation&#39;</span>
<span class="n">connectome_measure</span> <span class="o">=</span> <span class="n">ConnectivityMeasure</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">&#39;correlation&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">filename</span><span class="p">,</span> <span class="n">confound</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">func_filenames</span><span class="p">,</span> <span class="n">confounds</span><span class="p">):</span>
    <span class="c"># call transform from RegionExtractor object to extract timeseries signals</span>
    <span class="n">timeseries_each_subject</span> <span class="o">=</span> <span class="n">extractor</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">confounds</span><span class="o">=</span><span class="n">confound</span><span class="p">)</span>
    <span class="c"># call fit_transform from ConnectivityMeasure object</span>
    <span class="n">correlation</span> <span class="o">=</span> <span class="n">connectome_measure</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">([</span><span class="n">timeseries_each_subject</span><span class="p">])</span>
    <span class="c"># saving each subject correlation to correlations</span>
    <span class="n">correlations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">correlation</span><span class="p">)</span>

<span class="c"># Mean of all correlations</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">mean_correlations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">correlations</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_regions_extracted</span><span class="p">,</span>
                                                          <span class="n">n_regions_extracted</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="visualization-of-functional-connectivity-matrices">
<h2><a class="toc-backref" href="#id7">3.5.7. Visualization of functional connectivity matrices</a><a class="headerlink" href="#visualization-of-functional-connectivity-matrices" title="Permalink to this headline">¶</a></h2>
<p>Showing mean of correlation matrices computed between each extracted brain regions.
At this point, we make use of nilearn image and plotting utilities to find
automatically the coordinates required, for plotting connectome relations.
Left image is the correlations in a matrix form and right image is the
connectivity relations to brain regions plotted using <a class="reference internal" href="../modules/generated/nilearn.plotting.plot_connectome.html#nilearn.plotting.plot_connectome" title="nilearn.plotting.plot_connectome"><tt class="xref py py-func docutils literal"><span class="pre">plot_connectome</span></tt></a></p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">image</span>

<span class="n">regions_imgs</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">iter_img</span><span class="p">(</span><span class="n">regions_extracted_img</span><span class="p">)</span>
<span class="n">coords_connectome</span> <span class="o">=</span> <span class="p">[</span><span class="n">plotting</span><span class="o">.</span><span class="n">find_xyz_cut_coords</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">regions_imgs</span><span class="p">]</span>
<span class="n">title</span> <span class="o">=</span> <span class="s">&#39;Correlation interactions between </span><span class="si">%d</span><span class="s"> regions&#39;</span> <span class="o">%</span> <span class="n">n_regions_extracted</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">mean_correlations</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s">&quot;nearest&quot;</span><span class="p">,</span>
           <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">bwr</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
<span class="n">plotting</span><span class="o">.</span><span class="n">plot_connectome</span><span class="p">(</span><span class="n">mean_correlations</span><span class="p">,</span> <span class="n">coords_connectome</span><span class="p">,</span>
                         <span class="n">edge_threshold</span><span class="o">=</span><span class="s">&#39;90%&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>
</pre></div>
</div>
<p class="centered">
<strong><a class="reference external image-reference" href="../auto_examples/connectivity/plot_extract_regions_canica_maps.html"><img alt="matrix" src="../_images/sphx_glr_plot_extract_regions_canica_maps_0031.png" style="width: 480.0px; height: 360.0px;" /></a>
 <a class="reference external image-reference" href="../auto_examples/connectivity/plot_extract_regions_canica_maps.html"><img alt="connectome" src="../_images/sphx_glr_plot_extract_regions_canica_maps_0041.png" style="width: 396.0px; height: 156.0px;" /></a>
</strong></p></div>
<div class="section" id="validating-results">
<h2><a class="toc-backref" href="#id8">3.5.8. Validating results</a><a class="headerlink" href="#validating-results" title="Permalink to this headline">¶</a></h2>
<p>Showing only Default Mode Network (DMN) regions before and after region
extraction by manually identifying the index of DMN in ICA decomposed maps.</p>
<p>Left image displays the DMN regions without region extraction and right image
displays the DMN regions after region extraction. Here, we can validate that
the DMN regions are nicely separated displaying each extracted region in different color.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">img</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">index_img</span><span class="p">(</span><span class="n">components_img</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">coords</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">find_xyz_cut_coords</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">display</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">plot_stat_map</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">52</span><span class="p">,</span> <span class="mi">29</span><span class="p">)),</span>
                                 <span class="n">colorbar</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;ICA map: DMN mode&#39;</span><span class="p">)</span>

<span class="c"># Now, we plot DMN after region extraction to show that connected regions are</span>
<span class="c"># nicely separated. Each brain extracted region is indicated with separate color</span>

<span class="c"># For this, we take the indices of the all regions extracted related to original</span>
<span class="c"># ICA map 3.</span>
<span class="n">regions_indices_of_map3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">regions_index</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">display</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">plot_anat</span><span class="p">(</span><span class="n">cut_coords</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">52</span><span class="p">,</span> <span class="mi">29</span><span class="p">)),</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Extracted regions in DMN mode&#39;</span><span class="p">)</span>

<span class="c"># Now add as an overlay by looping over all the regions for right</span>
<span class="c"># temporoparietal function, posterior cingulate cortex, medial prefrontal</span>
<span class="c"># cortex, left temporoparietal junction</span>
<span class="n">color_list</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.29</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.54</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.78</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.96</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.73</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.47</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.22</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">0.26</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]</span>
<span class="k">for</span> <span class="n">each_index_of_map3</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="n">izip</span><span class="p">(</span><span class="n">regions_indices_of_map3</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color_list</span><span class="p">):</span>
    <span class="n">display</span><span class="o">.</span><span class="n">add_overlay</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">index_img</span><span class="p">(</span><span class="n">regions_extracted_img</span><span class="p">,</span> <span class="n">each_index_of_map3</span><span class="p">),</span>
                        <span class="n">cmap</span><span class="o">=</span><span class="n">plotting</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">alpha_cmap</span><span class="p">(</span><span class="n">color</span><span class="p">))</span>

<span class="n">plotting</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p class="centered">
<strong><a class="reference external image-reference" href="../auto_examples/connectivity/plot_extract_regions_canica_maps.html"><img alt="dmn" src="../_images/sphx_glr_plot_extract_regions_canica_maps_0051.png" style="width: 330.0px; height: 130.0px;" /></a>
 <a class="reference external image-reference" href="../auto_examples/connectivity/plot_extract_regions_canica_maps.html"><img alt="dmn_reg" src="../_images/sphx_glr_plot_extract_regions_canica_maps_0061.png" style="width: 330.0px; height: 130.0px;" /></a>
</strong></p><div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last">The full code can be found as an example:
<a class="reference internal" href="../auto_examples/connectivity/plot_extract_regions_canica_maps.html#sphx-glr-auto-examples-connectivity-plot-extract-regions-canica-maps-py"><em>Regions extraction using Canonical ICA maps and functional connectomes</em></a></p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../np-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="../manipulating_visualizing/index.html" title="4. Image manipulation and visualization"
             >next</a> |</li>
        <li class="right" >
          <a href="parcellating.html" title="3.4. Parcellating the brain in regions"
             >previous</a> |</li>
<li><a href="../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../AUTHORS.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li><a href="../user_guide.html" >User guide: table of contents</a> &raquo;</li>
          <li><a href="index.html" >3. Functional connectivity and resting state</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
            &copy; The nilearn developers 2010-2015.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.2.3.
        <span style="padding-left: 5ex;">
          <a href="../_sources/connectivity/region_extraction.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>