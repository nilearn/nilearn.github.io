:orphan:

########
Examples
########

.. warning::

    If you want to run the examples, make sure you execute them in a directory
    where you have write permissions, or you copy the examples into such a
    directory. If you install nilearn manually, make sure you have followed
    :ref:`the instructions <installation>`.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. thumbnail-parent-div-close

.. raw:: html

    </div>


===============
Basic tutorials
===============

Introductory examples that teach how to use nilearn.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Basic numerics and plotting with Python">

.. only:: html

  .. image:: /auto_examples/00_tutorials/images/thumb/sphx_glr_plot_python_101_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_00_tutorials_plot_python_101.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Basic numerics and plotting with Python</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Here we discover how to work with 3D and 4D niimgs.">

.. only:: html

  .. image:: /auto_examples/00_tutorials/images/thumb/sphx_glr_plot_3d_and_4d_niimg_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_00_tutorials_plot_3d_and_4d_niimg.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">3D and 4D niimgs: handling and visualizing</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A simple example showing how to load an existing Nifti file and use basic nilearn functionalities.">

.. only:: html

  .. image:: /auto_examples/00_tutorials/images/thumb/sphx_glr_plot_nilearn_101_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_00_tutorials_plot_nilearn_101.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Basic nilearn example: manipulating and looking at data</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Here we explain how surface images are represented within Nilearn and how you can plot, save and load them.">

.. only:: html

  .. image:: /auto_examples/00_tutorials/images/thumb/sphx_glr_plot_surface_101_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_00_tutorials_plot_surface_101.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Working with Surface images</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Here is a simple tutorial on decoding with nilearn. It reproduces the :footciteHaxby2001 study on a face vs cat discrimination task in a mask of the ventral stream.">

.. only:: html

  .. image:: /auto_examples/00_tutorials/images/thumb/sphx_glr_plot_decoding_tutorial_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_00_tutorials_plot_decoding_tutorial.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">A introduction tutorial to fMRI decoding</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this tutorial, we use a General Linear Model (GLM) to compare the fMRI signal during periods of auditory stimulation versus periods of rest.">

.. only:: html

  .. image:: /auto_examples/00_tutorials/images/thumb/sphx_glr_plot_single_subject_single_run_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_00_tutorials_plot_single_subject_single_run.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Intro to GLM Analysis: a single-run, single-subject fMRI dataset</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>

=============================
Visualization of brain images
=============================

See :ref:`plotting` for more details.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="See plotting for more plotting functionalities.">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_demo_glass_brain_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_demo_glass_brain.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Glass brain plotting in nilearn</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to fetch network matrices data from HCP beta-release of the Functional Connectivity Megatrawl project.">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_visualize_megatrawls_netmats_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_visualize_megatrawls_netmats.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Visualizing Megatrawls Network Matrices from Human Connectome Project</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to visualize probabilistic atlases made of 4D images. There are 3 different display types:">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_prob_atlas_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_prob_atlas.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Visualizing 4D probabilistic atlas maps</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot the regions of a reference atlas (Harvard-Oxford and Juelich atlases).">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_atlas_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_atlas.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Basic Atlas plotting</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Visualizing a probabilistic atlas requires visualizing the different maps that compose it.">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_overlay_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_overlay.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Visualizing a probabilistic atlas: the default mode in the MSDL atlas</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The dim argument controls the contrast of the background.">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_dim_plotting_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_dim_plotting.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Controlling the contrast of the background when plotting</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to download and fetch brain parcellations of multiple networks using fetch_atlas_basc_multiscale_2015 and visualize them using plotting function plot_roi.">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_multiscale_parcellations_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_multiscale_parcellations.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Visualizing multiscale functional brain parcellations</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Visualize HCP connectome workbench color maps shipped with Nilearn which can be used for plotting brain images on surface.">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_colormaps_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_colormaps.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Matplotlib colormaps in Nilearn</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Simple example to show Nifti data visualization.">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_visualization_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_visualization.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">NeuroImaging volumes visualization</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A common quality control step for functional MRI data is to visualize the data over time in a carpet plot (also known as a Power plot or a grayplot).">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_carpet_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_carpet.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Visualizing global patterns with a carpet plot</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Small script to plot the masks of the Haxby dataset.">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_haxby_masks_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_haxby_masks.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot Haxby masks</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In nilearn, vol_to_surf allows us to measure values of a 3d volume at the nodes of a cortical mesh, transforming it into surface data. This data can then be plotted with plot_surf_stat_map for example.">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_surface_projection_strategies_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_surface_projection_strategies.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Technical point: Illustration of the volume to surface sampling schemes</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Nilearn comes with a set of plotting functions for easy visualization of Nifti-like images such as statistical maps mapped onto anatomical images or onto glass brain representation, anatomical images, functional/EPI images, region specific mask images.">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_demo_plotting_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_demo_plotting.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plotting tools in nilearn</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The Destrieux parcellation (:footciteDestrieux2010) in fsaverage5 space as distributed with Freesurfer is used as the chosen atlas.">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_surf_atlas_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_surf_atlas.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Loading and plotting of a cortical surface atlas</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we show how to use some plotting options available with plotting functions of nilearn. These techniques are essential for visualizing brain image analysis results.">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_demo_more_plotting_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_demo_more_plotting.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">More plotting tools from nilearn</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The first part of this example goes through different options of the plot_glass_brain function (including plotting negative values).">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_demo_glass_brain_extensive_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_demo_glass_brain_extensive.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Glass brain plotting in nilearn (all options)</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example we compute the functional connectivity of a seed region to all other cortical nodes in the same hemisphere using Pearson product-moment correlation coefficient.">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_surf_stat_map_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_surf_stat_map.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Seed-based connectivity on the surface</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we will project a 3D statistical map onto a cortical mesh using SurfaceImage, display a surface plot of the projected map using plot_surf_stat_map with different plotting engines, and add contours of regions of interest using plot_surf_contours.">

.. only:: html

  .. image:: /auto_examples/01_plotting/images/thumb/sphx_glr_plot_3d_map_to_surface_projection_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_01_plotting_plot_3d_map_to_surface_projection.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Making a surface plot of a 3D statistical map</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>

=========================================
Decoding and predicting from brain images
=========================================

See :ref:`decoding` for more details.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this script we plot an overview of the stimuli used in :footciteHaxby2001.">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_haxby_stimuli_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_haxby_stimuli.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Show stimuli of Haxby et al. dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we use fast ensembling of regularized models (FREM) to solve a regression problem, predicting the gain level corresponding to each Beta maps regressed from mixed gambles experiment. FREM uses an implicit spatial regularization through fast clustering and aggregates a high number of  estimators trained on various splits of the training set, thus returning a very robust decoder at a lower computational cost than other spatially regularized methods.">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_mixed_gambles_frem_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_mixed_gambles_frem.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">FREM on Jimura et al "mixed gambles" dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Predicting age from gray-matter concentration maps from OASIS dataset. Note that age is a continuous variable, we use the regressor here, and not the classification object.">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_oasis_vbm_space_net_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_oasis_vbm_space_net.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Voxel-Based Morphometry on Oasis dataset with Space-Net prior</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example uses fast ensembling of regularized models (FREM) to decode a face vs house vs chair discrimination task from :footciteHaxby2001 study. FREM uses an implicit spatial regularization through fast clustering and aggregates a high number of estimators trained on various splits of the training set, thus returning a very robust decoder at a lower computational cost than other spatially regularized methods.">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_haxby_frem_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_haxby_frem.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Decoding with FREM: face vs house vs chair object recognition</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example does a simple but efficient decoding on the Haxby dataset: using a feature selection, followed by an SVM.">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_haxby_anova_svm_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_haxby_anova_svm.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Decoding with ANOVA + SVM: face vs house in the Haxby dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="We compare one vs all and one vs one multi-class strategies: the overall cross-validated accuracy and the confusion matrix.">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_haxby_multiclass_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_haxby_multiclass.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">The haxby dataset: different multi-class strategies</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This is a demo for surface-based searchlight decoding, as described in :footciteChen2011.">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_haxby_searchlight_surface_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_haxby_searchlight_surface.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Cortical surface-based searchlight decoding</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Searchlight analysis requires fitting a classifier a large amount of times. As a result, it is an intrinsically slow method. In order to speed up computing, in this example, Searchlight is run only on one slice on the fMRI (see the generated figures).">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_haxby_searchlight_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_haxby_searchlight.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Searchlight analysis of face vs house recognition</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Full step-by-step example of fitting a GLM to perform a decoding experiment. In this decoding analysis, we will be doing a one-vs-all classification. We use the data from one subject of the Haxby dataset.">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_haxby_glm_decoding_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_haxby_glm_decoding.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Decoding of a dataset after GLM fit for signal extraction</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this script we reproduce the data analysis conducted by :footciteHaxby2001.">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_haxby_full_analysis_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_haxby_full_analysis.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">ROI-based decoding analysis in Haxby et al. dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Here we set the number of features selected in an Anova-SVC approach to maximize the cross-validation score.">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_haxby_grid_search_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_haxby_grid_search.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Setting a parameter by cross-validation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example uses Voxel-Based Morphometry (VBM) to study the relationship between aging and gray matter density.">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_oasis_vbm_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_oasis_vbm.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Voxel-Based Morphometry on Oasis dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Here we compare different classifiers on a visual object recognition decoding task.">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_haxby_different_estimators_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_haxby_different_estimators.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Different classifiers in decoding the Haxby dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Nilearn&#x27;s Decoder object is a composite estimator that does several things under the hood and can hence be a bit difficult to understand at first.">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_haxby_understand_decoder_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_haxby_understand_decoder.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Understanding Decoder</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example simulates data according to a very simple sketch of brain imaging data and applies machine learning techniques to predict output values.">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_simulated_data_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_simulated_data.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Example of pattern recognition on simulated data</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example partly reproduces the encoding model presented in :footciteMiyawaki2008.">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_miyawaki_encoding_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_miyawaki_encoding.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Encoding models for visual stimuli from Miyawaki et al. 2008</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example reproduces the experiment presented in :footciteMiyawaki2008.">

.. only:: html

  .. image:: /auto_examples/02_decoding/images/thumb/sphx_glr_plot_miyawaki_reconstruction_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_02_decoding_plot_miyawaki_reconstruction.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Reconstruction of visual stimuli from Miyawaki et al. 2008</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>

=======================
Functional connectivity
=======================

See :ref:`parcellating_brain`, :ref:`extracting_rsn` or
:ref:`functional_connectomes` for more details.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example constructs a functional connectome using the sparse inverse covariance.">

.. only:: html

  .. image:: /auto_examples/03_connectivity/images/thumb/sphx_glr_plot_inverse_covariance_connectome_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_03_connectivity_plot_inverse_covariance_connectome.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Computing a connectome with sparse inverse covariance</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example extracts the signal on regions defined via a probabilistic atlas, to construct a functional connectome.">

.. only:: html

  .. image:: /auto_examples/03_connectivity/images/thumb/sphx_glr_plot_probabilistic_atlas_extraction_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_03_connectivity_plot_probabilistic_atlas_extraction.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Extracting signals of a probabilistic atlas of functional regions</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows a comparison of graph lasso and group-sparse covariance estimation of connectivity structure for a synthetic dataset.">

.. only:: html

  .. image:: /auto_examples/03_connectivity/images/thumb/sphx_glr_plot_simulated_connectome_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_03_connectivity_plot_simulated_connectome.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Connectivity structure estimation on simulated data</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to estimate a connectome on a group of subjects using the group sparse inverse covariance estimate.">

.. only:: html

  .. image:: /auto_examples/03_connectivity/images/thumb/sphx_glr_plot_multi_subject_connectome_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_03_connectivity_plot_multi_subject_connectome.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Group Sparse inverse covariance for multi-subject connectome</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Various approaches exist to derive spatial maps or networks from group fmr data. The methods extract distributed brain regions that exhibit similar BOLD fluctuations over time. Decomposition methods allow for generation of many independent maps simultaneously without the need to provide a priori information (e.g. seeds or priors.)">

.. only:: html

  .. image:: /auto_examples/03_connectivity/images/thumb/sphx_glr_plot_compare_decomposition_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_03_connectivity_plot_compare_decomposition.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to produce seed-to-voxel correlation maps for a single subject based on movie-watching fMRI scans. These maps depict the temporal correlation of a seed region with the rest of the brain.">

.. only:: html

  .. image:: /auto_examples/03_connectivity/images/thumb/sphx_glr_plot_seed_to_voxel_correlation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_03_connectivity_plot_seed_to_voxel_correlation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Producing single subject maps of seed-to-voxel correlation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use RegionExtractor to extract spatially constrained brain regions from whole brain maps decomposed using Dictionary learning and use them to build a functional connectome.">

.. only:: html

  .. image:: /auto_examples/03_connectivity/images/thumb/sphx_glr_plot_extract_regions_dictlearning_maps_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_03_connectivity_plot_extract_regions_dictlearning_maps.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Regions extraction using dictionary learning and functional connectomes</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example compares different kinds of functional connectivity between regions of interest : correlation, partial correlation, and tangent space embedding.">

.. only:: html

  .. image:: /auto_examples/03_connectivity/images/thumb/sphx_glr_plot_group_level_connectivity_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_03_connectivity_plot_group_level_connectivity.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Classification of age groups using functional connectivity</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Here we show how to extract signals from a brain parcellation and compute a correlation matrix.">

.. only:: html

  .. image:: /auto_examples/03_connectivity/images/thumb/sphx_glr_plot_signal_extraction_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_03_connectivity_plot_signal_extraction.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Extracting signals from a brain parcellation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This examples shows how to turn a parcellation into connectome for visualization. This requires choosing centers for each parcel or network, via find_parcellation_cut_coords for parcellation based on labels and find_probabilistic_atlas_cut_coords for parcellation based on probabilistic values.">

.. only:: html

  .. image:: /auto_examples/03_connectivity/images/thumb/sphx_glr_plot_atlas_comparison_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_03_connectivity_plot_atlas_comparison.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparing connectomes on different reference atlases</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to extract signals from spherical regions. We show how to build spheres around user-defined coordinates, as well as centered on coordinates from the Power-264 atlas (:footcitePower2011), and the Dosenbach-160 atlas (:footciteDosenbach2010).">

.. only:: html

  .. image:: /auto_examples/03_connectivity/images/thumb/sphx_glr_plot_sphere_based_connectome_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_03_connectivity_plot_sphere_based_connectome.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Extract signals on spheres and plot a connectome</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="We use spatially-constrained Ward-clustering, KMeans, Hierarchical KMeans and Recursive Neighbor Agglomeration (ReNA) to create a set of parcels.">

.. only:: html

  .. image:: /auto_examples/03_connectivity/images/thumb/sphx_glr_plot_data_driven_parcellations_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_03_connectivity_plot_data_driven_parcellations.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Clustering methods to learn a brain parcellation from fMRI</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>

=========================
GLM: First level analysis
=========================

These are examples focused on showcasing first level models functionality and single subject analysis.

See :ref:`glm` for more details.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows a full step-by-step workflow of fitting a GLM to signal extracted from a seed on the Posterior Cingulate Cortex and saving the results. More precisely, this example shows how to use a signal extracted from a seed region as the regressor in a GLM to determine the correlation of each region in the dataset with the seed region.">

.. only:: html

  .. image:: /auto_examples/04_glm_first_level/images/thumb/sphx_glr_plot_adhd_dmn_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_04_glm_first_level_plot_adhd_dmn.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Default Mode Network extraction of ADHD dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="FIR models are used to estimate the hemodyamic response non-parametrically. The example below shows that they&#x27;re good to do statistical inference even on fast event-related fMRI datasets.">

.. only:: html

  .. image:: /auto_examples/04_glm_first_level/images/thumb/sphx_glr_plot_fir_model_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_04_glm_first_level_plot_fir_model.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A full step-by-step example of fitting a GLM to experimental data sampled on the cortical surface and visualizing the results.">

.. only:: html

  .. image:: /auto_examples/04_glm_first_level/images/thumb/sphx_glr_plot_localizer_surface_analysis_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_04_glm_first_level_plot_localizer_surface_analysis.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Example of surface-based first-level analysis</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Create a BIDS-compatible events.tsv file from onset/trial-type information.">

.. only:: html

  .. image:: /auto_examples/04_glm_first_level/images/thumb/sphx_glr_plot_write_events_file_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_04_glm_first_level_plot_write_events_file.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Generate an events.tsv file for the NeuroSpin localizer task</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The example shows the analysis of an SPM dataset studying face perception. The analysis is performed in native space. Realignment parameters are provided with the input images, but those have not been resampled to a common space.">

.. only:: html

  .. image:: /auto_examples/04_glm_first_level/images/thumb/sphx_glr_plot_spm_multimodal_faces_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_04_glm_first_level_plot_spm_multimodal_faces.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Single-subject data (two runs) in native space</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Within this example we are going to plot the hemodynamic response function (HRF) model in SPM together with the HRF shape proposed by G.Glover, as well as their time and dispersion derivatives. We also illustrate how users can input a custom response function, which can for instance be useful when dealing with non human primate data acquired using a contrast agent. In our case, we input a custom response function for MION, a common agent used to enhance contrast on MRI images of monkeys.">

.. only:: html

  .. image:: /auto_examples/04_glm_first_level/images/thumb/sphx_glr_plot_hrf_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_04_glm_first_level_plot_hrf.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Example of MRI response functions</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Here we fit a First Level GLM with the minimize_memory-argument set to False. By doing so, the FirstLevelModel-object stores the residuals, which we can then inspect. Also, the predicted time series can be extracted, which is useful to assess the quality of the model fit.">

.. only:: html

  .. image:: /auto_examples/04_glm_first_level/images/thumb/sphx_glr_plot_predictions_residuals_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_04_glm_first_level_plot_predictions_residuals.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Predicted time series and residuals</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Three examples of design matrices specification and computation for first-level fMRI data analysis (event-related design, block design, FIR design).">

.. only:: html

  .. image:: /auto_examples/04_glm_first_level/images/thumb/sphx_glr_plot_design_matrix_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_04_glm_first_level_plot_design_matrix.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Examples of design matrices</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip=" Full step-by-step example of fitting a GLM to perform a first level analysis in an openneuro BIDS dataset. We demonstrate how BIDS derivatives can be exploited to perform a simple one subject analysis with minimal code. Details about the BIDS standard are available at https://bids.neuroimaging.io/. We also demonstrate how to download individual groups of files from the Openneuro s3 bucket.">

.. only:: html

  .. image:: /auto_examples/04_glm_first_level/images/thumb/sphx_glr_plot_bids_features_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_04_glm_first_level_plot_bids_features.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">First level analysis of a complete BIDS dataset from openneuro</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Here, we will go through a full step-by-step example of fitting a GLM to experimental data and visualizing the results. This is done on two runs of one subject of the FIAC dataset.">

.. only:: html

  .. image:: /auto_examples/04_glm_first_level/images/thumb/sphx_glr_plot_two_runs_model_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_04_glm_first_level_plot_two_runs_model.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Simple example of two-runs fMRI model fitting</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this tutorial, we study how first-level models are parametrized for fMRI data analysis and clarify the impact of these parameters on the results of the analysis.">

.. only:: html

  .. image:: /auto_examples/04_glm_first_level/images/thumb/sphx_glr_plot_first_level_details_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_04_glm_first_level_plot_first_level_details.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Understanding parameters of the first-level model</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>

===========================
GLM: Second level analysis
===========================

These are examples focused on showcasing second level models functionality and group level analysis.

See :ref:`glm` for more details.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how a second-level design matrix is specified: assuming that the data refer to a group of individuals, with one image per subject, the design matrix typically holds the characteristics of each individual.">

.. only:: html

  .. image:: /auto_examples/05_glm_second_level/images/thumb/sphx_glr_plot_second_level_design_matrix_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_05_glm_second_level_plot_second_level_design_matrix.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Example of second level design matrix</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This script showcases the so-called &quot;All resolution inference&quot; procedure (:footciteRosenblatt2018), in which the proportion of true discoveries in arbitrary clusters is estimated. The clusters can be defined from the input image, i.e. in a circular way, as the error control accounts for arbitrary cluster selection.">

.. only:: html

  .. image:: /auto_examples/05_glm_second_level/images/thumb/sphx_glr_plot_proportion_activated_voxels_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_05_glm_second_level_plot_proportion_activated_voxels.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Second-level fMRI model: true positive proportion in clusters</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Perform a one-sample t-test on a bunch of images (a.k.a. second-level analysis in fMRI) and threshold the resulting statistical map.">

.. only:: html

  .. image:: /auto_examples/05_glm_second_level/images/thumb/sphx_glr_plot_thresholding_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_05_glm_second_level_plot_thresholding.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Statistical testing of a second-level analysis</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Full step-by-step example of fitting a GLM to perform a second level analysis in experimental data and visualizing the results">

.. only:: html

  .. image:: /auto_examples/05_glm_second_level/images/thumb/sphx_glr_plot_second_level_two_sample_test_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_05_glm_second_level_plot_second_level_two_sample_test.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Second-level fMRI model: two-sample test, unpaired and paired</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example uses voxel-based morphometry (VBM) to study the relationship between aging, sex, and gray matter density.">

.. only:: html

  .. image:: /auto_examples/05_glm_second_level/images/thumb/sphx_glr_plot_oasis_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_05_glm_second_level_plot_oasis.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Voxel-Based Morphometry on OASIS dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Full step-by-step example of fitting a GLM to perform a second-level analysis (one-sample test) and visualizing the results.">

.. only:: html

  .. image:: /auto_examples/05_glm_second_level/images/thumb/sphx_glr_plot_second_level_one_sample_test_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_05_glm_second_level_plot_second_level_one_sample_test.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Second-level fMRI model: one sample test</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows the results obtained in a group analysis using a more complex contrast than a one- or two-sample t test. We use the [left button press (auditory cue)] task from the Localizer dataset and seek association between the contrast values and a variate that measures the speed of pseudo-word reading. No confounding variate is included in the model.">

.. only:: html

  .. image:: /auto_examples/05_glm_second_level/images/thumb/sphx_glr_plot_second_level_association_test_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_05_glm_second_level_plot_second_level_association_test.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Example of generic design in second-level models</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>

================================
Manipulating brain image volumes
================================

See :ref:`data_manipulation` for more details.



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The goal of this example is to illustrate the use of the function math_img on T-maps. We compute a negative image by multiplying its voxel values with -1.">

.. only:: html

  .. image:: /auto_examples/06_manipulating_images/images/thumb/sphx_glr_plot_negate_image_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_06_manipulating_images_plot_negate_image.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Negating an image with math_img</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The goal of this example is to illustrate the use of the function math_img with a list of images as input. We compare the means of 2 movie watching 4D images. The mean of the images could have been computed with nilearn mean_img function.">

.. only:: html

  .. image:: /auto_examples/06_manipulating_images/images/thumb/sphx_glr_plot_compare_mean_image_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_06_manipulating_images_plot_compare_mean_image.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparing the means of 2 images</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Here we smooth a mean EPI image and plot the result">

.. only:: html

  .. image:: /auto_examples/06_manipulating_images/images/thumb/sphx_glr_plot_smooth_mean_image_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_06_manipulating_images_plot_smooth_mean_image.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Smoothing an image</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use connected_label_regions to assign each spatially-separated region of the atlas a unique label.">

.. only:: html

  .. image:: /auto_examples/06_manipulating_images/images/thumb/sphx_glr_plot_extract_regions_labels_image_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_06_manipulating_images_plot_extract_regions_labels_image.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Breaking an atlas of labels in separated regions</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This simple example shows how to extract regions from Smith atlas resting state networks.">

.. only:: html

  .. image:: /auto_examples/06_manipulating_images/images/thumb/sphx_glr_plot_extract_rois_smith_atlas_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_06_manipulating_images_plot_extract_rois_smith_atlas.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Regions Extraction of Default Mode Networks using Smith Atlas</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The goal of this example is to illustrate the use of the function resample_to_img to resample an image to a template. We use the MNI152 template as the reference for resampling a t-map image. Function resample_img could also be used to achieve this.">

.. only:: html

  .. image:: /auto_examples/06_manipulating_images/images/thumb/sphx_glr_plot_resample_to_template_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_06_manipulating_images_plot_resample_to_template.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Resample an image to a template</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Here is a simple example of automatic mask computation using the nifti masker. The mask is computed and visualized.">

.. only:: html

  .. image:: /auto_examples/06_manipulating_images/images/thumb/sphx_glr_plot_nifti_simple_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_06_manipulating_images_plot_nifti_simple.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Simple example of NiftiMasker use</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to extract regions or separate the regions from a statistical map.">

.. only:: html

  .. image:: /auto_examples/06_manipulating_images/images/thumb/sphx_glr_plot_extract_rois_statistical_maps_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_06_manipulating_images_plot_extract_rois_statistical_maps.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Region Extraction using a t-statistical map (3D)</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This simple example shows how to extract signals from functional fMRI data and brain regions defined through an atlas. More precisely, this example shows how to use the NiftiLabelsMasker object to perform this operation in just a few lines of code.">

.. only:: html

  .. image:: /auto_examples/06_manipulating_images/images/thumb/sphx_glr_plot_nifti_labels_simple_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_06_manipulating_images_plot_nifti_labels_simple.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Extracting signals from brain regions using the NiftiLabelsMasker</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, the Nifti masker is used to automatically compute a mask.">

.. only:: html

  .. image:: /auto_examples/06_manipulating_images/images/thumb/sphx_glr_plot_mask_computation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_06_manipulating_images_plot_mask_computation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Understanding NiftiMasker and mask computation</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how an affine resampling works.">

.. only:: html

  .. image:: /auto_examples/06_manipulating_images/images/thumb/sphx_glr_plot_affine_transformation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_06_manipulating_images_plot_affine_transformation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Visualization of affine resamplings</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows manual steps to create and further modify an ROI spatial mask. They represent a means for &quot;data folding&quot;, i.e., extracting and then analyzing brain data from a subset of voxels rather than whole brain images. Example can also help alleviate curse of dimensionality (i.e., statistical problems that arise in the context of high-dimensional input variables).">

.. only:: html

  .. image:: /auto_examples/06_manipulating_images/images/thumb/sphx_glr_plot_roi_extraction_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_06_manipulating_images_plot_roi_extraction.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Computing a Region of Interest (ROI) mask manually</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>

=============================================
Advanced statistical analysis of brain images
=============================================



.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example is meant to demonstrate nilearn as a low-level tools used to combine feature extraction with a multivariate decomposition algorithm for movie-watching.">

.. only:: html

  .. image:: /auto_examples/07_advanced/images/thumb/sphx_glr_plot_ica_resting_state_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_07_advanced_plot_ica_resting_state.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Multivariate decompositions: Independent component analysis of fMRI</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use the Localizer dataset in a basic analysis. A standard Anova is performed (massively univariate F-test) and the resulting Bonferroni-corrected p-values are plotted. We use a calculation task and 20 subjects out of the 94 available.">

.. only:: html

  .. image:: /auto_examples/07_advanced/images/thumb/sphx_glr_plot_localizer_simple_analysis_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_07_advanced_plot_localizer_simple_analysis.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Massively univariate analysis of a calculation task from the Localizer dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to copy the header information from one of the input images to the result image when using the function math_img.">

.. only:: html

  .. image:: /auto_examples/07_advanced/images/thumb/sphx_glr_plot_copy_headers_math_img_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_07_advanced_plot_copy_headers_math_img.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Copying headers from input images with math_img</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Full step-by-step example of fitting a GLM to perform a first and second level analysis in a BIDS dataset and visualizing the results. Details about the BIDS standard can be consulted at https://bids.neuroimaging.io/.">

.. only:: html

  .. image:: /auto_examples/07_advanced/images/thumb/sphx_glr_plot_bids_analysis_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_07_advanced_plot_bids_analysis.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">BIDS dataset first and second level analysis</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to download statistical maps from Neurovault.">

.. only:: html

  .. image:: /auto_examples/07_advanced/images/thumb/sphx_glr_plot_neurovault_meta_analysis_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_07_advanced_plot_neurovault_meta_analysis.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">NeuroVault meta-analysis of stop-go paradigm studies</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Full step-by-step example of fitting a GLM (first and second level analysis) in a 10-subjects dataset and visualizing the results.">

.. only:: html

  .. image:: /auto_examples/07_advanced/images/thumb/sphx_glr_plot_surface_bids_analysis_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_07_advanced_plot_surface_bids_analysis.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Surface-based dataset first and second level analysis of a dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example compares different kinds of functional connectivity between regions of interest : correlation, partial correlation, and tangent space embedding.">

.. only:: html

  .. image:: /auto_examples/07_advanced/images/thumb/sphx_glr_plot_age_group_prediction_cross_val_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_07_advanced_plot_age_group_prediction_cross_val.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Functional connectivity predicts age group</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to download statistical maps from NeuroVault, label them with NeuroSynth terms, and compute ICA components across all the maps.">

.. only:: html

  .. image:: /auto_examples/07_advanced/images/thumb/sphx_glr_plot_ica_neurovault_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_07_advanced_plot_ica_neurovault.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">NeuroVault cross-study ICA maps</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows the results obtained in a massively univariate analysis performed at the inter-subject level with various methods. We use the [left button press (auditory cue)] task from the Localizer dataset and seek association between the contrast values and a variate that measures the speed of pseudo-word reading. No confounding variate is included in the model.">

.. only:: html

  .. image:: /auto_examples/07_advanced/images/thumb/sphx_glr_plot_localizer_mass_univariate_methods_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_07_advanced_plot_localizer_mass_univariate_methods.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Massively univariate analysis of a motor task from the Localizer dataset</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows some more &#x27;advanced&#x27; features to work with surface images.">

.. only:: html

  .. image:: /auto_examples/07_advanced/images/thumb/sphx_glr_plot_surface_image_and_maskers_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_07_advanced_plot_surface_image_and_maskers.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">A short demo of the surface images & maskers</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A permuted Ordinary Least Squares algorithm is run at each voxel in order to determine whether or not it behaves differently under a &quot;face viewing&quot; condition and a &quot;house viewing&quot; condition. We consider the mean image per run and per condition. Otherwise, the observations cannot be exchanged at random because a time dependence exists between observations within a same run (see :footciteWinkler2014 for more detailed explanations).">

.. only:: html

  .. image:: /auto_examples/07_advanced/images/thumb/sphx_glr_plot_haxby_mass_univariate_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_07_advanced_plot_haxby_mass_univariate.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Massively univariate analysis of face vs house recognition</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This tutorial opens the box of decoding pipelines to bridge integrated functionalities provided by the Decoder object with more advanced usecases. It reproduces basic examples functionalities with direct calls to scikit-learn function and gives pointers to more advanced objects. If some concepts seem unclear, please refer to the documentation on decoding &lt;decoding_intro&gt; and in particular to the advanced section &lt;going_further&gt;. As in many other examples, we perform decoding of the visual category of a stimuli on :footciteHaxby2001 dataset, focusing on distinguishing two categories: face and cat images.">

.. only:: html

  .. image:: /auto_examples/07_advanced/images/thumb/sphx_glr_plot_advanced_decoding_scikit_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_07_advanced_plot_advanced_decoding_scikit.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Advanced decoding using scikit learn</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows how to run beta series GLM models, which are a common modeling approach for a variety of analyses of task-based fMRI data with an event-related task design, including functional connectivity, Decoding, and representational similarity analysis.">

.. only:: html

  .. image:: /auto_examples/07_advanced/images/thumb/sphx_glr_plot_beta_series_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_07_advanced_plot_beta_series.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Beta-Series Modeling for Task-Based Functional Connectivity and Decoding</div>
    </div>


.. thumbnail-parent-div-close

.. raw:: html

    </div>


.. toctree::
   :hidden:
   :includehidden:


   /auto_examples/00_tutorials/index.rst
   /auto_examples/01_plotting/index.rst
   /auto_examples/02_decoding/index.rst
   /auto_examples/03_connectivity/index.rst
   /auto_examples/04_glm_first_level/index.rst
   /auto_examples/05_glm_second_level/index.rst
   /auto_examples/06_manipulating_images/index.rst
   /auto_examples/07_advanced/index.rst


.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-gallery

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download all examples in Python source code: auto_examples_python.zip </auto_examples/auto_examples_python.zip>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download all examples in Jupyter notebooks: auto_examples_jupyter.zip </auto_examples/auto_examples_jupyter.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
