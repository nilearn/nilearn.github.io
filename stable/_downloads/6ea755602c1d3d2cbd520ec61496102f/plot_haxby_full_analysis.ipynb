{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# ROI-based decoding analysis in Haxby et al. dataset\n\nIn this script we reproduce the data analysis\nconducted by :footcite:t:`Haxby2001`.\n\nSpecifically, we look at decoding accuracy for different objects in\nthree different masks: the full ventral stream (mask_vt), the house\nselective areas (mask_house) and the face selective areas (mask_face),\nthat have been defined via a standard GLM-based analysis.\n\n.. include:: ../../../examples/masker_note.rst\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Fetch data using nilearn dataset fetcher\nfrom nilearn import datasets\nfrom nilearn.plotting import show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and prepare the data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# by default we fetch 2nd subject data for analysis\nhaxby_dataset = datasets.fetch_haxby()\nfunc_filename = haxby_dataset.func[0]\n\n# Print basic information on the dataset\nprint(\n    \"First subject anatomical nifti image (3D) located is \"\n    f\"at: {haxby_dataset.anat[0]}\"\n)\nprint(\n    \"First subject functional nifti image (4D) is located \"\n    f\"at: {func_filename}\"\n)\n\n# load labels\nimport pandas as pd\n\n# Load nilearn NiftiMasker, the practical masking and unmasking tool\nfrom nilearn.maskers import NiftiMasker\n\nlabels = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\nstimuli = labels[\"labels\"]\n# identify resting state labels in order to be able to remove them\ntask_mask = stimuli != \"rest\"\n\n# find names of remaining active labels\ncategories = stimuli[task_mask].unique()\n\n# extract tags indicating to which acquisition run a tag belongs\nrun_labels = labels[\"chunks\"][task_mask]\n\n# apply the task_mask to  fMRI data (func_filename)\nfrom nilearn.image import index_img\n\ntask_data = index_img(func_filename, task_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Decoding on the different masks\n\nThe classifier used here is a support vector classifier (svc).\nWe use\n:class:`~nilearn.decoding.Decoder` and specify the classifier.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\n# Make a data splitting object for cross validation\nfrom sklearn.model_selection import LeaveOneGroupOut\n\nfrom nilearn.decoding import Decoder\n\ncv = LeaveOneGroupOut()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use :class:`~nilearn.decoding.Decoder` to estimate a baseline.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mask_names = [\"mask_vt\", \"mask_face\", \"mask_house\"]\n\nmask_scores = {}\nmask_chance_scores = {}\n\nfor mask_name in mask_names:\n    print(f\"Working on {mask_name}\")\n    # For decoding, standardizing is often very important\n    mask_filename = haxby_dataset[mask_name][0]\n    masker = NiftiMasker(mask_img=mask_filename, standardize=\"zscore_sample\")\n    mask_scores[mask_name] = {}\n    mask_chance_scores[mask_name] = {}\n\n    for category in categories:\n        print(f\"Processing {mask_name} {category}\")\n        classification_target = stimuli[task_mask] == category\n        # Specify the classifier to the decoder object.\n        # With the decoder we can input the masker directly.\n        # We are using the svc_l1 here because it is intra subject.\n        decoder = Decoder(\n            estimator=\"svc_l1\",\n            cv=cv,\n            mask=masker,\n            scoring=\"roc_auc\",\n            standardize=\"zscore_sample\",\n        )\n        decoder.fit(task_data, classification_target, groups=run_labels)\n        mask_scores[mask_name][category] = decoder.cv_scores_[1]\n        mean = np.mean(mask_scores[mask_name][category])\n        std = np.std(mask_scores[mask_name][category])\n        print(f\"Scores: {mean:1.2f} +- {std:1.2f}\")\n\n        dummy_classifier = Decoder(\n            estimator=\"dummy_classifier\",\n            cv=cv,\n            mask=masker,\n            scoring=\"roc_auc\",\n            standardize=\"zscore_sample\",\n        )\n        dummy_classifier.fit(\n            task_data, classification_target, groups=run_labels\n        )\n        mask_chance_scores[mask_name][category] = dummy_classifier.cv_scores_[\n            1\n        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## We make a simple bar plot to summarize the results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nplt.figure(constrained_layout=True)\n\ntick_position = np.arange(len(categories))\nplt.xticks(tick_position, categories, rotation=45)\n\nfor color, mask_name in zip(\"rgb\", mask_names):\n    score_means = [\n        np.mean(mask_scores[mask_name][category]) for category in categories\n    ]\n    plt.bar(\n        tick_position, score_means, label=mask_name, width=0.25, color=color\n    )\n\n    score_chance = [\n        np.mean(mask_chance_scores[mask_name][category])\n        for category in categories\n    ]\n    plt.bar(\n        tick_position,\n        score_chance,\n        width=0.25,\n        edgecolor=\"k\",\n        facecolor=\"none\",\n    )\n\n    tick_position = tick_position + 0.2\n\nplt.ylabel(\"Classification accuracy (AUC score)\")\nplt.xlabel(\"Visual stimuli category\")\nplt.ylim(0.3, 1)\nplt.legend(loc=\"lower right\")\nplt.title(\"Category-specific classification accuracy for different masks\")\n\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n\n .. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
