{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Voxel-Based Morphometry on Oasis dataset\n\nThis example uses Voxel-Based Morphometry (:term:`VBM`)\nto study the relationship between aging and gray matter density.\n\nThe data come from the [OASIS](https://sites.wustl.edu/oasisbrains/) project.\nIf you use it, you need to agree with the data usage agreement available\non the website.\n\nIt has been run through a standard :term:`VBM` pipeline (using SPM8 and\nNewSegment) to create :term:`VBM` maps, which we study here.\n\n## Predictive modeling analysis: VBM bio-markers of aging?\n\nWe run a standard SVM-ANOVA nilearn pipeline to predict age from the VBM\ndata. We use only 100 subjects from the OASIS dataset to limit the memory\nusage.\n\nNote that for an actual predictive modeling study of aging, the study\nshould be ran on the full set of subjects. Also, all parameters should be set\nby cross-validation. This includes the smoothing applied to the data and the\nnumber of features selected by the :term:`ANOVA` step. Indeed, even these\ndata-preparation parameter impact significantly the prediction score.\n\n\nAlso, parameters such as the smoothing should be applied to the data and the\nnumber of features selected by the :term:`ANOVA` step should be set by nested\ncross-validation, as they impact significantly the prediction score.\n\n## Brain mapping with mass univariate\n\n:term:`SVM` weights are very noisy,\npartly because heavy smoothing is detrimental for the prediction here.\nA standard analysis using mass-univariate :term:`GLM`\n(here permuted to have exact correction for multiple comparisons) gives a\nmuch clearer view of the important regions.\n\n____\n\n.. include:: ../../../examples/masker_note.rst\n\n..\n    Original authors:\n\n    - Elvis Dhomatob, Apr. 2014\n    - Virgile Fritsch, Apr 2014\n    - Gael Varoquaux, Apr 2014\n    - Andres Hoyos-Idrobo, Apr 2017\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom nilearn.datasets import fetch_oasis_vbm\nfrom nilearn.image import get_data\nfrom nilearn.maskers import NiftiMasker\n\nn_subjects = 100  # more subjects requires more memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Oasis dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "oasis_dataset = fetch_oasis_vbm(n_subjects=n_subjects, legacy_format=False)\ngray_matter_map_filenames = oasis_dataset.gray_matter_maps\nage = oasis_dataset.ext_vars[\"age\"].to_numpy()\n\n# Split data into training set and test set\nfrom sklearn.model_selection import train_test_split\n\ngm_imgs_train, gm_imgs_test, age_train, age_test = train_test_split(\n    gray_matter_map_filenames, age, train_size=0.6, random_state=0\n)\n\n# print basic information on the dataset\nprint(\n    \"First gray-matter anatomy image (3D) is located at: \"\n    f\"{oasis_dataset.gray_matter_maps[0]}\"\n)\nprint(\n    \"First white-matter anatomy image (3D) is located at: \"\n    f\"{oasis_dataset.white_matter_maps[0]}\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocess data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nifti_masker = NiftiMasker(\n    standardize=False, smoothing_fwhm=2, memory=\"nilearn_cache\"\n)  # cache options\ngm_maps_masked = nifti_masker.fit_transform(gm_imgs_train)\n\n# The features with too low between-subject variance are removed using\n# :class:`sklearn.feature_selection.VarianceThreshold`.\nfrom sklearn.feature_selection import VarianceThreshold\n\nvariance_threshold = VarianceThreshold(threshold=0.01)\nvariance_threshold.fit_transform(gm_maps_masked)\n\n# Then we convert the data back to the mask image in order to use it for\n# decoding process\nmask = nifti_masker.inverse_transform(variance_threshold.get_support())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prediction pipeline with :term:`ANOVA` and SVR using\n:class:`~nilearn.decoding.DecoderRegressor` Object\n\nIn nilearn we can benefit from the built-in DecoderRegressor object to\ndo :term:`ANOVA` with SVR instead of manually defining the whole pipeline.\nThis estimator also uses Cross Validation to select best models and ensemble\nthem. Furthermore, you can pass ``n_jobs=<some_high_value>`` to the\nDecoderRegressor class to take advantage of a multi-core system.\nTo save time (because these are anat images with many voxels), we include\nonly the 1-percent voxels most correlated with the age variable to fit. We\nalso want to set mask hyperparameter to be the mask we just obtained above.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.decoding import DecoderRegressor\n\ndecoder = DecoderRegressor(\n    estimator=\"svr\",\n    mask=mask,\n    scoring=\"neg_mean_absolute_error\",\n    screening_percentile=1,\n    n_jobs=2,\n    standardize=\"zscore_sample\",\n)\n# Fit and predict with the decoder\ndecoder.fit(gm_imgs_train, age_train)\n\n# Sort test data for better visualization (trend, etc.)\nperm = np.argsort(age_test)[::-1]\nage_test = age_test[perm]\ngm_imgs_test = np.array(gm_imgs_test)[perm]\nage_pred = decoder.predict(gm_imgs_test)\n\nprediction_score = -np.mean(decoder.cv_scores_[\"beta\"])\n\nprint(\"=== DECODER ===\")\nprint(f\"explained variance for the cross-validation: {prediction_score:f}\")\nprint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "weight_img = decoder.coef_img_[\"beta\"]\n\n# Create the figure\nfrom nilearn.plotting import plot_stat_map, show\n\nbg_filename = gray_matter_map_filenames[0]\nz_slice = 0\ndisplay = plot_stat_map(\n    weight_img, bg_img=bg_filename, display_mode=\"z\", cut_coords=[z_slice]\n)\ndisplay.title(\"SVM weights\")\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the quality of predictions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nplt.figure(figsize=(6, 4.5))\nplt.suptitle(f\"Decoder: Mean Absolute Error {prediction_score:.2f} years\")\nlinewidth = 3\nplt.plot(age_test, label=\"True age\", linewidth=linewidth)\nplt.plot(age_pred, \"--\", c=\"g\", label=\"Predicted age\", linewidth=linewidth)\nplt.ylabel(\"age\")\nplt.xlabel(\"subject\")\nplt.legend(loc=\"best\")\nplt.figure(figsize=(6, 4.5))\nplt.plot(\n    age_test - age_pred, label=\"True age - predicted age\", linewidth=linewidth\n)\nplt.xlabel(\"subject\")\nplt.legend(loc=\"best\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference with massively univariate model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Massively univariate model\")\n\ngm_maps_masked = NiftiMasker().fit_transform(gray_matter_map_filenames)\ndata = variance_threshold.fit_transform(gm_maps_masked)\n\n# Statistical inference\nfrom nilearn.mass_univariate import permuted_ols\n\n# This can be changed to use more CPUs.\nneg_log_pvals, t_scores_original_data, _ = permuted_ols(\n    age,\n    data,  # + intercept as a covariate by default\n    n_perm=2000,  # 1,000 in the interest of time; 10000 would be better\n    verbose=1,  # display progress bar\n    n_jobs=2,\n)\nsigned_neg_log_pvals = neg_log_pvals * np.sign(t_scores_original_data)\nsigned_neg_log_pvals_unmasked = nifti_masker.inverse_transform(\n    variance_threshold.inverse_transform(signed_neg_log_pvals)\n)\n\n# Show results\nthreshold = -np.log10(0.1)  # 10% corrected\n\nfig = plt.figure(figsize=(5.5, 7.5), facecolor=\"k\")\n\ndisplay = plot_stat_map(\n    signed_neg_log_pvals_unmasked,\n    bg_img=bg_filename,\n    threshold=threshold,\n    cmap=plt.cm.RdBu_r,\n    display_mode=\"z\",\n    cut_coords=[z_slice],\n    figure=fig,\n)\ntitle = (\n    \"Negative $\\\\log_{10}$ p-values\\n(Non-parametric + max-type correction)\"\n)\ndisplay.title(title)\n\nn_detections = (get_data(signed_neg_log_pvals_unmasked) > threshold).sum()\nprint(f\"\\n{int(n_detections)} detections\")\n\nshow()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
