
<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>NiLearn: Machine learning for NeuroImaging in Python &mdash; Machine learning for NeuroImaging</title>
    
    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.1b1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="top" title="Machine learning for NeuroImaging" href="../index.html" />
    <link rel="up" title="3. The nilearn building blocks" href="index.html" />
    <link rel="next" title="3.6.3.1.1. nilearn.masking.compute_epi_mask" href="generated/nilearn.masking.compute_epi_mask.html" />
    <link rel="prev" title="3.5. Plotting brain images" href="plotting.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">
<script type="text/javascript">
$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var top = 105 + $('.sphinxsidebarwrapper').offset().top - parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0)),
        sections = {},
        i        = 0,
	url	 = document.URL.replace(/#.*$/, ""),
	current_section = 0;

    // Grab positions of our sections 
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50;
    });

    $(window).scroll(function(event) {
	var pos   = $(window).scrollTop();
	// Lock the table of content to a fixed position once we scroll enough
	if(pos > top){
	    //begin to scroll
	    $('.sphinxsidebarwrapper').css("position", "fixed");
	    $('.sphinxsidebarwrapper').css("top", -105);
	}
	else{
	    //lock it back into place
	    $('.sphinxsidebarwrapper').css("position", "relative");
	    $('.sphinxsidebarwrapper').css("top",0);
	}
            
	// Highlight the current section
	$('a.internal').removeClass('active');
        for(i in sections){
            if(sections[i] > pos){
		break;
            };
	    if($('a.internal[href$="' + i + '"]').is(':visible')){
		current_section = i;
	    };
        }
	$('a.internal[href$="' + current_section + '"]').addClass('active');
    });

});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head>
  <body>
<div id="logo-banner">
  <div class="logo">
    <a href="../index.html">
      <img src="../_static/nilearn-logo.png" alt="NiLearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../auto_examples/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../data_analysis/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="haxby_searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../data_analysis/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../modules/reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>NiLearn:</h1>
    <h2>Machine learning for Neuro-Imaging in Python</h2>
  </div>
  <div class="search_form">
    <div id="cse" style="width: 100%;"></div>
    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">
      google.load('search', '1', {language : 'en'});
      google.setOnLoadCallback(function() {
      var customSearchControl = new google.search.CustomSearchControl('014136483057745874622:r-npolb1uki');
      customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
      var options = new google.search.DrawOptions();
      options.setAutoComplete(true);
      customSearchControl.draw('cse', options);
      }, true);
    </script>
  </div>
</div>



    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../np-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="generated/nilearn.masking.compute_epi_mask.html" title="3.6.3.1.1. nilearn.masking.compute_epi_mask"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="plotting.html" title="3.5. Plotting brain images"
             accesskey="P">previous</a> |</li>
<li><a href="../index.html">NiLearn Home</a> |&nbsp;</li>
<li><a href="../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../AUTHORS.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li><a href="index.html" accesskey="U">3. The nilearn building blocks</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../AUTHORS.html#citing">citing the
                    scikit-learn</a> if you use it.</p></li>
  </ul>

  <h3><a href="../user_guide.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">3.6. MRI data manipulation: input/output, masking, ROIs, smoothing...</a><ul>
<li><a class="reference internal" href="#loading-data">3.6.1. Loading data</a><ul>
<li><a class="reference internal" href="#fetching-datasets">3.6.1.1. Fetching datasets</a></li>
<li><a class="reference internal" href="#loading-your-own-data">3.6.1.2. Loading your own data</a></li>
</ul>
</li>
<li><a class="reference internal" href="#understanding-neuroimaging-data">3.6.2. Understanding Neuroimaging data</a><ul>
<li><a class="reference internal" href="#nifti-and-analyze-files">3.6.2.1. Nifti and Analyze files</a></li>
<li><a class="reference internal" href="#niimg-like-objects">3.6.2.2. Niimg-like objects</a></li>
<li><a class="reference internal" href="#text-files-phenotype-or-behavior">3.6.2.3. Text files: phenotype or behavior</a></li>
</ul>
</li>
<li><a class="reference internal" href="#masking-data-manually">3.6.3. Masking data manually</a><ul>
<li><a class="reference internal" href="#extracting-a-brain-mask">3.6.3.1. Extracting a brain mask</a></li>
<li><a class="reference internal" href="#from-4d-to-2d-arrays">3.6.3.2. From 4D to 2D arrays</a></li>
</ul>
</li>
<li><a class="reference internal" href="#functions-for-data-preparation-steps">3.6.4. Functions for data preparation steps</a></li>
<li><a class="reference internal" href="#image-operations-creating-a-roi-mask-manually">3.6.5. Image operations: creating a ROI mask manually</a><ul>
<li><a class="reference internal" href="#smoothing">3.6.5.1. Smoothing</a></li>
<li><a class="reference internal" href="#selecting-features">3.6.5.2. Selecting features</a></li>
<li><a class="reference internal" href="#thresholding">3.6.5.3. Thresholding</a></li>
<li><a class="reference internal" href="#mask-intersection">3.6.5.4. Mask intersection</a></li>
<li><a class="reference internal" href="#mask-dilation">3.6.5.5. Mask dilation</a></li>
<li><a class="reference internal" href="#extracting-connected-components">3.6.5.6. Extracting connected components</a></li>
<li><a class="reference internal" href="#saving-the-result">3.6.5.7. Saving the result</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="plotting.html"
                        title="previous chapter">3.5. Plotting brain images</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="generated/nilearn.masking.compute_epi_mask.html"
                        title="next chapter">3.6.3.1.1. nilearn.masking.compute_epi_mask</a></p>

<div class="navbar">
</div> <!-- end navbar -->

<script type="text/javascript">$('#searchbox-ml').show(0);</script>
<script type="text/javascript">$('#searchbox-site').show(0);</script>


        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="mri-data-manipulation-input-output-masking-rois-smoothing">
<span id="data-manipulation"></span><h1>3.6. MRI data manipulation: input/output, masking, ROIs, smoothing...<a class="headerlink" href="#mri-data-manipulation-input-output-masking-rois-smoothing" title="Permalink to this headline">¶</a></h1>
<p>This chapter presents the structure of brain image data and tools to
manipulation them.</p>
<div class="contents local topic" id="chapters-contents">
<p class="topic-title first"><strong>Chapters contents</strong></p>
<ul class="simple">
<li><a class="reference internal" href="#loading-data" id="id2">Loading data</a></li>
<li><a class="reference internal" href="#understanding-neuroimaging-data" id="id3">Understanding Neuroimaging data</a></li>
<li><a class="reference internal" href="#masking-data-manually" id="id4">Masking data manually</a></li>
<li><a class="reference internal" href="#functions-for-data-preparation-steps" id="id5">Functions for data preparation steps</a></li>
<li><a class="reference internal" href="#image-operations-creating-a-roi-mask-manually" id="id6">Image operations: creating a ROI mask manually</a></li>
</ul>
</div>
<div class="section" id="loading-data">
<span id="id1"></span><h2><a class="toc-backref" href="#id2">3.6.1. Loading data</a><a class="headerlink" href="#loading-data" title="Permalink to this headline">¶</a></h2>
<div class="section" id="fetching-datasets">
<h3>3.6.1.1. Fetching datasets<a class="headerlink" href="#fetching-datasets" title="Permalink to this headline">¶</a></h3>
<p>Nilearn package embeds a dataset fetching utility to download reference
datasets and atlases. Dataset fetching functions can be imported from
<a class="reference internal" href="../modules/reference.html#module-nilearn.datasets" title="nilearn.datasets"><tt class="xref py py-mod docutils literal"><span class="pre">nilearn.datasets</span></tt></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">haxby_files</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_haxby</span><span class="p">(</span><span class="n">n_subjects</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>They return a structure that contains the different file names:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="c"># The different files</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">haxby_files</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="go">[&#39;mask_house_little&#39;, &#39;anat&#39;, &#39;mask_house&#39;, &#39;mask_face&#39;, &#39;func&#39;, &#39;session_target&#39;, &#39;mask_vt&#39;, &#39;mask_face_little&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c">#  Path to first functional file</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">haxby_files</span><span class="o">.</span><span class="n">func</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> 
<span class="go">/.../nilearn_data/haxby2001/subj1/bold.nii.gz</span>
</pre></div>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>For a list of all the data fetching functions in nilearn, see <a class="reference internal" href="../modules/reference.html#datasets-ref"><em>nilearn.datasets: Automatic Dataset Fetching</em></a>.</p>
<p>The data are downloaded only once and stored locally, in one of the
following directories (in order of priority):</p>
<blockquote>
<div><ul class="simple">
<li>the folder specified by <cite>data_dir</cite> parameter in the fetching function
if it is specified</li>
<li>the global environment variable <cite>NILEARN_SHARED_DATA</cite> if it exists</li>
<li>the user environment variable <cite>NILEARN_DATA</cite> if it exists</li>
<li>the <cite>nilearn_data</cite> folder in the user home folder</li>
</ul>
</div></blockquote>
<p>Two different environment variables are provided to distinguish a global dataset
repository that may be read-only from a user-level one.
Note that you can copy that folder across computers to avoid
downloading the data twice.</p>
</div>
<div class="section" id="loading-your-own-data">
<h3>3.6.1.2. Loading your own data<a class="headerlink" href="#loading-your-own-data" title="Permalink to this headline">¶</a></h3>
<p>Using your own experiment in nilearn is as simple as declaring a list of
your files</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># dataset folder contains subject1.nii and subject2.nii</span>
<span class="n">my_data</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;dataset/subject1.nii&#39;</span><span class="p">,</span> <span class="s">&#39;dataset/subject2.nii&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>Python also provides helpers to work with filepaths. In particular,
<a class="reference external" href="http://docs.python.org/2.7/library/glob.html#glob.glob" title="(in Python v2.7)"><tt class="xref py py-func docutils literal"><span class="pre">glob.glob</span></tt></a> is useful to
list many files with a &#8220;wild-card&#8221;: *.nii</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">The result of <a class="reference external" href="http://docs.python.org/2.7/library/glob.html#glob.glob" title="(in Python v2.7)"><tt class="xref py py-func docutils literal"><span class="pre">glob.glob</span></tt></a> is not sorted. For neuroimaging, you
should always sort the output of glob using the <a class="reference external" href="http://docs.python.org/2.7/library/functions.html#sorted" title="(in Python v2.7)"><tt class="xref py py-func docutils literal"><span class="pre">sorted</span></tt></a>
function.</p>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="c"># dataset folder contains subject1.nii and subject2.nii</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">glob</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s">&#39;dataset/subject*.nii&#39;</span><span class="p">))</span> 
<span class="go">[&#39;dataset/subject1.nii&#39;, &#39;dataset/subject2.nii&#39;]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="understanding-neuroimaging-data">
<h2><a class="toc-backref" href="#id3">3.6.2. Understanding Neuroimaging data</a><a class="headerlink" href="#understanding-neuroimaging-data" title="Permalink to this headline">¶</a></h2>
<div class="section" id="nifti-and-analyze-files">
<h3>3.6.2.1. Nifti and Analyze files<a class="headerlink" href="#nifti-and-analyze-files" title="Permalink to this headline">¶</a></h3>
<div class="topic">
<p class="topic-title first"><strong>NIfTI and Analyze file structures</strong></p>
<p><a class="reference external" href="http://nifti.nimh.nih.gov/">NifTi</a> files (or Analyze files) are
the standard way of sharing data in neuroimaging. We may be
interested in the following three main components:</p>
<blockquote>
<div><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">data:</th><td class="field-body">raw scans bundled in a numpy array: <tt class="docutils literal"><span class="pre">data</span> <span class="pre">=</span> <span class="pre">img.get_data()</span></tt></td>
</tr>
<tr class="field-even field"><th class="field-name">affine:</th><td class="field-body">gives the correspondance between voxel index and spatial location:
<tt class="docutils literal"><span class="pre">affine</span> <span class="pre">=</span> <span class="pre">img.get_affine()</span></tt></td>
</tr>
<tr class="field-odd field"><th class="field-name">header:</th><td class="field-body">informations about the data (slice duration...):
<tt class="docutils literal"><span class="pre">header</span> <span class="pre">=</span> <span class="pre">img.get_header()</span></tt></td>
</tr>
</tbody>
</table>
</div></blockquote>
</div>
<p>Neuroimaging data can be loaded simply thanks to <a class="reference external" href="http://nipy.sourceforge.net/nibabel/">nibabel</a>. Once the file is
downloaded, a single line is needed to load it.</p>
<div class="highlight-python"><div class="highlight"><pre>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first"><strong>Dataset formatting: data shape</strong></p>
<p>We can find two main representations for MRI scans:</p>
<ul class="simple">
<li>a big 4D matrix representing 3D MRI along time, stored in a big 4D
NifTi file.
<a class="reference external" href="http://www.fmrib.ox.ac.uk/fsl/">FSL</a> users tend to
prefer this format.</li>
<li>several 3D matrices representing each volume (time point) of the
session, stored in set of 3D Nifti or analyse files.
<a class="reference external" href="http://www.fil.ion.ucl.ac.uk/spm/">SPM</a> users tend
to prefer this format.</li>
</ul>
</div>
</div>
<div class="section" id="niimg-like-objects">
<span id="niimg"></span><h3>3.6.2.2. Niimg-like objects<a class="headerlink" href="#niimg-like-objects" title="Permalink to this headline">¶</a></h3>
<p>Often, nilearn functions take as input parameters what we call
&#8220;Niimg-like objects:</p>
<p><strong>Niimg:</strong> A Niimg-like object can either be:</p>
<blockquote>
<div><ul class="simple">
<li>a file path to a Nifti or Analyse image</li>
<li>any object exposing <tt class="docutils literal"><span class="pre">get_data()</span></tt> and <tt class="docutils literal"><span class="pre">get_affine()</span></tt> methods, for
instance a <tt class="docutils literal"><span class="pre">Nifti1Image</span></tt> from <a class="reference external" href="http://nipy.sourceforge.net/nibabel/">nibabel</a>.</li>
</ul>
</div></blockquote>
<p><strong>Niimg-4D:</strong> Similarly, some functions require 4-dimensional Nifti-like
data, which we call Niimgs, or Niimg-4D. Accepted inputs are then:</p>
<blockquote>
<div><ul class="simple">
<li>A path to a 4-dimensional Nifti image</li>
<li>List of paths to 3-dimensional Nifti images</li>
<li>4-dimensional Nifti-like object</li>
<li>List of 3-dimensional Nifti-like objects</li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p><strong>Image affines</strong></p>
<p class="last">If you provide a sequence of Nifti images, all of them must have the same
affine.</p>
</div>
</div>
<div class="section" id="text-files-phenotype-or-behavior">
<h3>3.6.2.3. Text files: phenotype or behavior<a class="headerlink" href="#text-files-phenotype-or-behavior" title="Permalink to this headline">¶</a></h3>
<p>Phenotypic or behavioral data are often provided as text or CSV
(Comma Separated Values) file. They
can be loaded with <cite>numpy.genfromtxt</cite> but you may have to specify some options
(typically <cite>skip_header</cite> ignores column titles if needed).</p>
<p>For the Haxby datasets, we can load the categories of the images
presented to the subject:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">haxby_files</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_haxby</span><span class="p">(</span><span class="n">n_subjects</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="n">haxby_files</span><span class="o">.</span><span class="n">session_target</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_header</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">basestring</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="go">[&#39;bottle&#39; &#39;cat&#39; &#39;chair&#39; &#39;face&#39; &#39;house&#39; &#39;rest&#39; &#39;scissors&#39; &#39;scrambledpix&#39;</span>
<span class="go"> &#39;shoe&#39;]</span>
</pre></div>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
</div>
<div class="section" id="masking-data-manually">
<h2><a class="toc-backref" href="#id4">3.6.3. Masking data manually</a><a class="headerlink" href="#masking-data-manually" title="Permalink to this headline">¶</a></h2>
<div class="section" id="extracting-a-brain-mask">
<h3>3.6.3.1. Extracting a brain mask<a class="headerlink" href="#extracting-a-brain-mask" title="Permalink to this headline">¶</a></h3>
<p>If we do not have a mask of the relevant regions available, a brain mask
can be easily extracted from the fMRI data using the
<a class="reference internal" href="generated/nilearn.masking.compute_epi_mask.html#nilearn.masking.compute_epi_mask" title="nilearn.masking.compute_epi_mask"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.masking.compute_epi_mask</span></tt></a> function:</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/nilearn.masking.compute_epi_mask.html#nilearn.masking.compute_epi_mask" title="nilearn.masking.compute_epi_mask"><tt class="xref py py-obj docutils literal"><span class="pre">compute_epi_mask</span></tt></a>(epi_img[,&nbsp;lower_cutoff,&nbsp;...])</td>
<td>Compute a brain mask from fMRI data in 3D or 4D ndarrays.</td>
</tr>
</tbody>
</table>
<div class="figure align-right">
<a class="reference external image-reference" href="../auto_examples/manipulating_visualizing/plot_visualization.html"><img alt="../_images/plot_visualization_21.png" src="../_images/plot_visualization_21.png" style="width: 330.0px; height: 130.0px;" /></a>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># Simple computation of a mask from the fMRI data</span>
<span class="kn">from</span> <span class="nn">nilearn.masking</span> <span class="kn">import</span> <span class="n">compute_epi_mask</span>
<span class="n">mask_img</span> <span class="o">=</span> <span class="n">compute_epi_mask</span><span class="p">(</span><span class="n">func_filename</span><span class="p">)</span>

<span class="n">plot_roi</span><span class="p">(</span><span class="n">mask_img</span><span class="p">,</span> <span class="n">mean_haxby</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="from-4d-to-2d-arrays">
<span id="mask-4d-2-3d"></span><h3>3.6.3.2. From 4D to 2D arrays<a class="headerlink" href="#from-4d-to-2d-arrays" title="Permalink to this headline">¶</a></h3>
<p>fMRI data is usually represented as a 4D block of data: 3 spatial
dimensions and one of time. In practice, we are most often only
interested in working only on the time-series of the voxels in the
brain. It is thus convenient to apply a brain mask and go from a 4D
array to a 2D array, <cite>voxel</cite> <strong>x</strong> <cite>time</cite>, as depicted below:</p>
<a class="reference internal image-reference" href="../_images/masking.jpg"><img alt="../_images/masking.jpg" class="align-center" src="../_images/masking.jpg" style="width: 100%;" /></a>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">nilearn.masking</span> <span class="kn">import</span> <span class="n">apply_mask</span>
<span class="n">masked_data</span> <span class="o">=</span> <span class="n">apply_mask</span><span class="p">(</span><span class="n">func_filename</span><span class="p">,</span> <span class="n">mask_img</span><span class="p">)</span>

<span class="c"># masked_data shape is (timepoints, voxels). We can plot the first 150</span>
<span class="c"># timepoints from two voxels</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">masked_data</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:</span><span class="mi">150</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;Time [TRs]&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;Intensity&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">150</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">bottom</span><span class="o">=.</span><span class="mi">12</span><span class="p">,</span> <span class="n">top</span><span class="o">=.</span><span class="mi">95</span><span class="p">,</span> <span class="n">right</span><span class="o">=.</span><span class="mi">95</span><span class="p">,</span> <span class="n">left</span><span class="o">=.</span><span class="mi">12</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/manipulating_visualizing/plot_visualization.html"><img alt="../_images/plot_visualization_31.png" src="../_images/plot_visualization_31.png" style="width: 350.0px; height: 250.0px;" /></a>
</div>
</div>
</div>
<div class="section" id="functions-for-data-preparation-steps">
<span id="preprocessing-functions"></span><h2><a class="toc-backref" href="#id5">3.6.4. Functions for data preparation steps</a><a class="headerlink" href="#functions-for-data-preparation-steps" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><tt class="xref py py-class docutils literal"><span class="pre">NiftiMasker</span></tt></a> automatically does some important data preparation
steps. These steps are also available as simple functions if you want to
set up your own data preparation procedure:</p>
<ul class="simple">
<li>Resampling: <a class="reference internal" href="../modules/generated/nilearn.image.resample_img.html#nilearn.image.resample_img" title="nilearn.image.resample_img"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.image.resample_img</span></tt></a>. See the example
<a class="reference internal" href="../auto_examples/manipulating_visualizing/plot_affine_transformation.html#example-manipulating-visualizing-plot-affine-transformation-py"><em>Visualization of affine resamplings</em></a> to
see the effect of affine transforms on data and bounding boxes.</li>
<li>Computing the mean of images (in the time of 4th direction):
<a class="reference internal" href="../modules/generated/nilearn.image.mean_img.html#nilearn.image.mean_img" title="nilearn.image.mean_img"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.image.mean_img</span></tt></a></li>
<li>Swapping voxels of both hemisphere:
<a class="reference internal" href="../modules/generated/nilearn.image.swap_img_hemispheres.html#nilearn.image.swap_img_hemispheres" title="nilearn.image.swap_img_hemispheres"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.image.swap_img_hemispheres</span></tt></a></li>
<li>Smoothing: <a class="reference internal" href="../modules/generated/nilearn.image.smooth_img.html#nilearn.image.smooth_img" title="nilearn.image.smooth_img"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.image.smooth_img</span></tt></a></li>
<li>Masking:<ul>
<li>compute from EPI images: <a class="reference internal" href="generated/nilearn.masking.compute_epi_mask.html#nilearn.masking.compute_epi_mask" title="nilearn.masking.compute_epi_mask"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.masking.compute_epi_mask</span></tt></a></li>
<li>compute from images with a flat background:
<tt class="xref py py-func docutils literal"><span class="pre">nilearn.masking.compute_background_mask</span></tt></li>
<li>compute for multiple sessions/subjects:
<tt class="xref py py-func docutils literal"><span class="pre">nilearn.masking.compute_multi_epi_mask</span></tt>
<tt class="xref py py-func docutils literal"><span class="pre">nilearn.masking.compute_multi_background_mask</span></tt></li>
<li>apply: <tt class="xref py py-func docutils literal"><span class="pre">nilearn.masking.apply_mask</span></tt></li>
<li>intersect several masks (useful for multi sessions/subjects): <tt class="xref py py-func docutils literal"><span class="pre">nilearn.masking.intersect_masks</span></tt></li>
<li>unmasking: <tt class="xref py py-func docutils literal"><span class="pre">nilearn.masking.unmask</span></tt></li>
</ul>
</li>
<li>Cleaning signals: <a class="reference internal" href="../modules/generated/nilearn.signal.clean.html#nilearn.signal.clean" title="nilearn.signal.clean"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.signal.clean</span></tt></a></li>
</ul>
</div>
<div class="section" id="image-operations-creating-a-roi-mask-manually">
<h2><a class="toc-backref" href="#id6">3.6.5. Image operations: creating a ROI mask manually</a><a class="headerlink" href="#image-operations-creating-a-roi-mask-manually" title="Permalink to this headline">¶</a></h2>
<p>This section shows manual steps to create and finally control an ROI
mask. They are a good example of using basic image manipulation on Nifti
images.</p>
<div class="section" id="smoothing">
<h3>3.6.5.1. Smoothing<a class="headerlink" href="#smoothing" title="Permalink to this headline">¶</a></h3>
<p>Functional MRI data has a low signal-to-noise ratio. When using simple methods
that are not robust to noise, it is useful to smooth the data. Smoothing is
usually applied using a Gaussian function with 4mm to 8mm full-width at
half-maximum. The function <a class="reference internal" href="../modules/generated/nilearn.image.smooth_img.html#nilearn.image.smooth_img" title="nilearn.image.smooth_img"><tt class="xref py py-func docutils literal"><span class="pre">nilearn.image.smooth_img</span></tt></a> accounts for potential
anisotropy in the image affine. As many nilearn functions, it can also
use file names as input parameters.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">image</span>
<span class="n">fmri_filename</span> <span class="o">=</span> <span class="n">haxby_dataset</span><span class="o">.</span><span class="n">func</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">fmri_img</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">smooth_img</span><span class="p">(</span><span class="n">fmri_filename</span><span class="p">,</span> <span class="n">fwhm</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

<span class="c"># Plot the mean image</span>
<span class="n">fig_id</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">mean_img</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">mean_img</span><span class="p">(</span><span class="n">fmri_img</span><span class="p">)</span>
<span class="n">plot_epi</span><span class="p">(</span><span class="n">mean_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Smoothed mean EPI&#39;</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="n">cut_coords</span><span class="p">,</span>
         <span class="n">axes</span><span class="o">=</span><span class="n">fig_id</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/manipulating_visualizing/plot_roi_extraction.html"><img alt="../_images/plot_roi_extraction_11.png" src="../_images/plot_roi_extraction_11.png" style="width: 400.0px; height: 300.0px;" /></a>
</div>
</div>
<div class="section" id="selecting-features">
<h3>3.6.5.2. Selecting features<a class="headerlink" href="#selecting-features" title="Permalink to this headline">¶</a></h3>
<p>Functional MRI data are high dimensional compared to the number of samples
(usually 50000 voxels for 1000 samples). In this setting, machine learning
algorithm can perform poorly. However, a simple statistical test can help
reducing the number of voxels.</p>
<p>The Student&#8217;s t-test (<a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html#scipy.stats.ttest_ind" title="(in SciPy v0.14.1)"><tt class="xref py py-func docutils literal"><span class="pre">scipy.stats.ttest_ind</span></tt></a>) performs a simple statistical test that determines if two
distributions are statistically different. It can be used to compare voxel
timeseries in two different conditions (when houses or faces are shown in our
case). If the timeserie distribution is similar in the two conditions, then the
voxel is not very interesting to discriminate the condition.</p>
<p>This test returns p-values that represents probabilities that the two
timeseries are drawn from the same distribution. The lower is the p-value, the
more discriminative is the voxel.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="n">fmri_data</span> <span class="o">=</span> <span class="n">fmri_img</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span>
<span class="n">_</span><span class="p">,</span> <span class="n">p_values</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">fmri_data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">haxby_labels</span> <span class="o">==</span> <span class="s">&#39;face&#39;</span><span class="p">],</span>
                              <span class="n">fmri_data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">haxby_labels</span> <span class="o">==</span> <span class="s">&#39;house&#39;</span><span class="p">],</span>
                              <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c"># Use a log scale for p-values</span>
<span class="n">log_p_values</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">p_values</span><span class="p">)</span>
<span class="n">log_p_values</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">log_p_values</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">log_p_values</span><span class="p">[</span><span class="n">log_p_values</span> <span class="o">&gt;</span> <span class="mf">10.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">10.</span>
<span class="n">fig_id</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plot_stat_map</span><span class="p">(</span><span class="n">nibabel</span><span class="o">.</span><span class="n">Nifti1Image</span><span class="p">(</span><span class="n">log_p_values</span><span class="p">,</span> <span class="n">fmri_img</span><span class="o">.</span><span class="n">get_affine</span><span class="p">()),</span> <span class="n">mean_img</span><span class="p">,</span>
              <span class="n">title</span><span class="o">=</span><span class="s">&quot;p-values&quot;</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="n">cut_coords</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">fig_id</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/manipulating_visualizing/plot_roi_extraction.html"><img alt="../_images/plot_roi_extraction_11.png" src="../_images/plot_roi_extraction_11.png" style="width: 400.0px; height: 300.0px;" /></a>
</div>
<p>This feature selection method is available in the scikit-learn where it has been
extended to several classes, using the
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif" title="(in scikit-learn v0.15)"><tt class="xref py py-func docutils literal"><span class="pre">sklearn.feature_selection.f_classif</span></tt></a> function.</p>
</div>
<div class="section" id="thresholding">
<h3>3.6.5.3. Thresholding<a class="headerlink" href="#thresholding" title="Permalink to this headline">¶</a></h3>
<p>Higher p-values are kept as voxels of interest. Applying a threshold to an array
is easy thanks to numpy indexing a la Matlab.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">log_p_values</span><span class="p">[</span><span class="n">log_p_values</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">plot_stat_map</span><span class="p">(</span><span class="n">nibabel</span><span class="o">.</span><span class="n">Nifti1Image</span><span class="p">(</span><span class="n">log_p_values</span><span class="p">,</span> <span class="n">fmri_img</span><span class="o">.</span><span class="n">get_affine</span><span class="p">()),</span> <span class="n">mean_img</span><span class="p">,</span>
              <span class="n">title</span><span class="o">=</span><span class="s">&#39;Thresholded p-values&#39;</span><span class="p">,</span> <span class="n">annotate</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">colorbar</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
              <span class="n">cut_coords</span><span class="o">=</span><span class="n">cut_coords</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">fig_id</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/manipulating_visualizing/plot_roi_extraction.html"><img alt="../_images/plot_roi_extraction_21.png" src="../_images/plot_roi_extraction_21.png" style="width: 400.0px; height: 300.0px;" /></a>
</div>
</div>
<div class="section" id="mask-intersection">
<h3>3.6.5.4. Mask intersection<a class="headerlink" href="#mask-intersection" title="Permalink to this headline">¶</a></h3>
<p>We now want to restrict our study to the ventral temporal area. The
corresponding mask is provided in <cite>haxby.mask_vt</cite>. We want to compute the
intersection of this mask with our mask. The first step is to load it with
nibabel&#8217;s <tt class="xref py py-func docutils literal"><span class="pre">nibabel.load</span></tt>. We then use a logical &#8220;and&#8221;
&#8211; <tt class="xref py py-func docutils literal"><span class="pre">numpy.logical_and</span></tt> &#8211; to keep only voxels
that are selected in both masks.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># (intersection corresponds to an &quot;AND conjunction&quot;)</span>
<span class="n">bin_p_values</span> <span class="o">=</span> <span class="p">(</span><span class="n">log_p_values</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">mask_vt_filename</span> <span class="o">=</span> <span class="n">haxby_dataset</span><span class="o">.</span><span class="n">mask_vt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">vt</span> <span class="o">=</span> <span class="n">nibabel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">mask_vt_filename</span><span class="p">)</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">bin_p_values_and_vt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">bin_p_values</span><span class="p">,</span> <span class="n">vt</span><span class="p">)</span>

<span class="n">fig_id</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plot_roi</span><span class="p">(</span><span class="n">nibabel</span><span class="o">.</span><span class="n">Nifti1Image</span><span class="p">(</span><span class="n">bin_p_values_and_vt</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">),</span>
         <span class="n">fmri_img</span><span class="o">.</span><span class="n">get_affine</span><span class="p">()),</span>
         <span class="n">mean_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Intersection with ventral temporal mask&#39;</span><span class="p">,</span>
         <span class="n">cut_coords</span><span class="o">=</span><span class="n">cut_coords</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">fig_id</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/manipulating_visualizing/plot_roi_extraction.html"><img alt="../_images/plot_roi_extraction_21.png" src="../_images/plot_roi_extraction_21.png" style="width: 400.0px; height: 300.0px;" /></a>
</div>
</div>
<div class="section" id="mask-dilation">
<h3>3.6.5.5. Mask dilation<a class="headerlink" href="#mask-dilation" title="Permalink to this headline">¶</a></h3>
<p>We observe that our voxels are a bit scattered across the brain. To obtain more
compact shape, we use a <a class="reference external" href="http://en.wikipedia.org/wiki/Dilation_(morphology)">morphological dilation</a>. This is a common step to be sure
not to forget voxels located on the edge of a ROI.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">fig_id</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">ndimage</span>
<span class="n">dil_bin_p_values_and_vt</span> <span class="o">=</span> <span class="n">ndimage</span><span class="o">.</span><span class="n">binary_dilation</span><span class="p">(</span><span class="n">bin_p_values_and_vt</span><span class="p">)</span>
<span class="n">plot_roi</span><span class="p">(</span><span class="n">nibabel</span><span class="o">.</span><span class="n">Nifti1Image</span><span class="p">(</span><span class="n">dil_bin_p_values_and_vt</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">),</span>
                             <span class="n">fmri_img</span><span class="o">.</span><span class="n">get_affine</span><span class="p">()),</span>
         <span class="n">mean_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Dilated mask&#39;</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="n">cut_coords</span><span class="p">,</span>
         <span class="n">axes</span><span class="o">=</span><span class="n">fig_id</span><span class="p">,</span> <span class="n">annotate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/manipulating_visualizing/plot_roi_extraction.html"><img alt="../_images/plot_roi_extraction_21.png" src="../_images/plot_roi_extraction_21.png" style="width: 400.0px; height: 300.0px;" /></a>
</div>
</div>
<div class="section" id="extracting-connected-components">
<h3>3.6.5.6. Extracting connected components<a class="headerlink" href="#extracting-connected-components" title="Permalink to this headline">¶</a></h3>
<p>Scipy function <tt class="xref py py-func docutils literal"><span class="pre">scipy.ndimage.label</span></tt> identifies connected
components in our final mask: it assigns a separate integer label to each
one of them.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">labels</span><span class="p">,</span> <span class="n">n_labels</span> <span class="o">=</span> <span class="n">ndimage</span><span class="o">.</span><span class="n">label</span><span class="p">(</span><span class="n">dil_bin_p_values_and_vt</span><span class="p">)</span>
<span class="n">first_roi_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
<span class="n">second_roi_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
<span class="n">fig_id</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plot_roi</span><span class="p">(</span><span class="n">nibabel</span><span class="o">.</span><span class="n">Nifti1Image</span><span class="p">(</span><span class="n">first_roi_data</span><span class="p">,</span> <span class="n">fmri_img</span><span class="o">.</span><span class="n">get_affine</span><span class="p">()),</span>
         <span class="n">mean_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Connected components: first ROI&#39;</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">fig_id</span><span class="p">)</span>
<span class="n">fig_id</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plot_roi</span><span class="p">(</span><span class="n">nibabel</span><span class="o">.</span><span class="n">Nifti1Image</span><span class="p">(</span><span class="n">second_roi_data</span><span class="p">,</span> <span class="n">fmri_img</span><span class="o">.</span><span class="n">get_affine</span><span class="p">()),</span>
         <span class="n">mean_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Connected components: second ROI&#39;</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">fig_id</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plot_roi</span><span class="p">(</span><span class="n">nibabel</span><span class="o">.</span><span class="n">Nifti1Image</span><span class="p">(</span><span class="n">first_roi_data</span><span class="p">,</span> <span class="n">fmri_img</span><span class="o">.</span><span class="n">get_affine</span><span class="p">()),</span>
         <span class="n">mean_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Connected components: first ROI_&#39;</span><span class="p">,</span>
         <span class="n">output_file</span><span class="o">=</span><span class="s">&#39;snapshot_first_ROI.png&#39;</span><span class="p">)</span>
<span class="n">plot_roi</span><span class="p">(</span><span class="n">nibabel</span><span class="o">.</span><span class="n">Nifti1Image</span><span class="p">(</span><span class="n">second_roi_data</span><span class="p">,</span> <span class="n">fmri_img</span><span class="o">.</span><span class="n">get_affine</span><span class="p">()),</span>
         <span class="n">mean_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Connected components: second ROI&#39;</span><span class="p">,</span>
         <span class="n">output_file</span><span class="o">=</span><span class="s">&#39;snapshot_second_ROI.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/manipulating_visualizing/plot_roi_extraction.html"><img alt="../_images/plot_roi_extraction_31.png" src="../_images/plot_roi_extraction_31.png" style="width: 400.0px; height: 300.0px;" /></a>
</div>
</div>
<div class="section" id="saving-the-result">
<h3>3.6.5.7. Saving the result<a class="headerlink" href="#saving-the-result" title="Permalink to this headline">¶</a></h3>
<p>The final result is saved using nibabel for further consultation with a software
like FSLview for example.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">nibabel</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">nibabel</span><span class="o">.</span><span class="n">Nifti1Image</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">fmri_img</span><span class="o">.</span><span class="n">get_affine</span><span class="p">()),</span>
             <span class="s">&#39;mask_atlas.nii&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../np-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="generated/nilearn.masking.compute_epi_mask.html" title="3.6.3.1.1. nilearn.masking.compute_epi_mask"
             >next</a> |</li>
        <li class="right" >
          <a href="plotting.html" title="3.5. Plotting brain images"
             >previous</a> |</li>
<li><a href="../index.html">NiLearn Home</a> |&nbsp;</li>
<li><a href="../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../AUTHORS.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li><a href="index.html" >3. The nilearn building blocks</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
            &copy; INRIA Parietal 2010-2013.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.2.3.
        <span style="padding-left: 5ex;">
          <a href="../_sources/building_blocks/manipulating_mr_images.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>