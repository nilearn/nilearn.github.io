<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1.0 name=viewport><meta content="9.5.11. Example of surface-based first-level analysis"property=og:title><meta content=website property=og:type><meta content=https://nilearn.github.io/auto_examples/04_glm_first_level/plot_localizer_surface_analysis.html property=og:url><meta content=Nilearn property=og:site_name><meta content="A full step-by-step example of fitting a GLM to experimental data sampled on the cortical surface and visualizing the results. More specifically: A sequence of fMRI volumes is loaded., fMRI data ar..."property=og:description><meta content=https://nilearn.github.io/_static/nilearn-logo.png property=og:image><meta content=Nilearn property=og:image:alt><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/copybutton.css rel=stylesheet><link href=../../_static/sg_gallery.css rel=stylesheet><link href=../../_static/sg_gallery-binder.css rel=stylesheet><link href=../../_static/sg_gallery-dataframe.css rel=stylesheet><link href=../../_static/sg_gallery-rendered-html.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/clipboard.min.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="9.5.12. Understanding parameters of the first-level model"href=plot_first_level_details.html rel=next><link title="9.5.10. Predicted time series and residuals"href=plot_predictions_residuals.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../../modules/reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="9.5.12. Understanding parameters of the first-level model"accesskey=N href=plot_first_level_details.html>next</a> |</li><li class=right><a title="9.5.10. Predicted time series and residuals"accesskey=P href=plot_predictions_residuals.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../index.html>Examples</a> | </li><li><a href=../../modules/reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li><a href=../../glossary.html>Glossary</a>| </li><li><a href=../../bibliography.html>Bibliography</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../index.html><span class=section-number>9. </span>Nilearn usage examples</a> »</li><li class="nav-item nav-item-this"><a href>Nilearn: Statistical Analysis for NeuroImaging in Python</a></li></ul></div></div><div class=stable-banner>This is the <em>stable</em> documentation for the latest release of Nilearn, the current development version is available <a href=https://nilearn.github.io/dev/index.html>here</a>.</div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="sphx-glr-download-link-note admonition note"><p class=admonition-title>Note</p><p>Click <a class="reference internal"href=#sphx-glr-download-auto-examples-04-glm-first-level-plot-localizer-surface-analysis-py><span class="std std-ref">here</span></a> to download the full example code or to run this example in your browser via Binder</p></div><div class="sphx-glr-example-title section"id=example-of-surface-based-first-level-analysis><span id=sphx-glr-auto-examples-04-glm-first-level-plot-localizer-surface-analysis-py></span><h1><span class=section-number>9.5.11. </span>Example of surface-based first-level analysis<a title="Permalink to this headline"class=headerlink href=#example-of-surface-based-first-level-analysis>¶</a></h1><p>A full step-by-step example of fitting a GLM to experimental data sampled on the cortical surface and visualizing the results.</p><p>More specifically:</p><ol class="arabic simple"><li><p>A sequence of fMRI volumes is loaded.</p></li><li><p>fMRI data are projected onto a reference cortical surface (the FreeSurfer template, fsaverage).</p></li><li><p>A design matrix describing all the effects related to the data is computed.</p></li><li><p>A GLM is applied to the dataset (effect/covariance, then contrast estimation).</p></li></ol><p>The result of the analysis are statistical maps that are defined on the brain mesh. We display them using Nilearn capabilities.</p><p>The projection of fMRI data onto a given brain mesh requires that both are initially defined in the same space.</p><ul class=simple><li><p>The functional data should be coregistered to the anatomy from which the mesh was obtained.</p></li><li><p>Another possibility, used here, is to project the normalized fMRI data to an MNI-coregistered mesh, such as fsaverage.</p></li></ul><p>The advantage of this second approach is that it makes it easy to run second-level analyses on the surface. On the other hand, it is obviously less accurate than using a subject-tailored mesh.</p><div class=section id=prepare-data-and-analysis-parameters><h2><span class=section-number>9.5.11.1. </span>Prepare data and analysis parameters<a title="Permalink to this headline"class=headerlink href=#prepare-data-and-analysis-parameters>¶</a></h2><p>Prepare the timing parameters.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/functions.html#float title=builtins.float><span class=n>t_r</span></a> <span class=o>=</span> <span class=mf>2.4</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/functions.html#float title=builtins.float><span class=n>slice_time_ref</span></a> <span class=o>=</span> <span class=mf>0.5</span>
</pre></div></div><p>Prepare the data. First, the volume-based fMRI data.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn.datasets</span> <span class=kn>import</span> <a class="sphx-glr-backref-module-nilearn-datasets sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.datasets.fetch_localizer_first_level.html#nilearn.datasets.fetch_localizer_first_level title=nilearn.datasets.fetch_localizer_first_level><span class=n>fetch_localizer_first_level</span></a>
<a class="sphx-glr-backref-module-sklearn-utils sphx-glr-backref-type-py-function"href=https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch title=sklearn.utils.Bunch><span class=n>data</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-datasets sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.datasets.fetch_localizer_first_level.html#nilearn.datasets.fetch_localizer_first_level title=nilearn.datasets.fetch_localizer_first_level><span class=n>fetch_localizer_first_level</span></a><span class=p>()</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>fmri_img</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>data</span><span class=o>.</span><span class=n>epi_img</span></a>
</pre></div></div><p>Second, the experimental paradigm.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>events_file</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>data</span><span class=o>.</span><span class=n>events</span></a>
<span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
<a class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame title=pandas.core.frame.DataFrame><span class=n>events</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-function"href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_table.html#pandas.read_table title=pandas.read_table><span class=n>pd</span><span class=o>.</span><span class=n>read_table</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>events_file</span></a><span class=p>)</span>
</pre></div></div></div><div class=section id=project-the-fmri-image-to-the-surface><h2><span class=section-number>9.5.11.2. </span>Project the fMRI image to the surface<a title="Permalink to this headline"class=headerlink href=#project-the-fmri-image-to-the-surface>¶</a></h2><p>For this we need to get a mesh representing the geometry of the surface. We could use an individual mesh, but we first resort to a standard mesh, the so-called fsaverage5 template from the FreeSurfer software.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>import</span> <span class=nn>nilearn</span>
<a class="sphx-glr-backref-module-sklearn-utils sphx-glr-backref-type-py-function"href=https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch title=sklearn.utils.Bunch><span class=n>fsaverage</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-datasets sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.datasets.fetch_surf_fsaverage.html#nilearn.datasets.fetch_surf_fsaverage title=nilearn.datasets.fetch_surf_fsaverage><span class=n>nilearn</span><span class=o>.</span><span class=n>datasets</span><span class=o>.</span><span class=n>fetch_surf_fsaverage</span></a><span class=p>()</span>
</pre></div></div><p>The projection function simply takes the fMRI data and the mesh. Note that those correspond spatially, are they are both in MNI space.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn</span> <span class=kn>import</span> <span class=n>surface</span>
<a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>texture</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-surface sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.surface.vol_to_surf.html#nilearn.surface.vol_to_surf title=nilearn.surface.vol_to_surf><span class=n>surface</span><span class=o>.</span><span class=n>vol_to_surf</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>fmri_img</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>fsaverage</span><span class=o>.</span><span class=n>pial_right</span></a><span class=p>)</span>
</pre></div></div></div><div class=section id=perform-first-level-analysis><h2><span class=section-number>9.5.11.3. </span>Perform first level analysis<a title="Permalink to this headline"class=headerlink href=#perform-first-level-analysis>¶</a></h2><p>This involves computing the design matrix and fitting the model. We start by specifying the timing of fMRI frames.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/functions.html#int title=builtins.int><span class=n>n_scans</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#tuple title=builtins.tuple><span class=n>texture</span><span class=o>.</span><span class=n>shape</span></a><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
<a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>frame_times</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/functions.html#float title=builtins.float><span class=n>t_r</span></a> <span class=o>*</span> <span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"href=https://numpy.org/doc/stable/reference/generated/numpy.arange.html#numpy.arange title=numpy.arange><span class=n>np</span><span class=o>.</span><span class=n>arange</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/functions.html#int title=builtins.int><span class=n>n_scans</span></a><span class=p>)</span> <span class=o>+</span> <span class=o>.</span><span class=mi>5</span><span class=p>)</span>
</pre></div></div><p>Create the design matrix.</p><p>We specify an hrf model containing the Glover model and its time derivative The drift model is implicitly a cosine basis with a period cutoff at 128s.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn.glm.first_level</span> <span class=kn>import</span> <a class="sphx-glr-backref-module-nilearn-glm-first_level sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.glm.first_level.make_first_level_design_matrix.html#nilearn.glm.first_level.make_first_level_design_matrix title=nilearn.glm.first_level.make_first_level_design_matrix><span class=n>make_first_level_design_matrix</span></a>
<a class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame title=pandas.core.frame.DataFrame><span class=n>design_matrix</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-glm-first_level sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.glm.first_level.make_first_level_design_matrix.html#nilearn.glm.first_level.make_first_level_design_matrix title=nilearn.glm.first_level.make_first_level_design_matrix><span class=n>make_first_level_design_matrix</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>frame_times</span></a><span class=p>,</span>
                                               <a class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame title=pandas.core.frame.DataFrame><span class=n>events</span></a><span class=o>=</span><a class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame title=pandas.core.frame.DataFrame><span class=n>events</span></a><span class=p>,</span>
                                               <span class=n>hrf_model</span><span class=o>=</span><span class=s1>'glover + derivative'</span>
                                               <span class=p>)</span>
</pre></div></div><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>/home/nicolas/GitRepos/nilearn-fork/nilearn/glm/first_level/experimental_paradigm.py:89: UserWarning:

Unexpected column `Unnamed: 0` in events data will be ignored.

/home/nicolas/GitRepos/nilearn-fork/nilearn/glm/first_level/experimental_paradigm.py:89: UserWarning:

Unexpected column `Unnamed: 0.1` in events data will be ignored.
</pre></div></div><p>Setup and fit GLM.</p><p>Note that the output consists in 2 variables: <cite>labels</cite> and <cite>fit</cite>. <cite>labels</cite> tags voxels according to noise autocorrelation. <cite>estimates</cite> contains the parameter estimates. We keep them for later contrast computation.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn.glm.first_level</span> <span class=kn>import</span> <a class="sphx-glr-backref-module-nilearn-glm-first_level sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.glm.first_level.run_glm.html#nilearn.glm.first_level.run_glm title=nilearn.glm.first_level.run_glm><span class=n>run_glm</span></a>
<a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>labels</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>estimates</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-glm-first_level sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.glm.first_level.run_glm.html#nilearn.glm.first_level.run_glm title=nilearn.glm.first_level.run_glm><span class=n>run_glm</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>texture</span><span class=o>.</span><span class=n>T</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-property"href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.values.html#pandas.DataFrame.values title=pandas.DataFrame.values><span class=n>design_matrix</span><span class=o>.</span><span class=n>values</span></a><span class=p>)</span>
</pre></div></div></div><div class=section id=estimate-contrasts><h2><span class=section-number>9.5.11.4. </span>Estimate contrasts<a title="Permalink to this headline"class=headerlink href=#estimate-contrasts>¶</a></h2><p>Specify the contrasts.</p><p>For practical purpose, we first generate an identity matrix whose size is the number of columns of the design matrix.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>contrast_matrix</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"href=https://numpy.org/doc/stable/reference/generated/numpy.eye.html#numpy.eye title=numpy.eye><span class=n>np</span><span class=o>.</span><span class=n>eye</span></a><span class=p>(</span><a class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-property"href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html#pandas.DataFrame.shape title=pandas.DataFrame.shape><span class=n>design_matrix</span><span class=o>.</span><span class=n>shape</span></a><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
</pre></div></div><p>At first, we create basic contrasts.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a> <span class=o>=</span> <span class=nb>dict</span><span class=p>([(</span><span class=n>column</span><span class=p>,</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>contrast_matrix</span></a><span class=p>[</span><span class=n>i</span><span class=p>])</span>
                        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>column</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><a class="sphx-glr-backref-module-pandas-core-indexes-base sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Index.html#pandas.Index title=pandas.core.indexes.base.Index><span class=n>design_matrix</span><span class=o>.</span><span class=n>columns</span></a><span class=p>)])</span>
</pre></div></div><p>Next, we add some intermediate contrasts and one contrast adding all conditions with some auditory parts.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'audio'</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span>
    <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'audio_left_hand_button_press'</span><span class=p>]</span>
    <span class=o>+</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'audio_right_hand_button_press'</span><span class=p>]</span>
    <span class=o>+</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'audio_computation'</span><span class=p>]</span>
    <span class=o>+</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'sentence_listening'</span><span class=p>])</span>

<span class=c1># one contrast adding all conditions involving instructions reading</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'visual'</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span>
    <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'visual_left_hand_button_press'</span><span class=p>]</span>
    <span class=o>+</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'visual_right_hand_button_press'</span><span class=p>]</span>
    <span class=o>+</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'visual_computation'</span><span class=p>]</span>
    <span class=o>+</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'sentence_reading'</span><span class=p>])</span>

<span class=c1># one contrast adding all conditions involving computation</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'computation'</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'visual_computation'</span><span class=p>]</span>
                                  <span class=o>+</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'audio_computation'</span><span class=p>])</span>

<span class=c1># one contrast adding all conditions involving sentences</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'sentences'</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'sentence_listening'</span><span class=p>]</span>
                                <span class=o>+</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'sentence_reading'</span><span class=p>])</span>
</pre></div></div><p>Finally, we create a dictionary of more relevant contrasts</p><ul class=simple><li><p>‘left - right button press’: probes motor activity in left versus right button presses.</p></li><li><p>‘audio - visual’: probes the difference of activity between listening to some content or reading the same type of content (instructions, stories).</p></li><li><p>‘computation - sentences’: looks at the activity when performing a mental computation task versus simply reading sentences.</p></li></ul><p>Of course, we could define other contrasts, but we keep only 3 for simplicity.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>contrasts</span></a> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>'left - right button press'</span><span class=p>:</span> <span class=p>(</span>
        <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'audio_left_hand_button_press'</span><span class=p>]</span>
        <span class=o>-</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'audio_right_hand_button_press'</span><span class=p>]</span>
        <span class=o>+</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'visual_left_hand_button_press'</span><span class=p>]</span>
        <span class=o>-</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'visual_right_hand_button_press'</span><span class=p>]</span>
    <span class=p>),</span>
    <span class=s1>'audio - visual'</span><span class=p>:</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'audio'</span><span class=p>]</span> <span class=o>-</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'visual'</span><span class=p>],</span>
    <span class=s1>'computation - sentences'</span><span class=p>:</span> <span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'computation'</span><span class=p>]</span> <span class=o>-</span>
                                <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>basic_contrasts</span></a><span class=p>[</span><span class=s1>'sentences'</span><span class=p>]</span>
    <span class=p>)</span>
<span class=p>}</span>
</pre></div></div><p>Let’s estimate the contrasts by iterating over them.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn.glm.contrasts</span> <span class=kn>import</span> <a class="sphx-glr-backref-module-nilearn-glm sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.glm.compute_contrast.html#nilearn.glm.compute_contrast title=nilearn.glm.compute_contrast><span class=n>compute_contrast</span></a>
<span class=kn>from</span> <span class=nn>nilearn</span> <span class=kn>import</span> <span class=n>plotting</span>

<span class=k>for</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/functions.html#int title=builtins.int><span class=n>index</span></a><span class=p>,</span> <span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>contrast_id</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>contrast_val</span></a><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>contrasts</span></a><span class=o>.</span><span class=n>items</span><span class=p>()):</span>
    <span class=nb>print</span><span class=p>(</span><span class=s1>'  Contrast </span><span class=si>% i</span><span class=s1> out of </span><span class=si>%i</span><span class=s1>: </span><span class=si>%s</span><span class=s1>, right hemisphere'</span> <span class=o>%</span>
          <span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/functions.html#int title=builtins.int><span class=n>index</span></a> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>contrasts</span></a><span class=p>),</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>contrast_id</span></a><span class=p>))</span>
    <span class=c1># compute contrast-related statistics</span>
    <a class="sphx-glr-backref-module-nilearn-glm sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=../../modules/generated/nilearn.glm.Contrast.html#nilearn.glm.Contrast title=nilearn.glm.Contrast><span class=n>contrast</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-glm sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.glm.compute_contrast.html#nilearn.glm.compute_contrast title=nilearn.glm.compute_contrast><span class=n>compute_contrast</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>labels</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>estimates</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>contrast_val</span></a><span class=p>,</span>
                                <span class=n>contrast_type</span><span class=o>=</span><span class=s1>'t'</span><span class=p>)</span>
    <span class=c1># we present the Z-transform of the t map</span>
    <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>z_score</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-glm sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.glm.Contrast.html#nilearn.glm.Contrast.z_score title=nilearn.glm.Contrast.z_score><span class=n>contrast</span><span class=o>.</span><span class=n>z_score</span></a><span class=p>()</span>
    <span class=c1># we plot it on the surface, on the inflated fsaverage mesh,</span>
    <span class=c1># together with a suitable background to give an impression</span>
    <span class=c1># of the cortex folding.</span>
    <a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.plot_surf_stat_map.html#nilearn.plotting.plot_surf_stat_map title=nilearn.plotting.plot_surf_stat_map><span class=n>plotting</span><span class=o>.</span><span class=n>plot_surf_stat_map</span></a><span class=p>(</span>
        <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>fsaverage</span><span class=o>.</span><span class=n>infl_right</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>z_score</span></a><span class=p>,</span> <span class=n>hemi</span><span class=o>=</span><span class=s1>'right'</span><span class=p>,</span>
        <span class=n>title</span><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>contrast_id</span></a><span class=p>,</span> <span class=n>colorbar</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
        <span class=n>threshold</span><span class=o>=</span><span class=mf>3.</span><span class=p>,</span> <span class=n>bg_map</span><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>fsaverage</span><span class=o>.</span><span class=n>sulc_right</span></a><span class=p>)</span>
</pre></div></div><ul class=sphx-glr-horizontal><li><img alt="left - right button press"class=sphx-glr-multi-img src=../../_images/sphx_glr_plot_localizer_surface_analysis_001.png srcset=../../_images/sphx_glr_plot_localizer_surface_analysis_001.png></li><li><img alt="audio - visual"class=sphx-glr-multi-img src=../../_images/sphx_glr_plot_localizer_surface_analysis_002.png srcset=../../_images/sphx_glr_plot_localizer_surface_analysis_002.png></li><li><img alt="computation - sentences"class=sphx-glr-multi-img src=../../_images/sphx_glr_plot_localizer_surface_analysis_003.png srcset=../../_images/sphx_glr_plot_localizer_surface_analysis_003.png></li></ul><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>Contrast  1 out of 3: left - right button press, right hemisphere
Contrast  2 out of 3: audio - visual, right hemisphere
Contrast  3 out of 3: computation - sentences, right hemisphere
</pre></div></div></div><div class=section id=analysing-the-left-hemisphere><h2><span class=section-number>9.5.11.5. </span>Analysing the left hemisphere<a title="Permalink to this headline"class=headerlink href=#analysing-the-left-hemisphere>¶</a></h2><p>Note that re-creating the above analysis for the left hemisphere requires little additional code!</p><p>We project the fMRI data to the mesh.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>texture</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-surface sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.surface.vol_to_surf.html#nilearn.surface.vol_to_surf title=nilearn.surface.vol_to_surf><span class=n>surface</span><span class=o>.</span><span class=n>vol_to_surf</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>fmri_img</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>fsaverage</span><span class=o>.</span><span class=n>pial_left</span></a><span class=p>)</span>
</pre></div></div><p>Then we estimate the General Linear Model.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>labels</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>estimates</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-glm-first_level sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.glm.first_level.run_glm.html#nilearn.glm.first_level.run_glm title=nilearn.glm.first_level.run_glm><span class=n>run_glm</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>texture</span><span class=o>.</span><span class=n>T</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-pandas sphx-glr-backref-type-py-property"href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.values.html#pandas.DataFrame.values title=pandas.DataFrame.values><span class=n>design_matrix</span><span class=o>.</span><span class=n>values</span></a><span class=p>)</span>
</pre></div></div><p>Finally, we create contrast-specific maps and plot them.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=k>for</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/functions.html#int title=builtins.int><span class=n>index</span></a><span class=p>,</span> <span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>contrast_id</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>contrast_val</span></a><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>contrasts</span></a><span class=o>.</span><span class=n>items</span><span class=p>()):</span>
    <span class=nb>print</span><span class=p>(</span><span class=s1>'  Contrast </span><span class=si>% i</span><span class=s1> out of </span><span class=si>%i</span><span class=s1>: </span><span class=si>%s</span><span class=s1>, left hemisphere'</span> <span class=o>%</span>
          <span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/functions.html#int title=builtins.int><span class=n>index</span></a> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>contrasts</span></a><span class=p>),</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>contrast_id</span></a><span class=p>))</span>
    <span class=c1># compute contrasts</span>
    <a class="sphx-glr-backref-module-nilearn-glm sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=../../modules/generated/nilearn.glm.Contrast.html#nilearn.glm.Contrast title=nilearn.glm.Contrast><span class=n>contrast</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-glm sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.glm.compute_contrast.html#nilearn.glm.compute_contrast title=nilearn.glm.compute_contrast><span class=n>compute_contrast</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>labels</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#dict title=builtins.dict><span class=n>estimates</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>contrast_val</span></a><span class=p>,</span>
                                <span class=n>contrast_type</span><span class=o>=</span><span class=s1>'t'</span><span class=p>)</span>
    <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>z_score</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-glm sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.glm.Contrast.html#nilearn.glm.Contrast.z_score title=nilearn.glm.Contrast.z_score><span class=n>contrast</span><span class=o>.</span><span class=n>z_score</span></a><span class=p>()</span>
    <span class=c1># plot the result</span>
    <a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.plot_surf_stat_map.html#nilearn.plotting.plot_surf_stat_map title=nilearn.plotting.plot_surf_stat_map><span class=n>plotting</span><span class=o>.</span><span class=n>plot_surf_stat_map</span></a><span class=p>(</span>
        <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>fsaverage</span><span class=o>.</span><span class=n>infl_left</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>z_score</span></a><span class=p>,</span> <span class=n>hemi</span><span class=o>=</span><span class=s1>'left'</span><span class=p>,</span>
        <span class=n>title</span><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>contrast_id</span></a><span class=p>,</span> <span class=n>colorbar</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
        <span class=n>threshold</span><span class=o>=</span><span class=mf>3.</span><span class=p>,</span> <span class=n>bg_map</span><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#str title=builtins.str><span class=n>fsaverage</span><span class=o>.</span><span class=n>sulc_left</span></a><span class=p>)</span>

<a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.show.html#nilearn.plotting.show title=nilearn.plotting.show><span class=n>plotting</span><span class=o>.</span><span class=n>show</span></a><span class=p>()</span>
</pre></div></div><ul class=sphx-glr-horizontal><li><img alt="left - right button press"class=sphx-glr-multi-img src=../../_images/sphx_glr_plot_localizer_surface_analysis_004.png srcset=../../_images/sphx_glr_plot_localizer_surface_analysis_004.png></li><li><img alt="audio - visual"class=sphx-glr-multi-img src=../../_images/sphx_glr_plot_localizer_surface_analysis_005.png srcset=../../_images/sphx_glr_plot_localizer_surface_analysis_005.png></li><li><img alt="computation - sentences"class=sphx-glr-multi-img src=../../_images/sphx_glr_plot_localizer_surface_analysis_006.png srcset=../../_images/sphx_glr_plot_localizer_surface_analysis_006.png></li></ul><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>Contrast  1 out of 3: left - right button press, left hemisphere
Contrast  2 out of 3: audio - visual, left hemisphere
Contrast  3 out of 3: computation - sentences, left hemisphere
</pre></div></div><p class=sphx-glr-timing><strong>Total running time of the script:</strong> ( 0 minutes 16.988 seconds)</p><p><strong>Estimated memory usage:</strong> 121 MB</p><div class="sphx-glr-footer class sphx-glr-footer-example docutils container"id=sphx-glr-download-auto-examples-04-glm-first-level-plot-localizer-surface-analysis-py><div class="binder-badge docutils container"><a class="reference external image-reference"href=https://mybinder.org/v2/gh/nilearn/nilearn.github.io/main?filepath=examples/auto_examples/04_glm_first_level/plot_localizer_surface_analysis.ipynb><img alt="Launch binder"src=../../_images/binder_badge_logo3.svg width=150px></a></div><div class="sphx-glr-download sphx-glr-download-python docutils container"><p><a class="reference download internal"download href=../../_downloads/b7eb3f2924146abd15d79a4b7d48283e/plot_localizer_surface_analysis.py><code class="xref download docutils literal notranslate"><span class=pre>Download</span> <span class=pre>Python</span> <span class=pre>source</span> <span class=pre>code:</span> <span class=pre>plot_localizer_surface_analysis.py</span></code></a></p></div><div class="sphx-glr-download sphx-glr-download-jupyter docutils container"><p><a class="reference download internal"download href=../../_downloads/af0e1828cbbff81b7ed334306fbfe12c/plot_localizer_surface_analysis.ipynb><code class="xref download docutils literal notranslate"><span class=pre>Download</span> <span class=pre>Jupyter</span> <span class=pre>notebook:</span> <span class=pre>plot_localizer_surface_analysis.ipynb</span></code></a></p></div></div><p class=sphx-glr-signature><a class="reference external"href=https://sphinx-gallery.github.io>Gallery generated by Sphinx-Gallery</a></p></div></div><div class=clearer></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>9.5.11. Example of surface-based first-level analysis</a><ul><li><a class="reference internal"href=#prepare-data-and-analysis-parameters>9.5.11.1. Prepare data and analysis parameters</a></li><li><a class="reference internal"href=#project-the-fmri-image-to-the-surface>9.5.11.2. Project the fMRI image to the surface</a></li><li><a class="reference internal"href=#perform-first-level-analysis>9.5.11.3. Perform first level analysis</a></li><li><a class="reference internal"href=#estimate-contrasts>9.5.11.4. Estimate contrasts</a></li><li><a class="reference internal"href=#analysing-the-left-hemisphere>9.5.11.5. Analysing the left hemisphere</a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=plot_predictions_residuals.html><span class=section-number>9.5.10. </span>Predicted time series and residuals</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=plot_first_level_details.html><span class=section-number>9.5.12. </span>Understanding parameters of the first-level model</a></p><div id=searchbox role=search style=display:none><h3 id=searchlabel>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input aria-labelledby=searchlabel name=q><input type=submit value=Go></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2022. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 4.0.2. <span style=padding-left:5ex> <a href=../../_sources/auto_examples/04_glm_first_level/plot_localizer_surface_analysis.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>