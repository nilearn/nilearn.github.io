<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1.0 name=viewport><meta content="8.4.2. nilearn.decomposition.DictLearning"property=og:title><meta content=website property=og:type><meta content=https://nilearn.github.io/modules/generated/nilearn.decomposition.DictLearning.html property=og:url><meta content=Nilearn property=og:site_name><meta content="Examples using nilearn.decomposition.DictLearning: Deriving spatial maps from group fMRI data using ICA and Dictionary Learning Deriving spatial maps from group fMRI data using ICA and Dictionary L..."property=og:description><meta content=../../_images/sphx_glr_plot_compare_decomposition_thumb.png property=og:image><meta content="Deriving spatial maps from group fMRI data using ICA and Dictionary Learning"property=og:image:alt><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/copybutton.css rel=stylesheet><link href=../../_static/sg_gallery.css rel=stylesheet><link href=../../_static/sg_gallery-binder.css rel=stylesheet><link href=../../_static/sg_gallery-dataframe.css rel=stylesheet><link href=../../_static/sg_gallery-rendered-html.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/clipboard.min.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="8.5.1. nilearn.image.binarize_img"href=nilearn.image.binarize_img.html rel=next><link title="8.4.1. nilearn.decomposition.CanICA"href=nilearn.decomposition.CanICA.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="8.5.1. nilearn.image.binarize_img"accesskey=N href=nilearn.image.binarize_img.html>next</a> |</li><li class=right><a title="8.4.1. nilearn.decomposition.CanICA"accesskey=P href=nilearn.decomposition.CanICA.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../../auto_examples/index.html>Examples</a> | </li><li><a href=../reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li><a href=../../glossary.html>Glossary</a>| </li><li><a href=../../bibliography.html>Bibliography</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../reference.html><span class=section-number>8. </span>Reference documentation: all nilearn functions</a> »</li><li class="nav-item nav-item-this"><a href>Nilearn: Statistical Analysis for NeuroImaging in Python</a></li></ul></div></div><div class=stable-banner>This is the <em>stable</em> documentation for the latest release of Nilearn, the current development version is available <a href=https://nilearn.github.io/dev/index.html>here</a>.</div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="admonition note"><p class=admonition-title>Note</p><p>This page is a reference documentation. It only explains the class signature, and not how to use it. Please refer to the <a class="reference internal"href=../../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for the big picture.</p></div><div class=section id=nilearn-decomposition-dictlearning><h1><span class=section-number>8.4.2. </span>nilearn.decomposition.DictLearning<a title="Permalink to this headline"class=headerlink href=#nilearn-decomposition-dictlearning>¶</a></h1><dl class="py class"><dt class="sig sig-object py"id=nilearn.decomposition.DictLearning><em class=property><span class=pre>class</span> </em><span class="sig-prename descclassname"><span class=pre>nilearn.decomposition.</span></span><span class="sig-name descname"><span class=pre>DictLearning</span></span><span class=sig-paren>(</span><em class=sig-param><span class=n><span class=pre>n_components</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>20</span></span></em>, <em class=sig-param><span class=n><span class=pre>n_epochs</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>1</span></span></em>, <em class=sig-param><span class=n><span class=pre>alpha</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>10</span></span></em>, <em class=sig-param><span class=n><span class=pre>reduction_ratio</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>'auto'</span></span></em>, <em class=sig-param><span class=n><span class=pre>dict_init</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>random_state</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>batch_size</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>20</span></span></em>, <em class=sig-param><span class=n><span class=pre>method</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>'cd'</span></span></em>, <em class=sig-param><span class=n><span class=pre>mask</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>smoothing_fwhm</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>4</span></span></em>, <em class=sig-param><span class=n><span class=pre>standardize</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>True</span></span></em>, <em class=sig-param><span class=n><span class=pre>detrend</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>True</span></span></em>, <em class=sig-param><span class=n><span class=pre>low_pass</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>high_pass</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>t_r</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>target_affine</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>target_shape</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>mask_strategy</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>'epi'</span></span></em>, <em class=sig-param><span class=n><span class=pre>mask_args</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>n_jobs</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>1</span></span></em>, <em class=sig-param><span class=n><span class=pre>verbose</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>0</span></span></em>, <em class=sig-param><span class=n><span class=pre>memory</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>Memory(location=None)</span></span></em>, <em class=sig-param><span class=n><span class=pre>memory_level</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>0</span></span></em><span class=sig-paren>)</span><a class="reference external"href=https://github.com/nilearn/nilearn/blob/72e810f01/nilearn/decomposition/dict_learning.py#L37><span class=viewcode-link><span class=pre>[source]</span></span></a><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.DictLearning>¶</a></dt><dd><p>Perform a map learning algorithm based on spatial component sparsity, over a <a class="reference internal"href=../../glossary.html#term-CanICA><span class="xref std std-term">CanICA</span></a> initialization <a class="reference internal"href=#rd0eec3116114-1 id=id1>[1]</a>. This yields more stable maps than <a class="reference internal"href=../../glossary.html#term-CanICA><span class="xref std std-term">CanICA</span></a>.</p> <blockquote><div><div class=versionadded><p><span class="versionmodified added">New in version 0.2.</span></p></div></div></blockquote> <dl class=field-list><dt class=field-odd>Parameters</dt><dd class=field-odd><dl><dt><strong>mask</strong><span class=classifier>Niimg-like object or MultiNiftiMasker instance, optional</span></dt><dd><p>Mask to be used on data. If an instance of masker is passed, then its mask will be used. If no mask is given, it will be computed automatically by a MultiNiftiMasker with default parameters.</p></dd><dt><strong>n_components</strong><span class=classifier>int, optional</span></dt><dd><p>Number of components to extract. Default=20.</p></dd><dt><strong>batch_size</strong><span class=classifier>int, optional</span></dt><dd><p>The number of samples to take in each batch. Default=20.</p></dd><dt><strong>n_epochs</strong><span class=classifier>float, optional</span></dt><dd><p>Number of epochs the algorithm should run on the data. Default=1.</p></dd><dt><strong>alpha</strong><span class=classifier>float, optional</span></dt><dd><p>Sparsity controlling parameter. Default=10.</p></dd><dt><strong>dict_init</strong><span class=classifier>Niimg-like object, optional</span></dt><dd><p>Initial estimation of dictionary maps. Would be computed from CanICA if not provided.</p></dd><dt><strong>reduction_ratio</strong><span class=classifier>‘auto’ or float between 0. and 1., optional</span></dt><dd><ul class=simple><li><p>Between 0. or 1. : controls data reduction in the temporal domain. 1. means no reduction, < 1. calls for an SVD based reduction.</p></li><li><p>if set to ‘auto’, estimator will set the number of components per reduced session to be n_components. Default=’auto’.</p></li></ul></dd><dt><strong>method</strong><span class=classifier>{‘cd’, ‘lars’}, optional</span></dt><dd><p>Coding method used by sklearn backend. Below are the possible values. lars: uses the least angle regression method to solve the lasso problem (linear_model.lars_path) cd: uses the coordinate descent method to compute the Lasso solution (linear_model.Lasso). Lars will be faster if the estimated components are sparse. Default=’cd’.</p></dd><dt><strong>random_state</strong><span class=classifier>int or RandomState, optional</span></dt><dd><p>Pseudo number generator state used for random sampling.</p></dd><dt><strong>smoothing_fwhm</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#float><code class="xref py py-obj docutils literal notranslate"><span class=pre>float</span></code></a>, optional.</span></dt><dd><p>If <code class="docutils literal notranslate"><span class=pre>smoothing_fwhm</span></code> is not <code class="docutils literal notranslate"><span class=pre>None</span></code>, it gives the <a class="reference internal"href=../../glossary.html#term-FWHM><span class="xref std std-term">full-width at half maximum</span></a> in millimeters of the spatial smoothing to apply to the signal. Default=4mm.</p></dd><dt><strong>standardize</strong><span class=classifier>boolean, optional</span></dt><dd><p>If standardize is True, the time-series are centered and normed: their variance is put to 1 in the time dimension. Default=True.</p></dd><dt><strong>detrend</strong><span class=classifier>boolean, optional</span></dt><dd><p>If detrend is True, the time-series will be detrended before components extraction. Default=True.</p></dd><dt><strong>target_affine</strong><span class=classifier>3x3 or 4x4 matrix, optional</span></dt><dd><p>This parameter is passed to image.resample_img. Please see the related documentation for details.</p></dd><dt><strong>target_shape</strong><span class=classifier>3-tuple of integers, optional</span></dt><dd><p>This parameter is passed to image.resample_img. Please see the related documentation for details.</p></dd><dt><strong>low_pass</strong><span class=classifier>None or float, optional</span></dt><dd><p>This parameter is passed to signal.clean. Please see the related documentation for details.</p></dd><dt><strong>high_pass</strong><span class=classifier>None or float, optional</span></dt><dd><p>This parameter is passed to signal.clean. Please see the related documentation for details.</p></dd><dt><strong>t_r</strong><span class=classifier>float, optional</span></dt><dd><p>This parameter is passed to signal.clean. Please see the related documentation for details.</p></dd><dt><strong>mask_strategy</strong><span class=classifier>{‘background’, ‘epi’, ‘whole-brain-template’,’gm-template’, ‘wm-template’}, optional</span></dt><dd><p>The strategy used to compute the mask:</p> <blockquote><div><ul><li><p>‘background’: Use this option if your images present a clear homogeneous background.</p></li><li><p>‘epi’: Use this option if your images are raw EPI images</p></li><li><p>‘whole-brain-template’: This will extract the whole-brain part of your data by resampling the MNI152 brain mask for your data’s field of view.</p> <blockquote><div><div class="admonition note"><p class=admonition-title>Note</p><p>This option is equivalent to the previous ‘template’ option which is now deprecated.</p></div></div></blockquote></li><li><p>‘gm-template’: This will extract the gray matter part of your data by resampling the corresponding MNI152 template for your data’s field of view.</p> <blockquote><div><div class=versionadded><p><span class="versionmodified added">New in version 0.8.1.</span></p></div></div></blockquote></li><li><p>‘wm-template’: This will extract the white matter part of your data by resampling the corresponding MNI152 template for your data’s field of view.</p> <blockquote><div><div class=versionadded><p><span class="versionmodified added">New in version 0.8.1.</span></p></div></div></blockquote></li></ul></div></blockquote> <div class="admonition note"><p class=admonition-title>Note</p><p>Depending on this value, the mask will be computed from <a class="reference internal"href=nilearn.masking.compute_background_mask.html#nilearn.masking.compute_background_mask title=nilearn.masking.compute_background_mask><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.masking.compute_background_mask</span></code></a>, <a class="reference internal"href=nilearn.masking.compute_epi_mask.html#nilearn.masking.compute_epi_mask title=nilearn.masking.compute_epi_mask><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.masking.compute_epi_mask</span></code></a>, or <a class="reference internal"href=nilearn.masking.compute_brain_mask.html#nilearn.masking.compute_brain_mask title=nilearn.masking.compute_brain_mask><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.masking.compute_brain_mask</span></code></a>.</p></div> <p>Default=’epi’.</p></dd><dt><strong>mask_args</strong><span class=classifier>dict, optional</span></dt><dd><p>If mask is None, these are additional parameters passed to masking.compute_background_mask or masking.compute_epi_mask to fine-tune mask computation. Please see the related documentation for details.</p></dd><dt><strong>memory</strong><span class=classifier>instance of joblib.Memory or string, optional</span></dt><dd><p>Used to cache the masking process. By default, no caching is done. If a string is given, it is the path to the caching directory.</p></dd><dt><strong>memory_level</strong><span class=classifier>integer, optional</span></dt><dd><p>Rough estimator of the amount of memory used by caching. Higher value means more memory for caching. Default=0.</p></dd><dt><strong>n_jobs</strong><span class=classifier>integer, optional</span></dt><dd><p>The number of CPUs to use to do the computation. -1 means ‘all CPUs’, -2 ‘all CPUs but one’, and so on. Default=1.</p></dd><dt><strong>verbose</strong><span class=classifier>integer, optional</span></dt><dd><p>Indicate the level of verbosity. By default, nothing is printed. Default=0.</p></dd></dl></dd></dl> <p class=rubric>References</p> <dl class=citation><dt class=label id=rd0eec3116114-1><span class=brackets><a class=fn-backref href=#id1>1</a></span></dt><dd><p>Arthur Mensch, Gael Varoquaux, Bertrand Thirion, Compressed online dictionary learning for fast resting-state fMRI decomposition. IEEE 13th International Symposium on Biomedical Imaging (ISBI), 2016. pp. 1282-1285</p></dd></dl> <dl class=field-list><dt class=field-odd>Attributes</dt><dd class=field-odd><dl><dt><strong>`components_`</strong><span class=classifier>2D numpy array (n_components x n-voxels)</span></dt><dd><p>Masked dictionary components extracted from the input images.</p> <div class="admonition note"><p class=admonition-title>Note</p><p>Use attribute <cite>components_img_</cite> rather than manually unmasking <cite>components_</cite> with <cite>masker_</cite> attribute.</p></div></dd><dt><strong>`components_img_`</strong><span class=classifier>4D Nifti image</span></dt><dd><p>4D image giving the extracted components. Each 3D image is a component.</p> <div class=versionadded><p><span class="versionmodified added">New in version 0.4.1.</span></p></div></dd><dt><strong>`masker_`</strong><span class=classifier>instance of MultiNiftiMasker</span></dt><dd><p>Masker used to filter and mask data as first step. If an instance of MultiNiftiMasker is given in <cite>mask</cite> parameter, this is a copy of it. Otherwise, a masker is created using the value of <cite>mask</cite> and other NiftiMasker related parameters as initialization.</p></dd><dt><strong>`mask_img_`</strong><span class=classifier>Niimg-like object</span></dt><dd><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> The mask of the data. If no mask was given at masker creation, contains the automatically computed mask.</p></dd></dl></dd></dl> <dl class="py method"><dt class="sig sig-object py"id=nilearn.decomposition.DictLearning.__init__><span class="sig-name descname"><span class=pre>__init__</span></span><span class=sig-paren>(</span><em class=sig-param><span class=n><span class=pre>n_components</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>20</span></span></em>, <em class=sig-param><span class=n><span class=pre>n_epochs</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>1</span></span></em>, <em class=sig-param><span class=n><span class=pre>alpha</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>10</span></span></em>, <em class=sig-param><span class=n><span class=pre>reduction_ratio</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>'auto'</span></span></em>, <em class=sig-param><span class=n><span class=pre>dict_init</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>random_state</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>batch_size</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>20</span></span></em>, <em class=sig-param><span class=n><span class=pre>method</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>'cd'</span></span></em>, <em class=sig-param><span class=n><span class=pre>mask</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>smoothing_fwhm</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>4</span></span></em>, <em class=sig-param><span class=n><span class=pre>standardize</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>True</span></span></em>, <em class=sig-param><span class=n><span class=pre>detrend</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>True</span></span></em>, <em class=sig-param><span class=n><span class=pre>low_pass</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>high_pass</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>t_r</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>target_affine</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>target_shape</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>mask_strategy</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>'epi'</span></span></em>, <em class=sig-param><span class=n><span class=pre>mask_args</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>n_jobs</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>1</span></span></em>, <em class=sig-param><span class=n><span class=pre>verbose</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>0</span></span></em>, <em class=sig-param><span class=n><span class=pre>memory</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>Memory(location=None)</span></span></em>, <em class=sig-param><span class=n><span class=pre>memory_level</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>0</span></span></em><span class=sig-paren>)</span><a class="reference external"href=https://github.com/nilearn/nilearn/blob/72e810f01/nilearn/decomposition/dict_learning.py#L184><span class=viewcode-link><span class=pre>[source]</span></span></a><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.DictLearning.__init__>¶</a></dt><dd><p>Initialize self. See help(type(self)) for accurate signature.</p></dd></dl> <dl class="py method"><dt class="sig sig-object py"id=nilearn.decomposition.DictLearning.fit><span class="sig-name descname"><span class=pre>fit</span></span><span class=sig-paren>(</span><em class=sig-param><span class=n><span class=pre>imgs</span></span></em>, <em class=sig-param><span class=n><span class=pre>y</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>confounds</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em><span class=sig-paren>)</span><a class="reference external"href=https://github.com/nilearn/nilearn/blob/72e810f01/nilearn/decomposition/base.py#L361><span class=viewcode-link><span class=pre>[source]</span></span></a><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.DictLearning.fit>¶</a></dt><dd><p>Compute the mask and the components across subjects</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>imgs</strong><span class=classifier>list of Niimg-like objects</span></dt><dd><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> Data on which the mask is calculated. If this is a list, the affine is considered the same for all.</p></dd><dt><strong>confounds</strong><span class=classifier>list of CSV file paths or numpy.ndarrays or pandas DataFrames, optional</span></dt><dd><p>This parameter is passed to nilearn.signal.clean. Please see the related documentation for details. Should match with the list of imgs given.</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>self</strong><span class=classifier>object</span></dt><dd><p>Returns the instance itself. Contains attributes listed at the object level.</p></dd></dl></dd></dl></dd></dl> <dl class="py method"><dt class="sig sig-object py"id=nilearn.decomposition.DictLearning.fit_transform><span class="sig-name descname"><span class=pre>fit_transform</span></span><span class=sig-paren>(</span><em class=sig-param><span class=n><span class=pre>X</span></span></em>, <em class=sig-param><span class=n><span class=pre>y</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=o><span class=pre>**</span></span><span class=n><span class=pre>fit_params</span></span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.DictLearning.fit_transform>¶</a></dt><dd><p>Fit to data, then transform it.</p> <p>Fits transformer to <cite>X</cite> and <cite>y</cite> with optional parameters <cite>fit_params</cite> and returns a transformed version of <cite>X</cite>.</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>X</strong><span class=classifier>array-like of shape (n_samples, n_features)</span></dt><dd><p>Input samples.</p></dd><dt><strong>y</strong><span class=classifier>array-like of shape (n_samples,) or (n_samples, n_outputs), default=None</span></dt><dd><p>Target values (None for unsupervised transformations).</p></dd><dt><strong>**fit_params</strong><span class=classifier>dict</span></dt><dd><p>Additional fit parameters.</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>X_new</strong><span class=classifier>ndarray array of shape (n_samples, n_features_new)</span></dt><dd><p>Transformed array.</p></dd></dl></dd></dl></dd></dl> <dl class="py method"><dt class="sig sig-object py"id=nilearn.decomposition.DictLearning.get_params><span class="sig-name descname"><span class=pre>get_params</span></span><span class=sig-paren>(</span><em class=sig-param><span class=n><span class=pre>deep</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>True</span></span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.DictLearning.get_params>¶</a></dt><dd><p>Get parameters for this estimator.</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>deep</strong><span class=classifier>bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>params</strong><span class=classifier>dict</span></dt><dd><p>Parameter names mapped to their values.</p></dd></dl></dd></dl></dd></dl> <dl class="py method"><dt class="sig sig-object py"id=nilearn.decomposition.DictLearning.inverse_transform><span class="sig-name descname"><span class=pre>inverse_transform</span></span><span class=sig-paren>(</span><em class=sig-param><span class=n><span class=pre>loadings</span></span></em><span class=sig-paren>)</span><a class="reference external"href=https://github.com/nilearn/nilearn/blob/72e810f01/nilearn/decomposition/base.py#L468><span class=viewcode-link><span class=pre>[source]</span></span></a><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.DictLearning.inverse_transform>¶</a></dt><dd><p>Use provided loadings to compute corresponding linear component combination in whole-brain voxel space</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>loadings</strong><span class=classifier>list of numpy array (n_samples x n_components)</span></dt><dd><p>Component signals to transform back into voxel signals</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>reconstructed_imgs</strong><span class=classifier>list of nibabel.Nifti1Image</span></dt><dd><p>For each loading, reconstructed Nifti1Image</p></dd></dl></dd></dl></dd></dl> <dl class="py method"><dt class="sig sig-object py"id=nilearn.decomposition.DictLearning.score><span class="sig-name descname"><span class=pre>score</span></span><span class=sig-paren>(</span><em class=sig-param><span class=n><span class=pre>imgs</span></span></em>, <em class=sig-param><span class=n><span class=pre>confounds</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>per_component</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>False</span></span></em><span class=sig-paren>)</span><a class="reference external"href=https://github.com/nilearn/nilearn/blob/72e810f01/nilearn/decomposition/base.py#L505><span class=viewcode-link><span class=pre>[source]</span></span></a><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.DictLearning.score>¶</a></dt><dd><p>Score function based on explained variance on imgs.</p> <p>Should only be used by DecompositionEstimator derived classes</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>imgs</strong><span class=classifier>iterable of Niimg-like objects</span></dt><dd><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> Data to be scored</p></dd><dt><strong>confounds</strong><span class=classifier>CSV file path or numpy.ndarray or pandas DataFrame, optional</span></dt><dd><p>This parameter is passed to nilearn.signal.clean. Please see the related documentation for details</p></dd><dt><strong>per_component</strong><span class=classifier>bool, optional</span></dt><dd><p>Specify whether the explained variance ratio is desired for each map or for the global set of components. Default=False.</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>score</strong><span class=classifier>float</span></dt><dd><p>Holds the score for each subjects. Score is two dimensional if per_component is True. First dimension is squeezed if the number of subjects is one</p></dd></dl></dd></dl></dd></dl> <dl class="py method"><dt class="sig sig-object py"id=nilearn.decomposition.DictLearning.set_params><span class="sig-name descname"><span class=pre>set_params</span></span><span class=sig-paren>(</span><em class=sig-param><span class=o><span class=pre>**</span></span><span class=n><span class=pre>params</span></span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.DictLearning.set_params>¶</a></dt><dd><p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as <a class="reference external"title="(in scikit-learn v1.0)"href=https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline><code class="xref py py-class docutils literal notranslate"><span class=pre>Pipeline</span></code></a>). The latter have parameters of the form <code class="docutils literal notranslate"><span class=pre>&LTcomponent>__&LTparameter></span></code> so that it’s possible to update each component of a nested object.</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>**params</strong><span class=classifier>dict</span></dt><dd><p>Estimator parameters.</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>self</strong><span class=classifier>estimator instance</span></dt><dd><p>Estimator instance.</p></dd></dl></dd></dl></dd></dl> <dl class="py method"><dt class="sig sig-object py"id=nilearn.decomposition.DictLearning.transform><span class="sig-name descname"><span class=pre>transform</span></span><span class=sig-paren>(</span><em class=sig-param><span class=n><span class=pre>imgs</span></span></em>, <em class=sig-param><span class=n><span class=pre>confounds</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em><span class=sig-paren>)</span><a class="reference external"href=https://github.com/nilearn/nilearn/blob/72e810f01/nilearn/decomposition/base.py#L439><span class=viewcode-link><span class=pre>[source]</span></span></a><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.DictLearning.transform>¶</a></dt><dd><p>Project the data into a reduced representation</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>imgs</strong><span class=classifier>iterable of Niimg-like objects</span></dt><dd><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> Data to be projected</p></dd><dt><strong>confounds</strong><span class=classifier>CSV file path or numpy.ndarray or pandas DataFrame, optional</span></dt><dd><p>This parameter is passed to nilearn.signal.clean. Please see the related documentation for details</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>loadings</strong><span class=classifier>list of 2D ndarray,</span></dt><dd><p>For each subject, each sample, loadings for each decomposition components shape: number of subjects * (number of scans, number of regions)</p></dd></dl></dd></dl></dd></dl></dd></dl><div class=section id=examples-using-nilearn-decomposition-dictlearning><h2><span class=section-number>8.4.2.1. </span>Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.decomposition.DictLearning</span></code><a title="Permalink to this headline"class=headerlink href=#examples-using-nilearn-decomposition-dictlearning>¶</a></h2><div tooltip="Various approaches exist to derive spatial maps or networks from group fmr data. The methods ex..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id3><img alt="Deriving spatial maps from group fMRI data using ICA and Dictionary Learning"src=../../_images/sphx_glr_plot_compare_decomposition_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_compare_decomposition.html#sphx-glr-auto-examples-03-connectivity-plot-compare-decomposition-py><span class="std std-ref">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</span></a></span><a title="Permalink to this image"class=headerlink href=#id3>¶</a></p></div></div><div tooltip="This example shows how to use nilearn.regions.RegionExtractor to extract spatially constrained ..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id4><img alt="Regions extraction using :term:`Dictionary learning` and functional connectomes"src=../../_images/sphx_glr_plot_extract_regions_dictlearning_maps_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html#sphx-glr-auto-examples-03-connectivity-plot-extract-regions-dictlearning-maps-py><span class="std std-ref">Regions extraction using Dictionary learning and functional connectomes</span></a></span><a title="Permalink to this image"class=headerlink href=#id4>¶</a></p></div></div><div style=clear:both></div></div></div><div class=clearer></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>8.4.2. nilearn.decomposition.DictLearning</a><ul><li><a class="reference internal"href=#examples-using-nilearn-decomposition-dictlearning>8.4.2.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.decomposition.DictLearning</span></code></a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=nilearn.decomposition.CanICA.html><span class=section-number>8.4.1. </span>nilearn.decomposition.CanICA</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=nilearn.image.binarize_img.html><span class=section-number>8.5.1. </span>nilearn.image.binarize_img</a></p><div id=searchbox role=search style=display:none><h3 id=searchlabel>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input aria-labelledby=searchlabel name=q><input type=submit value=Go></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2022. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 4.0.2. <span style=padding-left:5ex> <a href=../../_sources/modules/generated/nilearn.decomposition.DictLearning.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>