<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1.0 name=viewport><meta content="8.11.11. nilearn.plotting.plot_glass_brain"property=og:title><meta content=website property=og:type><meta content=https://nilearn.github.io/modules/generated/nilearn.plotting.plot_glass_brain.html property=og:url><meta content=Nilearn property=og:site_name><meta content="Examples using nilearn.plotting.plot_glass_brain: Glass brain plotting in nilearn Glass brain plotting in nilearn, Plotting tools in nilearn Plotting tools in nilearn, Making a surface plot of a 3D..."property=og:description><meta content=../../_images/sphx_glr_plot_demo_glass_brain_thumb.png property=og:image><meta content="Glass brain plotting in nilearn"property=og:image:alt><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/copybutton.css rel=stylesheet><link href=../../_static/sg_gallery.css rel=stylesheet><link href=../../_static/sg_gallery-binder.css rel=stylesheet><link href=../../_static/sg_gallery-dataframe.css rel=stylesheet><link href=../../_static/sg_gallery-rendered-html.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/clipboard.min.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="8.11.12. nilearn.plotting.plot_connectome"href=nilearn.plotting.plot_connectome.html rel=next><link title="8.11.10. nilearn.plotting.plot_stat_map"href=nilearn.plotting.plot_stat_map.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="8.11.12. nilearn.plotting.plot_connectome"accesskey=N href=nilearn.plotting.plot_connectome.html>next</a> |</li><li class=right><a title="8.11.10. nilearn.plotting.plot_stat_map"accesskey=P href=nilearn.plotting.plot_stat_map.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../../auto_examples/index.html>Examples</a> | </li><li><a href=../reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li><a href=../../glossary.html>Glossary</a>| </li><li><a href=../../bibliography.html>Bibliography</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../reference.html><span class=section-number>8. </span>Reference documentation: all nilearn functions</a> »</li><li class="nav-item nav-item-this"><a href>Nilearn: Statistical Analysis for NeuroImaging in Python</a></li></ul></div></div><div class=stable-banner>This is the <em>stable</em> documentation for the latest release of Nilearn, the current development version is available <a href=https://nilearn.github.io/dev/index.html>here</a>.</div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="admonition note"><p class=admonition-title>Note</p><p>This page is a reference documentation. It only explains the function signature, and not how to use it. Please refer to the <a class="reference internal"href=../../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for the big picture.</p></div><div class=section id=nilearn-plotting-plot-glass-brain><h1><span class=section-number>8.11.11. </span>nilearn.plotting.plot_glass_brain<a title="Permalink to this headline"class=headerlink href=#nilearn-plotting-plot-glass-brain>¶</a></h1><dl class="py function"><dt class="sig sig-object py"id=nilearn.plotting.plot_glass_brain><span class="sig-prename descclassname"><span class=pre>nilearn.plotting.</span></span><span class="sig-name descname"><span class=pre>plot_glass_brain</span></span><span class=sig-paren>(</span><em class=sig-param><span class=n><span class=pre>stat_map_img</span></span></em>, <em class=sig-param><span class=n><span class=pre>output_file</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>display_mode</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>'ortho'</span></span></em>, <em class=sig-param><span class=n><span class=pre>colorbar</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>False</span></span></em>, <em class=sig-param><span class=n><span class=pre>cbar_tick_format</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>'%.2g'</span></span></em>, <em class=sig-param><span class=n><span class=pre>figure</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>axes</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>title</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>threshold</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>'auto'</span></span></em>, <em class=sig-param><span class=n><span class=pre>annotate</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>True</span></span></em>, <em class=sig-param><span class=n><span class=pre>black_bg</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>False</span></span></em>, <em class=sig-param><span class=n><span class=pre>cmap</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>alpha</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>0.7</span></span></em>, <em class=sig-param><span class=n><span class=pre>vmin</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>vmax</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>plot_abs</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>True</span></span></em>, <em class=sig-param><span class=n><span class=pre>symmetric_cbar</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>'auto'</span></span></em>, <em class=sig-param><span class=n><span class=pre>resampling_interpolation</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>'continuous'</span></span></em>, <em class=sig-param><span class=o><span class=pre>**</span></span><span class=n><span class=pre>kwargs</span></span></em><span class=sig-paren>)</span><a class="reference external"href=https://github.com/nilearn/nilearn/blob/72e810f01/nilearn/plotting/img_plotting.py#L1001><span class=viewcode-link><span class=pre>[source]</span></span></a><a title="Permalink to this definition"class=headerlink href=#nilearn.plotting.plot_glass_brain>¶</a></dt><dd><p>Plot 2d projections of an ROI/mask image (by default 3 projections: Frontal, Axial, and Lateral). The brain glass schematics are added on top of the image.</p> <p>The plotted image should be in MNI space for this function to work properly.</p> <p>Only glass brain can be plotted by switching stat_map_img to None.</p> <dl class=field-list><dt class=field-odd>Parameters</dt><dd class=field-odd><dl><dt><strong>stat_map_img</strong><span class=classifier>Niimg-like object</span></dt><dd><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> The statistical map image. It needs to be in MNI space in order to align with the brain schematics.</p></dd><dt><strong>output_file</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/stdtypes.html#str><code class="xref py py-obj docutils literal notranslate"><span class=pre>str</span></code></a>, or None, optional</span></dt><dd><p>The name of an image file to export the plot to. Valid extensions are .png, .pdf, .svg. If <code class="docutils literal notranslate"><span class=pre>output_file</span></code> is not None, the plot is saved to a file, and the display is closed.</p></dd><dt><strong>display_mode</strong><span class=classifier>string, optional</span></dt><dd><p>Choose the direction of the cuts: ‘x’ - sagittal, ‘y’ - coronal, ‘z’ - axial, ‘l’ - sagittal left hemisphere only, ‘r’ - sagittal right hemisphere only, ‘ortho’ - three cuts are performed in orthogonal directions. Possible values are: ‘ortho’, ‘x’, ‘y’, ‘z’, ‘xz’, ‘yx’, ‘yz’, ‘l’, ‘r’, ‘lr’, ‘lzr’, ‘lyr’, ‘lzry’, ‘lyrz’. Default=’ortho’.</p></dd><dt><strong>colorbar</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#bool><code class="xref py py-obj docutils literal notranslate"><span class=pre>bool</span></code></a>, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class=pre>True</span></code>, display a colorbar on the right of the plots. Default=False.</p></dd><dt><strong>cbar_tick_format: str, optional</strong></dt><dd><p>Controls how to format the tick labels of the colorbar. Ex: use “%i” to display as integers. Default is ‘%.2g’ for scientific notation.</p></dd><dt><strong>figure</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#int><code class="xref py py-obj docutils literal notranslate"><span class=pre>int</span></code></a>, or <a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure><code class="xref py py-class docutils literal notranslate"><span class=pre>matplotlib.figure.Figure</span></code></a>, or None, optional</span></dt><dd><p>Matplotlib figure used or its number. If <code class="docutils literal notranslate"><span class=pre>None</span></code> is given, a new figure is created.</p></dd><dt><strong>axes</strong><span class=classifier><a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/axes_api.html#matplotlib.axes.Axes><code class="xref py py-class docutils literal notranslate"><span class=pre>matplotlib.axes.Axes</span></code></a>, or 4 tupleof <a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#float><code class="xref py py-obj docutils literal notranslate"><span class=pre>float</span></code></a>: (xmin, ymin, width, height), optional</span></dt><dd><p>The axes, or the coordinates, in matplotlib figure space, of the axes used to display the plot. If <code class="docutils literal notranslate"><span class=pre>None</span></code>, the complete figure is used.</p></dd><dt><strong>title</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/stdtypes.html#str><code class="xref py py-obj docutils literal notranslate"><span class=pre>str</span></code></a>, or None, optional</span></dt><dd><p>The title displayed on the figure. Default=None.</p></dd><dt><strong>threshold</strong><span class=classifier>a number, None, or ‘auto’, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class=pre>None</span></code> is given, the image is not thresholded. If a number is given, it is used to threshold the image: values below the threshold (in absolute value) are plotted as transparent. If ‘auto’ is given, the threshold is determined magically by analysis of the image. Default=’auto’.</p></dd><dt><strong>annotate</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#bool><code class="xref py py-obj docutils literal notranslate"><span class=pre>bool</span></code></a>, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class=pre>annotate</span></code> is <code class="docutils literal notranslate"><span class=pre>True</span></code>, positions and left/right annotation are added to the plot. Default=True.</p></dd><dt><strong>black_bg</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#bool><code class="xref py py-obj docutils literal notranslate"><span class=pre>bool</span></code></a>, or ‘auto’, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class=pre>True</span></code>, the background of the image is set to be black. If you wish to save figures with a black background, you will need to pass facecolor=’k’, edgecolor=’k’ to <a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html#matplotlib.pyplot.savefig><code class="xref py py-func docutils literal notranslate"><span class=pre>matplotlib.pyplot.savefig</span></code></a>. Default=False.</p></dd><dt><strong>cmap</strong><span class=classifier><a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/_as_gen/matplotlib.colors.Colormap.html#matplotlib.colors.Colormap><code class="xref py py-class docutils literal notranslate"><span class=pre>matplotlib.colors.Colormap</span></code></a>, or <a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/stdtypes.html#str><code class="xref py py-obj docutils literal notranslate"><span class=pre>str</span></code></a>, optional</span></dt><dd><p>The colormap to use. Either a string which is a name of a matplotlib colormap, or a matplotlib colormap object. Default=None.</p></dd><dt><strong>alpha</strong><span class=classifier>float between 0 and 1, optional</span></dt><dd><p>Alpha transparency for the brain schematics. Default=0.7.</p></dd><dt><strong>vmin</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#float><code class="xref py py-obj docutils literal notranslate"><span class=pre>float</span></code></a>, optional</span></dt><dd><p>Lower bound of the colormap. If <code class="docutils literal notranslate"><span class=pre>None</span></code>, the min of the image is used. Passed to <a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html#matplotlib.pyplot.imshow><code class="xref py py-func docutils literal notranslate"><span class=pre>matplotlib.pyplot.imshow</span></code></a>.</p></dd><dt><strong>vmax</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#float><code class="xref py py-obj docutils literal notranslate"><span class=pre>float</span></code></a>, optional</span></dt><dd><p>Upper bound of the colormap. If <code class="docutils literal notranslate"><span class=pre>None</span></code>, the max of the image is used. Passed to <a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html#matplotlib.pyplot.imshow><code class="xref py py-func docutils literal notranslate"><span class=pre>matplotlib.pyplot.imshow</span></code></a>.</p></dd><dt><strong>plot_abs</strong><span class=classifier>boolean, optional</span></dt><dd><p>If set to True (default) maximum intensity projection of the absolute value will be used (rendering positive and negative values in the same manner). If set to false the sign of the maximum intensity will be represented with different colors. See <a class="reference external"href=http://nilearn.github.io/auto_examples/01_plotting/plot_demo_glass_brain_extensive.html>http://nilearn.github.io/auto_examples/01_plotting/plot_demo_glass_brain_extensive.html</a> for examples. Default=True.</p></dd><dt><strong>symmetric_cbar</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#bool><code class="xref py py-obj docutils literal notranslate"><span class=pre>bool</span></code></a>, or ‘auto’, optional</span></dt><dd><p>Specifies whether the colorbar should range from <code class="docutils literal notranslate"><span class=pre>-vmax</span></code> to <code class="docutils literal notranslate"><span class=pre>vmax</span></code> or from <code class="docutils literal notranslate"><span class=pre>vmin</span></code> to <code class="docutils literal notranslate"><span class=pre>vmax</span></code>. Setting to ‘auto’ will select the latter if the range of the whole image is either positive or negative.</p> <div class="admonition note"><p class=admonition-title>Note</p><p>The colormap will always range from <code class="docutils literal notranslate"><span class=pre>-vmax</span></code> to <code class="docutils literal notranslate"><span class=pre>vmax</span></code>.</p></div> <p>Default=’auto’.</p></dd><dt><strong>resampling_interpolation</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/stdtypes.html#str><code class="xref py py-obj docutils literal notranslate"><span class=pre>str</span></code></a>, optional</span></dt><dd><p>Interpolation to use when resampling the image to the destination space. Can be:</p> <blockquote><div><ul><li><p>“continuous”: use 3rd-order spline interpolation</p></li><li><p>“nearest”: use nearest-neighbor mapping.</p> <blockquote><div><div class="admonition note"><p class=admonition-title>Note</p><p>“nearest” is faster but can be noisier in some cases.</p></div></div></blockquote></li></ul></div></blockquote> <p>Default=’continuous’.</p></dd></dl></dd></dl> <p class=rubric>Notes</p> <p>Arrays should be passed in numpy convention: (x, y, z) ordered.</p></dd></dl><div class=section id=examples-using-nilearn-plotting-plot-glass-brain><h2><span class=section-number>8.11.11.1. </span>Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.plotting.plot_glass_brain</span></code><a title="Permalink to this headline"class=headerlink href=#examples-using-nilearn-plotting-plot-glass-brain>¶</a></h2><div tooltip="See plotting for more plotting functionalities."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id1><img alt="Glass brain plotting in nilearn"src=../../_images/sphx_glr_plot_demo_glass_brain_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_demo_glass_brain.html#sphx-glr-auto-examples-01-plotting-plot-demo-glass-brain-py><span class="std std-ref">Glass brain plotting in nilearn</span></a></span><a title="Permalink to this image"class=headerlink href=#id1>¶</a></p></div></div><div tooltip="Nilearn comes with a set of plotting functions for easy visualization of Nifti-like images such..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id2><img alt="Plotting tools in nilearn"src=../../_images/sphx_glr_plot_demo_plotting_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_demo_plotting.html#sphx-glr-auto-examples-01-plotting-plot-demo-plotting-py><span class="std std-ref">Plotting tools in nilearn</span></a></span><a title="Permalink to this image"class=headerlink href=#id2>¶</a></p></div></div><div tooltip="In this example, we will project a 3D statistical map onto a cortical mesh using vol_to_surf, d..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id3><img alt="Making a surface plot of a 3D statistical map"src=../../_images/sphx_glr_plot_3d_map_to_surface_projection_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_3d_map_to_surface_projection.html#sphx-glr-auto-examples-01-plotting-plot-3d-map-to-surface-projection-py><span class="std std-ref">Making a surface plot of a 3D statistical map</span></a></span><a title="Permalink to this image"class=headerlink href=#id3>¶</a></p></div></div><div tooltip="The first part of this example goes through different options of the plot_glass_brain function ..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id4><img alt="Glass brain plotting in nilearn (all options)"src=../../_images/sphx_glr_plot_demo_glass_brain_extensive_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_demo_glass_brain_extensive.html#sphx-glr-auto-examples-01-plotting-plot-demo-glass-brain-extensive-py><span class="std std-ref">Glass brain plotting in nilearn (all options)</span></a></span><a title="Permalink to this image"class=headerlink href=#id4>¶</a></p></div></div><div tooltip=" Full step-by-step example of fitting a GLM to perform a first level analysis in an openneuro B..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id5><img alt="First level analysis of a complete BIDS dataset from openneuro"src=../../_images/sphx_glr_plot_bids_features_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/04_glm_first_level/plot_bids_features.html#sphx-glr-auto-examples-04-glm-first-level-plot-bids-features-py><span class="std std-ref">First level analysis of a complete BIDS dataset from openneuro</span></a></span><a title="Permalink to this image"class=headerlink href=#id5>¶</a></p></div></div><div tooltip="Full step-by-step example of fitting a GLM to perform a second level analysis in experimental d..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id6><img alt="Second-level fMRI model: two-sample test, unpaired and paired"src=../../_images/sphx_glr_plot_second_level_two_sample_test_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/05_glm_second_level/plot_second_level_two_sample_test.html#sphx-glr-auto-examples-05-glm-second-level-plot-second-level-two-sample-test-py><span class="std std-ref">Second-level fMRI model: two-sample test, unpaired and paired</span></a></span><a title="Permalink to this image"class=headerlink href=#id6>¶</a></p></div></div><div tooltip="Full step-by-step example of fitting a GLM to perform a second-level analysis (one-sample test)..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id7><img alt="Second-level fMRI model: one sample test"src=../../_images/sphx_glr_plot_second_level_one_sample_test_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html#sphx-glr-auto-examples-05-glm-second-level-plot-second-level-one-sample-test-py><span class="std std-ref">Second-level fMRI model: one sample test</span></a></span><a title="Permalink to this image"class=headerlink href=#id7>¶</a></p></div></div><div tooltip=" Full step-by-step example of fitting a GLM to perform a first and second level analysis in a B..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id8><img alt="BIDS dataset first and second level analysis"src=../../_images/sphx_glr_plot_bids_analysis_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/07_advanced/plot_bids_analysis.html#sphx-glr-auto-examples-07-advanced-plot-bids-analysis-py><span class="std std-ref">BIDS dataset first and second level analysis</span></a></span><a title="Permalink to this image"class=headerlink href=#id8>¶</a></p></div></div><div tooltip="This example shows how to download statistical maps from NeuroVault"class=sphx-glr-thumbcontainer><div class="figure align-default"id=id9><img alt="NeuroVault meta-analysis of stop-go paradigm studies."src=../../_images/sphx_glr_plot_neurovault_meta_analysis_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/07_advanced/plot_neurovault_meta_analysis.html#sphx-glr-auto-examples-07-advanced-plot-neurovault-meta-analysis-py><span class="std std-ref">NeuroVault meta-analysis of stop-go paradigm studies.</span></a></span><a title="Permalink to this image"class=headerlink href=#id9>¶</a></p></div></div><div style=clear:both></div></div></div><div class=clearer></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>8.11.11. nilearn.plotting.plot_glass_brain</a><ul><li><a class="reference internal"href=#examples-using-nilearn-plotting-plot-glass-brain>8.11.11.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.plotting.plot_glass_brain</span></code></a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=nilearn.plotting.plot_stat_map.html><span class=section-number>8.11.10. </span>nilearn.plotting.plot_stat_map</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=nilearn.plotting.plot_connectome.html><span class=section-number>8.11.12. </span>nilearn.plotting.plot_connectome</a></p><div id=searchbox role=search style=display:none><h3 id=searchlabel>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input aria-labelledby=searchlabel name=q><input type=submit value=Go></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2022. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 4.0.2. <span style=padding-left:5ex> <a href=../../_sources/modules/generated/nilearn.plotting.plot_glass_brain.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>