<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1.0 name=viewport><meta content="8.6.2.2. nilearn.interfaces.fmriprep.load_confounds_strategy"property=og:title><meta content=website property=og:type><meta content=https://nilearn.github.io/modules/generated/nilearn.interfaces.fmriprep.load_confounds_strategy.html property=og:url><meta content=Nilearn property=og:site_name><meta content="Examples using nilearn.interfaces.fmriprep.load_confounds_strategy: Extracting signals from a brain parcellation Extracting signals from a brain parcellation,"property=og:description><meta content=../../_images/sphx_glr_plot_signal_extraction_thumb.png property=og:image><meta content="Extracting signals from a brain parcellation"property=og:image:alt><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/copybutton.css rel=stylesheet><link href=../../_static/sg_gallery.css rel=stylesheet><link href=../../_static/sg_gallery-binder.css rel=stylesheet><link href=../../_static/sg_gallery-dataframe.css rel=stylesheet><link href=../../_static/sg_gallery-rendered-html.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/clipboard.min.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="8.6.3.1. nilearn.interfaces.fsl.get_design_from_fslmat"href=nilearn.interfaces.fsl.get_design_from_fslmat.html rel=next><link title="8.6.2.1. nilearn.interfaces.fmriprep.load_confounds"href=nilearn.interfaces.fmriprep.load_confounds.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="8.6.3.1. nilearn.interfaces.fsl.get_design_from_fslmat"accesskey=N href=nilearn.interfaces.fsl.get_design_from_fslmat.html>next</a> |</li><li class=right><a title="8.6.2.1. nilearn.interfaces.fmriprep.load_confounds"accesskey=P href=nilearn.interfaces.fmriprep.load_confounds.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../../auto_examples/index.html>Examples</a> | </li><li><a href=../reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li><a href=../../glossary.html>Glossary</a>| </li><li><a href=../../bibliography.html>Bibliography</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../reference.html><span class=section-number>8. </span>Reference documentation: all nilearn functions</a> »</li><li class="nav-item nav-item-this"><a href>Nilearn: Statistical Analysis for NeuroImaging in Python</a></li></ul></div></div><div class=stable-banner>This is the <em>stable</em> documentation for the latest release of Nilearn, the current development version is available <a href=https://nilearn.github.io/dev/index.html>here</a>.</div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="admonition note"><p class=admonition-title>Note</p><p>This page is a reference documentation. It only explains the function signature, and not how to use it. Please refer to the <a class="reference internal"href=../../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for the big picture.</p></div><div class=section id=nilearn-interfaces-fmriprep-load-confounds-strategy><h1><span class=section-number>8.6.2.2. </span>nilearn.interfaces.fmriprep.load_confounds_strategy<a title="Permalink to this headline"class=headerlink href=#nilearn-interfaces-fmriprep-load-confounds-strategy>¶</a></h1><dl class="py function"><dt class="sig sig-object py"id=nilearn.interfaces.fmriprep.load_confounds_strategy><span class="sig-prename descclassname"><span class=pre>nilearn.interfaces.fmriprep.</span></span><span class="sig-name descname"><span class=pre>load_confounds_strategy</span></span><span class=sig-paren>(</span><em class=sig-param><span class=n><span class=pre>img_files</span></span></em>, <em class=sig-param><span class=n><span class=pre>denoise_strategy</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>'simple'</span></span></em>, <em class=sig-param><span class=o><span class=pre>**</span></span><span class=n><span class=pre>kwargs</span></span></em><span class=sig-paren>)</span><a class="reference external"href=https://github.com/nilearn/nilearn/blob/72e810f01/nilearn/interfaces/fmriprep/load_confounds_strategy.py#L55><span class=viewcode-link><span class=pre>[source]</span></span></a><a title="Permalink to this definition"class=headerlink href=#nilearn.interfaces.fmriprep.load_confounds_strategy>¶</a></dt><dd><p>Use preset strategy to load confounds from <a class="reference internal"href=../../glossary.html#term-fMRIPrep><span class="xref std std-term">fMRIPrep</span></a>.</p> <p><cite>load_confounds_strategy</cite> provides an interface to select confounds based on past literature with limited parameters for user customisation.</p> <div class=versionadded><p><span class="versionmodified added">New in version 0.9.0.</span></p></div> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>img_files</strong><span class=classifier>path to processed image files, optionally as a list.</span></dt><dd><p>Processed nii.gz/dtseries.nii/func.gii file reside in a <a class="reference internal"href=../../glossary.html#term-fMRIPrep><span class="xref std std-term">fMRIPrep</span></a> generated functional derivative directory (i.e.The associated confound files should be in the same directory as the image file). As long as the image file, confound related tsv and json are in the same directory with BIDS-compliant names, <a class="reference internal"href=nilearn.interfaces.fmriprep.load_confounds.html#nilearn.interfaces.fmriprep.load_confounds title=nilearn.interfaces.fmriprep.load_confounds><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.interfaces.fmriprep.load_confounds</span></code></a> can retrieve the relevant files correctly.</p> <ul class=simple><li><p><cite>nii.gz</cite> or <cite>dtseries.nii</cite>: path to files, optionally as a list.</p></li><li><p><cite>func.gii</cite>: list of a pair of paths to files, optionally as a list of lists.</p></li></ul></dd><dt><strong>denoise_strategy</strong><span class=classifier>{‘simple’, ‘srubbing’, ‘compcor’, ‘ica_aroma’}</span></dt><dd><p>Name of preset denoising strategies. Each strategy has a set of associated configurable parameters. For customiseable parameters, please see the table in Notes.</p> <ul class=simple><li><p>‘simple’: Load confounds for a simple denoising strategy commonly used in resting state functional connectivity, described in <a class="footnote-reference brackets"href=#fox2005 id=id1>1</a>. With the global signal regression, this approach can remove confounds without compromising the temporal degrees of freedom.</p></li><li><p>‘srubbing’: Load confounds for scrubbing describbed in <a class="footnote-reference brackets"href=#power2012 id=id2>2</a>. This approach can reliably remove the impact of high motion volumes in functional connectome, however, it might not be suitable with subjects with high motion (more than 50% timeseries flagged as high motion). One should adjust the threshold based on the characteristics of the dataset, or remove high motion subjects from the dataset.</p></li><li><p>‘compcor’: Load confounds using the CompCor strategy from <a class="footnote-reference brackets"href=#behzadi200790 id=id3>3</a>. CompCor estimates noise through principal component analysis on regions that are unlikely to contain signal. Thus it might not be a suitable approach for researchers who want explicit description of the source of noise. Empirically, Compcor has shown similar effect of removing physiological noise as methods that explicitly model and remove physiology signals. Compcor can suffer from loss of temporal degrees of freedom when using explained variance as the noise component estimation as the number of compcor component can be really high. Please refer to <a class="reference internal"href=../../glossary.html#term-fMRIPrep><span class="xref std std-term">fMRIPrep</span></a> documentation for more details.</p></li><li><p>‘ica_aroma’: Load confounds for non-aggresive ICA-AROMA strategy described in <a class="footnote-reference brackets"href=#pruim2015 id=id4>4</a>. The strategy requires <a class="reference internal"href=../../glossary.html#term-fMRIPrep><span class="xref std std-term">fMRIPrep</span></a> outputs generated with <cite>–use-aroma</cite> suffixed with <cite>desc-smoothAROMAnonaggr_bold</cite>. ICA-AROMA increases the run time of <a class="reference internal"href=../../glossary.html#term-fMRIPrep><span class="xref std std-term">fMRIPrep</span></a>, however, the strategy performs well in various benchmarks (<a class="footnote-reference brackets"href=#ciric2017 id=id5>5</a>, <a class="footnote-reference brackets"href=#parker2018 id=id6>6</a>). See Notes for more details about this option.</p></li></ul></dd><dt><strong>Other keyword arguments:</strong></dt><dd><p>See additional parameters associated with <cite>denoise_strategy</cite> in Notes and refer to the documentation of <a class="reference internal"href=nilearn.interfaces.fmriprep.load_confounds.html#nilearn.interfaces.fmriprep.load_confounds title=nilearn.interfaces.fmriprep.load_confounds><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.interfaces.fmriprep.load_confounds</span></code></a>.</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>confounds</strong><span class=classifier>pandas.DataFrame, or list of</span></dt><dd><p>A reduced version of <a class="reference internal"href=../../glossary.html#term-fMRIPrep><span class="xref std std-term">fMRIPrep</span></a> confounds based on selected strategy and flags. An intercept is automatically added to the list of confounds. The columns contains the labels of the regressors.</p></dd><dt><strong>sample_mask</strong><span class=classifier>None, numpy.ndarray, or list of</span></dt><dd><p>When no volume requires removal, the value is None. Otherwise, shape: (number of scans - number of volumes removed, ) The index of the niimgs along time/fourth dimension for valid volumes for subsequent analysis. This attribute should be passed to parameter <cite>sample_mask</cite> of <a class="reference internal"href=nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker title=nilearn.maskers.NiftiMasker><code class="xref py py-class docutils literal notranslate"><span class=pre>nilearn.maskers.NiftiMasker</span></code></a> or <a class="reference internal"href=nilearn.signal.clean.html#nilearn.signal.clean title=nilearn.signal.clean><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.signal.clean</span></code></a>. Volumes are removed if flagged as following:</p> <ul class=simple><li><p>Non-steady-state volumes (if present)</p></li><li><p>Motion outliers detected by scrubbing</p></li></ul></dd></dl></dd></dl> <div class="admonition seealso"><p class=admonition-title>See also</p><dl class=simple><dt><a class="reference internal"href=nilearn.interfaces.fmriprep.load_confounds.html#nilearn.interfaces.fmriprep.load_confounds title=nilearn.interfaces.fmriprep.load_confounds><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.interfaces.fmriprep.load_confounds</span></code></a></dt><dd></dd></dl></div> <p class=rubric>Notes</p> <ol class=arabic><li><p>The following table details the default options of each preset strategies. Parameters with <cite>*</cite> denote customisable parameters. Please see <a class="reference internal"href=nilearn.interfaces.fmriprep.load_confounds.html#nilearn.interfaces.fmriprep.load_confounds title=nilearn.interfaces.fmriprep.load_confounds><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.interfaces.fmriprep.load_confounds</span></code></a>.</p> <blockquote><div><table class="docutils align-default"><colgroup><col style=width:8%><col style=width:8%><col style=width:5%><col style=width:5%><col style=width:11%><col style=width:4%><col style=width:10%><col style=width:16%><col style=width:12%><col style=width:8%><col style=width:8%><col style=width:5%></colgroup><thead><tr class=row-odd><th class=head><p>strategy</p></th><th class=head><p>high_pass</p></th><th class=head><p>motion</p></th><th class=head><p>wm_csf</p></th><th class=head><p>global_signal</p></th><th class=head><p>scrub</p></th><th class=head><p>fd_threshold</p></th><th class=head><p>std_dvars_threshold</p></th><th class=head><p>compcor</p></th><th class=head><p>n_compcor</p></th><th class=head><p>ica_aroma</p></th><th class=head><p>demean</p></th></tr></thead><tbody><tr class=row-even><td><p>simple</p></td><td><p>True</p></td><td><p>full*</p></td><td><p>basic*</p></td><td><p>None*</p></td><td><p>N/A</p></td><td><p>N/A</p></td><td><p>N/A</p></td><td><p>N/A</p></td><td><p>N/A</p></td><td><p>N/A</p></td><td><p>True*</p></td></tr><tr class=row-odd><td><p>scrubbing</p></td><td><p>True</p></td><td><p>full*</p></td><td><p>full</p></td><td><p>None*</p></td><td><p>5*</p></td><td><p>0.2*</p></td><td><p>3*</p></td><td><p>N/A</p></td><td><p>N/A</p></td><td><p>N/A</p></td><td><p>True*</p></td></tr><tr class=row-even><td><p>compcor</p></td><td><p>True</p></td><td><p>full*</p></td><td><p>N/A</p></td><td><p>N/A</p></td><td><p>N/A</p></td><td><p>N/A</p></td><td><p>N/A</p></td><td><p>anat_combined*</p></td><td><p>all*</p></td><td><p>N/A</p></td><td><p>True*</p></td></tr><tr class=row-odd><td><p>ica_aroma</p></td><td><p>True</p></td><td><p>N/A</p></td><td><p>basic*</p></td><td><p>None*</p></td><td><p>N/A</p></td><td><p>N/A</p></td><td><p>N/A</p></td><td><p>N/A</p></td><td><p>N/A</p></td><td><p>full</p></td><td><p>True*</p></td></tr></tbody></table></div></blockquote></li><li><p>ICA-AROMA is implemented in two steps in <a class="footnote-reference brackets"href=#pruim2015 id=id7>4</a>:</p> <blockquote><div><p>i. A non-aggressive denoising immediately after <a class="reference internal"href=../../glossary.html#term-ICA><span class="xref std std-term">ICA</span></a> classification. A linear regression estimates signals with all independent components as predictors. A partial regression is then applied to remove variance associated with noise independent components. <a class="reference internal"href=../../glossary.html#term-fMRIPrep><span class="xref std std-term">fMRIPrep</span></a> performs this step and generates files in <cite>MNI152NLin6Asym</cite> template, suffixed with <cite>desc-smoothAROMAnonaggr_bold</cite>.</p><p>One can produce <cite>desc-smoothAROMAnonaggr_bold</cite> in other spatial templates, please refer to <a class="reference internal"href=../../glossary.html#term-fMRIPrep><span class="xref std std-term">fMRIPrep</span></a> documentation on ICA-AROMA <a class="reference external"href=https://fmriprep.org/en/latest/workflows.html#ica-aroma>https://fmriprep.org/en/latest/workflows.html#ica-aroma</a></p><p>ii. Confound regression step (mean signals from WM and CSF). Confound regressors generated by this function with <cite>denoise_strategy=”ica_aroma”</cite>.</p><p>For more discussion regarding choosing the nuisance regressors before or after denoising with ICA-AROMA has a detriment on outcome measures, please see notebook 5. <a class="reference external"href=https://github.com/nipreps/fmriprep-notebooks/>https://github.com/nipreps/fmriprep-notebooks/</a></p></div></blockquote></li></ol> <p class=rubric>References</p> <p><dl class="footnote brackets"><dt class=label id=fox2005><span class=brackets><a class=fn-backref href=#id1>1</a></span></dt><dd><p>Michael D. Fox, Abraham Z. Snyder, Justin L Vincent, Maurizio Corbetta, David C. Van Essen, and Marcus E. Raichle. The human brain is intrinsically organized into dynamic, anticorrelated functional networks. <em>Proceedings of the National Academy of Sciences</em>, 102(27):9673–9678, July 2005. <a class="reference external"href=https://doi.org/10.1073/pnas.0504136102>doi:10.1073/pnas.0504136102</a>.</p></dd><dt class=label id=power2012><span class=brackets><a class=fn-backref href=#id2>2</a></span></dt><dd><p>Jonathan D. Power, Kelly A. Barnes, Abraham Z. Snyder, Bradley L. Schlaggar, and Steven E. Petersen. Spurious but systematic correlations in functional connectivity MRI networks arise from subject motion. <em>NeuroImage</em>, 59(3):2142–2154, 2012. URL: <a class="reference external"href="http://www.ncbi.nlm.nih.gov/pubmed/22019881 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3254728">http://www.ncbi.nlm.nih.gov/pubmed/22019881 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3254728</a>, <a class="reference external"href=https://doi.org/10.1016/j.neuroimage.2011.10.018>doi:10.1016/j.neuroimage.2011.10.018</a>.</p></dd><dt class=label id=behzadi200790><span class=brackets><a class=fn-backref href=#id3>3</a></span></dt><dd><p>Yashar Behzadi, Khaled Restom, Joy Liau, and Thomas T. Liu. A component based noise correction method (compcor) for bold and perfusion based fmri. <em>NeuroImage</em>, 37(1):90–101, 2007. URL: <a class="reference external"href=https://www.sciencedirect.com/science/article/pii/S1053811907003837>https://www.sciencedirect.com/science/article/pii/S1053811907003837</a>, <a class="reference external"href=https://doi.org/https://doi.org/10.1016/j.neuroimage.2007.04.042>doi:https://doi.org/10.1016/j.neuroimage.2007.04.042</a>.</p></dd><dt class=label id=pruim2015><span class=brackets>4</span><span class=fn-backref>(<a href=#id4>1</a>,<a href=#id7>2</a>)</span></dt><dd><p>Raimon H. R. Pruim, Maarten Mennes, Daan van Rooij, Alberto Llera, Jan K. Buitelaar, and Christian F. Beckmann. ICA-AROMA: a robust ICA-based strategy for removing motion artifacts from fMRI data. <em>Neuroimage</em>, 112:267–277, 2015. <a class="reference external"href=https://doi.org/10.1016/j.neuroimage.2015.02.064>doi:10.1016/j.neuroimage.2015.02.064</a>.</p></dd><dt class=label id=ciric2017><span class=brackets><a class=fn-backref href=#id5>5</a></span></dt><dd><p>Rastko Ciric, Daniel H. Wolf, Jonathan D. Power, David R. Roalf, Graham L. Baum, Kosha Ruparel, Russell T. Shinohara, Mark A. Elliott, Simon B. Eickhoff, Christos Davatzikos, Ruben C. Gur, Raquel E. Gur, Danielle S. Bassett, and Theodore D. Satterthwaite. Benchmarking of participant-level confound regression strategies for the control of motion artifact in studies of functional connectivity. <em>NeuroImage</em>, 154(1):174–187, 2017. <a class="reference external"href=https://doi.org/10.1016/j.neuroimage.2017.03.020>doi:10.1016/j.neuroimage.2017.03.020</a>.</p></dd><dt class=label id=parker2018><span class=brackets><a class=fn-backref href=#id6>6</a></span></dt><dd><p>Linden Parkes, Ben Fulcher, Murat Yücel, and Alex Fornito. An evaluation of the efficacy, reliability, and sensitivity of motion correction strategies for resting-state functional MRI. <em>NeuroImage</em>, 171:415–436, May 2018. <a class="reference external"href=https://doi.org/10.1016/j.neuroimage.2017.12.073>doi:10.1016/j.neuroimage.2017.12.073</a>.</p></dd></dl></dd></dl><div class=section id=examples-using-nilearn-interfaces-fmriprep-load-confounds-strategy><h2><span class=section-number>8.6.2.2.1. </span>Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.interfaces.fmriprep.load_confounds_strategy</span></code><a title="Permalink to this headline"class=headerlink href=#examples-using-nilearn-interfaces-fmriprep-load-confounds-strategy>¶</a></h2><div tooltip="Here we show how to extract signals from a brain parcellation and compute a correlation matrix."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id8><img alt="Extracting signals from a brain parcellation"src=../../_images/sphx_glr_plot_signal_extraction_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_signal_extraction.html#sphx-glr-auto-examples-03-connectivity-plot-signal-extraction-py><span class="std std-ref">Extracting signals from a brain parcellation</span></a></span><a title="Permalink to this image"class=headerlink href=#id8>¶</a></p></div></div><div style=clear:both></div></div></div><div class=clearer></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>8.6.2.2. nilearn.interfaces.fmriprep.load_confounds_strategy</a><ul><li><a class="reference internal"href=#examples-using-nilearn-interfaces-fmriprep-load-confounds-strategy>8.6.2.2.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.interfaces.fmriprep.load_confounds_strategy</span></code></a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=nilearn.interfaces.fmriprep.load_confounds.html><span class=section-number>8.6.2.1. </span>nilearn.interfaces.fmriprep.load_confounds</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=nilearn.interfaces.fsl.get_design_from_fslmat.html><span class=section-number>8.6.3.1. </span>nilearn.interfaces.fsl.get_design_from_fslmat</a></p><div id=searchbox role=search style=display:none><h3 id=searchlabel>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input aria-labelledby=searchlabel name=q><input type=submit value=Go></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2022. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 4.0.2. <span style=padding-left:5ex> <a href=../../_sources/modules/generated/nilearn.interfaces.fmriprep.load_confounds_strategy.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>