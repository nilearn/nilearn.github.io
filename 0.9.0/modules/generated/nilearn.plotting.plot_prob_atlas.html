<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1.0 name=viewport><meta content="8.11.14. nilearn.plotting.plot_prob_atlas"property=og:title><meta content=website property=og:type><meta content=https://nilearn.github.io/modules/generated/nilearn.plotting.plot_prob_atlas.html property=og:url><meta content=Nilearn property=og:site_name><meta content="Examples using nilearn.plotting.plot_prob_atlas: Visualizing a probabilistic atlas: the default mode in the MSDL atlas Visualizing a probabilistic atlas: the default mode in the MSDL atlas, Visuali..."property=og:description><meta content=../../_images/sphx_glr_plot_overlay_thumb.png property=og:image><meta content="Visualizing a probabilistic atlas: the default mode in the MSDL atlas"property=og:image:alt><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/copybutton.css rel=stylesheet><link href=../../_static/sg_gallery.css rel=stylesheet><link href=../../_static/sg_gallery-binder.css rel=stylesheet><link href=../../_static/sg_gallery-dataframe.css rel=stylesheet><link href=../../_static/sg_gallery-rendered-html.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/clipboard.min.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="8.11.15. nilearn.plotting.plot_carpet"href=nilearn.plotting.plot_carpet.html rel=next><link title="8.11.13. nilearn.plotting.plot_markers"href=nilearn.plotting.plot_markers.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="8.11.15. nilearn.plotting.plot_carpet"accesskey=N href=nilearn.plotting.plot_carpet.html>next</a> |</li><li class=right><a title="8.11.13. nilearn.plotting.plot_markers"accesskey=P href=nilearn.plotting.plot_markers.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../../auto_examples/index.html>Examples</a> | </li><li><a href=../reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li><a href=../../glossary.html>Glossary</a>| </li><li><a href=../../bibliography.html>Bibliography</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../reference.html><span class=section-number>8. </span>Reference documentation: all nilearn functions</a> »</li><li class="nav-item nav-item-this"><a href>Nilearn: Statistical Analysis for NeuroImaging in Python</a></li></ul></div></div><div class=stable-banner>This is the <em>stable</em> documentation for the latest release of Nilearn, the current development version is available <a href=https://nilearn.github.io/dev/index.html>here</a>.</div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="admonition note"><p class=admonition-title>Note</p><p>This page is a reference documentation. It only explains the function signature, and not how to use it. Please refer to the <a class="reference internal"href=../../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for the big picture.</p></div><div class=section id=nilearn-plotting-plot-prob-atlas><h1><span class=section-number>8.11.14. </span>nilearn.plotting.plot_prob_atlas<a title="Permalink to this headline"class=headerlink href=#nilearn-plotting-plot-prob-atlas>¶</a></h1><dl class="py function"><dt class="sig sig-object py"id=nilearn.plotting.plot_prob_atlas><span class="sig-prename descclassname"><span class=pre>nilearn.plotting.</span></span><span class="sig-name descname"><span class=pre>plot_prob_atlas</span></span><span class=sig-paren>(</span><em class=sig-param><span class=pre>maps_img</span></em>, <em class=sig-param><span class=pre>bg_img=&LTMNI152Template></span></em>, <em class=sig-param><span class=pre>view_type='auto'</span></em>, <em class=sig-param><span class=pre>threshold='auto'</span></em>, <em class=sig-param><span class=pre>linewidths=2.5</span></em>, <em class=sig-param><span class=pre>cut_coords=None</span></em>, <em class=sig-param><span class=pre>output_file=None</span></em>, <em class=sig-param><span class=pre>display_mode='ortho'</span></em>, <em class=sig-param><span class=pre>figure=None</span></em>, <em class=sig-param><span class=pre>axes=None</span></em>, <em class=sig-param><span class=pre>title=None</span></em>, <em class=sig-param><span class=pre>annotate=True</span></em>, <em class=sig-param><span class=pre>draw_cross=True</span></em>, <em class=sig-param><span class=pre>black_bg='auto'</span></em>, <em class=sig-param><span class=pre>dim='auto'</span></em>, <em class=sig-param><span class=pre>colorbar=False</span></em>, <em class=sig-param><span class=pre>cmap=&LTmatplotlib.colors.LinearSegmentedColormap</span> <span class=pre>object></span></em>, <em class=sig-param><span class=pre>vmin=None</span></em>, <em class=sig-param><span class=pre>vmax=None</span></em>, <em class=sig-param><span class=pre>alpha=0.7</span></em>, <em class=sig-param><span class=pre>**kwargs</span></em><span class=sig-paren>)</span><a class="reference external"href=https://github.com/nilearn/nilearn/blob/72e810f01/nilearn/plotting/img_plotting.py#L731><span class=viewcode-link><span class=pre>[source]</span></span></a><a title="Permalink to this definition"class=headerlink href=#nilearn.plotting.plot_prob_atlas>¶</a></dt><dd><p>Plot the probabilistic atlases onto the anatomical image by default MNI template</p> <dl class=field-list><dt class=field-odd>Parameters</dt><dd class=field-odd><dl><dt><strong>maps_img</strong><span class=classifier>Niimg-like object or the filename</span></dt><dd><p>4D image of the probabilistic atlas maps.</p></dd><dt><strong>bg_img</strong><span class=classifier>Niimg-like object, optional</span></dt><dd><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>input_output</a>. The background image to plot on top of. If nothing is specified, the MNI152 template will be used. To turn off background image, just pass “bg_img=False”. Default=MNI152TEMPLATE.</p> <div class=versionadded><p><span class="versionmodified added">New in version 0.4.0.</span></p></div></dd><dt><strong>view_type</strong><span class=classifier>{‘auto’, ‘contours’, ‘filled_contours’, ‘continuous’}, optional</span></dt><dd><p>By default view_type == ‘auto’, means maps will be displayed automatically using any one of the three view types. The automatic selection of view type depends on the total number of maps. If view_type == ‘contours’, maps are overlaid as contours If view_type == ‘filled_contours’, maps are overlaid as contours along with color fillings inside the contours. If view_type == ‘continuous’, maps are overlaid as continuous colors irrespective of the number maps. Default=’auto’.</p></dd><dt><strong>threshold</strong><span class=classifier>a str or a number, list of str or numbers, optional</span></dt><dd><p>This parameter is optional and is used to threshold the maps image using the given value or automatically selected value. The values in the image above the threshold level will be visualized. The default strategy, computes a threshold level that seeks to minimize (yet not eliminate completely) the overlap between several maps for a better visualization. The threshold can also be expressed as a percentile over the values of the whole atlas. In that case, the value must be specified as string finishing with a percent sign, e.g., “25.3%”. If a single string is provided, the same percentile will be applied over the whole atlas. Otherwise, if a list of percentiles is provided, each 3D map is thresholded with certain percentile sequentially. Length of percentiles given should match the number of 3D map in time (4th) dimension. If a number or a list of numbers, the given value will be used directly to threshold the maps without any percentile calculation. If None, a very small threshold is applied to remove numerical noise from the maps background.</p></dd><dt><strong>linewidths</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#float><code class="xref py py-obj docutils literal notranslate"><span class=pre>float</span></code></a>, optional</span></dt><dd><p>Set the boundary thickness of the contours. Only reflects when <code class="docutils literal notranslate"><span class=pre>view_type=contours</span></code>. Default=2.5.</p></dd><dt><strong>cut_coords</strong><span class=classifier>None, a <a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/stdtypes.html#tuple><code class="xref py py-obj docutils literal notranslate"><span class=pre>tuple</span></code></a> of <a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#float><code class="xref py py-obj docutils literal notranslate"><span class=pre>float</span></code></a>, or <a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#int><code class="xref py py-obj docutils literal notranslate"><span class=pre>int</span></code></a>, optional</span></dt><dd><p>The MNI coordinates of the point where the cut is performed.</p> <blockquote><div><ul class=simple><li><p>If <code class="docutils literal notranslate"><span class=pre>display_mode</span></code> is ‘ortho’ or ‘tiled’, this should be a 3-tuple: <code class="docutils literal notranslate"><span class=pre>(x,</span> <span class=pre>y,</span> <span class=pre>z)</span></code></p></li><li><p>For <code class="docutils literal notranslate"><span class=pre>display_mode</span> <span class=pre>==</span> <span class=pre>'x'</span></code>, ‘y’, or ‘z’, then these are the coordinates of each cut in the corresponding direction.</p></li><li><p>If <code class="docutils literal notranslate"><span class=pre>None</span></code> is given, the cuts are calculated automatically.</p></li><li><p>If <code class="docutils literal notranslate"><span class=pre>display_mode</span></code> is ‘mosaic’, and the number of cuts is the same for all directions, <code class="docutils literal notranslate"><span class=pre>cut_coords</span></code> can be specified as an integer. It can also be a length 3 tuple specifying the number of cuts for every direction if these are different.</p></li></ul><div class="admonition note"><p class=admonition-title>Note</p><p>If <code class="docutils literal notranslate"><span class=pre>display_mode</span></code> is ‘x’, ‘y’ or ‘z’, <code class="docutils literal notranslate"><span class=pre>cut_coords</span></code> can be an integer, in which case it specifies the number of cuts to perform.</p></div></div></blockquote></dd><dt><strong>output_file</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/stdtypes.html#str><code class="xref py py-obj docutils literal notranslate"><span class=pre>str</span></code></a>, or None, optional</span></dt><dd><p>The name of an image file to export the plot to. Valid extensions are .png, .pdf, .svg. If <code class="docutils literal notranslate"><span class=pre>output_file</span></code> is not None, the plot is saved to a file, and the display is closed.</p></dd><dt><strong>display_mode</strong><span class=classifier>{‘ortho’, ‘tiled’, ‘mosaic’,’x’,’y’, ‘z’, ‘yx’, ‘xz’, ‘yz’}, optional</span></dt><dd><p>Choose the direction of the cuts:</p> <blockquote><div><ul class=simple><li><p>‘x’: sagital</p></li><li><p>‘y’: coronal</p></li><li><p>‘z’: axial</p></li><li><p>‘ortho’: three cuts are performed in orthogonal directions</p></li><li><p>‘tiled’: three cuts are performed and arranged in a 2x2 grid</p></li><li><p>‘mosaic’: three cuts are performed along multiple rows and columns</p></li></ul></div></blockquote> <p>Default=’ortho’.</p></dd><dt><strong>figure</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#int><code class="xref py py-obj docutils literal notranslate"><span class=pre>int</span></code></a>, or <a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure><code class="xref py py-class docutils literal notranslate"><span class=pre>matplotlib.figure.Figure</span></code></a>, or None, optional</span></dt><dd><p>Matplotlib figure used or its number. If <code class="docutils literal notranslate"><span class=pre>None</span></code> is given, a new figure is created.</p></dd><dt><strong>axes</strong><span class=classifier><a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/axes_api.html#matplotlib.axes.Axes><code class="xref py py-class docutils literal notranslate"><span class=pre>matplotlib.axes.Axes</span></code></a>, or 4 tupleof <a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#float><code class="xref py py-obj docutils literal notranslate"><span class=pre>float</span></code></a>: (xmin, ymin, width, height), optional</span></dt><dd><p>The axes, or the coordinates, in matplotlib figure space, of the axes used to display the plot. If <code class="docutils literal notranslate"><span class=pre>None</span></code>, the complete figure is used.</p></dd><dt><strong>title</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/stdtypes.html#str><code class="xref py py-obj docutils literal notranslate"><span class=pre>str</span></code></a>, or None, optional</span></dt><dd><p>The title displayed on the figure. Default=None.</p></dd><dt><strong>annotate</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#bool><code class="xref py py-obj docutils literal notranslate"><span class=pre>bool</span></code></a>, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class=pre>annotate</span></code> is <code class="docutils literal notranslate"><span class=pre>True</span></code>, positions and left/right annotation are added to the plot. Default=True.</p></dd><dt><strong>draw_cross</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#bool><code class="xref py py-obj docutils literal notranslate"><span class=pre>bool</span></code></a>, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class=pre>draw_cross</span></code> is <code class="docutils literal notranslate"><span class=pre>True</span></code>, a cross is drawn on the plot to indicate the cut position. Default=True.</p></dd><dt><strong>black_bg</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#bool><code class="xref py py-obj docutils literal notranslate"><span class=pre>bool</span></code></a>, or ‘auto’, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class=pre>True</span></code>, the background of the image is set to be black. If you wish to save figures with a black background, you will need to pass facecolor=’k’, edgecolor=’k’ to <a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html#matplotlib.pyplot.savefig><code class="xref py py-func docutils literal notranslate"><span class=pre>matplotlib.pyplot.savefig</span></code></a>. Default=’auto’.</p></dd><dt><strong>dim</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#float><code class="xref py py-obj docutils literal notranslate"><span class=pre>float</span></code></a>, or ‘auto’, optional</span></dt><dd><p>Dimming factor applied to background image. By default, automatic heuristics are applied based upon the background image intensity. Accepted float values, where a typical span is between -2 and 2 (-2 = increase contrast; 2 = decrease contrast), but larger values can be used for a more pronounced effect. 0 means no dimming. Default=’auto’.</p></dd><dt><strong>cmap</strong><span class=classifier><a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/_as_gen/matplotlib.colors.Colormap.html#matplotlib.colors.Colormap><code class="xref py py-class docutils literal notranslate"><span class=pre>matplotlib.colors.Colormap</span></code></a>, or <a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/stdtypes.html#str><code class="xref py py-obj docutils literal notranslate"><span class=pre>str</span></code></a>, optional</span></dt><dd><p>The colormap to use. Either a string which is a name of a matplotlib colormap, or a matplotlib colormap object. Default=`plt.cm.gist_rainbow`.</p></dd><dt><strong>colorbar</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#bool><code class="xref py py-obj docutils literal notranslate"><span class=pre>bool</span></code></a>, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class=pre>True</span></code>, display a colorbar on the right of the plots. Default=False.</p></dd><dt><strong>vmin</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#float><code class="xref py py-obj docutils literal notranslate"><span class=pre>float</span></code></a>, optional</span></dt><dd><p>Lower bound of the colormap. If <code class="docutils literal notranslate"><span class=pre>None</span></code>, the min of the image is used. Passed to <a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html#matplotlib.pyplot.imshow><code class="xref py py-func docutils literal notranslate"><span class=pre>matplotlib.pyplot.imshow</span></code></a>.</p></dd><dt><strong>vmax</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#float><code class="xref py py-obj docutils literal notranslate"><span class=pre>float</span></code></a>, optional</span></dt><dd><p>Upper bound of the colormap. If <code class="docutils literal notranslate"><span class=pre>None</span></code>, the max of the image is used. Passed to <a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html#matplotlib.pyplot.imshow><code class="xref py py-func docutils literal notranslate"><span class=pre>matplotlib.pyplot.imshow</span></code></a>.</p></dd><dt><strong>alpha</strong><span class=classifier>float between 0 and 1, optional</span></dt><dd><p>Alpha sets the transparency of the color inside the filled contours. Default=0.7.</p></dd></dl></dd></dl> <div class="admonition seealso"><p class=admonition-title>See also</p><dl class=simple><dt><a class="reference internal"href=nilearn.plotting.plot_roi.html#nilearn.plotting.plot_roi title=nilearn.plotting.plot_roi><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.plotting.plot_roi</span></code></a></dt><dd><p>To simply plot max-prob atlases (3D images)</p></dd></dl></div></dd></dl><div class=section id=examples-using-nilearn-plotting-plot-prob-atlas><h2><span class=section-number>8.11.14.1. </span>Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.plotting.plot_prob_atlas</span></code><a title="Permalink to this headline"class=headerlink href=#examples-using-nilearn-plotting-plot-prob-atlas>¶</a></h2><div tooltip="Visualizing a probabilistic atlas requires visualizing the different maps that compose it."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id1><img alt="Visualizing a probabilistic atlas: the default mode in the MSDL atlas"src=../../_images/sphx_glr_plot_overlay_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_overlay.html#sphx-glr-auto-examples-01-plotting-plot-overlay-py><span class="std std-ref">Visualizing a probabilistic atlas: the default mode in the MSDL atlas</span></a></span><a title="Permalink to this image"class=headerlink href=#id1>¶</a></p></div></div><div tooltip="This example shows how to visualize probabilistic atlases made of 4D images. There are 3 differ..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id2><img alt="Visualizing 4D probabilistic atlas maps"src=../../_images/sphx_glr_plot_prob_atlas_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_prob_atlas.html#sphx-glr-auto-examples-01-plotting-plot-prob-atlas-py><span class="std std-ref">Visualizing 4D probabilistic atlas maps</span></a></span><a title="Permalink to this image"class=headerlink href=#id2>¶</a></p></div></div><div tooltip="Various approaches exist to derive spatial maps or networks from group fmr data. The methods ex..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id3><img alt="Deriving spatial maps from group fMRI data using ICA and Dictionary Learning"src=../../_images/sphx_glr_plot_compare_decomposition_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_compare_decomposition.html#sphx-glr-auto-examples-03-connectivity-plot-compare-decomposition-py><span class="std std-ref">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</span></a></span><a title="Permalink to this image"class=headerlink href=#id3>¶</a></p></div></div><div tooltip="This example shows how to use nilearn.regions.RegionExtractor to extract spatially constrained ..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id4><img alt="Regions extraction using :term:`Dictionary learning` and functional connectomes"src=../../_images/sphx_glr_plot_extract_regions_dictlearning_maps_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html#sphx-glr-auto-examples-03-connectivity-plot-extract-regions-dictlearning-maps-py><span class="std std-ref">Regions extraction using Dictionary learning and functional connectomes</span></a></span><a title="Permalink to this image"class=headerlink href=#id4>¶</a></p></div></div><div tooltip="This simple example shows how to extract regions from Smith atlas resting state networks."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id5><img alt="Regions Extraction of Default Mode Networks using Smith Atlas"src=../../_images/sphx_glr_plot_extract_rois_smith_atlas_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/06_manipulating_images/plot_extract_rois_smith_atlas.html#sphx-glr-auto-examples-06-manipulating-images-plot-extract-rois-smith-atlas-py><span class="std std-ref">Regions Extraction of Default Mode Networks using Smith Atlas</span></a></span><a title="Permalink to this image"class=headerlink href=#id5>¶</a></p></div></div><div tooltip="This example shows how to extract regions or separate the regions from a statistical map."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id6><img alt="Region Extraction using a t-statistical map (3D)"src=../../_images/sphx_glr_plot_extract_rois_statistical_maps_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/06_manipulating_images/plot_extract_rois_statistical_maps.html#sphx-glr-auto-examples-06-manipulating-images-plot-extract-rois-statistical-maps-py><span class="std std-ref">Region Extraction using a t-statistical map (3D)</span></a></span><a title="Permalink to this image"class=headerlink href=#id6>¶</a></p></div></div><div style=clear:both></div></div></div><div class=clearer></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>8.11.14. nilearn.plotting.plot_prob_atlas</a><ul><li><a class="reference internal"href=#examples-using-nilearn-plotting-plot-prob-atlas>8.11.14.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.plotting.plot_prob_atlas</span></code></a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=nilearn.plotting.plot_markers.html><span class=section-number>8.11.13. </span>nilearn.plotting.plot_markers</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=nilearn.plotting.plot_carpet.html><span class=section-number>8.11.15. </span>nilearn.plotting.plot_carpet</a></p><div id=searchbox role=search style=display:none><h3 id=searchlabel>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input aria-labelledby=searchlabel name=q><input type=submit value=Go></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2022. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 4.0.2. <span style=padding-left:5ex> <a href=../../_sources/modules/generated/nilearn.plotting.plot_prob_atlas.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>