
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nilearn: Statistical Analysis for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/nature.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2.3. FREM: fast ensembling of regularized models for robust decoding" href="frem.html" />
    <link rel="prev" title="2.1. An introduction to decoding" href="decoding_intro.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">


<script type="text/javascript">
function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});
</script>
<script type="text/javascript">
function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../index.html">
      <img src="../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../manipulating_images/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../modules/reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Statistics for NeuroImaging in Python</h2>
  </div>
  <div class="search_form">
    <div class="gcse-search" id="cse" style="width: 100%;"></div>
    <script>
      (function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </div>
</div>



<div class=related-wrapper>
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="frem.html" title="2.3. FREM: fast ensembling of regularized models for robust decoding"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="decoding_intro.html" title="2.1. An introduction to decoding"
             accesskey="P">previous</a> |</li>
<li><a href="../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../authors.html">About</a>|&nbsp;</li>
<li><a href="../glossary.html">Glossary</a>|&nbsp;</li>
<li><a href="../bibliography.html">Bibliography</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="index.html" accesskey="U"><span class="section-number">2. </span>Decoding and MVPA: predicting from brain images</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Nilearn: Statistical Analysis for NeuroImaging in Python</a></li> 
      </ul>
    </div>
</div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="choosing-the-right-predictive-model-for-neuroimaging">
<span id="estimator-choice"></span><h1><span class="section-number">2.2. </span>Choosing the right predictive model for neuroimaging<a class="headerlink" href="#choosing-the-right-predictive-model-for-neuroimaging" title="Permalink to this headline">¶</a></h1>
<p>This page gives a few simple considerations on the choice of an estimator to
tackle your <em>decoding</em> application, that is the prediction of external
variables such as behavior or clinical traits from brain images. It is
focusing on practical concepts to understand which prediction pipeline
is well suited to your problem and how to implement it easily with Nilearn.
This builds on concepts introduced in this <a class="reference internal" href="decoding_intro.html#decoding-intro"><span class="std std-ref">didactic
introduction to decoding with nilearn</span></a>.</p>
<div class="contents local topic" id="contents">
<p class="topic-title"><strong>Contents</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="#predictions-regression-classification-and-multi-class" id="id3">Predictions: regression, classification and multi-class</a></p></li>
<li><p><a class="reference internal" href="#different-linear-models" id="id4">Different linear models</a></p></li>
<li><p><a class="reference internal" href="#setting-estimator-parameters" id="id5">Setting estimator parameters</a></p></li>
<li><p><a class="reference internal" href="#bagging-several-models" id="id6">Bagging several models</a></p></li>
<li><p><a class="reference internal" href="#references" id="id7">References</a></p></li>
</ul>
</div>
<div class="section" id="predictions-regression-classification-and-multi-class">
<h2><a class="toc-backref" href="#id3"><span class="section-number">2.2.1. </span>Predictions: regression, classification and multi-class</a><a class="headerlink" href="#predictions-regression-classification-and-multi-class" title="Permalink to this headline">¶</a></h2>
<p>As seen in the previous section, high-level objects in Nilearn help you decode
easily your dataset using a <strong>mask</strong> and/or <strong>feature selection</strong>. You can tune
the <strong>cross-validation</strong> and <strong>scoring</strong> schemes of your model. Those objects
come in two kinds, depending on your usecase : <a class="reference internal" href="../glossary.html#term-regression"><span class="xref std std-term">Regression</span></a> or <a class="reference internal" href="../glossary.html#term-classification"><span class="xref std std-term">Classification</span></a>.</p>
<div class="section" id="regression">
<h3><span class="section-number">2.2.1.1. </span>Regression<a class="headerlink" href="#regression" title="Permalink to this headline">¶</a></h3>
<p>A <a class="reference internal" href="../glossary.html#term-regression"><span class="xref std std-term">regression</span></a> problem is a learning task in which the variable to predict
–that we often call <strong>y</strong> – is a continuous value, such as an age.
Encoding models [Naselaris <em>et al.</em> <a class="footnote-reference brackets" href="#naselaris2011" id="id1">1</a>] typically call for regressions.
<a class="reference internal" href="../modules/generated/nilearn.decoding.DecoderRegressor.html#nilearn.decoding.DecoderRegressor" title="nilearn.decoding.DecoderRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">nilearn.decoding.DecoderRegressor</span></code></a> implement easy and efficient
regression pipelines.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference internal" href="../modules/generated/nilearn.decoding.FREMRegressor.html#nilearn.decoding.FREMRegressor" title="nilearn.decoding.FREMRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">nilearn.decoding.FREMRegressor</span></code></a>, a pipeline described in the
<a class="reference internal" href="frem.html#frem"><span class="std std-ref">userguide</span></a>, which yields very good regression performance for
neuroimaging at a reasonable computational cost.</p></li>
</ul>
</div>
</div>
<div class="section" id="classification-two-classes-or-multi-class">
<h3><span class="section-number">2.2.1.2. </span>Classification: two classes or multi-class<a class="headerlink" href="#classification-two-classes-or-multi-class" title="Permalink to this headline">¶</a></h3>
<p>A <a class="reference internal" href="../glossary.html#term-classification"><span class="xref std std-term">classification</span></a> task consists in predicting a <em>class</em> label for each
observation. In other words, the variable to predict is categorical.</p>
<p>Often <a class="reference internal" href="../glossary.html#term-classification"><span class="xref std std-term">classification</span></a> is performed between two classes, but it may well be
applied to multiple classes, in which case it is known as a multi-class
problem. It is important to keep in mind that the larger the number of
classes, the harder the prediction problem.</p>
<p><a class="reference internal" href="../modules/generated/nilearn.decoding.Decoder.html#nilearn.decoding.Decoder" title="nilearn.decoding.Decoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">nilearn.decoding.Decoder</span></code></a> implement easy and efficient
<a class="reference internal" href="../glossary.html#term-classification"><span class="xref std std-term">classification</span></a> pipelines.</p>
<p>Some estimators support multi-class prediction out of the box, but many
work by dividing the multi-class problem in a set of two class problems.
There are two noteworthy strategies:</p>
<dl class="field-list simple">
<dt class="field-odd">One versus All</dt>
<dd class="field-odd"><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.multiclass.OneVsRestClassifier</span></code></a>
An estimator is trained to distinguish each class from all the others,
and during prediction, the final decision is taken by a vote across
the different estimators.</p>
</dd>
<dt class="field-even">One versus One</dt>
<dd class="field-even"><p><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html#sklearn.multiclass.OneVsOneClassifier" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.multiclass.OneVsOneClassifier</span></code></a>
An estimator is trained to distinguish each pair of classes,
and during prediction, the final decision is taken by a vote across
the different estimators.</p>
</dd>
</dl>
<p>The “One vs One” strategy is more computationally costly than the “One
vs All”. The former scales as the square of the number of classes,
whereas the latter is linear with the number of classes.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/multiclass.html">Multi-class prediction in scikit-learn’s documentation</a></p></li>
<li><p><a class="reference internal" href="../modules/generated/nilearn.decoding.FREMClassifier.html#nilearn.decoding.FREMClassifier" title="nilearn.decoding.FREMClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">nilearn.decoding.FREMClassifier</span></code></a>, a pipeline described in the
<a class="reference internal" href="frem.html#frem"><span class="std std-ref">userguide</span></a>, yielding state-of-the art decoding performance.</p></li>
</ul>
</div>
<p><strong>Confusion matrix</strong> <a class="reference external" href="http://en.wikipedia.org/wiki/Confusion_matrix">The confusion matrix</a>,
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix" title="(in scikit-learn v0.24)"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.confusion_matrix</span></code></a> is a useful tool to
understand the classifier’s errors in a multiclass problem.</p>
<div class="figure align-left">
<a class="reference external image-reference" href="../auto_examples/02_decoding/plot_haxby_multiclass.html"><img alt="../_images/sphx_glr_plot_haxby_multiclass_001.png" src="../_images/sphx_glr_plot_haxby_multiclass_001.png" style="width: 240.0px; height: 180.0px;" /></a>
</div>
<div class="figure align-left">
<a class="reference external image-reference" href="../auto_examples/02_decoding/plot_haxby_multiclass.html"><img alt="../_images/sphx_glr_plot_haxby_multiclass_002.png" src="../_images/sphx_glr_plot_haxby_multiclass_002.png" style="width: 280.0px; height: 200.0px;" /></a>
</div>
<div class="figure align-left">
<a class="reference external image-reference" href="../auto_examples/02_decoding/plot_haxby_multiclass.html"><img alt="../_images/sphx_glr_plot_haxby_multiclass_003.png" src="../_images/sphx_glr_plot_haxby_multiclass_003.png" style="width: 280.0px; height: 200.0px;" /></a>
</div>
</div>
</div>
<div class="section" id="different-linear-models">
<h2><a class="toc-backref" href="#id4"><span class="section-number">2.2.2. </span>Different linear models</a><a class="headerlink" href="#different-linear-models" title="Permalink to this headline">¶</a></h2>
<p>Using Nilearn high-level objects, several estimators are easily available
to model the relations between your images and the target to predict.
For <a class="reference internal" href="../glossary.html#term-classification"><span class="xref std std-term">classification</span></a>, <a class="reference internal" href="../modules/generated/nilearn.decoding.Decoder.html#nilearn.decoding.Decoder" title="nilearn.decoding.Decoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">nilearn.decoding.Decoder</span></code></a> let you choose them
through the <cite>estimator</cite> parameter:</p>
<ul class="simple">
<li><p><cite>svc</cite> (same as <cite>svc_l2</cite>) : The <a class="reference external" href="https://scikit-learn.org/stable/modules/svm.html">support vector classifier</a>.</p></li>
<li><p><cite>svc_l1</cite> : SVC using <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_l1_l2_sparsity">L1 penalization</a> that yields a sparse solution : only a subset of feature weights is different from zero and contribute to prediction.</p></li>
<li><p><cite>logistic</cite> (or <cite>logistic_l2</cite>) : The <a class="reference external" href="https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression">logistic regression</a> with <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_l1_l2_sparsity.html">l2 penalty</a>.</p></li>
<li><p><cite>logistic_l1</cite> :  The <a class="reference external" href="https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression">logistic regression</a> with <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic_l1_l2_sparsity.html">l1 penalty</a> (<strong>sparse model</strong>).</p></li>
<li><p><cite>ridge_classifier</cite> : A <a class="reference external" href="https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression-and-classification">Ridge Regression variant</a>.</p></li>
<li><p><cite>dummy classifier</cite> : A <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html">dummy classifier</a> is a classifier that makes predictions using simple rules. It is useful as a simple baseline to compare with other classifiers.</p></li>
</ul>
<p>In <a class="reference internal" href="../modules/generated/nilearn.decoding.DecoderRegressor.html#nilearn.decoding.DecoderRegressor" title="nilearn.decoding.DecoderRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">nilearn.decoding.DecoderRegressor</span></code></a> you can use some of these objects counterparts for regression :</p>
<ul class="simple">
<li><p><cite>svr</cite> : <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html">Support vector regression</a>.</p></li>
<li><p><cite>ridge_regressor</cite> (same as <cite>ridge</cite>) : <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html">Ridge regression</a>.</p></li>
<li><p><cite>dummy_regressor</cite> : A <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html">dummy regressor</a> is a regressor that makes predictions using simple rules. It is useful as a simple baseline to compare with other regressors.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p><strong>There is no free lunch</strong>: no estimator will work uniformly better
in every situation.</p></li>
<li><p>The SVC-l2 is fairly insensitive to the choice of the regularization
parameter which makes it a good and cheap first approach to most problems</p></li>
<li><p>The ridge is fast to fit and cross-validate, but it will not work well on
ill-separated classes, and, most importantly give ugly weight maps</p></li>
<li><p>Whenever a model uses sparsity (have l1 in its name here) the parameter
selection (amount of sparsity used) can change result a lot and is difficult
to tune well.</p></li>
<li><p>What is done to the data  <strong>before</strong> applying the estimator is
often  <strong>more important</strong> than the choice of estimator. Typically,
standardizing the data is important, smoothing can often be useful,
and nuisance effects, such as session effect, must be removed.</p></li>
<li><p>Many more estimators are available in scikit-learn (see the
<a class="reference external" href="http://scikit-learn.org/stable/supervised_learning.html">scikit-learn documentation on supervised learning</a>). To learn to
do decoding with any of these, see : <a class="reference internal" href="going_further.html#going-further"><span class="std std-ref">Running scikit-learn functions for more control on the analysis</span></a></p></li>
</ul>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/02_decoding/plot_haxby_different_estimators.html"><img alt="../_images/sphx_glr_plot_haxby_different_estimators_001.png" src="../_images/sphx_glr_plot_haxby_different_estimators_001.png" style="width: 480.0px; height: 480.0px;" /></a>
</div>
<hr class="docutils" />
<p>The corresponding weight maps (below) differ widely from one estimator to
the other, although the prediction scores are fairly similar. In other
terms, a well-performing estimator in terms of prediction error gives us
little guarantee on the brain maps.</p>
<a class="reference external image-reference" href="../auto_examples/02_decoding/plot_haxby_different_estimators.html"><img alt="../_images/sphx_glr_plot_haxby_different_estimators_006.png" src="../_images/sphx_glr_plot_haxby_different_estimators_006.png" style="width: 203.0px; height: 160.29999999999998px;" /></a>
<a class="reference external image-reference" href="../auto_examples/02_decoding/plot_haxby_different_estimators.html"><img alt="../_images/sphx_glr_plot_haxby_different_estimators_005.png" src="../_images/sphx_glr_plot_haxby_different_estimators_005.png" style="width: 203.0px; height: 160.29999999999998px;" /></a>
<a class="reference external image-reference" href="../auto_examples/02_decoding/plot_haxby_different_estimators.html"><img alt="../_images/sphx_glr_plot_haxby_different_estimators_004.png" src="../_images/sphx_glr_plot_haxby_different_estimators_004.png" style="width: 203.0px; height: 160.29999999999998px;" /></a>
<a class="reference external image-reference" href="../auto_examples/02_decoding/plot_haxby_different_estimators.html"><img alt="../_images/sphx_glr_plot_haxby_different_estimators_002.png" src="../_images/sphx_glr_plot_haxby_different_estimators_002.png" style="width: 203.0px; height: 160.29999999999998px;" /></a>
<a class="reference external image-reference" href="../auto_examples/02_decoding/plot_haxby_different_estimators.html"><img alt="../_images/sphx_glr_plot_haxby_different_estimators_003.png" src="../_images/sphx_glr_plot_haxby_different_estimators_003.png" style="width: 203.0px; height: 160.29999999999998px;" /></a>
</div>
<div class="section" id="setting-estimator-parameters">
<h2><a class="toc-backref" href="#id5"><span class="section-number">2.2.3. </span>Setting estimator parameters</a><a class="headerlink" href="#setting-estimator-parameters" title="Permalink to this headline">¶</a></h2>
<p>Most estimators have parameters (called “hyper-parameters”) that can be set
to optimize their performance to a given problem. By default, the Decoder
objects in Nilearn already try several values to roughly adapt to your problem.</p>
<p>If you want to try more specific sets of parameters relevant to the model
your using, you can pass a dictionary to <cite>param_grid</cite> argument. It must contain
values for the suitable argument name. For example SVC has a parameter <cite>C</cite>.
By default, the values tried for <cite>C</cite> are [1,10,100].</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Full code example on parameter setting can be found at :
<a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_grid_search.html#sphx-glr-auto-examples-02-decoding-plot-haxby-grid-search-py"><span class="std std-ref">Setting a parameter by cross-validation</span></a></p>
</div>
<p>Be careful about <strong>overfitting</strong>. Giving a grid containing too many parameter
close to each other will be computationnaly costly to fit and may result in
choosing a parameter that works best on your training set, but does not give
as good performances on your data. You can see below an example in which the
curve showing the score as a function of the parameter has bumps and peaks
due to this noise.</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/02_decoding/plot_haxby_grid_search.html"><img alt="../_images/sphx_glr_plot_haxby_grid_search_001.png" src="../_images/sphx_glr_plot_haxby_grid_search_001.png" style="width: 360.0px; height: 240.0px;" /></a>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference external" href="http://scikit-learn.org/stable/modules/grid_search.html">The scikit-learn documentation on parameter selection</a></p>
</div>
</div>
<div class="section" id="bagging-several-models">
<h2><a class="toc-backref" href="#id6"><span class="section-number">2.2.4. </span>Bagging several models</a><a class="headerlink" href="#bagging-several-models" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator">Bagging</a>
is a classical machine learning method to create ensemble of models that usually
generalize to new data better than single model. The easiest way is to average
the prediction of several models trained on slightly different part of a
dataset and thus should have different bias that may cancel out.</p>
<p>The <a class="reference internal" href="../modules/generated/nilearn.decoding.Decoder.html#nilearn.decoding.Decoder" title="nilearn.decoding.Decoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">nilearn.decoding.Decoder</span></code></a> and <a class="reference internal" href="../modules/generated/nilearn.decoding.DecoderRegressor.html#nilearn.decoding.DecoderRegressor" title="nilearn.decoding.DecoderRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">nilearn.decoding.DecoderRegressor</span></code></a>
implement a kind of bagging scheme under the hood in their <cite>fit</cite> method to
yield better and more stable decoders. For each cross-validation fold,
the best model coefficients are retained. The average of all those linear
models is then used to make predictions.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p>The <a class="reference external" href="http://scikit-learn.org">scikit-learn documentation</a>
has very detailed explanations on a large variety of estimators and
machine learning techniques. To become better at decoding, you need
to study it.</p></li>
<li><p><a class="reference internal" href="frem.html#frem"><span class="std std-ref">FREM</span></a>, a pipeline bagging many models that yields very
good decoding performance at a reasonable computational cost.</p></li>
<li><p><a class="reference internal" href="space_net.html#space-net"><span class="std std-ref">SpaceNet</span></a>, a method promoting sparsity that can also
give good brain decoding power and improved decoder maps when sparsity
is important.</p></li>
</ul>
</div>
</div>
<div class="section" id="references">
<h2><a class="toc-backref" href="#id7"><span class="section-number">2.2.5. </span>References</a><a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p><dl class="footnote brackets">
<dt class="label" id="naselaris2011"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Thomas Naselaris, Kendrick N. Kay, Shinji Nishimoto, and Jack L. Gallant. Encoding and decoding in fmri. <em>NeuroImage</em>, 56(2):400–410, May 2011. 20691790[pmid]. URL: <a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/20691790">https://pubmed.ncbi.nlm.nih.gov/20691790</a>, <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2010.07.073">doi:10.1016/j.neuroimage.2010.07.073</a>.</p>
</dd>
</dl>
</p>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">2.2. Choosing the right predictive model for neuroimaging</a><ul>
<li><a class="reference internal" href="#predictions-regression-classification-and-multi-class">2.2.1. Predictions: regression, classification and multi-class</a><ul>
<li><a class="reference internal" href="#regression">2.2.1.1. Regression</a></li>
<li><a class="reference internal" href="#classification-two-classes-or-multi-class">2.2.1.2. Classification: two classes or multi-class</a></li>
</ul>
</li>
<li><a class="reference internal" href="#different-linear-models">2.2.2. Different linear models</a></li>
<li><a class="reference internal" href="#setting-estimator-parameters">2.2.3. Setting estimator parameters</a></li>
<li><a class="reference internal" href="#bagging-several-models">2.2.4. Bagging several models</a></li>
<li><a class="reference internal" href="#references">2.2.5. References</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="decoding_intro.html"
                        title="previous chapter"><span class="section-number">2.1. </span>An introduction to decoding</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="frem.html"
                        title="next chapter"><span class="section-number">2.3. </span>FREM: fast ensembling of regularized models for robust decoding</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
            &copy; The nilearn developers 2010-2021.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 4.0.2.
        <span style="padding-left: 5ex;">
          <a href="../_sources/decoding/estimator_choice.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>