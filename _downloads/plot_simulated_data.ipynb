{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# Example of pattern recognition on simulated data\n\n\nThis example simulates data according to a very simple sketch of brain\nimaging data and applies machine learning techniques to predict output\nvalues.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Licence : BSD\n\nprint(__doc__)\n\nfrom time import time\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import linalg, ndimage\n\nfrom sklearn import linear_model, svm\nfrom sklearn.utils import check_random_state\nfrom sklearn.cross_validation import KFold\nfrom sklearn.feature_selection import f_regression\n\nimport nibabel\n\nfrom nilearn import decoding\nimport nilearn.masking"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Function to generate data\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "def create_simulation_data(snr=0, n_samples=2 * 100, size=12, random_state=1):\n    generator = check_random_state(random_state)\n    roi_size = 2  # size / 3\n    smooth_X = 1\n    # Coefs\n    w = np.zeros((size, size, size))\n    w[0:roi_size, 0:roi_size, 0:roi_size] = -0.6\n    w[-roi_size:, -roi_size:, 0:roi_size] = 0.5\n    w[0:roi_size, -roi_size:, -roi_size:] = -0.6\n    w[-roi_size:, 0:roi_size:, -roi_size:] = 0.5\n    w[(size - roi_size) // 2:(size + roi_size) // 2,\n      (size - roi_size) // 2:(size + roi_size) // 2,\n      (size - roi_size) // 2:(size + roi_size) // 2] = 0.5\n    w = w.ravel()\n    # Generate smooth background noise\n    XX = generator.randn(n_samples, size, size, size)\n    noise = []\n    for i in range(n_samples):\n        Xi = ndimage.filters.gaussian_filter(XX[i, :, :, :], smooth_X)\n        Xi = Xi.ravel()\n        noise.append(Xi)\n    noise = np.array(noise)\n    # Generate the signal y\n    y = generator.randn(n_samples)\n    X = np.dot(y[:, np.newaxis], w[np.newaxis])\n    norm_noise = linalg.norm(X, 2) / np.exp(snr / 20.)\n    noise_coef = norm_noise / linalg.norm(noise, 2)\n    noise *= noise_coef\n    snr = 20 * np.log(linalg.norm(X, 2) / linalg.norm(noise, 2))\n    print(\"SNR: %.1f dB\" % snr)\n    # Mixing of signal + noise and splitting into train/test\n    X += noise\n    X -= X.mean(axis=-1)[:, np.newaxis]\n    X /= X.std(axis=-1)[:, np.newaxis]\n    X_test = X[n_samples // 2:, :]\n    X_train = X[:n_samples // 2, :]\n    y_test = y[n_samples // 2:]\n    y = y[:n_samples // 2]\n\n    return X_train, X_test, y, y_test, snr, noise, w, size\n\n\ndef plot_slices(data, title=None):\n    plt.figure(figsize=(5.5, 2.2))\n    vmax = np.abs(data).max()\n    for i in (0, 6, 11):\n        plt.subplot(1, 3, i // 5 + 1)\n        plt.imshow(data[:, :, i], vmin=-vmax, vmax=vmax,\n                   interpolation=\"nearest\", cmap=plt.cm.RdBu_r)\n        plt.xticks(())\n        plt.yticks(())\n    plt.subplots_adjust(hspace=0.05, wspace=0.05, left=.03, right=.97, top=.9)\n    if title is not None:\n        plt.suptitle(title, y=.95)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Create data\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "X_train, X_test, y_train, y_test, snr, _, coefs, size = \\\n    create_simulation_data(snr=-10, n_samples=100, size=12)\n\n# Create masks for SearchLight. process_mask is the voxels where SearchLight\n# computation is performed. It is a subset of the brain mask, just to reduce\n# computation time.\nmask = np.ones((size, size, size), np.bool)\nmask_img = nibabel.Nifti1Image(mask.astype(np.int), np.eye(4))\nprocess_mask = np.zeros((size, size, size), np.bool)\nprocess_mask[:, :, 0] = True\nprocess_mask[:, :, 6] = True\nprocess_mask[:, :, 11] = True\nprocess_mask_img = nibabel.Nifti1Image(process_mask.astype(np.int), np.eye(4))\n\ncoefs = np.reshape(coefs, [size, size, size])\nplot_slices(coefs, title=\"Ground truth\")"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Compute the results and estimated coef maps for different estimators\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "classifiers = [\n    ('bayesian_ridge', linear_model.BayesianRidge(normalize=True)),\n    ('enet_cv', linear_model.ElasticNetCV(alphas=[5, 1, 0.5, 0.1],\n                                          l1_ratio=0.05)),\n    ('ridge_cv', linear_model.RidgeCV(alphas=[100, 10, 1, 0.1], cv=5)),\n    ('svr', svm.SVR(kernel='linear', C=0.001)),\n    ('searchlight', decoding.SearchLight(\n        mask_img, process_mask_img=process_mask_img,\n        radius=2.7, scoring='r2', estimator=svm.SVR(kernel=\"linear\"),\n        cv=KFold(y_train.size, n_folds=4),\n        verbose=1, n_jobs=1))\n]\n\n# Run the estimators\nfor name, classifier in classifiers:\n    t1 = time()\n    if name != \"searchlight\":\n        classifier.fit(X_train, y_train)\n    else:\n        X = nilearn.masking.unmask(X_train, mask_img)\n        classifier.fit(X, y_train)\n        del X\n    elapsed_time = time() - t1\n\n    if name != 'searchlight':\n        coefs = classifier.coef_\n        coefs = np.reshape(coefs, [size, size, size])\n        score = classifier.score(X_test, y_test)\n        title = '%s: prediction score %.3f, training time: %.2fs' % (\n                classifier.__class__.__name__, score,\n                elapsed_time)\n\n    else:  # Searchlight\n        coefs = classifier.scores_\n        title = '%s: training time: %.2fs' % (\n                classifier.__class__.__name__,\n                elapsed_time)\n\n    # We use the plot_slices function provided in the example to\n    # plot the results\n    plot_slices(coefs, title=title)\n\n    print(title)\n\nf_values, p_values = f_regression(X_train, y_train)\np_values = np.reshape(p_values, (size, size, size))\np_values = -np.log10(p_values)\np_values[np.isnan(p_values)] = 0\np_values[p_values > 10] = 10\nplot_slices(p_values, title=\"f_regress\")\n\nplt.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.10", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}