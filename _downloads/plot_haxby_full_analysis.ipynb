{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nROI-based decoding analysis in Haxby et al. dataset\n=====================================================\n\nIn this script we reproduce the data analysis conducted by\nHaxby et al. in \"Distributed and Overlapping Representations of Faces and\nObjects in Ventral Temporal Cortex\".\n\nSpecifically, we look at decoding accuracy for different objects in\nthree different masks: the full ventral stream (mask_vt), the house\nselective areas (mask_house) and the face selective areas (mask_face),\nthat have been defined via a standard GLM-based analysis.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "First we load and prepare the data\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Fetch data using nilearn dataset fetcher\nfrom nilearn import datasets\nhaxby_dataset = datasets.fetch_haxby(n_subjects=1)\nfunc_filename = haxby_dataset.func[0]\n\n# Print basic information on the dataset\nprint('First subject anatomical nifti image (3D) located is at: %s' %\n      haxby_dataset.anat[0])\nprint('First subject functional nifti image (4D) is located at: %s' %\n      func_filename)\n\n# Load nilearn NiftiMasker, the practical masking and unmasking tool\nfrom nilearn.input_data import NiftiMasker\n\n# load labels\nimport numpy as np\nlabels = np.recfromcsv(haxby_dataset.session_target[0], delimiter=\" \")\nstimuli = labels['labels']\n\n# identify resting state labels in order to be able to remove them\nresting_state = stimuli == b\"rest\"\n\n# find names of remaining active labels\ncategories = np.unique(stimuli[np.logical_not(resting_state)])\n\n# extract tags indicating to which acquisition run a tag belongs\nsession_labels = labels[\"chunks\"][np.logical_not(resting_state)]"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Then we use scikit-learn for decoding on the different masks\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# The classifier: a support vector classifier\nfrom sklearn.svm import SVC\nclassifier = SVC(C=1., kernel=\"linear\")\n\n# A classifier to set the chance level\nfrom sklearn.dummy import DummyClassifier\ndummy_classifier = DummyClassifier()\n\n# Make a data splitting object for cross validation\nfrom sklearn.cross_validation import LeaveOneLabelOut, cross_val_score\ncv = LeaveOneLabelOut(session_labels)\n\nmask_names = ['mask_vt', 'mask_face', 'mask_house']\n\nmask_scores = {}\nmask_chance_scores = {}\n\nfor mask_name in mask_names:\n    print(\"Working on mask %s\" % mask_name)\n    # For decoding, standardizing is often very important\n    mask_filename = haxby_dataset[mask_name][0]\n    masker = NiftiMasker(mask_img=mask_filename, standardize=True)\n    masked_timecourses = masker.fit_transform(\n        func_filename)[np.logical_not(resting_state)]\n\n    mask_scores[mask_name] = {}\n    mask_chance_scores[mask_name] = {}\n\n    for category in categories:\n        print(\"Processing %s %s\" % (mask_name, category))\n        task_mask = np.logical_not(resting_state)\n        classification_target = (stimuli[task_mask] == category)\n        mask_scores[mask_name][category] = cross_val_score(\n            classifier,\n            masked_timecourses,\n            classification_target,\n            cv=cv, scoring=\"f1\")\n\n        mask_chance_scores[mask_name][category] = cross_val_score(\n            dummy_classifier,\n            masked_timecourses,\n            classification_target,\n            cv=cv, scoring=\"f1\")\n\n        print(\"Scores: %1.2f +- %1.2f\" % (\n            mask_scores[mask_name][category].mean(),\n            mask_scores[mask_name][category].std()))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "We make a simple bar plot to summarize the results\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import matplotlib.pyplot as plt\nplt.figure()\n\ntick_position = np.arange(len(categories))\nplt.xticks(tick_position, categories, rotation=45)\n\nfor color, mask_name in zip('rgb', mask_names):\n    score_means = [mask_scores[mask_name][category].mean()\n                   for category in categories]\n    plt.bar(tick_position, score_means, label=mask_name,\n            width=.25, color=color)\n\n    score_chance = [mask_chance_scores[mask_name][category].mean()\n                    for category in categories]\n    plt.bar(tick_position, score_chance,\n            width=.25, edgecolor='k', facecolor='none')\n\n    tick_position = tick_position + .2\n\nplt.ylabel('Classification accurancy (f1 score)')\nplt.xlabel('Visual stimuli category')\nplt.legend(loc='best')\nplt.title('Category-specific classification accuracy for different masks')\nplt.tight_layout()\n\n\nplt.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.6", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}