{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nDecoding with SpaceNet: face vs house object recognition\n=========================================================\n\nHere is a simple example of decoding with a SpaceNet prior (i.e Graph-Net,\nTV-l1, etc.), reproducing the Haxby 2001 study on a face vs house\ndiscrimination task.\n\nSee also the SpaceNet documentation: `space_net`.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "Load the Haxby dataset\n------------------------\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from nilearn.datasets import fetch_haxby\ndata_files = fetch_haxby()\n\n# Load behavioral data\nimport pandas as pd\nbehavioral = pd.read_csv(data_files.session_target[0], sep=\" \")\n\n# Restrict to face and house conditions\nconditions = behavioral['labels']\ncondition_mask = conditions.isin(['face', 'house'])\n\n# Split data into train and test samples, using the chunks\ncondition_mask_train = (condition_mask) & (behavioral['chunks'] <= 6)\ncondition_mask_test = (condition_mask) & (behavioral['chunks'] > 6)\n\n# Apply this sample mask to X (fMRI data) and y (behavioral labels)\n# Because the data is in one single large 4D image, we need to use\n# index_img to do the split easily\nfrom nilearn.image import index_img\nfunc_filenames = data_files.func[0]\nX_train = index_img(func_filenames, condition_mask_train)\nX_test = index_img(func_filenames, condition_mask_test)\ny_train = conditions[condition_mask_train]\ny_test = conditions[condition_mask_test]\n\n# Compute the mean epi to be used for the background of the plotting\nfrom nilearn.image import mean_img\nbackground_img = mean_img(func_filenames)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Fit SpaceNet with a Graph-Net penalty\n--------------------------------------\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from nilearn.decoding import SpaceNetClassifier\n\n# Fit model on train data and predict on test data\ndecoder = SpaceNetClassifier(memory=\"nilearn_cache\", penalty='graph-net')\ndecoder.fit(X_train, y_train)\ny_pred = decoder.predict(X_test)\naccuracy = (y_pred == y_test).mean() * 100.\nprint(\"Graph-net classification accuracy : %g%%\" % accuracy)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Visualization of Graph-net weights\n------------------------------------\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from nilearn.plotting import plot_stat_map, show\ncoef_img = decoder.coef_img_\nplot_stat_map(coef_img, background_img,\n              title=\"graph-net: accuracy %g%%\" % accuracy,\n              cut_coords=(-52, -5), display_mode=\"yz\")\n\n# Save the coefficients to a nifti file\ncoef_img.to_filename('haxby_graph-net_weights.nii')"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Now Fit SpaceNet with a TV-l1 penalty\n--------------------------------------\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "decoder = SpaceNetClassifier(memory=\"nilearn_cache\", penalty='tv-l1')\ndecoder.fit(X_train, y_train)\ny_pred = decoder.predict(X_test)\naccuracy = (y_pred == y_test).mean() * 100.\nprint(\"TV-l1 classification accuracy : %g%%\" % accuracy)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Visualization of TV-L1 weights\n-------------------------------\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "coef_img = decoder.coef_img_\nplot_stat_map(coef_img, background_img,\n              title=\"tv-l1: accuracy %g%%\" % accuracy,\n              cut_coords=(-52, -5), display_mode=\"yz\")\n\n# Save the coefficients to a nifti file\ncoef_img.to_filename('haxby_tv-l1_weights.nii')\nshow()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "We can see that the TV-l1 penalty is 3 times slower to converge and\ngives the same prediction accuracy. However, it yields much\ncleaner coefficient maps\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.15", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}