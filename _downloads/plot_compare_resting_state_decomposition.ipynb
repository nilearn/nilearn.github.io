{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "pygments_lexer": "ipython3",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.5.6",
      "file_extension": ".py",
      "nbconvert_exporter": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "metadata": {
        "collapsed": false
      },
      "source": [
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null,
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "\nDictionary Learning and ICA for doing group analysis of resting-state fMRI\n==========================================================================\n\nThis example applies dictionary learning and ICA to resting-state data,\nvisualizing resulting components using atlas plotting tools.\n\nDictionary learning is a sparsity based decomposition method for extracting\nspatial maps. It extracts maps that are naturally sparse and usually cleaner\nthan ICA\n\n   * Arthur Mensch et al. `Compressed online dictionary learning for fast resting-state fMRI decomposition\n     <https://hal.archives-ouvertes.fr/hal-01271033/>`_,\n     ISBI 2016, Lecture Notes in Computer Science\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The use of the attribute `components_img_` from decomposition\n    estimators is implemented from version 0.4.1.\n    For older versions, unmask the deprecated attribute `components_` to\n    get the components image using attribute `masker_` embedded in estimator.\n    See the `section Inverse transform: unmasking data <unmasking_step>`.</p></div>\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "Load ADHD rest dataset\n-----------------------\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "collapsed": false
      },
      "source": [
        "from nilearn import datasets\n\nadhd_dataset = datasets.fetch_adhd(n_subjects=30)\nfunc_filenames = adhd_dataset.func  # list of 4D nifti files for each subject\n\n# print basic information on the dataset\nprint('First functional nifti image (4D) is at: %s' %\n      adhd_dataset.func[0])  # 4D data"
      ],
      "outputs": [],
      "execution_count": null,
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "Create two decomposition estimators\n------------------------------------\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "collapsed": false
      },
      "source": [
        "from nilearn.decomposition import DictLearning, CanICA\n\nn_components = 40"
      ],
      "outputs": [],
      "execution_count": null,
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "Dictionary learning\n--------------------\n\nWe use as \"template\" as a strategy to compute the mask, as this leads\nto slightly faster and more reproducible results. However, the images\nneed to be in MNI template space\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "collapsed": false
      },
      "source": [
        "dict_learning = DictLearning(n_components=n_components,\n                             memory=\"nilearn_cache\", memory_level=2,\n                             verbose=1,\n                             random_state=0,\n                             n_epochs=1,\n                             mask_strategy='template')"
      ],
      "outputs": [],
      "execution_count": null,
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "CanICA\n------\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "collapsed": false
      },
      "source": [
        "canica = CanICA(n_components=n_components,\n                memory=\"nilearn_cache\", memory_level=2,\n                threshold=3.,\n                n_init=1,\n                verbose=1,\n                mask_strategy='template')"
      ],
      "outputs": [],
      "execution_count": null,
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "Fit both estimators\n--------------------\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "collapsed": false
      },
      "source": [
        "estimators = [dict_learning, canica]\nnames = {dict_learning: 'DictionaryLearning', canica: 'CanICA'}\ncomponents_imgs = []\n\nfor estimator in estimators:\n    print('[Example] Learning maps using %s model' % names[estimator])\n    estimator.fit(func_filenames)\n    print('[Example] Saving results')\n    # Grab extracted components umasked back to Nifti image.\n    # Note: For older versions, less than 0.4.1. components_img_\n    # is not implemented. See Note section above for details.\n    components_img = estimator.components_img_\n    components_img.to_filename('%s_resting_state.nii.gz' %\n                               names[estimator])\n    components_imgs.append(components_img)"
      ],
      "outputs": [],
      "execution_count": null,
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "Visualize the results\n----------------------\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "collapsed": false
      },
      "source": [
        "from nilearn.plotting import (plot_prob_atlas, find_xyz_cut_coords, show,\n                              plot_stat_map)\nfrom nilearn.image import index_img\n\n# Selecting specific maps to display: maps were manually chosen to be similar\nindices = {dict_learning: 25, canica: 33}\n# We select relevant cut coordinates for displaying\ncut_component = index_img(components_imgs[0], indices[dict_learning])\ncut_coords = find_xyz_cut_coords(cut_component)\nfor estimator, components in zip(estimators, components_imgs):\n    # 4D plotting\n    plot_prob_atlas(components, view_type=\"filled_contours\",\n                    title=\"%s\" % names[estimator],\n                    cut_coords=cut_coords, colorbar=False)\n    # 3D plotting\n    plot_stat_map(index_img(components, indices[estimator]),\n                  title=\"%s\" % names[estimator],\n                  cut_coords=cut_coords, colorbar=False)\nshow()"
      ],
      "outputs": [],
      "execution_count": null,
      "cell_type": "code"
    }
  ]
}