{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nDictionary Learning and ICA for doing group analysis of resting-state fMRI\n==========================================================================\n\nThis example applies dictionary learning and ICA to resting-state data,\nvisualizing resulting components using atlas plotting tools.\n\nDictionary learning is a sparsity based decomposition method for extracting\nspatial maps. It extracts maps that are naturally sparse and usually cleaner\nthan ICA\n\n    * Gael Varoquaux et al.\n      Multi-subject dictionary learning to segment an atlas of brain spontaneous\n      activity\n      Information Processing in Medical Imaging, 2011, pp. 562-573, Lecture Notes\n      in Computer Science\n\nAvailable on https://hal.inria.fr/inria-00588898/en/\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "Load ADHD rest dataset\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from nilearn import datasets\n\nadhd_dataset = datasets.fetch_adhd(n_subjects=30)\nfunc_filenames = adhd_dataset.func  # list of 4D nifti files for each subject\n\n# print basic information on the dataset\nprint('First functional nifti image (4D) is at: %s' %\n      adhd_dataset.func[0])  # 4D data"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Create two decomposition estimators\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from nilearn.decomposition import DictLearning, CanICA\n\nn_components = 40"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Dictionary learning\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "dict_learning = DictLearning(n_components=n_components,\n                             memory=\"nilearn_cache\", memory_level=2,\n                             verbose=1,\n                             random_state=0,\n                             n_epochs=1)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "CanICA\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "canica = CanICA(n_components=n_components,\n                memory=\"nilearn_cache\", memory_level=2,\n                threshold=3.,\n                n_init=1,\n                verbose=1)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Fit both estimators\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "estimators = [dict_learning, canica]\nnames = {dict_learning: 'DictionaryLearning', canica: 'CanICA'}\ncomponents_imgs = []\n\nfor estimator in estimators:\n    print('[Example] Learning maps using %s model' % names[estimator])\n    estimator.fit(func_filenames)\n    print('[Example] Saving results')\n    # Decomposition estimator embeds their own masker\n    masker = estimator.masker_\n    # Drop output maps to a Nifti   file\n    components_img = masker.inverse_transform(estimator.components_)\n    components_img.to_filename('%s_resting_state.nii.gz' %\n                               names[estimator])\n    components_imgs.append(components_img)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Visualize the results\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from nilearn.plotting import (plot_prob_atlas, find_xyz_cut_coords, show,\n                              plot_stat_map)\nfrom nilearn.image import index_img\n\n# Selecting specific maps to display: maps were manually chosen to be similar\nindices = {dict_learning: 1, canica: 31}\n# We select relevant cut coordinates for displaying\ncut_component = index_img(components_imgs[0], indices[dict_learning])\ncut_coords = find_xyz_cut_coords(cut_component)\nfor estimator, components in zip(estimators, components_imgs):\n    # 4D plotting\n    plot_prob_atlas(components, view_type=\"filled_contours\",\n                    title=\"%s\" % names[estimator],\n                    cut_coords=cut_coords, colorbar=False)\n    # 3D plotting\n    plot_stat_map(index_img(components, indices[estimator]),\n                  title=\"%s\" % names[estimator],\n                  cut_coords=cut_coords, colorbar=False)\nshow()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.6", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}