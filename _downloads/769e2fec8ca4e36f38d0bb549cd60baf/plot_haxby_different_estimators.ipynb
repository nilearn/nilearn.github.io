{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nDifferent classifiers in decoding the Haxby dataset\n=====================================================\n\nHere we compare different classifiers on a visual object recognition\ndecoding task.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start by loading the data and applying simple transformations to it\n-----------------------------------------------------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Fetch data using nilearn dataset fetcher\nfrom nilearn import datasets\n# by default 2nd subject data will be fetched\nhaxby_dataset = datasets.fetch_haxby()\n\n# print basic information on the dataset\nprint('First subject anatomical nifti image (3D) located is at: %s' %\n      haxby_dataset.anat[0])\nprint('First subject functional nifti image (4D) is located at: %s' %\n      haxby_dataset.func[0])\n\n# load labels\nimport numpy as np\nimport pandas as pd\nlabels = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\nstimuli = labels['labels']\n# identify resting state labels in order to be able to remove them\ntask_mask = (stimuli != 'rest')\n\n# find names of remaining active labels\ncategories = stimuli[task_mask].unique()\n\n# extract tags indicating to which acquisition run a tag belongs\nsession_labels = labels['chunks'][task_mask]\n\n# Load the fMRI data\nfrom nilearn.input_data import NiftiMasker\n\n# For decoding, standardizing is often very important\nmask_filename = haxby_dataset.mask_vt[0]\nmasker = NiftiMasker(mask_img=mask_filename, standardize=True)\nfunc_filename = haxby_dataset.func[0]\nmasked_timecourses = masker.fit_transform(\n    func_filename)[task_mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we define the various classifiers that we use\n---------------------------------------------------\nA support vector classifier\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\nsvm = SVC(C=1., kernel=\"linear\")\n\n# The logistic regression\nfrom sklearn.linear_model import (LogisticRegression,\n                                  RidgeClassifier,\n                                  RidgeClassifierCV,\n                                  )\nlogistic = LogisticRegression(C=1., penalty=\"l1\", solver='liblinear')\nlogistic_50 = LogisticRegression(C=50., penalty=\"l1\", solver='liblinear')\nlogistic_l2 = LogisticRegression(C=1., penalty=\"l2\", solver='liblinear')\n\n# Cross-validated versions of these classifiers\nfrom sklearn.model_selection import GridSearchCV\n# GridSearchCV is slow, but note that it takes an 'n_jobs' parameter that\n# can significantly speed up the fitting process on computers with\n# multiple cores\nsvm_cv = GridSearchCV(SVC(C=1., kernel=\"linear\"),\n                      param_grid={'C': [.1, 1., 10., 100.]},\n                      scoring='f1', n_jobs=1, cv=3, iid=False)\n\nlogistic_cv = GridSearchCV(\n        LogisticRegression(C=1., penalty=\"l1\", solver='liblinear'),\n        param_grid={'C': [.1, 1., 10., 100.]},\n        scoring='f1', cv=3, iid=False,\n        )\nlogistic_l2_cv = GridSearchCV(\n        LogisticRegression(C=1., penalty=\"l2\", solver='liblinear'),\n        param_grid={\n            'C': [.1, 1., 10., 100.]\n            },\n        scoring='f1', cv=3, iid=False,\n        )\n\n# The ridge classifier has a specific 'CV' object that can set it's\n# parameters faster than using a GridSearchCV\nridge = RidgeClassifier()\nridge_cv = RidgeClassifierCV()\n\n# A dictionary, to hold all our classifiers\nclassifiers = {'SVC': svm,\n               'SVC cv': svm_cv,\n               'log l1': logistic,\n               'log l1 50': logistic_50,\n               'log l1 cv': logistic_cv,\n               'log l2': logistic_l2,\n               'log l2 cv': logistic_l2_cv,\n               'ridge': ridge,\n               'ridge cv': ridge_cv\n               }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we compute prediction scores\n----------------------------------\nRun time for all these classifiers\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Make a data splitting object for cross validation\nfrom sklearn.model_selection import LeaveOneGroupOut, cross_val_score\ncv = LeaveOneGroupOut()\n\nimport time\n\nclassifiers_scores = {}\n\nfor classifier_name, classifier in sorted(classifiers.items()):\n    classifiers_scores[classifier_name] = {}\n    print(70 * '_')\n\n    for category in categories:\n        classification_target = stimuli[task_mask].isin([category])\n        t0 = time.time()\n        classifiers_scores[classifier_name][category] = cross_val_score(\n            classifier,\n            masked_timecourses,\n            classification_target,\n            cv=cv,\n            groups=session_labels,\n            scoring=\"f1\",\n        )\n\n        print(\n            \"%10s: %14s -- scores: %1.2f +- %1.2f, time %.2fs\" %\n            (\n                classifier_name,\n                category,\n                classifiers_scores[classifier_name][category].mean(),\n                classifiers_scores[classifier_name][category].std(),\n                time.time() - t0,\n            ),\n        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we make a rudimentary diagram\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nplt.figure()\n\ntick_position = np.arange(len(categories))\nplt.xticks(tick_position, categories, rotation=45)\n\nfor color, classifier_name in zip(\n        ['b', 'c', 'm', 'g', 'y', 'k', '.5', 'r', '#ffaaaa'],\n        sorted(classifiers)):\n    score_means = [classifiers_scores[classifier_name][category].mean()\n                   for category in categories]\n    plt.bar(tick_position, score_means, label=classifier_name,\n            width=.11, color=color)\n    tick_position = tick_position + .09\n\nplt.ylabel('Classification accurancy (f1 score)')\nplt.xlabel('Visual stimuli category')\nplt.ylim(ymin=0)\nplt.legend(loc='lower center', ncol=3)\nplt.title(\n    'Category-specific classification accuracy for different classifiers')\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, w plot the face vs house map for the different classifiers\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Use the average EPI as a background\nfrom nilearn import image\nmean_epi_img = image.mean_img(func_filename)\n\n# Restrict the decoding to face vs house\ncondition_mask = stimuli.isin(['face', 'house'])\nmasked_timecourses = masked_timecourses[\n    condition_mask[task_mask]]\nstimuli = (stimuli[condition_mask] == 'face')\n# Transform the stimuli to binary values\nstimuli.astype(np.int)\n\nfrom nilearn.plotting import plot_stat_map, show\n\nfor classifier_name, classifier in sorted(classifiers.items()):\n    classifier.fit(masked_timecourses, stimuli)\n\n    if hasattr(classifier, 'coef_'):\n        weights = classifier.coef_[0]\n    elif hasattr(classifier, 'best_estimator_'):\n        weights = classifier.best_estimator_.coef_[0]\n    else:\n        continue\n    weight_img = masker.inverse_transform(weights)\n    weight_map = weight_img.get_data()\n    threshold = np.max(np.abs(weight_map)) * 1e-3\n    plot_stat_map(weight_img, bg_img=mean_epi_img,\n                  display_mode='z', cut_coords=[-15],\n                  threshold=threshold,\n                  title='%s: face vs house' % classifier_name)\n\nshow()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}