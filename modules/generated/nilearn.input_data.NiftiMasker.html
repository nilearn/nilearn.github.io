
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Nilearn: Machine learning for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="7.6.2. nilearn.input_data.MultiNiftiMasker" href="nilearn.input_data.MultiNiftiMasker.html" />
    <link rel="prev" title="7.5.19. nilearn.image.threshold_img" href="nilearn.image.threshold_img.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">


<script type="text/javascript">
function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000)
        $('.related-wrapper').css("position", "sticky")
        $('.related-wrapper').css("top", 0)
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative")
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight()
    var banner_width = $('#logo-banner').outerWidth()
    var width = $('.related-wrapper').css("height", $('.related').outerHeight())

    updateTopMenuPosition(banner_height, width)

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth()
        var menu_height = $('.related').outerHeight()
        $('.related').css("width", banner_width)
        $('.related-wrapper').css("height", menu_height)
        updateTopMenuPosition(banner_height, width)
    })
});
</script>
<script type="text/javascript">
function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop()
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed")
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative")
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0
    current_section = 0
    $('a.internal').removeClass('active')
    for(i in sections) {
        if(sections[i] > pos) {
            break
        };
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        };
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active')
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight()
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0))
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop
    sections = {}
    url = document.URL.replace(/#.*$/, "")

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections)

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight()
        updateSideBarPosition(top, tocOffset, sections)
    });
});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../../index.html">
      <img src="../../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../../manipulating_images/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Machine learning for Neuro-Imaging in Python</h2>
  </div>
  <div class="search_form">
    <div class="gcse-search" id="cse" style="width: 100%;"></div>
    <script>
      (function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </div>
</div>



<div class=related-wrapper>
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="nilearn.input_data.MultiNiftiMasker.html" title="7.6.2. nilearn.input_data.MultiNiftiMasker"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="nilearn.image.threshold_img.html" title="7.5.19. nilearn.image.threshold_img"
             accesskey="P">previous</a> |</li>
<li><a href="../../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../reference.html" accesskey="U">7. Reference documentation: all nilearn functions</a> &#187;</li> 
      </ul>
    </div>
</div>

      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">7.6.1. nilearn.input_data.NiftiMasker</a><ul>
<li><a class="reference internal" href="#examples-using-nilearn-input-data-niftimasker">7.6.1.1. Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.input_data.NiftiMasker</span></code></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="nilearn.image.threshold_img.html"
                        title="previous chapter">7.5.19. nilearn.image.threshold_img</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="nilearn.input_data.MultiNiftiMasker.html"
                        title="next chapter">7.6.2. nilearn.input_data.MultiNiftiMasker</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This page is a reference documentation. It only explains the class
signature, and not how to use it. Please refer to the
<a class="reference internal" href="../../user_guide.html#user-guide"><span class="std std-ref">user guide</span></a> for the big picture.</p>
</div>
<div class="section" id="nilearn-input-data-niftimasker">
<h1>7.6.1. nilearn.input_data.NiftiMasker<a class="headerlink" href="#nilearn-input-data-niftimasker" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="nilearn.input_data.NiftiMasker">
<em class="property">class </em><code class="descclassname">nilearn.input_data.</code><code class="descname">NiftiMasker</code><span class="sig-paren">(</span><em>mask_img=None</em>, <em>sessions=None</em>, <em>smoothing_fwhm=None</em>, <em>standardize=False</em>, <em>detrend=False</em>, <em>low_pass=None</em>, <em>high_pass=None</em>, <em>t_r=None</em>, <em>target_affine=None</em>, <em>target_shape=None</em>, <em>mask_strategy='background'</em>, <em>mask_args=None</em>, <em>sample_mask=None</em>, <em>dtype=None</em>, <em>memory_level=1</em>, <em>memory=Memory(location=None)</em>, <em>verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.NiftiMasker" title="Permalink to this definition">¶</a></dt>
<dd><p>Applying a mask to extract time-series from Niimg-like objects.</p>
<p>NiftiMasker is useful when preprocessing (detrending, standardization,
resampling, etc.) of in-mask voxels is necessary. Use case: working with
time series of resting-state or task maps.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>mask_img</strong> : Niimg-like object, optional</p>
<blockquote>
<div><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
Mask for the data. If not given, a mask is computed in the fit step.
Optional parameters (mask_args and mask_strategy) can be set to
fine tune the mask extraction.</p>
</div></blockquote>
<p><strong>sessions</strong> : numpy array, optional</p>
<blockquote>
<div><p>Add a session level to the preprocessing. Each session will be
detrended independently. Must be a 1D array of n_samples elements.</p>
</div></blockquote>
<p><strong>smoothing_fwhm</strong> : float, optional</p>
<blockquote>
<div><p>If smoothing_fwhm is not None, it gives the full-width half maximum in
millimeters of the spatial smoothing to apply to the signal.</p>
</div></blockquote>
<p><strong>standardize</strong> : boolean, optional</p>
<blockquote>
<div><p>If standardize is True, the time-series are centered and normed:
their mean is put to 0 and their variance to 1 in the time dimension.</p>
</div></blockquote>
<p><strong>detrend</strong> : boolean, optional</p>
<blockquote>
<div><p>This parameter is passed to signal.clean. Please see the related
documentation for details</p>
</div></blockquote>
<p><strong>low_pass: None or float, optional</strong></p>
<blockquote>
<div><p>This parameter is passed to signal.clean. Please see the related
documentation for details</p>
</div></blockquote>
<p><strong>high_pass: None or float, optional</strong></p>
<blockquote>
<div><p>This parameter is passed to signal.clean. Please see the related
documentation for details</p>
</div></blockquote>
<p><strong>t_r</strong> : float, optional</p>
<blockquote>
<div><p>This parameter is passed to signal.clean. Please see the related
documentation for details</p>
</div></blockquote>
<p><strong>target_affine</strong> : 3x3 or 4x4 matrix, optional</p>
<blockquote>
<div><p>This parameter is passed to image.resample_img. Please see the
related documentation for details.</p>
</div></blockquote>
<p><strong>target_shape</strong> : 3-tuple of integers, optional</p>
<blockquote>
<div><p>This parameter is passed to image.resample_img. Please see the
related documentation for details.</p>
</div></blockquote>
<p><strong>mask_strategy: {‘background’, ‘epi’ or ‘template’}, optional</strong></p>
<blockquote>
<div><p>The strategy used to compute the mask: use ‘background’ if your
images present a clear homogeneous background, ‘epi’ if they
are raw EPI images, or you could use ‘template’ which will
extract the gray matter part of your data by resampling the MNI152
brain mask for your data’s field of view.
Depending on this value, the mask will be computed from
masking.compute_background_mask, masking.compute_epi_mask or
masking.compute_gray_matter_mask. Default is ‘background’.</p>
</div></blockquote>
<p><strong>mask_args</strong> : dict, optional</p>
<blockquote>
<div><p>If mask is None, these are additional parameters passed to
masking.compute_background_mask or masking.compute_epi_mask
to fine-tune mask computation. Please see the related documentation
for details.</p>
</div></blockquote>
<p><strong>sample_mask</strong> : Any type compatible with numpy-array indexing</p>
<blockquote>
<div><p>Masks the niimgs along time/fourth dimension. This complements
3D masking by the mask_img argument. This masking step is applied
before data preprocessing at the beginning of NiftiMasker.transform.
This is useful to perform data subselection as part of a scikit-learn
pipeline.</p>
</div></blockquote>
<p><strong>`dtype: {dtype, “auto”}</strong></p>
<blockquote>
<div><p>Data type toward which the data should be converted. If “auto”, the
data will be converted to int32 if dtype is discrete and float32 if it
is continuous.</p>
</div></blockquote>
<p><strong>memory</strong> : instance of joblib.Memory or string</p>
<blockquote>
<div><p>Used to cache the masking process.
By default, no caching is done. If a string is given, it is the
path to the caching directory.</p>
</div></blockquote>
<p><strong>memory_level</strong> : integer, optional</p>
<blockquote>
<div><p>Rough estimator of the amount of memory used by caching. Higher value
means more memory for caching.</p>
</div></blockquote>
<p><strong>verbose</strong> : integer, optional</p>
<blockquote class="last">
<div><p>Indicate the level of verbosity. By default, nothing is printed</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference internal" href="nilearn.masking.compute_background_mask.html#nilearn.masking.compute_background_mask" title="nilearn.masking.compute_background_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.masking.compute_background_mask</span></code></a>, <a class="reference internal" href="nilearn.masking.compute_epi_mask.html#nilearn.masking.compute_epi_mask" title="nilearn.masking.compute_epi_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.masking.compute_epi_mask</span></code></a>, <a class="reference internal" href="nilearn.image.resample_img.html#nilearn.image.resample_img" title="nilearn.image.resample_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.image.resample_img</span></code></a>, <a class="reference internal" href="nilearn.masking.apply_mask.html#nilearn.masking.apply_mask" title="nilearn.masking.apply_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.masking.apply_mask</span></code></a>, <a class="reference internal" href="nilearn.signal.clean.html#nilearn.signal.clean" title="nilearn.signal.clean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.signal.clean</span></code></a></p>
</div>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="15%" />
<col width="85%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><cite>mask_img_</cite></td>
<td>(nibabel.Nifti1Image) The mask of the data, or the computed one.</td>
</tr>
<tr class="row-even"><td><cite>affine_</cite></td>
<td>(4x4 numpy array) Affine of the transformed image.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="nilearn.input_data.NiftiMasker.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>mask_img=None</em>, <em>sessions=None</em>, <em>smoothing_fwhm=None</em>, <em>standardize=False</em>, <em>detrend=False</em>, <em>low_pass=None</em>, <em>high_pass=None</em>, <em>t_r=None</em>, <em>target_affine=None</em>, <em>target_shape=None</em>, <em>mask_strategy='background'</em>, <em>mask_args=None</em>, <em>sample_mask=None</em>, <em>dtype=None</em>, <em>memory_level=1</em>, <em>memory=Memory(location=None)</em>, <em>verbose=0</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.NiftiMasker.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.NiftiMasker.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>imgs=None</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.NiftiMasker.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the mask corresponding to the data</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>imgs: list of Niimg-like objects</strong></p>
<blockquote class="last">
<div><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
Data on which the mask must be calculated. If this is a list,
the affine is considered the same for all.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.NiftiMasker.fit_transform">
<code class="descname">fit_transform</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em>, <em>confounds=None</em>, <em>**fit_params</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.NiftiMasker.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : Niimg-like object</p>
<blockquote>
<div><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a></p>
</div></blockquote>
<p><strong>y</strong> : numpy array of shape [n_samples]</p>
<blockquote>
<div><p>Target values.</p>
</div></blockquote>
<p><strong>confounds: list of confounds, optional</strong></p>
<blockquote>
<div><p>List of confounds (2D arrays or filenames pointing to CSV
files). Must be of same length than imgs_list.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>X_new</strong> : numpy array of shape [n_samples, n_features_new]</p>
<blockquote class="last">
<div><p>Transformed array.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.NiftiMasker.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.NiftiMasker.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.NiftiMasker.inverse_transform">
<code class="descname">inverse_transform</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.NiftiMasker.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform the 2D data matrix back to an image in brain space.</p>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.NiftiMasker.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.NiftiMasker.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.NiftiMasker.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>imgs</em>, <em>confounds=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.NiftiMasker.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply mask, spatial and temporal preprocessing</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>imgs: 3D/4D Niimg-like object</strong></p>
<blockquote>
<div><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
Images to process. It must boil down to a 4D image with scans
number as last dimension.</p>
</div></blockquote>
<p><strong>confounds: CSV file or array-like, optional</strong></p>
<blockquote>
<div><p>This parameter is passed to signal.clean. Please see the related
documentation for details.
shape: (number of scans, number of confounds)</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">region_signals: 2D numpy.ndarray</p>
<blockquote class="last">
<div><p>Signal for each element.
shape: (number of scans, number of elements)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nilearn.input_data.NiftiMasker.transform_single_imgs">
<code class="descname">transform_single_imgs</code><span class="sig-paren">(</span><em>imgs</em>, <em>confounds=None</em>, <em>copy=True</em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.input_data.NiftiMasker.transform_single_imgs" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply mask, spatial and temporal preprocessing</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>imgs: 3D/4D Niimg-like object</strong></p>
<blockquote>
<div><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
Images to process. It must boil down to a 4D image with scans
number as last dimension.</p>
</div></blockquote>
<p><strong>confounds: CSV file or array-like, optional</strong></p>
<blockquote>
<div><p>This parameter is passed to signal.clean. Please see the related
documentation for details.
shape: (number of scans, number of confounds)</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">region_signals: 2D numpy.ndarray</p>
<blockquote class="last">
<div><p>Signal for each voxel inside the mask.
shape: (number of scans, number of voxels)</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<div class="section" id="examples-using-nilearn-input-data-niftimasker">
<h2>7.6.1.1. Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.input_data.NiftiMasker</span></code><a class="headerlink" href="#examples-using-nilearn-input-data-niftimasker" title="Permalink to this headline">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="Here is a simple tutorial on decoding with nilearn. It reproduces the Haxby 2001 study on a fac..."><div class="figure" id="id1">
<img alt="../../_images/sphx_glr_plot_decoding_tutorial_thumb.png" src="../../_images/sphx_glr_plot_decoding_tutorial_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/plot_decoding_tutorial.html#sphx-glr-auto-examples-plot-decoding-tutorial-py"><span class="std std-ref">A introduction tutorial to fMRI decoding</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example does a simple but efficient decoding on the Haxby dataset: using a feature selecti..."><div class="figure" id="id2">
<img alt="../../_images/sphx_glr_plot_haxby_anova_svm_thumb.png" src="../../_images/sphx_glr_plot_haxby_anova_svm_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_anova_svm.html#sphx-glr-auto-examples-02-decoding-plot-haxby-anova-svm-py"><span class="std std-ref">Decoding with ANOVA + SVM: face vs house in the Haxby dataset</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we compare different classifiers on a visual object recognition decoding task. "><div class="figure" id="id3">
<img alt="../../_images/sphx_glr_plot_haxby_different_estimators_thumb.png" src="../../_images/sphx_glr_plot_haxby_different_estimators_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_different_estimators.html#sphx-glr-auto-examples-02-decoding-plot-haxby-different-estimators-py"><span class="std std-ref">Different classifiers in decoding the Haxby dataset</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this script we reproduce the data analysis conducted by Haxby et al. in "Distributed and Ove..."><div class="figure" id="id4">
<img alt="../../_images/sphx_glr_plot_haxby_full_analysis_thumb.png" src="../../_images/sphx_glr_plot_haxby_full_analysis_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_full_analysis.html#sphx-glr-auto-examples-02-decoding-plot-haxby-full-analysis-py"><span class="std std-ref">ROI-based decoding analysis in Haxby et al. dataset</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we set the number of features selected in an Anova-SVC approach to maximize the cross-vali..."><div class="figure" id="id5">
<img alt="../../_images/sphx_glr_plot_haxby_grid_search_thumb.png" src="../../_images/sphx_glr_plot_haxby_grid_search_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_grid_search.html#sphx-glr-auto-examples-02-decoding-plot-haxby-grid-search-py"><span class="std std-ref">Setting a parameter by cross-validation</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We compare one vs all and one vs one multi-class strategies: the overall cross-validated accura..."><div class="figure" id="id6">
<img alt="../../_images/sphx_glr_plot_haxby_multiclass_thumb.png" src="../../_images/sphx_glr_plot_haxby_multiclass_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_multiclass.html#sphx-glr-auto-examples-02-decoding-plot-haxby-multiclass-py"><span class="std std-ref">The haxby dataset: different multi-class strategies</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Searchlight analysis requires fitting a classifier a large amount of times. As a result, it is ..."><div class="figure" id="id7">
<img alt="../../_images/sphx_glr_plot_haxby_searchlight_thumb.png" src="../../_images/sphx_glr_plot_haxby_searchlight_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_searchlight.html#sphx-glr-auto-examples-02-decoding-plot-haxby-searchlight-py"><span class="std std-ref">Searchlight analysis of face vs house recognition</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example uses Voxel-Based Morphometry (VBM) to study the relationship between aging and gra..."><div class="figure" id="id8">
<img alt="../../_images/sphx_glr_plot_oasis_vbm_thumb.png" src="../../_images/sphx_glr_plot_oasis_vbm_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_oasis_vbm.html#sphx-glr-auto-examples-02-decoding-plot-oasis-vbm-py"><span class="std std-ref">Voxel-Based Morphometry on Oasis dataset</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to produce seed-to-voxel correlation maps for a single subject based on ..."><div class="figure" id="id9">
<img alt="../../_images/sphx_glr_plot_seed_to_voxel_correlation_thumb.png" src="../../_images/sphx_glr_plot_seed_to_voxel_correlation_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html#sphx-glr-auto-examples-03-connectivity-plot-seed-to-voxel-correlation-py"><span class="std std-ref">Producing single subject maps of seed-to-voxel correlation</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, the Nifti masker is used to automatically compute a mask."><div class="figure" id="id10">
<img alt="../../_images/sphx_glr_plot_mask_computation_thumb.png" src="../../_images/sphx_glr_plot_mask_computation_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_manipulating_images/plot_mask_computation.html#sphx-glr-auto-examples-04-manipulating-images-plot-mask-computation-py"><span class="std std-ref">Understanding NiftiMasker and mask computation</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here is a simple example of automatic mask computation using the nifti masker. The mask is comp..."><div class="figure" id="id11">
<img alt="../../_images/sphx_glr_plot_nifti_simple_thumb.png" src="../../_images/sphx_glr_plot_nifti_simple_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_manipulating_images/plot_nifti_simple.html#sphx-glr-auto-examples-04-manipulating-images-plot-nifti-simple-py"><span class="std std-ref">Simple example of NiftiMasker use</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="A permuted Ordinary Least Squares algorithm is run at each voxel in order to detemine whether o..."><div class="figure" id="id12">
<img alt="../../_images/sphx_glr_plot_haxby_mass_univariate_thumb.png" src="../../_images/sphx_glr_plot_haxby_mass_univariate_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_advanced/plot_haxby_mass_univariate.html#sphx-glr-auto-examples-05-advanced-plot-haxby-mass-univariate-py"><span class="std std-ref">Massively univariate analysis of face vs house recognition</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to download statistical maps from NeuroVault, label them with NeuroSynth..."><div class="figure" id="id13">
<img alt="../../_images/sphx_glr_plot_ica_neurovault_thumb.png" src="../../_images/sphx_glr_plot_ica_neurovault_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_advanced/plot_ica_neurovault.html#sphx-glr-auto-examples-05-advanced-plot-ica-neurovault-py"><span class="std std-ref">NeuroVault cross-study ICA maps.</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip=" This example is meant to demonstrate nilearn as a low-level tools used to combine feature extr..."><div class="figure" id="id14">
<img alt="../../_images/sphx_glr_plot_ica_resting_state_thumb.png" src="../../_images/sphx_glr_plot_ica_resting_state_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_advanced/plot_ica_resting_state.html#sphx-glr-auto-examples-05-advanced-plot-ica-resting-state-py"><span class="std std-ref">Multivariate decompositions: Independent component analysis of fMRI</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows the results obtained in a massively univariate analysis performed at the int..."><div class="figure" id="id15">
<img alt="../../_images/sphx_glr_plot_localizer_mass_univariate_methods_thumb.png" src="../../_images/sphx_glr_plot_localizer_mass_univariate_methods_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_advanced/plot_localizer_mass_univariate_methods.html#sphx-glr-auto-examples-05-advanced-plot-localizer-mass-univariate-methods-py"><span class="std std-ref">Massively univariate analysis of a motor task from the Localizer dataset</span></a></span></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use the Localizer dataset in a basic analysis. A standard Anova is pe..."><div class="figure" id="id16">
<img alt="../../_images/sphx_glr_plot_localizer_simple_analysis_thumb.png" src="../../_images/sphx_glr_plot_localizer_simple_analysis_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_advanced/plot_localizer_simple_analysis.html#sphx-glr-auto-examples-05-advanced-plot-localizer-simple-analysis-py"><span class="std std-ref">Massively univariate analysis of a calculation task from the Localizer dataset</span></a></span></p>
</div>
</div><div style='clear:both'></div></div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
            &copy; The nilearn developers 2010-2015.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.7.9.
        <span style="padding-left: 5ex;">
          <a href="../../_sources/modules/generated/nilearn.input_data.NiftiMasker.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>