
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nilearn: Statistical Analysis for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="8.5.9. nilearn.image.iter_img" href="nilearn.image.iter_img.html" />
    <link rel="prev" title="8.5.7. nilearn.image.high_variance_confounds" href="nilearn.image.high_variance_confounds.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">


<script type="text/javascript">
function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});
</script>
<script type="text/javascript">
function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../../index.html">
      <img src="../../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../../manipulating_images/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Statistics for NeuroImaging in Python</h2>
  </div>
  <div class="search_form">
    <div class="gcse-search" id="cse" style="width: 100%;"></div>
    <script>
      (function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </div>
</div>



<div class=related-wrapper>
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="nilearn.image.iter_img.html" title="8.5.9. nilearn.image.iter_img"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="nilearn.image.high_variance_confounds.html" title="8.5.7. nilearn.image.high_variance_confounds"
             accesskey="P">previous</a> |</li>
<li><a href="../../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../reference.html" accesskey="U"><span class="section-number">8. </span>Reference documentation: all nilearn functions</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Nilearn: Statistical Analysis for NeuroImaging in Python</a></li> 
      </ul>
    </div>
</div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page is a reference documentation. It only explains the
function signature, and not how to use it. Please refer to the
<a class="reference internal" href="../../user_guide.html#user-guide"><span class="std std-ref">user guide</span></a> for the big picture.</p>
</div>
<div class="section" id="nilearn-image-index-img">
<h1><span class="section-number">8.5.8. </span>nilearn.image.index_img<a class="headerlink" href="#nilearn-image-index-img" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="nilearn.image.index_img">
<code class="sig-prename descclassname">nilearn.image.</code><code class="sig-name descname">index_img</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">imgs</span></em>, <em class="sig-param"><span class="n">index</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.image.index_img" title="Permalink to this definition">¶</a></dt>
<dd><p>Indexes into a 4D Niimg-like object in the fourth dimension.</p>
<p>Common use cases include extracting a 3D image out of <cite>img</cite> or
creating a 4D image whose data is a subset of <cite>img</cite> data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>imgs</strong><span class="classifier">4D Niimg-like object</span></dt><dd><p>See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>.</p>
</dd>
<dt><strong>index</strong><span class="classifier">Any type compatible with numpy array indexing</span></dt><dd><p>Used for indexing the 4D data array in the fourth dimension.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference external" href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="(in NiBabel v3.2.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Nifti1Image</span></code></a></dt><dd><p>Indexed image.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="nilearn.image.concat_imgs.html#nilearn.image.concat_imgs" title="nilearn.image.concat_imgs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.image.concat_imgs</span></code></a></dt><dd></dd>
<dt><a class="reference internal" href="nilearn.image.iter_img.html#nilearn.image.iter_img" title="nilearn.image.iter_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.image.iter_img</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Examples</p>
<p>First we concatenate two MNI152 images to create a 4D-image:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nilearn.image</span> <span class="kn">import</span> <span class="n">concat_imgs</span><span class="p">,</span> <span class="n">index_img</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">joint_mni_image</span> <span class="o">=</span> <span class="n">concat_imgs</span><span class="p">([</span><span class="n">datasets</span><span class="o">.</span><span class="n">load_mni152_template</span><span class="p">(),</span>
<span class="gp">... </span>                               <span class="n">datasets</span><span class="o">.</span><span class="n">load_mni152_template</span><span class="p">()])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">joint_mni_image</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(91, 109, 91, 2)</span>
</pre></div>
</div>
<p>We can now select one slice from the last dimension of this 4D-image:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">single_mni_image</span> <span class="o">=</span> <span class="n">index_img</span><span class="p">(</span><span class="n">joint_mni_image</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">single_mni_image</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(91, 109, 91)</span>
</pre></div>
</div>
<p>We can also select multiple frames using the <cite>slice</cite> constructor:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">five_mni_images</span> <span class="o">=</span> <span class="n">concat_imgs</span><span class="p">([</span><span class="n">datasets</span><span class="o">.</span><span class="n">load_mni152_template</span><span class="p">()]</span> <span class="o">*</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">five_mni_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(91, 109, 91, 5)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">first_three_images</span> <span class="o">=</span> <span class="n">index_img</span><span class="p">(</span><span class="n">five_mni_images</span><span class="p">,</span>
<span class="gp">... </span>                               <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">first_three_images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(91, 109, 91, 3)</span>
</pre></div>
</div>
</dd></dl>

<div class="section" id="examples-using-nilearn-image-index-img">
<h2><span class="section-number">8.5.8.1. </span>Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.image.index_img</span></code><a class="headerlink" href="#examples-using-nilearn-image-index-img" title="Permalink to this headline">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="Here we discover how to work with 3D and 4D niimgs."><div class="figure align-default" id="id1">
<img alt="3D and 4D niimgs: handling and visualizing" src="../../_images/sphx_glr_plot_3d_and_4d_niimg_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/plot_3d_and_4d_niimg.html#sphx-glr-auto-examples-plot-3d-and-4d-niimg-py"><span class="std std-ref">3D and 4D niimgs: handling and visualizing</span></a></span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here is a simple tutorial on decoding with nilearn. It reproduces the Haxby 2001 study on a fac..."><div class="figure align-default" id="id2">
<img alt="A introduction tutorial to fMRI decoding" src="../../_images/sphx_glr_plot_decoding_tutorial_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/plot_decoding_tutorial.html#sphx-glr-auto-examples-plot-decoding-tutorial-py"><span class="std std-ref">A introduction tutorial to fMRI decoding</span></a></span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Visualizing a probablistic atlas requires visualizing the different maps that compose it."><div class="figure align-default" id="id3">
<img alt="Visualizing a probablistic atlas: the default mode in the MSDL atlas" src="../../_images/sphx_glr_plot_overlay_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/01_plotting/plot_overlay.html#sphx-glr-auto-examples-01-plotting-plot-overlay-py"><span class="std std-ref">Visualizing a probablistic atlas: the default mode in the MSDL atlas</span></a></span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example uses fast ensembling of regularized models (FREM) to decode a face vs house discri..."><div class="figure align-default" id="id4">
<img alt="Decoding with FREM: face vs house object recognition" src="../../_images/sphx_glr_plot_haxby_frem_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_frem.html#sphx-glr-auto-examples-02-decoding-plot-haxby-frem-py"><span class="std std-ref">Decoding with FREM: face vs house object recognition</span></a></span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example does a simple but efficient decoding on the Haxby dataset: using a feature selecti..."><div class="figure align-default" id="id5">
<img alt="Decoding with ANOVA + SVM: face vs house in the Haxby dataset" src="../../_images/sphx_glr_plot_haxby_anova_svm_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_anova_svm.html#sphx-glr-auto-examples-02-decoding-plot-haxby-anova-svm-py"><span class="std std-ref">Decoding with ANOVA + SVM: face vs house in the Haxby dataset</span></a></span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This is a demo for surface-based searchlight decoding, as described in: Chen, Y., Namburi, P., ..."><div class="figure align-default" id="id6">
<img alt="Cortical surface-based searchlight decoding" src="../../_images/sphx_glr_plot_haxby_searchlight_surface_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_searchlight_surface.html#sphx-glr-auto-examples-02-decoding-plot-haxby-searchlight-surface-py"><span class="std std-ref">Cortical surface-based searchlight decoding</span></a></span><a class="headerlink" href="#id6" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Searchlight analysis requires fitting a classifier a large amount of times. As a result, it is ..."><div class="figure align-default" id="id7">
<img alt="Searchlight analysis of face vs house recognition" src="../../_images/sphx_glr_plot_haxby_searchlight_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_searchlight.html#sphx-glr-auto-examples-02-decoding-plot-haxby-searchlight-py"><span class="std std-ref">Searchlight analysis of face vs house recognition</span></a></span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Full step-by-step example of fitting a GLM to perform a decoding experiment. We use the data fr..."><div class="figure align-default" id="id8">
<img alt="Decoding of a dataset after GLM fit for signal extraction" src="../../_images/sphx_glr_plot_haxby_glm_decoding_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_glm_decoding.html#sphx-glr-auto-examples-02-decoding-plot-haxby-glm-decoding-py"><span class="std std-ref">Decoding of a dataset after GLM fit for signal extraction</span></a></span><a class="headerlink" href="#id8" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we set the number of features selected in an Anova-SVC approach to maximize the cross-vali..."><div class="figure align-default" id="id9">
<img alt="Setting a parameter by cross-validation" src="../../_images/sphx_glr_plot_haxby_grid_search_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_grid_search.html#sphx-glr-auto-examples-02-decoding-plot-haxby-grid-search-py"><span class="std std-ref">Setting a parameter by cross-validation</span></a></span><a class="headerlink" href="#id9" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this script we reproduce the data analysis conducted by Haxby et al. in &quot;Distributed and Ove..."><div class="figure align-default" id="id10">
<img alt="ROI-based decoding analysis in Haxby et al. dataset" src="../../_images/sphx_glr_plot_haxby_full_analysis_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_full_analysis.html#sphx-glr-auto-examples-02-decoding-plot-haxby-full-analysis-py"><span class="std std-ref">ROI-based decoding analysis in Haxby et al. dataset</span></a></span><a class="headerlink" href="#id10" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we compare different classifiers on a visual object recognition decoding task."><div class="figure align-default" id="id11">
<img alt="Different classifiers in decoding the Haxby dataset" src="../../_images/sphx_glr_plot_haxby_different_estimators_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_different_estimators.html#sphx-glr-auto-examples-02-decoding-plot-haxby-different-estimators-py"><span class="std std-ref">Different classifiers in decoding the Haxby dataset</span></a></span><a class="headerlink" href="#id11" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use nilearn.regions.RegionExtractor to extract spatially constrained ..."><div class="figure align-default" id="id12">
<img alt="Regions extraction using Dictionary Learning and functional connectomes" src="../../_images/sphx_glr_plot_extract_regions_dictlearning_maps_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html#sphx-glr-auto-examples-03-connectivity-plot-extract-regions-dictlearning-maps-py"><span class="std std-ref">Regions extraction using Dictionary Learning and functional connectomes</span></a></span><a class="headerlink" href="#id12" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We use spatially-constrained Ward-clustering, KMeans, and Recursive Neighbor Agglomeration (ReN..."><div class="figure align-default" id="id13">
<img alt="Clustering methods to learn a brain parcellation from fMRI" src="../../_images/sphx_glr_plot_data_driven_parcellations_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_data_driven_parcellations.html#sphx-glr-auto-examples-03-connectivity-plot-data-driven-parcellations-py"><span class="std std-ref">Clustering methods to learn a brain parcellation from fMRI</span></a></span><a class="headerlink" href="#id13" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This simple example shows how to extract regions from Smith atlas resting state networks."><div class="figure align-default" id="id14">
<img alt="Regions Extraction of Default Mode Networks using Smith Atlas" src="../../_images/sphx_glr_plot_extract_rois_smith_atlas_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_extract_rois_smith_atlas.html#sphx-glr-auto-examples-06-manipulating-images-plot-extract-rois-smith-atlas-py"><span class="std std-ref">Regions Extraction of Default Mode Networks using Smith Atlas</span></a></span><a class="headerlink" href="#id14" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here is a simple example of automatic mask computation using the nifti masker. The mask is comp..."><div class="figure align-default" id="id15">
<img alt="Simple example of NiftiMasker use" src="../../_images/sphx_glr_plot_nifti_simple_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_nifti_simple.html#sphx-glr-auto-examples-06-manipulating-images-plot-nifti-simple-py"><span class="std std-ref">Simple example of NiftiMasker use</span></a></span><a class="headerlink" href="#id15" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, the Nifti masker is used to automatically compute a mask."><div class="figure align-default" id="id16">
<img alt="Understanding NiftiMasker and mask computation" src="../../_images/sphx_glr_plot_mask_computation_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_mask_computation.html#sphx-glr-auto-examples-06-manipulating-images-plot-mask-computation-py"><span class="std std-ref">Understanding NiftiMasker and mask computation</span></a></span><a class="headerlink" href="#id16" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip=" This example is meant to demonstrate nilearn as a low-level tools used to combine feature extr..."><div class="figure align-default" id="id17">
<img alt="Multivariate decompositions: Independent component analysis of fMRI" src="../../_images/sphx_glr_plot_ica_resting_state_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/07_advanced/plot_ica_resting_state.html#sphx-glr-auto-examples-07-advanced-plot-ica-resting-state-py"><span class="std std-ref">Multivariate decompositions: Independent component analysis of fMRI</span></a></span><a class="headerlink" href="#id17" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This tutorial opens the box of decoding pipelines to bridge integrated functionalities provided..."><div class="figure align-default" id="id18">
<img alt="Advanced decoding using scikit learn" src="../../_images/sphx_glr_plot_advanced_decoding_scikit_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/07_advanced/plot_advanced_decoding_scikit.html#sphx-glr-auto-examples-07-advanced-plot-advanced-decoding-scikit-py"><span class="std std-ref">Advanced decoding using scikit learn</span></a></span><a class="headerlink" href="#id18" title="Permalink to this image">¶</a></p>
</div>
</div><div style='clear:both'></div></div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">8.5.8. nilearn.image.index_img</a><ul>
<li><a class="reference internal" href="#examples-using-nilearn-image-index-img">8.5.8.1. Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.image.index_img</span></code></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="nilearn.image.high_variance_confounds.html"
                        title="previous chapter"><span class="section-number">8.5.7. </span>nilearn.image.high_variance_confounds</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="nilearn.image.iter_img.html"
                        title="next chapter"><span class="section-number">8.5.9. </span>nilearn.image.iter_img</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
            &copy; The nilearn developers 2010-2020.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 3.4.2.
        <span style="padding-left: 5ex;">
          <a href="../../_sources/modules/generated/nilearn.image.index_img.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>