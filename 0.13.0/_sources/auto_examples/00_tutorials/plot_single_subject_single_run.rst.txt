
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/00_tutorials/plot_single_subject_single_run.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_00_tutorials_plot_single_subject_single_run.py>`
        to download the full example code or to run this example in your browser via Binder.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_00_tutorials_plot_single_subject_single_run.py:


Intro to GLM Analysis: a single-run, single-subject fMRI dataset
================================================================

In this tutorial, we use a General Linear Model (:term:`GLM`) to compare the
:term:`fMRI` signal during periods of auditory stimulation
versus periods of rest.

.. warning::

    The analysis described here is performed in the native space,
    directly on the original :term:`EPI` scans
    without any spatial or temporal preprocessing.
    More sensitive results would likely be obtained on the corrected,
    spatially normalized and smoothed images.

.. GENERATED FROM PYTHON SOURCE LINES 18-26

Retrieving the data
-------------------

.. note:: In this tutorial, we load the data using a data downloading
          function. To input your own data, you will need to provide
          a list of paths to your own files in the ``subject_data`` variable.
          These should abide to the Brain Imaging Data Structure
          (:term:`BIDS`) organization.

.. GENERATED FROM PYTHON SOURCE LINES 26-31

.. code-block:: Python


    from nilearn.datasets import fetch_spm_auditory

    subject_data = fetch_spm_auditory()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [fetch_spm_auditory] Dataset found in /home/remi-gau/nilearn_data/spm_auditory




.. GENERATED FROM PYTHON SOURCE LINES 32-34

Inspecting the dataset
----------------------

.. GENERATED FROM PYTHON SOURCE LINES 36-37

print paths of func image

.. GENERATED FROM PYTHON SOURCE LINES 37-39

.. code-block:: Python

    subject_data.func[0]





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    '/home/remi-gau/nilearn_data/spm_auditory/MoAEpilot/sub-01/func/sub-01_task-auditory_bold.nii'



.. GENERATED FROM PYTHON SOURCE LINES 40-41

We can display the mean functional image and the subject's anatomy:

.. GENERATED FROM PYTHON SOURCE LINES 41-53

.. code-block:: Python

    from nilearn.image import mean_img
    from nilearn.plotting import plot_anat, plot_img, plot_stat_map, show

    fmri_img = subject_data.func
    mean_img = mean_img(subject_data.func[0])
    plot_img(mean_img, cbar_tick_format="%i")

    plot_anat(subject_data.anat, cbar_tick_format="%i")

    show()





.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_001.png
         :alt: plot single subject single run
         :srcset: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_001.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_002.png
         :alt: plot single subject single run
         :srcset: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_002.png
         :class: sphx-glr-multi-img





.. GENERATED FROM PYTHON SOURCE LINES 54-61

Specifying the experimental paradigm
------------------------------------

We must now provide a description of the experiment, that is,
define the timing of the auditory stimulation and rest periods.
This is typically provided in an events.tsv file.
The path of this file is provided in the dataset.

.. GENERATED FROM PYTHON SOURCE LINES 61-67

.. code-block:: Python

    import pandas as pd

    events = pd.read_table(subject_data.events)
    events







.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>onset</th>
          <th>duration</th>
          <th>trial_type</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>42</td>
          <td>42</td>
          <td>listening</td>
        </tr>
        <tr>
          <th>1</th>
          <td>126</td>
          <td>42</td>
          <td>listening</td>
        </tr>
        <tr>
          <th>2</th>
          <td>210</td>
          <td>42</td>
          <td>listening</td>
        </tr>
        <tr>
          <th>3</th>
          <td>294</td>
          <td>42</td>
          <td>listening</td>
        </tr>
        <tr>
          <th>4</th>
          <td>378</td>
          <td>42</td>
          <td>listening</td>
        </tr>
        <tr>
          <th>5</th>
          <td>462</td>
          <td>42</td>
          <td>listening</td>
        </tr>
        <tr>
          <th>6</th>
          <td>546</td>
          <td>42</td>
          <td>listening</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 68-74

Performing the :term:`GLM` analysis
-----------------------------------

It is now time to create and estimate a ``FirstLevelModel`` object,
that will generate the *design matrix*
using the information provided by the ``events`` object.

.. GENERATED FROM PYTHON SOURCE LINES 74-77

.. code-block:: Python


    from nilearn.glm.first_level import FirstLevelModel








.. GENERATED FROM PYTHON SOURCE LINES 78-92

Parameters of the first-level model

* ``t_r=7(s)`` is the time of repetition of acquisitions
* ``noise_model='ar1'`` specifies the noise covariance model:
  a lag-1 dependence
* ``standardize=False`` means that we do not want
  to rescale the time series to mean 0, variance 1
* ``hrf_model='spm'`` means that we rely
  on the :term:`SPM` "canonical hrf" model
  (without time or dispersion derivatives)
* ``drift_model='cosine'`` means that we model the signal drifts
  as slow oscillating time functions
* ``high_pass=0.01`` (Hz) defines the cutoff frequency
  (inverse of the time period).

.. GENERATED FROM PYTHON SOURCE LINES 92-102

.. code-block:: Python

    fmri_glm = FirstLevelModel(
        t_r=subject_data.t_r,
        noise_model="ar1",
        standardize=False,
        hrf_model="spm",
        drift_model="cosine",
        high_pass=0.01,
        verbose=1,
    )








.. GENERATED FROM PYTHON SOURCE LINES 103-104

Now that we have specified the model, we can run it on the :term:`fMRI` image

.. GENERATED FROM PYTHON SOURCE LINES 104-106

.. code-block:: Python

    fmri_glm = fmri_glm.fit(fmri_img, events)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [FirstLevelModel.fit] Loading data from '/home/remi-gau/nilearn_data/spm_auditory/MoAEpilot/sub-01/func/sub-01_task-auditory_bold.nii'
    [FirstLevelModel.fit] Computing mask
    [FirstLevelModel.fit] Resampling mask
    [FirstLevelModel.fit] Finished fit
    [FirstLevelModel.fit] Computing run 1 out of 1 runs (go take a coffee, a big one).
    [FirstLevelModel.fit] Performing mask computation.
    [FirstLevelModel.fit] Loading data from <nibabel.nifti1.Nifti1Image object at 0x75879149cfd0>
    [FirstLevelModel.fit] Extracting region signals
    [FirstLevelModel.fit] Cleaning extracted signals
    [FirstLevelModel.fit] Masking took 0 seconds.
    [FirstLevelModel.fit] Performing GLM computation.
    [FirstLevelModel.fit] GLM took 0 seconds.
    [FirstLevelModel.fit] Computation of 1 runs done in 0 seconds.




.. GENERATED FROM PYTHON SOURCE LINES 107-109

One can inspect the design matrix (rows represent time, and
columns contain the predictors).

.. GENERATED FROM PYTHON SOURCE LINES 109-111

.. code-block:: Python

    design_matrix = fmri_glm.design_matrices_[0]








.. GENERATED FROM PYTHON SOURCE LINES 112-114

Formally, we have taken the first design matrix, because the model is
implictily meant to for multiple runs.

.. GENERATED FROM PYTHON SOURCE LINES 114-120

.. code-block:: Python

    from nilearn.plotting import plot_design_matrix

    plot_design_matrix(design_matrix)

    show()




.. image-sg:: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_003.png
   :alt: plot single subject single run
   :srcset: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 121-123

Save the design matrix image to disk
first create a directory where you want to write the images

.. GENERATED FROM PYTHON SOURCE LINES 123-131

.. code-block:: Python

    from pathlib import Path

    output_dir = Path.cwd() / "results" / "plot_single_subject_single_run"
    output_dir.mkdir(exist_ok=True, parents=True)
    print(f"Output will be saved to: {output_dir}")

    plot_design_matrix(design_matrix, output_file=output_dir / "design_matrix.png")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Output will be saved to: /home/remi-gau/github/nilearn/nilearn/examples/00_tutorials/results/plot_single_subject_single_run




.. GENERATED FROM PYTHON SOURCE LINES 132-135

The first column contains the expected response profile of regions which are
sensitive to the auditory stimulation.
Let's plot this first column

.. GENERATED FROM PYTHON SOURCE LINES 135-144

.. code-block:: Python

    import matplotlib.pyplot as plt

    plt.plot(design_matrix["listening"])
    plt.xlabel("scan")
    plt.title("Expected Auditory Response")

    show()





.. image-sg:: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_004.png
   :alt: Expected Auditory Response
   :srcset: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_004.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 145-162

Detecting voxels with significant effects
-----------------------------------------

To access the estimated coefficients (Betas of the :term:`GLM` model),
we created :term:`contrast` with a single '1' in each of the columns:
The role of the :term:`contrast` is to select some columns of the model
--and potentially weight them-- to study the associated statistics.
So in a nutshell, a :term:`contrast`
is a weighted combination of the estimated effects.
Here we can define canonical contrasts that just consider
the effect of the stimulation in isolation.

.. note::

      Here the baseline is implicit, so passing a value of 1
      for the first column will give contrast for: ``listening > rest``


.. GENERATED FROM PYTHON SOURCE LINES 162-169

.. code-block:: Python


    import numpy as np

    n_regressors = design_matrix.shape[1]
    activation = np.zeros(n_regressors)
    activation[0] = 1








.. GENERATED FROM PYTHON SOURCE LINES 170-172

Let's look at it: plot the coefficients of the :term:`contrast`,
indexed by the names of the columns of the design matrix.

.. GENERATED FROM PYTHON SOURCE LINES 172-177

.. code-block:: Python


    from nilearn.plotting import plot_contrast_matrix

    plot_contrast_matrix(contrast_def=activation, design_matrix=design_matrix)




.. image-sg:: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_005.png
   :alt: plot single subject single run
   :srcset: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_005.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <Axes: label='conditions'>



.. GENERATED FROM PYTHON SOURCE LINES 178-181

Below, we compute the :term:`'estimated effect'<Parameter Estimate>`.
It is in :term:`BOLD` signal unit, but has no statistical guarantees,
because it does not take into account the associated variance.

.. GENERATED FROM PYTHON SOURCE LINES 181-184

.. code-block:: Python


    eff_map = fmri_glm.compute_contrast(activation, output_type="effect_size")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [FirstLevelModel.compute_contrast] Computing image from signals




.. GENERATED FROM PYTHON SOURCE LINES 185-189

In order to get statistical significance, we form a t-statistic, and
directly convert it into z-scale. The z-scale means that the values
are scaled to match a standard Gaussian distribution (mean=0,
variance=1), across voxels, if there were no effects in the data.

.. GENERATED FROM PYTHON SOURCE LINES 189-193

.. code-block:: Python


    z_map = fmri_glm.compute_contrast(activation, output_type="z_score")






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [FirstLevelModel.compute_contrast] Computing image from signals




.. GENERATED FROM PYTHON SOURCE LINES 194-202

Plot thresholded z scores map
-----------------------------

We display it on top of the average functional image of the series
(could be the anatomical image of the subject).
We use arbitrarily a threshold of 3.0 in z-scale.
We'll see later how to use corrected thresholds.
We will show 3 axial views, with display_mode='z' and cut_coords=3.

.. GENERATED FROM PYTHON SOURCE LINES 202-217

.. code-block:: Python

    plotting_config = {
        "bg_img": mean_img,
        "display_mode": "z",
        "cut_coords": 3,
        "black_bg": True,
    }
    plot_stat_map(
        z_map,
        threshold=3,
        title="listening > rest (|Z|>3)",
        figure=plt.figure(figsize=(10, 4)),
        **plotting_config,
    )
    show()




.. image-sg:: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_006.png
   :alt: plot single subject single run
   :srcset: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_006.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 218-225

.. note::

  Notice how the visualizations above shows both 'activated' voxels
  with Z > 3,
  as well as 'deactivated' voxels with Z < -3.
  In the rest of this example we will show only the activate voxels
  by using one-sided tests.

.. GENERATED FROM PYTHON SOURCE LINES 227-238

Statistical significance testing
--------------------------------

One should worry about the statistical validity of the procedure:
here we used an arbitrary
threshold of 3.0 but the threshold should provide some guarantees on
the risk of false detections (aka type-1 errors in statistics).
One suggestion is to control the false positive rate
(:term:`fpr<FPR correction>`, denoted by alpha)
at a certain level, e.g. 0.001: this means that there is 0.1% chance
of declaring an inactive :term:`voxel`, active.

.. GENERATED FROM PYTHON SOURCE LINES 238-260

.. code-block:: Python


    from nilearn.glm import threshold_stats_img

    clean_map, threshold = threshold_stats_img(
        z_map,
        alpha=0.001,
        height_control="fpr",
        two_sided=False,  # using a one-sided test
    )
    # Let's use a sequential colormap as we will only display positive values.
    plotting_config["cmap"] = "inferno"
    plot_stat_map(
        clean_map,
        threshold=threshold,
        title=(
            f"listening > rest (Uncorrected p<0.001; threshold: {threshold:.3f})"
        ),
        figure=plt.figure(figsize=(10, 4)),
        **plotting_config,
    )
    show()




.. image-sg:: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_007.png
   :alt: plot single subject single run
   :srcset: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_007.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 261-266

The problem is that with this you expect 0.001 * n_voxels to show up
while they're not active --- tens to hundreds of voxels. A more
conservative solution is to control the family wise error rate,
i.e. the probability of making only one false detection, say at
5%. For that we use the so-called Bonferroni correction.

.. GENERATED FROM PYTHON SOURCE LINES 266-282

.. code-block:: Python


    clean_map, threshold = threshold_stats_img(
        z_map, alpha=0.05, height_control="bonferroni", two_sided=False
    )
    plot_stat_map(
        clean_map,
        threshold=threshold,
        title=(
            "listening > rest (p<0.05 Bonferroni-corrected, "
            f"threshold: {threshold:.3f})"
        ),
        figure=plt.figure(figsize=(10, 4)),
        **plotting_config,
    )
    show()




.. image-sg:: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_008.png
   :alt: plot single subject single run
   :srcset: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_008.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 283-287

This is quite conservative indeed!  A popular alternative is to
control the expected proportion of
false discoveries among detections. This is called the False
discovery rate.

.. GENERATED FROM PYTHON SOURCE LINES 287-302

.. code-block:: Python


    clean_map, threshold = threshold_stats_img(
        z_map, alpha=0.05, height_control="fdr", two_sided=False
    )
    plot_stat_map(
        clean_map,
        threshold=threshold,
        title=(
            f"listening > rest (p<0.05 FDR-corrected; threshold: {threshold:.3f})"
        ),
        figure=plt.figure(figsize=(10, 4)),
        **plotting_config,
    )
    show()




.. image-sg:: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_009.png
   :alt: plot single subject single run
   :srcset: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_009.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 303-308

Finally people like to discard isolated voxels (aka "small
clusters") from these images. It is possible to generate a
thresholded map with small clusters removed by providing a
cluster_threshold argument. Here clusters smaller than 10 voxels
will be discarded.

.. GENERATED FROM PYTHON SOURCE LINES 308-330

.. code-block:: Python


    clean_map, threshold = threshold_stats_img(
        z_map,
        alpha=0.05,
        height_control="fdr",
        cluster_threshold=10,
        two_sided=False,
    )
    plot_stat_map(
        clean_map,
        threshold=threshold,
        title=(
            "listening > rest "
            f"(p<0.05 FDR-corrected; threshold: {threshold:.3f}; "
            "clusters > 10 voxels)"
        ),
        figure=plt.figure(figsize=(10, 4)),
        **plotting_config,
    )
    show()





.. image-sg:: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_010.png
   :alt: plot single subject single run
   :srcset: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_010.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 331-332

We can save the effect and zscore maps to the disk.

.. GENERATED FROM PYTHON SOURCE LINES 332-335

.. code-block:: Python

    z_map.to_filename(output_dir / "listening_gt_rest_z_map.nii.gz")
    eff_map.to_filename(output_dir / "listening_gt_rest_eff_map.nii.gz")








.. GENERATED FROM PYTHON SOURCE LINES 336-347

We can furthermore extract and report the found positions in a table.

.. seealso::

    This function does not report any named anatomical location
    for the clusters.
    To get the names of the location of the clusters
    according to one or several atlases,
    we recommend using
    the `atlasreader package <https://github.com/miykael/atlasreader>`_.


.. GENERATED FROM PYTHON SOURCE LINES 347-354

.. code-block:: Python

    from nilearn.reporting import get_clusters_table

    table = get_clusters_table(
        z_map, stat_threshold=threshold, cluster_threshold=20
    )
    table






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>Cluster ID</th>
          <th>X</th>
          <th>Y</th>
          <th>Z</th>
          <th>Peak Stat</th>
          <th>Cluster Size (mm3)</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>1</td>
          <td>-60.0</td>
          <td>-6.0</td>
          <td>42.0</td>
          <td>9.341729</td>
          <td>3888</td>
        </tr>
        <tr>
          <th>1</th>
          <td>1a</td>
          <td>-51.0</td>
          <td>-12.0</td>
          <td>39.0</td>
          <td>7.952826</td>
          <td></td>
        </tr>
        <tr>
          <th>2</th>
          <td>1b</td>
          <td>-63.0</td>
          <td>0.0</td>
          <td>42.0</td>
          <td>7.595170</td>
          <td></td>
        </tr>
        <tr>
          <th>3</th>
          <td>1c</td>
          <td>-42.0</td>
          <td>-12.0</td>
          <td>39.0</td>
          <td>7.034967</td>
          <td></td>
        </tr>
        <tr>
          <th>4</th>
          <td>2</td>
          <td>60.0</td>
          <td>0.0</td>
          <td>36.0</td>
          <td>8.738699</td>
          <td>1620</td>
        </tr>
        <tr>
          <th>5</th>
          <td>2a</td>
          <td>45.0</td>
          <td>-12.0</td>
          <td>42.0</td>
          <td>6.850138</td>
          <td></td>
        </tr>
        <tr>
          <th>6</th>
          <td>2b</td>
          <td>69.0</td>
          <td>6.0</td>
          <td>30.0</td>
          <td>4.062676</td>
          <td></td>
        </tr>
        <tr>
          <th>7</th>
          <td>3</td>
          <td>66.0</td>
          <td>15.0</td>
          <td>27.0</td>
          <td>7.947193</td>
          <td>837</td>
        </tr>
        <tr>
          <th>8</th>
          <td>3a</td>
          <td>51.0</td>
          <td>3.0</td>
          <td>30.0</td>
          <td>6.676518</td>
          <td></td>
        </tr>
        <tr>
          <th>9</th>
          <td>4</td>
          <td>36.0</td>
          <td>-3.0</td>
          <td>15.0</td>
          <td>7.945328</td>
          <td>1161</td>
        </tr>
        <tr>
          <th>10</th>
          <td>4a</td>
          <td>39.0</td>
          <td>-12.0</td>
          <td>12.0</td>
          <td>5.511866</td>
          <td></td>
        </tr>
        <tr>
          <th>11</th>
          <td>5</td>
          <td>51.0</td>
          <td>30.0</td>
          <td>27.0</td>
          <td>6.825038</td>
          <td>675</td>
        </tr>
        <tr>
          <th>12</th>
          <td>5a</td>
          <td>48.0</td>
          <td>21.0</td>
          <td>27.0</td>
          <td>6.763636</td>
          <td></td>
        </tr>
        <tr>
          <th>13</th>
          <td>5b</td>
          <td>57.0</td>
          <td>39.0</td>
          <td>27.0</td>
          <td>5.631803</td>
          <td></td>
        </tr>
        <tr>
          <th>14</th>
          <td>6</td>
          <td>45.0</td>
          <td>-18.0</td>
          <td>57.0</td>
          <td>5.901255</td>
          <td>972</td>
        </tr>
        <tr>
          <th>15</th>
          <td>6a</td>
          <td>39.0</td>
          <td>-15.0</td>
          <td>63.0</td>
          <td>5.213951</td>
          <td></td>
        </tr>
        <tr>
          <th>16</th>
          <td>6b</td>
          <td>45.0</td>
          <td>-21.0</td>
          <td>63.0</td>
          <td>4.108046</td>
          <td></td>
        </tr>
        <tr>
          <th>17</th>
          <td>6c</td>
          <td>36.0</td>
          <td>-9.0</td>
          <td>66.0</td>
          <td>4.090935</td>
          <td></td>
        </tr>
        <tr>
          <th>18</th>
          <td>7</td>
          <td>-15.0</td>
          <td>-60.0</td>
          <td>66.0</td>
          <td>5.005065</td>
          <td>864</td>
        </tr>
        <tr>
          <th>19</th>
          <td>7a</td>
          <td>-15.0</td>
          <td>-60.0</td>
          <td>57.0</td>
          <td>4.546246</td>
          <td></td>
        </tr>
        <tr>
          <th>20</th>
          <td>7b</td>
          <td>-3.0</td>
          <td>-60.0</td>
          <td>57.0</td>
          <td>4.463430</td>
          <td></td>
        </tr>
        <tr>
          <th>21</th>
          <td>8</td>
          <td>-12.0</td>
          <td>-69.0</td>
          <td>51.0</td>
          <td>4.269133</td>
          <td>540</td>
        </tr>
        <tr>
          <th>22</th>
          <td>8a</td>
          <td>-18.0</td>
          <td>-63.0</td>
          <td>48.0</td>
          <td>4.081260</td>
          <td></td>
        </tr>
        <tr>
          <th>23</th>
          <td>8b</td>
          <td>-6.0</td>
          <td>-69.0</td>
          <td>51.0</td>
          <td>3.530991</td>
          <td></td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 355-356

This table can be saved for future use.

.. GENERATED FROM PYTHON SOURCE LINES 356-359

.. code-block:: Python


    table.to_csv(output_dir / "table.csv")








.. GENERATED FROM PYTHON SOURCE LINES 360-376

Performing an F-test
--------------------

"listening > rest" is a typical t test: condition versus baseline.
Another popular type of test is an F test in which
one seeks whether a certain combination of conditions
(possibly two-, three- or higher-dimensional)
explains a significant proportion of the signal.
Here one might for instance test which voxels are well
explained by the combination of more active or less active than rest.

.. note::

   As opposed to t-tests, the beta images produced by of F-tests
   only contain positive values.


.. GENERATED FROM PYTHON SOURCE LINES 378-381

Specify the :term:`contrast` and compute the corresponding map.
Actually, the :term:`contrast` specification is done exactly the same way
as for t-contrasts.

.. GENERATED FROM PYTHON SOURCE LINES 381-388

.. code-block:: Python


    z_map = fmri_glm.compute_contrast(
        activation,
        output_type="z_score",
        stat_type="F",  # set stat_type to 'F' to perform an F test
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [FirstLevelModel.compute_contrast] Computing image from signals




.. GENERATED FROM PYTHON SOURCE LINES 389-391

Note that the statistic has been converted to a z-variable,
which makes it easier to represent it.

.. GENERATED FROM PYTHON SOURCE LINES 391-407

.. code-block:: Python


    clean_map, threshold = threshold_stats_img(
        z_map,
        alpha=0.05,
        height_control="fdr",
        cluster_threshold=10,
        two_sided=False,
    )
    plot_stat_map(
        clean_map,
        threshold=threshold,
        title="Effects of interest (fdr=0.05), clusters > 10 voxels",
        figure=plt.figure(figsize=(10, 4)),
        **plotting_config,
    )
    show()



.. image-sg:: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_011.png
   :alt: plot single subject single run
   :srcset: /auto_examples/00_tutorials/images/sphx_glr_plot_single_subject_single_run_011.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 17.868 seconds)

**Estimated memory usage:**  682 MB


.. _sphx_glr_download_auto_examples_00_tutorials_plot_single_subject_single_run.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/nilearn/nilearn/0.13.0?urlpath=lab/tree/notebooks/auto_examples/00_tutorials/plot_single_subject_single_run.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_single_subject_single_run.ipynb <plot_single_subject_single_run.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_single_subject_single_run.py <plot_single_subject_single_run.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_single_subject_single_run.zip <plot_single_subject_single_run.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
