
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/03_connectivity/plot_multi_subject_connectome.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_03_connectivity_plot_multi_subject_connectome.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_03_connectivity_plot_multi_subject_connectome.py:


Group Sparse inverse covariance for multi-subject connectome
============================================================

This example shows how to estimate a connectome on a group of subjects
using the group sparse inverse covariance estimate.

.. include:: ../../../examples/masker_note.rst

.. GENERATED FROM PYTHON SOURCE LINES 11-46

.. code-block:: default

    import numpy as np
    from nilearn import plotting

    n_subjects = 4  # subjects to consider for group-sparse covariance (max: 40)


    def plot_matrices(cov, prec, title, labels):
        """Plot covariance and precision matrices, for a given processing."""
        prec = prec.copy()  # avoid side effects

        # Put zeros on the diagonal, for graph clarity.
        size = prec.shape[0]
        prec[list(range(size)), list(range(size))] = 0
        span = max(abs(prec.min()), abs(prec.max()))

        # Display covariance matrix
        plotting.plot_matrix(
            cov,
            cmap=plotting.cm.bwr,
            vmin=-1,
            vmax=1,
            title=f"{title} / covariance",
            labels=labels,
        )
        # Display precision matrix
        plotting.plot_matrix(
            prec,
            cmap=plotting.cm.bwr,
            vmin=-span,
            vmax=span,
            title=f"{title} / precision",
            labels=labels,
        )









.. GENERATED FROM PYTHON SOURCE LINES 47-49

Fetching datasets
------------------

.. GENERATED FROM PYTHON SOURCE LINES 49-60

.. code-block:: default

    from nilearn import datasets

    msdl_atlas_dataset = datasets.fetch_atlas_msdl()
    rest_dataset = datasets.fetch_development_fmri(n_subjects=n_subjects)

    # print basic information on the dataset
    print(
        f"First subject functional nifti image (4D) is at: {rest_dataset.func[0]}"
    )






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    First subject functional nifti image (4D) is at: /home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz




.. GENERATED FROM PYTHON SOURCE LINES 61-63

Extracting region signals
-------------------------

.. GENERATED FROM PYTHON SOURCE LINES 63-92

.. code-block:: default

    from nilearn.maskers import NiftiMapsMasker

    masker = NiftiMapsMasker(
        msdl_atlas_dataset.maps,
        resampling_target="maps",
        detrend=True,
        high_variance_confounds=True,
        low_pass=None,
        high_pass=0.01,
        t_r=2,
        standardize="zscore_sample",
        memory="nilearn_cache",
        memory_level=1,
        verbose=2,
    )
    masker.fit()

    subject_time_series = []
    func_filenames = rest_dataset.func
    confound_filenames = rest_dataset.confounds
    for func_filename, confound_filename in zip(
        func_filenames, confound_filenames
    ):
        print(f"Processing file {func_filename}")

        region_ts = masker.transform(func_filename, confounds=confound_filename)
        subject_time_series.append(region_ts)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [NiftiMapsMasker.fit] loading regions from /home/yasmin/nilearn/nilearn_data/msdl_atlas/MSDL_rois/msdl_rois.nii
    Processing file /home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz
    ________________________________________________________________________________
    [Memory] Calling nilearn.image.image.high_variance_confounds...
    high_variance_confounds('/home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz')
    __________________________________________high_variance_confounds - 1.0s, 0.0min
    ________________________________________________________________________________
    [Memory] Calling nilearn.maskers.base_masker._filter_and_extract...
    _filter_and_extract('/home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',
    <nilearn.maskers.nifti_maps_masker._ExtractionFunctor object at 0x7fb57e1ff070>, { 'allow_overlap': True,
      'clean_kwargs': {},
      'detrend': True,
      'dtype': None,
      'high_pass': 0.01,
      'high_variance_confounds': True,
      'low_pass': None,
      'maps_img': '/home/yasmin/nilearn/nilearn_data/msdl_atlas/MSDL_rois/msdl_rois.nii',
      'mask_img': None,
      'reports': True,
      'smoothing_fwhm': None,
      'standardize': 'zscore_sample',
      'standardize_confounds': True,
      't_r': 2,
      'target_affine': array([[   4.,    0.,    0.,  -78.],
           [   0.,    4.,    0., -111.],
           [   0.,    0.,    4.,  -51.],
           [   0.,    0.,    0.,    1.]]),
      'target_shape': (40, 48, 35)}, confounds=[ array([[-0.174325, ..., -0.048779],
           ...,
           [-0.044073, ...,  0.155444]]),
      '/home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_desc-reducedConfounds_regressors.tsv'], sample_mask=None, dtype=None, memory=Memory(location=nilearn_cache/joblib), memory_level=1, verbose=2)
    [NiftiMapsMasker.transform_single_imgs] Loading data from /home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz
    [NiftiMapsMasker.transform_single_imgs] Resampling images
    [NiftiMapsMasker.transform_single_imgs] Extracting region signals
    [NiftiMapsMasker.transform_single_imgs] Cleaning extracted signals
    /home/yasmin/miniconda3/envs/nilearn-dev/lib/python3.10/site-packages/joblib/memory.py:349: FutureWarning:

    The default strategy for standardize is currently 'zscore' which incorrectly uses population std to calculate sample zscores. The new strategy 'zscore_sample' corrects this behavior by using the sample std. In release 0.13, the default strategy will be replaced by the new strategy and the 'zscore' option will be removed. Please use 'zscore_sample' instead.

    _______________________________________________filter_and_extract - 6.7s, 0.1min
    Processing file /home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar001_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz
    ________________________________________________________________________________
    [Memory] Calling nilearn.image.image.high_variance_confounds...
    high_variance_confounds('/home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar001_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz')
    __________________________________________high_variance_confounds - 0.9s, 0.0min
    ________________________________________________________________________________
    [Memory] Calling nilearn.maskers.base_masker._filter_and_extract...
    _filter_and_extract('/home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar001_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',
    <nilearn.maskers.nifti_maps_masker._ExtractionFunctor object at 0x7fb5792958a0>, { 'allow_overlap': True,
      'clean_kwargs': {},
      'detrend': True,
      'dtype': None,
      'high_pass': 0.01,
      'high_variance_confounds': True,
      'low_pass': None,
      'maps_img': '/home/yasmin/nilearn/nilearn_data/msdl_atlas/MSDL_rois/msdl_rois.nii',
      'mask_img': None,
      'reports': True,
      'smoothing_fwhm': None,
      'standardize': 'zscore_sample',
      'standardize_confounds': True,
      't_r': 2,
      'target_affine': array([[   4.,    0.,    0.,  -78.],
           [   0.,    4.,    0., -111.],
           [   0.,    0.,    4.,  -51.],
           [   0.,    0.,    0.,    1.]]),
      'target_shape': (40, 48, 35)}, confounds=[ array([[-0.151677, ..., -0.057023],
           ...,
           [-0.206928, ...,  0.102714]]),
      '/home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar001_task-pixar_desc-reducedConfounds_regressors.tsv'], sample_mask=None, dtype=None, memory=Memory(location=nilearn_cache/joblib), memory_level=1, verbose=2)
    [NiftiMapsMasker.transform_single_imgs] Loading data from /home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar001_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz
    [NiftiMapsMasker.transform_single_imgs] Resampling images
    [NiftiMapsMasker.transform_single_imgs] Extracting region signals
    [NiftiMapsMasker.transform_single_imgs] Cleaning extracted signals
    /home/yasmin/miniconda3/envs/nilearn-dev/lib/python3.10/site-packages/joblib/memory.py:349: FutureWarning:

    The default strategy for standardize is currently 'zscore' which incorrectly uses population std to calculate sample zscores. The new strategy 'zscore_sample' corrects this behavior by using the sample std. In release 0.13, the default strategy will be replaced by the new strategy and the 'zscore' option will be removed. Please use 'zscore_sample' instead.

    _______________________________________________filter_and_extract - 6.7s, 0.1min
    Processing file /home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar002_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz
    ________________________________________________________________________________
    [Memory] Calling nilearn.image.image.high_variance_confounds...
    high_variance_confounds('/home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar002_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz')
    __________________________________________high_variance_confounds - 0.9s, 0.0min
    ________________________________________________________________________________
    [Memory] Calling nilearn.maskers.base_masker._filter_and_extract...
    _filter_and_extract('/home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar002_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',
    <nilearn.maskers.nifti_maps_masker._ExtractionFunctor object at 0x7fb5792977c0>, { 'allow_overlap': True,
      'clean_kwargs': {},
      'detrend': True,
      'dtype': None,
      'high_pass': 0.01,
      'high_variance_confounds': True,
      'low_pass': None,
      'maps_img': '/home/yasmin/nilearn/nilearn_data/msdl_atlas/MSDL_rois/msdl_rois.nii',
      'mask_img': None,
      'reports': True,
      'smoothing_fwhm': None,
      'standardize': 'zscore_sample',
      'standardize_confounds': True,
      't_r': 2,
      'target_affine': array([[   4.,    0.,    0.,  -78.],
           [   0.,    4.,    0., -111.],
           [   0.,    0.,    4.,  -51.],
           [   0.,    0.,    0.,    1.]]),
      'target_shape': (40, 48, 35)}, confounds=[ array([[ 0.127944, ..., -0.087084],
           ...,
           [-0.015679, ..., -0.02587 ]]),
      '/home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar002_task-pixar_desc-reducedConfounds_regressors.tsv'], sample_mask=None, dtype=None, memory=Memory(location=nilearn_cache/joblib), memory_level=1, verbose=2)
    [NiftiMapsMasker.transform_single_imgs] Loading data from /home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar002_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz
    [NiftiMapsMasker.transform_single_imgs] Resampling images
    [NiftiMapsMasker.transform_single_imgs] Extracting region signals
    [NiftiMapsMasker.transform_single_imgs] Cleaning extracted signals
    /home/yasmin/miniconda3/envs/nilearn-dev/lib/python3.10/site-packages/joblib/memory.py:349: FutureWarning:

    The default strategy for standardize is currently 'zscore' which incorrectly uses population std to calculate sample zscores. The new strategy 'zscore_sample' corrects this behavior by using the sample std. In release 0.13, the default strategy will be replaced by the new strategy and the 'zscore' option will be removed. Please use 'zscore_sample' instead.

    _______________________________________________filter_and_extract - 6.5s, 0.1min
    Processing file /home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar003_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz
    ________________________________________________________________________________
    [Memory] Calling nilearn.image.image.high_variance_confounds...
    high_variance_confounds('/home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar003_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz')
    __________________________________________high_variance_confounds - 0.9s, 0.0min
    ________________________________________________________________________________
    [Memory] Calling nilearn.maskers.base_masker._filter_and_extract...
    _filter_and_extract('/home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar003_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',
    <nilearn.maskers.nifti_maps_masker._ExtractionFunctor object at 0x7fb579296110>, { 'allow_overlap': True,
      'clean_kwargs': {},
      'detrend': True,
      'dtype': None,
      'high_pass': 0.01,
      'high_variance_confounds': True,
      'low_pass': None,
      'maps_img': '/home/yasmin/nilearn/nilearn_data/msdl_atlas/MSDL_rois/msdl_rois.nii',
      'mask_img': None,
      'reports': True,
      'smoothing_fwhm': None,
      'standardize': 'zscore_sample',
      'standardize_confounds': True,
      't_r': 2,
      'target_affine': array([[   4.,    0.,    0.,  -78.],
           [   0.,    4.,    0., -111.],
           [   0.,    0.,    4.,  -51.],
           [   0.,    0.,    0.,    1.]]),
      'target_shape': (40, 48, 35)}, confounds=[ array([[-0.089762, ..., -0.062316],
           ...,
           [-0.065223, ..., -0.022868]]),
      '/home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar003_task-pixar_desc-reducedConfounds_regressors.tsv'], sample_mask=None, dtype=None, memory=Memory(location=nilearn_cache/joblib), memory_level=1, verbose=2)
    [NiftiMapsMasker.transform_single_imgs] Loading data from /home/yasmin/nilearn/nilearn_data/development_fmri/development_fmri/sub-pixar003_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz
    [NiftiMapsMasker.transform_single_imgs] Resampling images
    [NiftiMapsMasker.transform_single_imgs] Extracting region signals
    [NiftiMapsMasker.transform_single_imgs] Cleaning extracted signals
    /home/yasmin/miniconda3/envs/nilearn-dev/lib/python3.10/site-packages/joblib/memory.py:349: FutureWarning:

    The default strategy for standardize is currently 'zscore' which incorrectly uses population std to calculate sample zscores. The new strategy 'zscore_sample' corrects this behavior by using the sample std. In release 0.13, the default strategy will be replaced by the new strategy and the 'zscore' option will be removed. Please use 'zscore_sample' instead.

    _______________________________________________filter_and_extract - 6.6s, 0.1min




.. GENERATED FROM PYTHON SOURCE LINES 93-95

Computing group-sparse precision matrices
-----------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 95-110

.. code-block:: default

    from nilearn.connectome import GroupSparseCovarianceCV

    gsc = GroupSparseCovarianceCV(verbose=2)
    gsc.fit(subject_time_series)

    try:
        from sklearn.covariance import GraphicalLassoCV
    except ImportError:
        # for Scitkit-Learn < v0.20.0
        from sklearn.covariance import GraphLassoCV as GraphicalLassoCV

    gl = GraphicalLassoCV(verbose=2)
    gl.fit(np.concatenate(subject_time_series))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 2
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 7
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0
    [Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s remaining:    0.0s
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 2
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 2
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 1
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 1
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 2
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 6
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0
    [Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.9s finished
    [GroupSparseCovarianceCV.fit] [GroupSparseCovarianceCV] Done refinement  0 out of 4
    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 3
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 6
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 1
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0
    [Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 4
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 3
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 3
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 6
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0
    [Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.2s finished
    [GroupSparseCovarianceCV.fit] [GroupSparseCovarianceCV] Done refinement  1 out of 4
    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 5
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 1
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 1
    [Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 9
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 10
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 5
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0
    [Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   15.3s finished
    [GroupSparseCovarianceCV.fit] [GroupSparseCovarianceCV] Done refinement  2 out of 4
    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 6
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 1
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 1
    [Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 11
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 11
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 5
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0
    [GroupSparseCovarianceCV.fit] Log-likelihood on test set is decreasing. Stopping at iteration 0
    [Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.4s finished
    [GroupSparseCovarianceCV.fit] [GroupSparseCovarianceCV] Done refinement  3 out of 4
    [GroupSparseCovarianceCV.fit] Final optimization
    [GroupSparseCovarianceCV.fit] tolerance reached at iteration number 19: 8.841e-04
    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    ....[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s
    ................[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished
    [GraphicalLassoCV] Done refinement  1 out of 4:   0s
    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    ....[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s
    ................[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished
    [GraphicalLassoCV] Done refinement  2 out of 4:   2s
    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    ....[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s
    ................[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.4s finished
    [GraphicalLassoCV] Done refinement  3 out of 4:   3s
    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    ....[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s
    ................[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished
    [GraphicalLassoCV] Done refinement  4 out of 4:   4s
    [Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
    [Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished
    [graphical_lasso] Iteration   0, cost  1.68e+02, dual gap 1.123e+00
    [graphical_lasso] Iteration   1, cost  1.68e+02, dual gap -1.664e-03
    [graphical_lasso] Iteration   2, cost  1.68e+02, dual gap 1.158e-04
    [graphical_lasso] Iteration   3, cost  1.68e+02, dual gap 1.389e-04
    [graphical_lasso] Iteration   4, cost  1.68e+02, dual gap 1.530e-04
    [graphical_lasso] Iteration   5, cost  1.68e+02, dual gap 1.318e-04
    [graphical_lasso] Iteration   6, cost  1.68e+02, dual gap 6.844e-05


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GraphicalLassoCV(verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">GraphicalLassoCV</label><div class="sk-toggleable__content"><pre>GraphicalLassoCV(verbose=2)</pre></div></div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 111-113

Displaying results
------------------

.. GENERATED FROM PYTHON SOURCE LINES 113-148

.. code-block:: default

    atlas_img = msdl_atlas_dataset.maps
    atlas_region_coords = plotting.find_probabilistic_atlas_cut_coords(atlas_img)
    labels = msdl_atlas_dataset.labels

    plotting.plot_connectome(
        gl.covariance_,
        atlas_region_coords,
        edge_threshold="90%",
        title="Covariance",
        display_mode="lzr",
    )
    plotting.plot_connectome(
        -gl.precision_,
        atlas_region_coords,
        edge_threshold="90%",
        title="Sparse inverse covariance (GraphicalLasso)",
        display_mode="lzr",
        edge_vmax=0.5,
        edge_vmin=-0.5,
    )
    plot_matrices(gl.covariance_, gl.precision_, "GraphicalLasso", labels)

    title = "GroupSparseCovariance"
    plotting.plot_connectome(
        -gsc.precisions_[..., 0],
        atlas_region_coords,
        edge_threshold="90%",
        title=title,
        display_mode="lzr",
        edge_vmax=0.5,
        edge_vmin=-0.5,
    )
    plot_matrices(gsc.covariances_[..., 0], gsc.precisions_[..., 0], title, labels)

    plotting.show()



.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/03_connectivity/images/sphx_glr_plot_multi_subject_connectome_001.png
         :alt: plot multi subject connectome
         :srcset: /auto_examples/03_connectivity/images/sphx_glr_plot_multi_subject_connectome_001.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/03_connectivity/images/sphx_glr_plot_multi_subject_connectome_002.png
         :alt: plot multi subject connectome
         :srcset: /auto_examples/03_connectivity/images/sphx_glr_plot_multi_subject_connectome_002.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/03_connectivity/images/sphx_glr_plot_multi_subject_connectome_003.png
         :alt: plot multi subject connectome
         :srcset: /auto_examples/03_connectivity/images/sphx_glr_plot_multi_subject_connectome_003.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/03_connectivity/images/sphx_glr_plot_multi_subject_connectome_004.png
         :alt: plot multi subject connectome
         :srcset: /auto_examples/03_connectivity/images/sphx_glr_plot_multi_subject_connectome_004.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/03_connectivity/images/sphx_glr_plot_multi_subject_connectome_005.png
         :alt: plot multi subject connectome
         :srcset: /auto_examples/03_connectivity/images/sphx_glr_plot_multi_subject_connectome_005.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/03_connectivity/images/sphx_glr_plot_multi_subject_connectome_006.png
         :alt: plot multi subject connectome
         :srcset: /auto_examples/03_connectivity/images/sphx_glr_plot_multi_subject_connectome_006.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/03_connectivity/images/sphx_glr_plot_multi_subject_connectome_007.png
         :alt: plot multi subject connectome
         :srcset: /auto_examples/03_connectivity/images/sphx_glr_plot_multi_subject_connectome_007.png
         :class: sphx-glr-multi-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  39.127 seconds)

**Estimated memory usage:**  610 MB


.. _sphx_glr_download_auto_examples_03_connectivity_plot_multi_subject_connectome.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/nilearn/nilearn/0.10.1?urlpath=lab/tree/notebooks/auto_examples/03_connectivity/plot_multi_subject_connectome.ipynb
        :alt: Launch binder
        :width: 150 px



    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_multi_subject_connectome.py <plot_multi_subject_connectome.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_multi_subject_connectome.ipynb <plot_multi_subject_connectome.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
