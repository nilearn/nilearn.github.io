<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1.0 name=viewport><meta content="3.3. Extracting functional brain networks: ICA and related"property=og:title><meta content=website property=og:type><meta content=https://nilearn.github.io/connectivity/resting_state_networks.html property=og:url><meta content=Nilearn property=og:site_name><meta content="Page summary: This page demonstrates the use of multi-subject decompositions models to extract brain-networks from fMRI data in a data-driven way. Specifically, we will apply Independent Component ..."property=og:description><meta content=../_images/sphx_glr_plot_compare_decomposition_001.png property=og:image><meta content=Nilearn property=og:image:alt><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../_static/pygments.css rel=stylesheet><link href=../_static/nature.css rel=stylesheet><link href=../_static/copybutton.css rel=stylesheet><link href=../_static/sg_gallery.css rel=stylesheet><link href=../_static/sg_gallery-binder.css rel=stylesheet><link href=../_static/sg_gallery-dataframe.css rel=stylesheet><link href=../_static/sg_gallery-rendered-html.css rel=stylesheet><script data-url_root=../ id=documentation_options src=../_static/documentation_options.js></script><script src=../_static/jquery.js></script><script src=../_static/underscore.js></script><script src=../_static/doctools.js></script><script src=../_static/clipboard.min.js></script><script src=../_static/copybutton.js></script><link rel="shortcut icon"href=../_static/favicon.ico><link href=../search.html rel=search title=Search><link title="3.4. Region Extraction for better brain parcellations"href=region_extraction.html rel=next><link title="3.2.3.1. Group-sparse covariance estimation"href=../developers/group_sparse_covariance.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script><body><div id=logo-banner><div class=logo><a href=../index.html> <img alt="Nilearn logo"border=0 src=../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=parcellating.html>Ward clustering</a></small></li><li><a href=../decoding/searchlight.html>Searchlight</a></li><li><big><a href=#>ICA</a></big></li><li><a href=../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../modules/reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../py-modindex.html>modules</a></li><li class=right><a title="3.4. Region Extraction for better brain parcellations"accesskey=N href=region_extraction.html>next</a> |</li><li class=right><a title="3.2.3.1. Group-sparse covariance estimation"accesskey=P href=../developers/group_sparse_covariance.html>previous</a> |</li><li><a href=../index.html>Nilearn Home</a> | </li><li><a href=../user_guide.html>User Guide</a> | </li><li><a href=../auto_examples/index.html>Examples</a> | </li><li><a href=../modules/reference.html>Reference</a> | </li><li id=navbar-about><a href=../authors.html>About</a>| </li><li><a href=../glossary.html>Glossary</a>| </li><li><a href=../bibliography.html>Bibliography</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=index.html><span class=section-number>3. </span>Functional connectivity and resting state</a> »</li><li class="nav-item nav-item-this"><a href>Nilearn: Statistical Analysis for NeuroImaging in Python</a></li></ul></div></div><div class=stable-banner>This is the <em>stable</em> documentation for the latest release of Nilearn, the current development version is available <a href=https://nilearn.github.io/dev/index.html>here</a>.</div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class=section id=extracting-functional-brain-networks-ica-and-related><span id=extracting-rsn></span><h1><span class=section-number>3.3. </span>Extracting functional brain networks: ICA and related<a title="Permalink to this headline"class=headerlink href=#extracting-functional-brain-networks-ica-and-related>¶</a></h1><div class=topic><p class=topic-title><strong>Page summary</strong></p><p>This page demonstrates the use of multi-subject decompositions models to extract brain-networks from <a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a> data in a data-driven way. Specifically, we will apply Independent Component Analysis (<a class="reference internal"href=../glossary.html#term-ICA><span class="xref std std-term">ICA</span></a>), which implements a multivariate random effects model across subjects. We will then compare <a class="reference internal"href=../glossary.html#term-ICA><span class="xref std std-term">ICA</span></a> to a newer technique, based on dictionary learning.</p></div><div class=section id=multi-subject-ica-canica><h2><span class=section-number>3.3.1. </span>Multi-subject ICA: CanICA<a title="Permalink to this headline"class=headerlink href=#multi-subject-ica-canica>¶</a></h2><div class=topic><p class=topic-title><strong>References</strong></p><ul class=simple><li><p>G. Varoquaux et al. “A group model for stable multi-subject ICA on fMRI datasets”, <a class="reference external"href=http://www.sciencedirect.com/science/article/pii/S1053811910001618>NeuroImage Vol 51 (2010)</a>, p. 288-299</p></li></ul></div><div class=section id=objective><h3><span class=section-number>3.3.1.1. </span>Objective<a title="Permalink to this headline"class=headerlink href=#objective>¶</a></h3><p><a class="reference internal"href=../glossary.html#term-ICA><span class="xref std std-term">ICA</span></a> is a useful approach for finding independent sources from <a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a> images. <a class="reference internal"href=../glossary.html#term-ICA><span class="xref std std-term">ICA</span></a> and similar techniques can be therefore used to define regions or networks that share similar <a class="reference internal"href=../glossary.html#term-BOLD><span class="xref std std-term">BOLD</span></a> signal across time. The <a class="reference internal"href=../glossary.html#term-CanICA><span class="xref std std-term">CanICA</span></a> incorporates information both within-subjects and across subjects to arrive at consensus components.</p><div class=topic><p class=topic-title><strong>Nilearn data for examples</strong></p><p>Nilearn provides easy-to-analyze data to explore functional connectivity and resting: the <a class="reference external"href=https://osf.io/5hju4/files/>brain development dataset</a>, which has been preprocessed using <a class="reference external"href=https://osf.io/wjtyq/>FMRIPrep and Nilearn</a> We use nilearn functions to fetch data from Internet and get the filenames (<a class="reference internal"href=../manipulating_images/input_output.html#loading-data><span class="std std-ref">more on data loading</span></a>).</p></div></div><div class=section id=fitting-canica-model-with-nilearn><h3><span class=section-number>3.3.1.2. </span>Fitting CanICA model with nilearn<a title="Permalink to this headline"class=headerlink href=#fitting-canica-model-with-nilearn>¶</a></h3><p><a class="reference internal"href=../modules/generated/nilearn.decomposition.CanICA.html#nilearn.decomposition.CanICA title=nilearn.decomposition.CanICA><code class="xref py py-class docutils literal notranslate"><span class=pre>CanICA</span></code></a> is a ready-to-use object that can be applied to multi-subject Nifti data, for instance presented as filenames, and will perform a multi-subject <a class="reference internal"href=../glossary.html#term-ICA><span class="xref std std-term">ICA</span></a> decomposition following the <a class="reference internal"href=../glossary.html#term-CanICA><span class="xref std std-term">CanICA</span></a> model. As with every object in nilearn, we give its parameters at construction, and then fit it on the data. For examples of this process, see here: <a class="reference internal"href=../auto_examples/03_connectivity/plot_compare_decomposition.html#sphx-glr-auto-examples-03-connectivity-plot-compare-decomposition-py><span class="std std-ref">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</span></a></p><p>Once an <a class="reference internal"href=../glossary.html#term-ICA><span class="xref std std-term">ICA</span></a> object has been fit to an <a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a> dataset, the individual components can be accessed as a 4D Nifti object using the <code class="docutils literal notranslate"><span class=pre>components_img_</span></code> attribute.</p></div><div class=section id=visualizing-results><h3><span class=section-number>3.3.1.3. </span>Visualizing results<a title="Permalink to this headline"class=headerlink href=#visualizing-results>¶</a></h3><p>We can visualize each component outlined over the brain:</p><div class="figure align-center"><a class="reference external image-reference"href=../auto_examples/03_connectivity/plot_compare_decomposition.html><img alt=../_images/sphx_glr_plot_compare_decomposition_001.png src=../_images/sphx_glr_plot_compare_decomposition_001.png></a></div><p>We can also plot the map for different components separately:</p><p class=centered><strong><a class="reference internal"href=../_images/sphx_glr_plot_compare_decomposition_002.png><img alt=ic1 src=../_images/sphx_glr_plot_compare_decomposition_002.png style=width:23%></a> <a class="reference internal"href=../_images/sphx_glr_plot_compare_decomposition_003.png><img alt=ic2 src=../_images/sphx_glr_plot_compare_decomposition_003.png style=width:23%></a> <a class="reference internal"href=../_images/sphx_glr_plot_compare_decomposition_004.png><img alt=ic3 src=../_images/sphx_glr_plot_compare_decomposition_004.png style=width:23%></a> <a class="reference internal"href=../_images/sphx_glr_plot_compare_decomposition_005.png><img alt=ic4 src=../_images/sphx_glr_plot_compare_decomposition_005.png style=width:23%></a></strong></p><div class="admonition seealso"><p class=admonition-title>See also</p><p>The full code can be found as an example: <a class="reference internal"href=../auto_examples/03_connectivity/plot_compare_decomposition.html#sphx-glr-auto-examples-03-connectivity-plot-compare-decomposition-py><span class="std std-ref">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</span></a></p></div><div class="admonition note"><p class=admonition-title>Note</p><p>Note that as the <a class="reference internal"href=../glossary.html#term-ICA><span class="xref std std-term">ICA</span></a> components are not ordered, the two components displayed on your computer might not match those of the documentation. For a fair representation, you should display all components and investigate which one resemble those displayed above.</p></div></div><div class=section id=interpreting-such-components><h3><span class=section-number>3.3.1.4. </span>Interpreting such components<a title="Permalink to this headline"class=headerlink href=#interpreting-such-components>¶</a></h3><p><a class="reference internal"href=../glossary.html#term-ICA><span class="xref std std-term">ICA</span></a>, and related algorithms, extract patterns that coactivate in the signal. As a result, it finds functional networks, but also patterns of non neural activity, ie confounding signals. Both are visible in the plots of the components.</p></div></div><div class=section id=an-alternative-to-ica-dictionary-learning><h2><span class=section-number>3.3.2. </span>An alternative to <a class="reference internal"href=../glossary.html#term-ICA><span class="xref std std-term">ICA</span></a>: <a class="reference internal"href=../glossary.html#term-Dictionary-learning><span class="xref std std-term">Dictionary learning</span></a><a title="Permalink to this headline"class=headerlink href=#an-alternative-to-ica-dictionary-learning>¶</a></h2><p>Recent work has shown that <a class="reference internal"href=../glossary.html#term-Dictionary-learning><span class="xref std std-term">Dictionary learning</span></a> based techniques outperform <a class="reference internal"href=../glossary.html#term-ICA><span class="xref std std-term">ICA</span></a> in term of stability and constitutes a better first step in a statistical analysis pipeline. <a class="reference internal"href=../glossary.html#term-Dictionary-learning><span class="xref std std-term">Dictionary learning</span></a> in neuro-imaging seeks to extract a few representative temporal elements along with their sparse spatial loadings, which constitute good extracted maps.</p><div class=topic><p class=topic-title><strong>References</strong></p><ul class=simple><li><p>Arthur Mensch et al. <a class="reference external"href=https://hal.archives-ouvertes.fr/hal-01271033/>Compressed online dictionary learning for fast resting-state fMRI decomposition</a>, ISBI 2016, Lecture Notes in Computer Science</p></li></ul></div><p><a class="reference internal"href=../modules/generated/nilearn.decomposition.DictLearning.html#nilearn.decomposition.DictLearning title=nilearn.decomposition.DictLearning><code class="xref py py-class docutils literal notranslate"><span class=pre>DictLearning</span></code></a> is a ready-to-use class with the same interface as <a class="reference internal"href=../modules/generated/nilearn.decomposition.CanICA.html#nilearn.decomposition.CanICA title=nilearn.decomposition.CanICA><code class="xref py py-class docutils literal notranslate"><span class=pre>CanICA</span></code></a>. Sparsity of output map is controlled by a parameter alpha: using a larger alpha yields sparser maps.</p><p>We can fit both estimators to compare them. 4D plotting (using <a class="reference internal"href=../modules/generated/nilearn.plotting.plot_prob_atlas.html#nilearn.plotting.plot_prob_atlas title=nilearn.plotting.plot_prob_atlas><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.plotting.plot_prob_atlas</span></code></a>) offers an efficient way to compare both resulting outputs.</p><div class="figure align-center"><a class="reference external image-reference"href=../auto_examples/03_connectivity/plot_compare_decomposition.html><img alt=../_images/sphx_glr_plot_compare_decomposition_022.png src=../_images/sphx_glr_plot_compare_decomposition_022.png></a></div><div class="figure align-center"><a class="reference external image-reference"href=../auto_examples/03_connectivity/plot_compare_decomposition.html><img alt=../_images/sphx_glr_plot_compare_decomposition_001.png src=../_images/sphx_glr_plot_compare_decomposition_001.png></a></div><p>Maps obtained with <a class="reference internal"href=../glossary.html#term-Dictionary-learning><span class="xref std std-term">Dictionary learning</span></a> are often easier to exploit as they are more contrasted than <a class="reference internal"href=../glossary.html#term-ICA><span class="xref std std-term">ICA</span></a> maps, with blobs usually better defined. Typically, <em>smoothing can be lower than when doing ICA</em>.</p><p class=centered><strong><a class="reference internal"href=../_images/sphx_glr_plot_compare_decomposition_023.png><img alt=dl1 src=../_images/sphx_glr_plot_compare_decomposition_023.png style=width:23%></a> <a class="reference internal"href=../_images/sphx_glr_plot_compare_decomposition_024.png><img alt=dl2 src=../_images/sphx_glr_plot_compare_decomposition_024.png style=width:23%></a> <a class="reference internal"href=../_images/sphx_glr_plot_compare_decomposition_025.png><img alt=dl3 src=../_images/sphx_glr_plot_compare_decomposition_025.png style=width:23%></a> <a class="reference internal"href=../_images/sphx_glr_plot_compare_decomposition_026.png><img alt=dl4 src=../_images/sphx_glr_plot_compare_decomposition_026.png style=width:23%></a></strong></p><p>While <a class="reference internal"href=../glossary.html#term-Dictionary-learning><span class="xref std std-term">Dictionary learning</span></a> computation time is comparable to <a class="reference internal"href=../glossary.html#term-CanICA><span class="xref std std-term">CanICA</span></a>, obtained atlases have been shown to outperform <a class="reference internal"href=../glossary.html#term-ICA><span class="xref std std-term">ICA</span></a> in a variety of classification tasks.</p><div class="admonition seealso"><p class=admonition-title>See also</p><p>The full code can be found as an example: <a class="reference internal"href=../auto_examples/03_connectivity/plot_compare_decomposition.html#sphx-glr-auto-examples-03-connectivity-plot-compare-decomposition-py><span class="std std-ref">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</span></a></p></div><div class="admonition seealso"><p class=admonition-title>See also</p><p>Learn how to extract <a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a> data from regions created with <a class="reference internal"href=../glossary.html#term-Dictionary-learning><span class="xref std std-term">Dictionary learning</span></a> with this example: <a class="reference internal"href=../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html#sphx-glr-auto-examples-03-connectivity-plot-extract-regions-dictlearning-maps-py><span class="std std-ref">Regions extraction using Dictionary learning and functional connectomes</span></a></p></div></div></div><div class=clearer></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>3.3. Extracting functional brain networks: ICA and related</a><ul><li><a class="reference internal"href=#multi-subject-ica-canica>3.3.1. Multi-subject ICA: CanICA</a><ul><li><a class="reference internal"href=#objective>3.3.1.1. Objective</a></li><li><a class="reference internal"href=#fitting-canica-model-with-nilearn>3.3.1.2. Fitting CanICA model with nilearn</a></li><li><a class="reference internal"href=#visualizing-results>3.3.1.3. Visualizing results</a></li><li><a class="reference internal"href=#interpreting-such-components>3.3.1.4. Interpreting such components</a></li></ul></li><li><a class="reference internal"href=#an-alternative-to-ica-dictionary-learning>3.3.2. An alternative to <span class="xref std std-term">ICA</span>: <span class="xref std std-term">Dictionary learning</span></a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=../developers/group_sparse_covariance.html><span class=section-number>3.2.3.1. </span>Group-sparse covariance estimation</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=region_extraction.html><span class=section-number>3.4. </span>Region Extraction for better brain parcellations</a></p><div id=searchbox role=search style=display:none><h3 id=searchlabel>Quick search</h3><div class=searchformwrapper><form action=../search.html class=search><input aria-labelledby=searchlabel name=q><input type=submit value=Go></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2022. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 4.0.2. <span style=padding-left:5ex> <a href=../_sources/connectivity/resting_state_networks.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>