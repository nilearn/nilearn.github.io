<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1.0 name=viewport><meta content="3.4. Region Extraction for better brain parcellations"property=og:title><meta content=website property=og:type><meta content=https://nilearn.github.io/connectivity/region_extraction.html property=og:url><meta content=Nilearn property=og:site_name><meta content="Page summary: This section shows how to use RegionExtractor to extract connected regions/components into a separate brain region and also shows how to learn functional connectivity interactions bet..."property=og:description><meta content=auto_examples/03_connectivity/images/sphx_glr_plot_extract_regions_dictlearning_maps_001.png property=og:image><meta content=dict-maps property=og:image:alt><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../_static/pygments.css rel=stylesheet><link href=../_static/nature.css rel=stylesheet><link href=../_static/copybutton.css rel=stylesheet><link href=../_static/sg_gallery.css rel=stylesheet><link href=../_static/sg_gallery-binder.css rel=stylesheet><link href=../_static/sg_gallery-dataframe.css rel=stylesheet><link href=../_static/sg_gallery-rendered-html.css rel=stylesheet><script data-url_root=../ id=documentation_options src=../_static/documentation_options.js></script><script src=../_static/jquery.js></script><script src=../_static/underscore.js></script><script src=../_static/doctools.js></script><script src=../_static/clipboard.min.js></script><script src=../_static/copybutton.js></script><link rel="shortcut icon"href=../_static/favicon.ico><link href=../search.html rel=search title=Search><link title="3.5. Clustering to parcellate the brain in regions"href=parcellating.html rel=next><link title="3.3. Extracting functional brain networks: ICA and related"href=resting_state_networks.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script><body><div id=logo-banner><div class=logo><a href=../index.html> <img alt="Nilearn logo"border=0 src=../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=parcellating.html>Ward clustering</a></small></li><li><a href=../decoding/searchlight.html>Searchlight</a></li><li><big><a href=resting_state_networks.html>ICA</a></big></li><li><a href=../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../modules/reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../py-modindex.html>modules</a></li><li class=right><a title="3.5. Clustering to parcellate the brain in regions"accesskey=N href=parcellating.html>next</a> |</li><li class=right><a title="3.3. Extracting functional brain networks: ICA and related"accesskey=P href=resting_state_networks.html>previous</a> |</li><li><a href=../index.html>Nilearn Home</a> | </li><li><a href=../user_guide.html>User Guide</a> | </li><li><a href=../auto_examples/index.html>Examples</a> | </li><li><a href=../modules/reference.html>Reference</a> | </li><li id=navbar-about><a href=../authors.html>About</a>| </li><li><a href=../glossary.html>Glossary</a>| </li><li><a href=../bibliography.html>Bibliography</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=index.html><span class=section-number>3. </span>Functional connectivity and resting state</a> »</li><li class="nav-item nav-item-this"><a href>Nilearn: Statistical Analysis for NeuroImaging in Python</a></li></ul></div></div><div class=stable-banner>This is the <em>stable</em> documentation for the latest release of Nilearn, the current development version is available <a href=https://nilearn.github.io/dev/index.html>here</a>.</div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class=section id=region-extraction-for-better-brain-parcellations><span id=region-extraction></span><h1><span class=section-number>3.4. </span>Region Extraction for better brain parcellations<a title="Permalink to this headline"class=headerlink href=#region-extraction-for-better-brain-parcellations>¶</a></h1><div class=topic><p class=topic-title><strong>Page summary</strong></p><p>This section shows how to use <a class="reference internal"href=../modules/generated/nilearn.regions.RegionExtractor.html#nilearn.regions.RegionExtractor title=nilearn.regions.RegionExtractor><code class="xref py py-class docutils literal notranslate"><span class=pre>RegionExtractor</span></code></a> to extract connected regions/components into a separate brain region and also shows how to learn functional connectivity interactions between each separate region.</p></div><div class="contents local topic"id=contents><p class=topic-title><strong>Contents</strong></p><ul class=simple><li><p><a class="reference internal"href=#fetching-movie-watching-based-functional-datasets id=id1>Fetching movie-watching based functional datasets</a></p></li><li><p><a class="reference internal"href=#brain-maps-using-dictionary-learning id=id2>Brain maps using <a class="reference internal"href=../glossary.html#term-Dictionary-learning><span class="xref std std-term">Dictionary learning</span></a></a></p></li><li><p><a class="reference internal"href=#visualization-of-dictionary-learning-maps id=id3>Visualization of <a class="reference internal"href=../glossary.html#term-Dictionary-learning><span class="xref std std-term">Dictionary learning</span></a> maps</a></p></li><li><p><a class="reference internal"href=#region-extraction-with-dictionary-learning-maps id=id4>Region Extraction with <a class="reference internal"href=../glossary.html#term-Dictionary-learning><span class="xref std std-term">Dictionary learning</span></a> maps</a></p></li><li><p><a class="reference internal"href=#visualization-of-region-extraction-results id=id5>Visualization of Region Extraction results</a></p></li><li><p><a class="reference internal"href=#computing-functional-connectivity-matrices id=id6>Computing functional connectivity matrices</a></p></li><li><p><a class="reference internal"href=#visualization-of-functional-connectivity-matrices id=id7>Visualization of functional connectivity matrices</a></p></li><li><p><a class="reference internal"href=#validating-results id=id8>Validating results</a></p></li></ul></div><div class=topic><p class=topic-title><strong>References</strong></p><ul class=simple><li><p><a class="reference external"href=https://hal.inria.fr/hal-01093944>Abraham et al. “Region segmentation for sparse decompositions: better brain parcellations from rest fMRI”, Sparsity Techniques in Medical Imaging, Sep 2014</a></p></li></ul></div><div class=section id=fetching-movie-watching-based-functional-datasets><h2><a class=toc-backref href=#id1><span class=section-number>3.4.1. </span>Fetching movie-watching based functional datasets</a><a title="Permalink to this headline"class=headerlink href=#fetching-movie-watching-based-functional-datasets>¶</a></h2><p>We use a naturalistic stimuli based movie-watching functional connectivity dataset of 20 subjects, which is already preprocessed, downsampled to 4mm isotropic resolution, and publicly available at <a class="reference external"href=https://osf.io/5hju4/files/>https://osf.io/5hju4/files/</a>. We use utilities <a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_development_fmri.html#nilearn.datasets.fetch_development_fmri title=nilearn.datasets.fetch_development_fmri><code class="xref py py-func docutils literal notranslate"><span class=pre>fetch_development_fmri</span></code></a> implemented in nilearn for automatic fetching of this dataset.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn</span> <span class=kn>import</span> <span class=n>datasets</span>

<span class=n>rest_dataset</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>fetch_development_fmri</span><span class=p>(</span><span class=n>n_subjects</span><span class=o>=</span><span class=mi>20</span><span class=p>)</span>
<span class=n>func_filenames</span> <span class=o>=</span> <span class=n>rest_dataset</span><span class=o>.</span><span class=n>func</span>
<span class=n>confounds</span> <span class=o>=</span> <span class=n>rest_dataset</span><span class=o>.</span><span class=n>confounds</span>

</pre></div></div></div><div class=section id=brain-maps-using-dictionary-learning><h2><a class=toc-backref href=#id2><span class=section-number>3.4.2. </span>Brain maps using <a class="reference internal"href=../glossary.html#term-Dictionary-learning><span class="xref std std-term">Dictionary learning</span></a></a><a title="Permalink to this headline"class=headerlink href=#brain-maps-using-dictionary-learning>¶</a></h2><p>Here, we use object <a class="reference internal"href=../modules/generated/nilearn.decomposition.DictLearning.html#nilearn.decomposition.DictLearning title=nilearn.decomposition.DictLearning><code class="xref py py-class docutils literal notranslate"><span class=pre>DictLearning</span></code></a>, a multi subject model to decompose multi subjects <a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a> datasets into functionally defined maps. We do this by setting the parameters and calling <a class="reference internal"href=../modules/generated/nilearn.decomposition.DictLearning.html#nilearn.decomposition.DictLearning.fit title=nilearn.decomposition.DictLearning.fit><code class="xref py py-meth docutils literal notranslate"><span class=pre>DictLearning.fit</span></code></a> on the filenames of datasets without necessarily converting each file to <a class="reference external"title="(in NiBabel v3.2.2+146.ga20f13ad)"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image><code class="xref py py-class docutils literal notranslate"><span class=pre>Nifti1Image</span></code></a> object.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn.decomposition</span> <span class=kn>import</span> <span class=n>DictLearning</span>

<span class=c1># Initialize DictLearning object</span>
<span class=n>dict_learn</span> <span class=o>=</span> <span class=n>DictLearning</span><span class=p>(</span><span class=n>n_components</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span> <span class=n>smoothing_fwhm</span><span class=o>=</span><span class=mf>6.</span><span class=p>,</span>
                          <span class=n>memory</span><span class=o>=</span><span class=s2>"nilearn_cache"</span><span class=p>,</span> <span class=n>memory_level</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
                          <span class=n>random_state</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
<span class=c1># Fit to the data</span>
<span class=n>dict_learn</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>func_filenames</span><span class=p>)</span>
<span class=c1># Resting state networks/maps in attribute `components_img_`</span>
<span class=n>components_img</span> <span class=o>=</span> <span class=n>dict_learn</span><span class=o>.</span><span class=n>components_img_</span>

</pre></div></div></div><div class=section id=visualization-of-dictionary-learning-maps><h2><a class=toc-backref href=#id3><span class=section-number>3.4.3. </span>Visualization of <a class="reference internal"href=../glossary.html#term-Dictionary-learning><span class="xref std std-term">Dictionary learning</span></a> maps</a><a title="Permalink to this headline"class=headerlink href=#visualization-of-dictionary-learning-maps>¶</a></h2><p>Showing maps stored in <code class="docutils literal notranslate"><span class=pre>components_img</span></code> using nilearn plotting utilities. Here, we use <a class="reference internal"href=../modules/generated/nilearn.plotting.plot_prob_atlas.html#nilearn.plotting.plot_prob_atlas title=nilearn.plotting.plot_prob_atlas><code class="xref py py-func docutils literal notranslate"><span class=pre>plot_prob_atlas</span></code></a> for easy visualization of 4D atlas maps onto the anatomical standard template. Each map is displayed in different color and colors are random and automatically picked.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn</span> <span class=kn>import</span> <span class=n>plotting</span>

<span class=n>plotting</span><span class=o>.</span><span class=n>plot_prob_atlas</span><span class=p>(</span><span class=n>components_img</span><span class=p>,</span> <span class=n>view_type</span><span class=o>=</span><span class=s1>'filled_contours'</span><span class=p>,</span>
                         <span class=n>title</span><span class=o>=</span><span class=s1>'Dictionary Learning maps'</span><span class=p>)</span>

</pre></div></div><p class=centered><strong><a class="reference external"href=../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html><img alt=dict-maps src=../_images/sphx_glr_plot_extract_regions_dictlearning_maps_001.png style=width:528px;height:208px></a></strong></p></div><div class=section id=region-extraction-with-dictionary-learning-maps><h2><a class=toc-backref href=#id4><span class=section-number>3.4.4. </span>Region Extraction with <a class="reference internal"href=../glossary.html#term-Dictionary-learning><span class="xref std std-term">Dictionary learning</span></a> maps</a><a title="Permalink to this headline"class=headerlink href=#region-extraction-with-dictionary-learning-maps>¶</a></h2><p>We use object <a class="reference internal"href=../modules/generated/nilearn.regions.RegionExtractor.html#nilearn.regions.RegionExtractor title=nilearn.regions.RegionExtractor><code class="xref py py-class docutils literal notranslate"><span class=pre>RegionExtractor</span></code></a> for extracting brain connected regions from dictionary maps into separated brain activation regions with automatic thresholding strategy selected as <code class="docutils literal notranslate"><span class=pre>thresholding_strategy='ratio_n_voxels'</span></code>. We use thresholding strategy to first get foreground information present in the maps and then followed by robust region extraction on foreground information using Random Walker algorithm selected as <code class="docutils literal notranslate"><span class=pre>extractor='local_regions'</span></code>.</p><p>Here, we control foreground extraction using parameter <code class="docutils literal notranslate"><span class=pre>threshold=.5</span></code>, which represents the expected proportion of <a class="reference internal"href=../glossary.html#term-voxel><span class="xref std std-term">voxels</span></a> included in the regions (i.e. with a non-zero value in one of the maps). If you need to keep more proportion of <a class="reference internal"href=../glossary.html#term-voxel><span class="xref std std-term">voxels</span></a> then threshold should be tweaked according to the maps data.</p><p>The parameter <code class="docutils literal notranslate"><span class=pre>min_region_size=1350</span> <span class=pre>mm^3</span></code> is to keep the minimum number of extracted regions. We control the small spurious regions size by thresholding in <a class="reference internal"href=../glossary.html#term-voxel><span class="xref std std-term">voxel</span></a> units to adapt well to the resolution of the image. Please see the documentation of <a class="reference internal"href=../modules/generated/nilearn.regions.connected_regions.html#nilearn.regions.connected_regions title=nilearn.regions.connected_regions><code class="xref py py-func docutils literal notranslate"><span class=pre>connected_regions</span></code></a> for more details.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn.regions</span> <span class=kn>import</span> <span class=n>RegionExtractor</span>

<span class=n>extractor</span> <span class=o>=</span> <span class=n>RegionExtractor</span><span class=p>(</span><span class=n>components_img</span><span class=p>,</span> <span class=n>threshold</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span>
                            <span class=n>thresholding_strategy</span><span class=o>=</span><span class=s1>'ratio_n_voxels'</span><span class=p>,</span>
                            <span class=n>extractor</span><span class=o>=</span><span class=s1>'local_regions'</span><span class=p>,</span>
                            <span class=n>standardize</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>min_region_size</span><span class=o>=</span><span class=mi>1350</span><span class=p>)</span>
<span class=c1># Just call fit() to process for regions extraction</span>
<span class=n>extractor</span><span class=o>.</span><span class=n>fit</span><span class=p>()</span>
<span class=c1># Extracted regions are stored in regions_img_</span>
<span class=n>regions_extracted_img</span> <span class=o>=</span> <span class=n>extractor</span><span class=o>.</span><span class=n>regions_img_</span>
<span class=c1># Each region index is stored in index_</span>
<span class=n>regions_index</span> <span class=o>=</span> <span class=n>extractor</span><span class=o>.</span><span class=n>index_</span>
<span class=c1># Total number of regions extracted</span>
<span class=n>n_regions_extracted</span> <span class=o>=</span> <span class=n>regions_extracted_img</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>

</pre></div></div></div><div class=section id=visualization-of-region-extraction-results><h2><a class=toc-backref href=#id5><span class=section-number>3.4.5. </span>Visualization of Region Extraction results</a><a title="Permalink to this headline"class=headerlink href=#visualization-of-region-extraction-results>¶</a></h2><p>Showing region extraction results. The same function <a class="reference internal"href=../modules/generated/nilearn.plotting.plot_prob_atlas.html#nilearn.plotting.plot_prob_atlas title=nilearn.plotting.plot_prob_atlas><code class="xref py py-func docutils literal notranslate"><span class=pre>plot_prob_atlas</span></code></a> is used for visualizing extracted regions on a standard template. Each extracted brain region is assigned a color and as you can see that visual cortex area is extracted quite nicely into each hemisphere.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=n>title</span> <span class=o>=</span> <span class=p>(</span><span class=s1>'</span><span class=si>%d</span><span class=s1> regions are extracted from </span><span class=si>%d</span><span class=s1> components.'</span>
         <span class=s1>'</span><span class=se>\n</span><span class=s1>Each separate color of region indicates extracted region'</span>
         <span class=o>%</span> <span class=p>(</span><span class=n>n_regions_extracted</span><span class=p>,</span> <span class=mi>8</span><span class=p>))</span>
<span class=n>plotting</span><span class=o>.</span><span class=n>plot_prob_atlas</span><span class=p>(</span><span class=n>regions_extracted_img</span><span class=p>,</span> <span class=n>view_type</span><span class=o>=</span><span class=s1>'filled_contours'</span><span class=p>,</span>
                         <span class=n>title</span><span class=o>=</span><span class=n>title</span><span class=p>)</span>

</pre></div></div><p class=centered><strong><a class="reference external"href=../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html><img alt=dict src=../_images/sphx_glr_plot_extract_regions_dictlearning_maps_002.png style=width:528px;height:208px></a></strong></p></div><div class=section id=computing-functional-connectivity-matrices><h2><a class=toc-backref href=#id6><span class=section-number>3.4.6. </span>Computing functional connectivity matrices</a><a title="Permalink to this headline"class=headerlink href=#computing-functional-connectivity-matrices>¶</a></h2><p>Here, we use the object called <a class="reference internal"href=../modules/generated/nilearn.connectome.ConnectivityMeasure.html#nilearn.connectome.ConnectivityMeasure title=nilearn.connectome.ConnectivityMeasure><code class="xref py py-class docutils literal notranslate"><span class=pre>ConnectivityMeasure</span></code></a> to compute functional connectivity measured between each extracted brain regions. Many different kinds of measures exists in nilearn such as “correlation”, “partial correlation”, “tangent”, “covariance”, “precision”. But, here we show how to compute only correlations by selecting parameter as <code class="docutils literal notranslate"><span class=pre>kind='correlation'</span></code> as initialized in the object.</p><p>The first step to do is to extract subject specific time series signals using functional data stored in <code class="docutils literal notranslate"><span class=pre>func_filenames</span></code> and the second step is to call <a class="reference internal"href=../modules/generated/nilearn.connectome.ConnectivityMeasure.html#nilearn.connectome.ConnectivityMeasure.fit_transform title=nilearn.connectome.ConnectivityMeasure.fit_transform><code class="xref py py-meth docutils literal notranslate"><span class=pre>ConnectivityMeasure.fit_transform</span></code></a> on the time series signals. Here, for each subject we have time series signals of <code class="docutils literal notranslate"><span class=pre>shape=(168,</span> <span class=pre>n_regions_extracted)</span></code> where 168 is the length of time series and <code class="docutils literal notranslate"><span class=pre>n_regions_extracted</span></code> is the number of extracted regions. Likewise, we have a total of 20 subject specific time series signals. The third step, we compute the mean correlation across all subjects.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn.connectome</span> <span class=kn>import</span> <span class=n>ConnectivityMeasure</span>

<span class=n>correlations</span> <span class=o>=</span> <span class=p>[]</span>
<span class=c1># Initializing ConnectivityMeasure object with kind='correlation'</span>
<span class=n>connectome_measure</span> <span class=o>=</span> <span class=n>ConnectivityMeasure</span><span class=p>(</span><span class=n>kind</span><span class=o>=</span><span class=s1>'correlation'</span><span class=p>)</span>
<span class=k>for</span> <span class=n>filename</span><span class=p>,</span> <span class=n>confound</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>func_filenames</span><span class=p>,</span> <span class=n>confounds</span><span class=p>):</span>
    <span class=c1># call transform from RegionExtractor object to extract timeseries signals</span>
    <span class=n>timeseries_each_subject</span> <span class=o>=</span> <span class=n>extractor</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>filename</span><span class=p>,</span> <span class=n>confounds</span><span class=o>=</span><span class=n>confound</span><span class=p>)</span>
    <span class=c1># call fit_transform from ConnectivityMeasure object</span>
    <span class=n>correlation</span> <span class=o>=</span> <span class=n>connectome_measure</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>([</span><span class=n>timeseries_each_subject</span><span class=p>])</span>
    <span class=c1># saving each subject correlation to correlations</span>
    <span class=n>correlations</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>correlation</span><span class=p>)</span>

<span class=c1># Mean of all correlations</span>
<span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
<span class=n>mean_correlations</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>correlations</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>n_regions_extracted</span><span class=p>,</span>
                                                          <span class=n>n_regions_extracted</span><span class=p>)</span>

</pre></div></div></div><div class=section id=visualization-of-functional-connectivity-matrices><h2><a class=toc-backref href=#id7><span class=section-number>3.4.7. </span>Visualization of functional connectivity matrices</a><a title="Permalink to this headline"class=headerlink href=#visualization-of-functional-connectivity-matrices>¶</a></h2><p>Showing mean of correlation matrices computed between each extracted brain regions. At this point, we make use of nilearn image and plotting utilities to find automatically the coordinates required, for plotting connectome relations. Left image is the correlations in a matrix form and right image is the connectivity relations to brain regions plotted using <a class="reference internal"href=../modules/generated/nilearn.plotting.plot_connectome.html#nilearn.plotting.plot_connectome title=nilearn.plotting.plot_connectome><code class="xref py py-func docutils literal notranslate"><span class=pre>plot_connectome</span></code></a></p><div class="highlight-default notranslate"><div class=highlight><pre><span></span>
<span class=n>title</span> <span class=o>=</span> <span class=s1>'Correlation between </span><span class=si>%d</span><span class=s1> regions'</span> <span class=o>%</span> <span class=n>n_regions_extracted</span>

<span class=c1># First plot the matrix</span>
<span class=n>display</span> <span class=o>=</span> <span class=n>plotting</span><span class=o>.</span><span class=n>plot_matrix</span><span class=p>(</span><span class=n>mean_correlations</span><span class=p>,</span> <span class=n>vmax</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>vmin</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span>
                               <span class=n>colorbar</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>title</span><span class=o>=</span><span class=n>title</span><span class=p>)</span>

<span class=c1># Then find the center of the regions and plot a connectome</span>
<span class=n>regions_img</span> <span class=o>=</span> <span class=n>regions_extracted_img</span>
<span class=n>coords_connectome</span> <span class=o>=</span> <span class=n>plotting</span><span class=o>.</span><span class=n>find_probabilistic_atlas_cut_coords</span><span class=p>(</span><span class=n>regions_img</span><span class=p>)</span>

<span class=n>plotting</span><span class=o>.</span><span class=n>plot_connectome</span><span class=p>(</span><span class=n>mean_correlations</span><span class=p>,</span> <span class=n>coords_connectome</span><span class=p>,</span>
                         <span class=n>edge_threshold</span><span class=o>=</span><span class=s1>'90%'</span><span class=p>,</span> <span class=n>title</span><span class=o>=</span><span class=n>title</span><span class=p>)</span>

</pre></div></div><p class=centered><strong><a class="reference external"href=../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html><img alt=matrix src=../_images/sphx_glr_plot_extract_regions_dictlearning_maps_003.png style=width:420px;height:300px></a> <a class="reference external"href=../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html><img alt=connectome src=../_images/sphx_glr_plot_extract_regions_dictlearning_maps_004.png style=width:396px;height:156px></a></strong></p></div><div class=section id=validating-results><h2><a class=toc-backref href=#id8><span class=section-number>3.4.8. </span>Validating results</a><a title="Permalink to this headline"class=headerlink href=#validating-results>¶</a></h2><p>Showing only one specific network regions before and after region extraction. The first image displays the regions of one specific functional network without region extraction.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn</span> <span class=kn>import</span> <span class=n>image</span>

<span class=n>img</span> <span class=o>=</span> <span class=n>image</span><span class=o>.</span><span class=n>index_img</span><span class=p>(</span><span class=n>components_img</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
<span class=n>coords</span> <span class=o>=</span> <span class=n>plotting</span><span class=o>.</span><span class=n>find_xyz_cut_coords</span><span class=p>(</span><span class=n>img</span><span class=p>)</span>
<span class=n>display</span> <span class=o>=</span> <span class=n>plotting</span><span class=o>.</span><span class=n>plot_stat_map</span><span class=p>(</span><span class=n>img</span><span class=p>,</span> <span class=n>cut_coords</span><span class=o>=</span><span class=n>coords</span><span class=p>,</span> <span class=n>colorbar</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
                                 <span class=n>title</span><span class=o>=</span><span class=s1>'Showing one specific network'</span><span class=p>)</span>

</pre></div></div><p class=centered><strong><a class="reference external"href=../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html><img alt=dmn src=../_images/sphx_glr_plot_extract_regions_dictlearning_maps_005.png style=width:528px;height:208px></a></strong></p><p>The second image displays the regions split apart after region extraction. Here, we can validate that regions are nicely separated identified by each extracted region in different color.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=n>regions_indices_of_map3</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>regions_index</span><span class=p>)</span> <span class=o>==</span> <span class=mi>4</span><span class=p>)</span>

<span class=n>display</span> <span class=o>=</span> <span class=n>plotting</span><span class=o>.</span><span class=n>plot_anat</span><span class=p>(</span><span class=n>cut_coords</span><span class=o>=</span><span class=n>coords</span><span class=p>,</span>
                             <span class=n>title</span><span class=o>=</span><span class=s1>'Regions from this network'</span><span class=p>)</span>

<span class=c1># Add as an overlay all the regions of index 4</span>
<span class=n>colors</span> <span class=o>=</span> <span class=s1>'rgbcmyk'</span>
<span class=k>for</span> <span class=n>each_index_of_map3</span><span class=p>,</span> <span class=n>color</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>regions_indices_of_map3</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>colors</span><span class=p>):</span>
    <span class=n>display</span><span class=o>.</span><span class=n>add_overlay</span><span class=p>(</span><span class=n>image</span><span class=o>.</span><span class=n>index_img</span><span class=p>(</span><span class=n>regions_extracted_img</span><span class=p>,</span> <span class=n>each_index_of_map3</span><span class=p>),</span>
                        <span class=n>cmap</span><span class=o>=</span><span class=n>plotting</span><span class=o>.</span><span class=n>cm</span><span class=o>.</span><span class=n>alpha_cmap</span><span class=p>(</span><span class=n>color</span><span class=p>))</span>

<span class=n>plotting</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</pre></div></div><p class=centered><strong><a class="reference external"href=../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html><img alt=dmn_reg src=../_images/sphx_glr_plot_extract_regions_dictlearning_maps_006.png style=width:528px;height:208px></a></strong></p><div class="admonition seealso"><p class=admonition-title>See also</p><p>The full code can be found as an example: <a class="reference internal"href=../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html#sphx-glr-auto-examples-03-connectivity-plot-extract-regions-dictlearning-maps-py><span class="std std-ref">Regions extraction using Dictionary learning and functional connectomes</span></a></p></div></div></div><div class=clearer></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>3.4. Region Extraction for better brain parcellations</a><ul><li><a class="reference internal"href=#fetching-movie-watching-based-functional-datasets>3.4.1. Fetching movie-watching based functional datasets</a></li><li><a class="reference internal"href=#brain-maps-using-dictionary-learning>3.4.2. Brain maps using <span class="xref std std-term">Dictionary learning</span></a></li><li><a class="reference internal"href=#visualization-of-dictionary-learning-maps>3.4.3. Visualization of <span class="xref std std-term">Dictionary learning</span> maps</a></li><li><a class="reference internal"href=#region-extraction-with-dictionary-learning-maps>3.4.4. Region Extraction with <span class="xref std std-term">Dictionary learning</span> maps</a></li><li><a class="reference internal"href=#visualization-of-region-extraction-results>3.4.5. Visualization of Region Extraction results</a></li><li><a class="reference internal"href=#computing-functional-connectivity-matrices>3.4.6. Computing functional connectivity matrices</a></li><li><a class="reference internal"href=#visualization-of-functional-connectivity-matrices>3.4.7. Visualization of functional connectivity matrices</a></li><li><a class="reference internal"href=#validating-results>3.4.8. Validating results</a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=resting_state_networks.html><span class=section-number>3.3. </span>Extracting functional brain networks: ICA and related</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=parcellating.html><span class=section-number>3.5. </span>Clustering to parcellate the brain in regions</a></p><div id=searchbox role=search style=display:none><h3 id=searchlabel>Quick search</h3><div class=searchformwrapper><form action=../search.html class=search><input aria-labelledby=searchlabel name=q><input type=submit value=Go></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2022. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 4.0.2. <span style=padding-left:5ex> <a href=../_sources/connectivity/region_extraction.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>