<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1.0 name=viewport><meta content="3.5. Clustering to parcellate the brain in regions"property=og:title><meta content=website property=og:type><meta content=https://nilearn.github.io/connectivity/parcellating.html property=og:url><meta content=Nilearn property=og:site_name><meta content="This page discusses how clustering can be used to parcellate the brain into homogeneous regions from functional imaging data., Reference: A big-picture reference on the use of clustering for brain ..."property=og:description><meta content=../_images/sphx_glr_plot_data_driven_parcellations_001.png property=og:image><meta content=Nilearn property=og:image:alt><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../_static/pygments.css rel=stylesheet><link href=../_static/nature.css rel=stylesheet><link href=../_static/copybutton.css rel=stylesheet><link href=../_static/sg_gallery.css rel=stylesheet><link href=../_static/sg_gallery-binder.css rel=stylesheet><link href=../_static/sg_gallery-dataframe.css rel=stylesheet><link href=../_static/sg_gallery-rendered-html.css rel=stylesheet><script data-url_root=../ id=documentation_options src=../_static/documentation_options.js></script><script src=../_static/jquery.js></script><script src=../_static/underscore.js></script><script src=../_static/doctools.js></script><script src=../_static/clipboard.min.js></script><script src=../_static/copybutton.js></script><link rel="shortcut icon"href=../_static/favicon.ico><link href=../search.html rel=search title=Search><link title="4. Plotting brain images"href=../plotting/index.html rel=next><link title="3.4. Region Extraction for better brain parcellations"href=region_extraction.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script><body><div id=logo-banner><div class=logo><a href=../index.html> <img alt="Nilearn logo"border=0 src=../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=#>Ward clustering</a></small></li><li><a href=../decoding/searchlight.html>Searchlight</a></li><li><big><a href=resting_state_networks.html>ICA</a></big></li><li><a href=../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../modules/reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../py-modindex.html>modules</a></li><li class=right><a title="4. Plotting brain images"accesskey=N href=../plotting/index.html>next</a> |</li><li class=right><a title="3.4. Region Extraction for better brain parcellations"accesskey=P href=region_extraction.html>previous</a> |</li><li><a href=../index.html>Nilearn Home</a> | </li><li><a href=../user_guide.html>User Guide</a> | </li><li><a href=../auto_examples/index.html>Examples</a> | </li><li><a href=../modules/reference.html>Reference</a> | </li><li id=navbar-about><a href=../authors.html>About</a>| </li><li><a href=../glossary.html>Glossary</a>| </li><li><a href=../bibliography.html>Bibliography</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=index.html><span class=section-number>3. </span>Functional connectivity and resting state</a> »</li><li class="nav-item nav-item-this"><a href>Nilearn: Statistical Analysis for NeuroImaging in Python</a></li></ul></div></div><div class=stable-banner>This is the <em>stable</em> documentation for the latest release of Nilearn, the current development version is available <a href=https://nilearn.github.io/dev/index.html>here</a>.</div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class=section id=clustering-to-parcellate-the-brain-in-regions><span id=parcellating-brain></span><h1><span class=section-number>3.5. </span>Clustering to parcellate the brain in regions<a title="Permalink to this headline"class=headerlink href=#clustering-to-parcellate-the-brain-in-regions>¶</a></h1><p>This page discusses how clustering can be used to parcellate the brain into homogeneous regions from functional imaging data.</p><div class=line-block><div class=line><br></div></div><div class=topic><p class=topic-title><strong>Reference</strong></p><p>A big-picture reference on the use of clustering for brain parcellations.</p><blockquote><div><p>Thirion, et al. <a class="reference external"href=http://journal.frontiersin.org/article/10.3389/fnins.2014.00167/full>“Which fMRI clustering gives good brain parcellations?.”</a> Frontiers in neuroscience 8.167 (2014): 13.</p></div></blockquote></div><div class=section id=data-loading-movie-watching-data><h2><span class=section-number>3.5.1. </span>Data loading: movie-watching data<a title="Permalink to this headline"class=headerlink href=#data-loading-movie-watching-data>¶</a></h2><p>Clustering is commonly applied to resting-state data, but any brain functional data will give rise of a functional parcellation, capturing intrinsic brain architecture in the case of resting-state data. In the examples, we use naturalistic stimuli-based movie watching brain development data downloaded with the function <a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_development_fmri.html#nilearn.datasets.fetch_development_fmri title=nilearn.datasets.fetch_development_fmri><code class="xref py py-func docutils literal notranslate"><span class=pre>fetch_development_fmri</span></code></a> (see <a class="reference internal"href=../manipulating_images/input_output.html#loading-data><span class="std std-ref">Inputing data: file names or image objects</span></a>).</p></div><div class=section id=applying-clustering><h2><span class=section-number>3.5.2. </span>Applying clustering<a title="Permalink to this headline"class=headerlink href=#applying-clustering>¶</a></h2><div class=topic><p class=topic-title><strong>Which clustering to use</strong></p><p>The question of which clustering method to use is in itself subject to debate. There are many clustering methods; their computational cost will vary, as well as their results. A <a class="reference external"href=http://journal.frontiersin.org/article/10.3389/fnins.2014.00167/full>well-cited empirical comparison paper, Thirion et al. 2014</a> suggests that:</p><ul class=simple><li><p>For a large number of clusters, it is preferable to use Ward agglomerative clustering with spatial constraints</p></li><li><p>For a small number of clusters, it is preferable to use Kmeans clustering after spatially-smoothing the data.</p></li></ul><p>Both algorithms are provided by this object <a class="reference internal"href=../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations title=nilearn.regions.Parcellations><code class="xref py py-class docutils literal notranslate"><span class=pre>nilearn.regions.Parcellations</span></code></a> as well as two algorithms tailored to more specific usecases:</p><ul class=simple><li><p><a class="reference internal"href=../modules/generated/nilearn.regions.ReNA.html#nilearn.regions.ReNA title=nilearn.regions.ReNA><code class="xref py py-class docutils literal notranslate"><span class=pre>nilearn.regions.ReNA</span></code></a> is a quicker alternative to Ward with a small loss of precision, it is ideal to downsize the number of voxels by 10 quickly.</p></li><li><p>Hierarchical KMeans is useful to obtain a small number of clusters after spatial smoothing, that will be better balanced than with Kmeans.</p></li></ul><p>All these algorithms are showcased in a full code example : <a class="reference internal"href=../auto_examples/03_connectivity/plot_data_driven_parcellations.html#sphx-glr-auto-examples-03-connectivity-plot-data-driven-parcellations-py><span class="std std-ref">here</span></a>. Below, we focus on explaining the principle of Ward.</p></div><div class=line-block><div class=line><br></div></div><p><strong>Compute a connectivity matrix</strong> Before applying Ward’s method, we compute a spatial neighborhood matrix, aka connectivity matrix. This is useful to constrain clusters to form contiguous parcels (see <a class="reference external"href=http://scikit-learn.org/stable/modules/clustering.html#adding-connectivity-constraints>the scikit-learn documentation</a>)</p><p>This is done from the mask computed by the masker: a niimg from which we extract a numpy array and then the connectivity matrix.</p><p><strong>Ward clustering principle</strong> Ward’s algorithm is a hierarchical clustering algorithm: it recursively merges voxels, then clusters that have similar signal (parameters, measurements or time courses).</p><p><strong>Caching</strong> In practice the implementation of Ward clustering first computes a tree of possible merges, and then, given a requested number of clusters, breaks apart the tree at the right level.</p><p>As the tree is independent of the number of clusters, we can rely on caching to speed things up when varying the number of clusters. In Wards clustering, the <em>memory</em> parameter is used to cache the computed component tree. You can give it either a <em>joblib.Memory</em> instance or the name of a directory used for caching.</p><div class="admonition note"><p class=admonition-title>Note</p><p>The Ward clustering computing 1000 parcels runs typically in about 10 seconds. Admittedly, this is very fast.</p></div><div class="admonition note"><p class=admonition-title>Note</p><p>The steps detailed above such as computing connectivity matrix for Ward, caching and clustering are all implemented within the <a class="reference internal"href=../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations title=nilearn.regions.Parcellations><code class="xref py py-class docutils literal notranslate"><span class=pre>nilearn.regions.Parcellations</span></code></a> object.</p></div><div class="admonition seealso"><p class=admonition-title>See also</p><ul class=simple><li><p>A function <a class="reference internal"href=../modules/generated/nilearn.regions.connected_label_regions.html#nilearn.regions.connected_label_regions title=nilearn.regions.connected_label_regions><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.regions.connected_label_regions</span></code></a> which can be useful to break down connected components into regions. For instance, clusters defined using KMeans whereas it is not necessary for Ward clustering due to its spatial connectivity.</p></li></ul></div></div><div class=section id=using-and-visualizing-the-resulting-parcellation><h2><span class=section-number>3.5.3. </span>Using and visualizing the resulting parcellation<a title="Permalink to this headline"class=headerlink href=#using-and-visualizing-the-resulting-parcellation>¶</a></h2><div class=section id=visualizing-the-parcellation><h3><span class=section-number>3.5.3.1. </span>Visualizing the parcellation<a title="Permalink to this headline"class=headerlink href=#visualizing-the-parcellation>¶</a></h3><p>The labels of the parcellation are found in the <cite>labels_img_</cite> attribute of the <a class="reference internal"href=../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations title=nilearn.regions.Parcellations><code class="xref py py-class docutils literal notranslate"><span class=pre>nilearn.regions.Parcellations</span></code></a> object after fitting it to the data using <em>ward.fit</em>. We directly use the result for visualization.</p><p>To visualize the clusters, we assign random colors to each cluster for the labels visualization.</p><div class="figure align-center"><a class="reference external image-reference"href=../auto_examples/03_connectivity/plot_data_driven_parcellations.html><img alt=../_images/sphx_glr_plot_data_driven_parcellations_001.png src=../_images/sphx_glr_plot_data_driven_parcellations_001.png style=width:352px;height:208px></a></div></div><div class=section id=compressed-representation><h3><span class=section-number>3.5.3.2. </span>Compressed representation<a title="Permalink to this headline"class=headerlink href=#compressed-representation>¶</a></h3><p>The clustering can be used to transform the data into a smaller representation, taking the average on each parcel:</p><ul class=simple><li><p>call <em>ward.transform</em> to obtain the mean value of each cluster (for each scan)</p></li><li><p>call <em>ward.inverse_transform</em> on the previous result to turn it back into the masked picture shape</p></li></ul><p><a class="reference external"href=../auto_examples/03_connectivity/plot_data_driven_parcellations.html><img alt=left_img src=../_images/sphx_glr_plot_data_driven_parcellations_002.png style=width:49%></a> <a class="reference external"href=../auto_examples/03_connectivity/plot_data_driven_parcellations.html><img alt=right_img src=../_images/sphx_glr_plot_data_driven_parcellations_003.png style=width:49%></a></p><p>We can see that using only 2000 parcels, the original image is well approximated.</p><div class=line-block><div class=line><br></div></div><div class=topic><p class=topic-title><strong>Example code</strong></p><p>All the steps discussed in this section can be seen implemented in <a class="reference internal"href=../auto_examples/03_connectivity/plot_data_driven_parcellations.html#sphx-glr-auto-examples-03-connectivity-plot-data-driven-parcellations-py><span class="std std-ref">a full code example</span></a>.</p></div></div></div></div><div class=clearer></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>3.5. Clustering to parcellate the brain in regions</a><ul><li><a class="reference internal"href=#data-loading-movie-watching-data>3.5.1. Data loading: movie-watching data</a></li><li><a class="reference internal"href=#applying-clustering>3.5.2. Applying clustering</a></li><li><a class="reference internal"href=#using-and-visualizing-the-resulting-parcellation>3.5.3. Using and visualizing the resulting parcellation</a><ul><li><a class="reference internal"href=#visualizing-the-parcellation>3.5.3.1. Visualizing the parcellation</a></li><li><a class="reference internal"href=#compressed-representation>3.5.3.2. Compressed representation</a></li></ul></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=region_extraction.html><span class=section-number>3.4. </span>Region Extraction for better brain parcellations</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=../plotting/index.html><span class=section-number>4. </span>Plotting brain images</a></p><div id=searchbox role=search style=display:none><h3 id=searchlabel>Quick search</h3><div class=searchformwrapper><form action=../search.html class=search><input aria-labelledby=searchlabel name=q><input type=submit value=Go></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2022. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 4.0.2. <span style=padding-left:5ex> <a href=../_sources/connectivity/parcellating.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>