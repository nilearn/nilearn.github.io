<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1.0 name=viewport><meta content="8. Reference documentation: all nilearn functions"property=og:title><meta content=website property=og:type><meta content=https://nilearn.github.io/modules/reference.html property=og:url><meta content=Nilearn property=og:site_name><meta content="This is the class and function reference of nilearn. Please refer to the user guide for more information and usage examples. List of modules: nilearn.connectome: Functional Connectivity, nilearn.da..."property=og:description><meta content=https://nilearn.github.io/_static/nilearn-logo.png property=og:image><meta content=Nilearn property=og:image:alt><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../_static/pygments.css rel=stylesheet><link href=../_static/nature.css rel=stylesheet><link href=../_static/copybutton.css rel=stylesheet><link href=../_static/sg_gallery.css rel=stylesheet><link href=../_static/sg_gallery-binder.css rel=stylesheet><link href=../_static/sg_gallery-dataframe.css rel=stylesheet><link href=../_static/sg_gallery-rendered-html.css rel=stylesheet><script data-url_root=../ id=documentation_options src=../_static/documentation_options.js></script><script src=../_static/jquery.js></script><script src=../_static/underscore.js></script><script src=../_static/doctools.js></script><script src=../_static/clipboard.min.js></script><script src=../_static/copybutton.js></script><link rel="shortcut icon"href=../_static/favicon.ico><link href=../search.html rel=search title=Search><link title="8.1.1. nilearn.connectome.ConnectivityMeasure"href=generated/nilearn.connectome.ConnectivityMeasure.html rel=next><link title="7.2. Downloading statistical maps from the Neurovault repository"href=../building_blocks/neurovault.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script><body><div id=logo-banner><div class=logo><a href=../index.html> <img alt="Nilearn logo"border=0 src=../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=##module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../py-modindex.html>modules</a></li><li class=right><a title="8.1.1. nilearn.connectome.ConnectivityMeasure"accesskey=N href=generated/nilearn.connectome.ConnectivityMeasure.html>next</a> |</li><li class=right><a title="7.2. Downloading statistical maps from the Neurovault repository"accesskey=P href=../building_blocks/neurovault.html>previous</a> |</li><li><a href=../index.html>Nilearn Home</a> | </li><li><a href=../user_guide.html>User Guide</a> | </li><li><a href=../auto_examples/index.html>Examples</a> | </li><li><a href=#>Reference</a> | </li><li id=navbar-about><a href=../authors.html>About</a>| </li><li><a href=../glossary.html>Glossary</a>| </li><li><a href=../bibliography.html>Bibliography</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a accesskey=U href=../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-this"><a href>Nilearn: Statistical Analysis for NeuroImaging in Python</a></li></ul></div></div><div class=stable-banner>This is the <em>stable</em> documentation for the latest release of Nilearn, the current development version is available <a href=https://nilearn.github.io/dev/index.html>here</a>.</div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class=section id=reference-documentation-all-nilearn-functions><h1><span class=section-number>8. </span>Reference documentation: all nilearn functions<a title="Permalink to this headline"class=headerlink href=#reference-documentation-all-nilearn-functions>¶</a></h1><p>This is the class and function reference of nilearn. Please refer to the <a class="reference internal"href=../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for more information and usage examples.</p><div class="contents local topic"id=list-of-modules><p class=topic-title><strong>List of modules</strong></p><ul class=simple><li><p><a class="reference internal"href=#module-nilearn.connectome id=id4><a class="reference internal"href=#module-nilearn.connectome title=nilearn.connectome><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.connectome</span></code></a>: Functional Connectivity</a></p></li><li><p><a class="reference internal"href=#module-nilearn.datasets id=id5><a class="reference internal"href=#module-nilearn.datasets title=nilearn.datasets><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.datasets</span></code></a>: Automatic Dataset Fetching</a></p> <ul><li><p><a class="reference internal"href=#templates id=id6>Templates</a></p></li><li><p><a class="reference internal"href=#atlases id=id7>Atlases</a></p></li><li><p><a class="reference internal"href=#preprocessed-datasets id=id8>Preprocessed datasets</a></p></li><li><p><a class="reference internal"href=#statistical-maps-derivatives id=id9>Statistical maps/derivatives</a></p></li><li><p><a class="reference internal"href=#general-functions id=id10>General functions</a></p></li></ul></li><li><p><a class="reference internal"href=#module-nilearn.decoding id=id11><a class="reference internal"href=#module-nilearn.decoding title=nilearn.decoding><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.decoding</span></code></a>: Decoding</a></p></li><li><p><a class="reference internal"href=#module-nilearn.decomposition id=id12><a class="reference internal"href=#module-nilearn.decomposition title=nilearn.decomposition><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.decomposition</span></code></a>: Multivariate Decompositions</a></p></li><li><p><a class="reference internal"href=#module-nilearn.image id=id13><a class="reference internal"href=#module-nilearn.image title=nilearn.image><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.image</span></code></a>: Image Processing and Resampling Utilities</a></p></li><li><p><a class="reference internal"href=#module-nilearn.interfaces id=id14><a class="reference internal"href=#module-nilearn.interfaces title=nilearn.interfaces><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.interfaces</span></code></a>: Loading components from interfaces</a></p> <ul><li><p><a class="reference internal"href=#module-nilearn.interfaces.bids id=id15><a class="reference internal"href=#module-nilearn.interfaces.bids title=nilearn.interfaces.bids><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.interfaces.bids</span></code></a></a></p></li><li><p><a class="reference internal"href=#module-nilearn.interfaces.fmriprep id=id16><a class="reference internal"href=#module-nilearn.interfaces.fmriprep title=nilearn.interfaces.fmriprep><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.interfaces.fmriprep</span></code></a></a></p></li><li><p><a class="reference internal"href=#module-nilearn.interfaces.fsl id=id17><a class="reference internal"href=#module-nilearn.interfaces.fsl title=nilearn.interfaces.fsl><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.interfaces.fsl</span></code></a></a></p></li></ul></li><li><p><a class="reference internal"href=#module-nilearn.maskers id=id18><a class="reference internal"href=#module-nilearn.maskers title=nilearn.maskers><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.maskers</span></code></a>: Extracting Signals from Brain Images</a></p></li><li><p><a class="reference internal"href=#module-nilearn.masking id=id19><a class="reference internal"href=#module-nilearn.masking title=nilearn.masking><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.masking</span></code></a>: Data Masking Utilities</a></p></li><li><p><a class="reference internal"href=#module-nilearn.regions id=id20><a class="reference internal"href=#module-nilearn.regions title=nilearn.regions><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.regions</span></code></a>: Operating on Regions</a></p></li><li><p><a class="reference internal"href=#module-nilearn.mass_univariate id=id21><a class="reference internal"href=#module-nilearn.mass_univariate title=nilearn.mass_univariate><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.mass_univariate</span></code></a>: Mass-Univariate Analysis</a></p></li><li><p><a class="reference internal"href=#module-nilearn.plotting id=id22><a class="reference internal"href=#module-nilearn.plotting title=nilearn.plotting><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.plotting</span></code></a>: Plotting Brain Data</a></p> <ul><li><p><a class="reference internal"href=#module-nilearn.plotting.displays id=id23><a class="reference internal"href=#module-nilearn.plotting.displays title=nilearn.plotting.displays><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.plotting.displays</span></code></a>: Interacting with figures</a></p></li></ul></li><li><p><a class="reference internal"href=#module-nilearn.signal id=id24><a class="reference internal"href=#module-nilearn.signal title=nilearn.signal><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.signal</span></code></a>: Preprocessing Time Series</a></p></li><li><p><a class="reference internal"href=#module-nilearn.glm id=id25><a class="reference internal"href=#module-nilearn.glm title=nilearn.glm><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.glm</span></code></a>: Generalized Linear Models</a></p> <ul><li><p><a class="reference internal"href=#module-nilearn.glm.first_level id=id26><a class="reference internal"href=#module-nilearn.glm.first_level title=nilearn.glm.first_level><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.glm.first_level</span></code></a></a></p></li><li><p><a class="reference internal"href=#module-nilearn.glm.second_level id=id27><a class="reference internal"href=#module-nilearn.glm.second_level title=nilearn.glm.second_level><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.glm.second_level</span></code></a></a></p></li></ul></li><li><p><a class="reference internal"href=#module-nilearn.reporting id=id28><a class="reference internal"href=#module-nilearn.reporting title=nilearn.reporting><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.reporting</span></code></a>: Reporting Functions</a></p></li><li><p><a class="reference internal"href=#module-nilearn.surface id=id29><a class="reference internal"href=#module-nilearn.surface title=nilearn.surface><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.surface</span></code></a>: Manipulating Surface Data</a></p></li></ul></div><div class=section id=module-nilearn.connectome><span id=nilearn-connectome-functional-connectivity></span><span id=connectome-ref></span><h2><a class=toc-backref href=#id4><span class=section-number>8.1. </span><a class="reference internal"href=#module-nilearn.connectome title=nilearn.connectome><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.connectome</span></code></a>: Functional Connectivity</a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.connectome>¶</a></h2><p>Tools for computing functional connectivity matrices and also implementation of algorithm for sparse multi subjects learning of Gaussian graphical models.</p><p><strong>Classes</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.connectome.ConnectivityMeasure.html#nilearn.connectome.ConnectivityMeasure title=nilearn.connectome.ConnectivityMeasure><code class="xref py py-obj docutils literal notranslate"><span class=pre>ConnectivityMeasure</span></code></a>([cov_estimator, kind, …])</p></td><td><p>A class that computes different kinds of functional connectivity matrices.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.connectome.GroupSparseCovariance.html#nilearn.connectome.GroupSparseCovariance title=nilearn.connectome.GroupSparseCovariance><code class="xref py py-obj docutils literal notranslate"><span class=pre>GroupSparseCovariance</span></code></a>([alpha, tol, …])</p></td><td><p>Covariance and precision matrix estimator.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.connectome.GroupSparseCovarianceCV.html#nilearn.connectome.GroupSparseCovarianceCV title=nilearn.connectome.GroupSparseCovarianceCV><code class="xref py py-obj docutils literal notranslate"><span class=pre>GroupSparseCovarianceCV</span></code></a>([alphas, …])</p></td><td><p>Sparse inverse covariance w/ cross-validated choice of the parameter.</p></td></tr></tbody></table><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.connectome.sym_matrix_to_vec.html#nilearn.connectome.sym_matrix_to_vec title=nilearn.connectome.sym_matrix_to_vec><code class="xref py py-obj docutils literal notranslate"><span class=pre>sym_matrix_to_vec</span></code></a>(symmetric[, discard_diagonal])</p></td><td><p>Return the flattened lower triangular part of an array.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.connectome.vec_to_sym_matrix.html#nilearn.connectome.vec_to_sym_matrix title=nilearn.connectome.vec_to_sym_matrix><code class="xref py py-obj docutils literal notranslate"><span class=pre>vec_to_sym_matrix</span></code></a>(vec[, diagonal])</p></td><td><p>Return the symmetric matrix given its flattened lower triangular part.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.connectome.group_sparse_covariance.html#nilearn.connectome.group_sparse_covariance title=nilearn.connectome.group_sparse_covariance><code class="xref py py-obj docutils literal notranslate"><span class=pre>group_sparse_covariance</span></code></a>(subjects, alpha[, …])</p></td><td><p>Compute sparse precision matrices and covariance matrices.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.connectome.cov_to_corr.html#nilearn.connectome.cov_to_corr title=nilearn.connectome.cov_to_corr><code class="xref py py-obj docutils literal notranslate"><span class=pre>cov_to_corr</span></code></a>(covariance)</p></td><td><p>Return correlation matrix for a given covariance matrix.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.connectome.prec_to_partial.html#nilearn.connectome.prec_to_partial title=nilearn.connectome.prec_to_partial><code class="xref py py-obj docutils literal notranslate"><span class=pre>prec_to_partial</span></code></a>(precision)</p></td><td><p>Return partial correlation matrix for a given precision matrix.</p></td></tr></tbody></table></div><div class=section id=module-nilearn.datasets><span id=nilearn-datasets-automatic-dataset-fetching></span><span id=datasets-ref></span><h2><a class=toc-backref href=#id5><span class=section-number>8.2. </span><a class="reference internal"href=#module-nilearn.datasets title=nilearn.datasets><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.datasets</span></code></a>: Automatic Dataset Fetching</a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.datasets>¶</a></h2><p>Helper functions to download NeuroImaging datasets</p><p><strong>User guide:</strong> See the <a class="reference internal"href=../manipulating_images/input_output.html#datasets><span class="std std-ref">Fetching open datasets from Internet</span></a> section for further details.</p><div class=section id=templates><h3><a class=toc-backref href=#id6><span class=section-number>8.2.1. </span>Templates</a><a title="Permalink to this headline"class=headerlink href=#templates>¶</a></h3><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_icbm152_2009.html#nilearn.datasets.fetch_icbm152_2009 title=nilearn.datasets.fetch_icbm152_2009><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_icbm152_2009</span></code></a>([data_dir, url, resume, …])</p></td><td><p>Download and load the ICBM152 template (dated 2009).</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_icbm152_brain_gm_mask.html#nilearn.datasets.fetch_icbm152_brain_gm_mask title=nilearn.datasets.fetch_icbm152_brain_gm_mask><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_icbm152_brain_gm_mask</span></code></a>([data_dir, …])</p></td><td><p>Downloads ICBM152 template first, then loads the ‘gm’ mask.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_surf_fsaverage.html#nilearn.datasets.fetch_surf_fsaverage title=nilearn.datasets.fetch_surf_fsaverage><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_surf_fsaverage</span></code></a>([mesh, data_dir])</p></td><td><p>Download a Freesurfer fsaverage surface.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.load_mni152_brain_mask.html#nilearn.datasets.load_mni152_brain_mask title=nilearn.datasets.load_mni152_brain_mask><code class="xref py py-obj docutils literal notranslate"><span class=pre>load_mni152_brain_mask</span></code></a>([resolution, threshold])</p></td><td><p>Load the MNI152 whole-brain mask.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.load_mni152_gm_mask.html#nilearn.datasets.load_mni152_gm_mask title=nilearn.datasets.load_mni152_gm_mask><code class="xref py py-obj docutils literal notranslate"><span class=pre>load_mni152_gm_mask</span></code></a>([resolution, threshold, …])</p></td><td><p>Load the MNI152 grey-matter mask.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.load_mni152_gm_template.html#nilearn.datasets.load_mni152_gm_template title=nilearn.datasets.load_mni152_gm_template><code class="xref py py-obj docutils literal notranslate"><span class=pre>load_mni152_gm_template</span></code></a>([resolution])</p></td><td><p>Load the MNI152 grey-matter template.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.load_mni152_template.html#nilearn.datasets.load_mni152_template title=nilearn.datasets.load_mni152_template><code class="xref py py-obj docutils literal notranslate"><span class=pre>load_mni152_template</span></code></a>([resolution])</p></td><td><p>Load the MNI152 skullstripped T1 template.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.load_mni152_wm_mask.html#nilearn.datasets.load_mni152_wm_mask title=nilearn.datasets.load_mni152_wm_mask><code class="xref py py-obj docutils literal notranslate"><span class=pre>load_mni152_wm_mask</span></code></a>([resolution, threshold, …])</p></td><td><p>Load the MNI152 white-matter mask.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.load_mni152_wm_template.html#nilearn.datasets.load_mni152_wm_template title=nilearn.datasets.load_mni152_wm_template><code class="xref py py-obj docutils literal notranslate"><span class=pre>load_mni152_wm_template</span></code></a>([resolution])</p></td><td><p>Load the MNI152 white-matter template.</p></td></tr></tbody></table></div><div class=section id=atlases><h3><a class=toc-backref href=#id7><span class=section-number>8.2.2. </span>Atlases</a><a title="Permalink to this headline"class=headerlink href=#atlases>¶</a></h3><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_atlas_aal.html#nilearn.datasets.fetch_atlas_aal title=nilearn.datasets.fetch_atlas_aal><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_atlas_aal</span></code></a>([version, data_dir, url, …])</p></td><td><p>Downloads and returns the AAL template for SPM 12.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_atlas_allen_2011.html#nilearn.datasets.fetch_atlas_allen_2011 title=nilearn.datasets.fetch_atlas_allen_2011><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_atlas_allen_2011</span></code></a>([data_dir, url, …])</p></td><td><p>Download and return file names for the Allen and MIALAB <a class="reference internal"href=../glossary.html#term-ICA><span class="xref std std-term">ICA</span></a> <a class="reference internal"href=../glossary.html#term-Probabilistic-atlas><span class="xref std std-term">Probabilistic atlas</span></a> (dated 2011).</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_atlas_basc_multiscale_2015.html#nilearn.datasets.fetch_atlas_basc_multiscale_2015 title=nilearn.datasets.fetch_atlas_basc_multiscale_2015><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_atlas_basc_multiscale_2015</span></code></a>([version, …])</p></td><td><p>Downloads and loads multiscale functional brain parcellations.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_atlas_craddock_2012.html#nilearn.datasets.fetch_atlas_craddock_2012 title=nilearn.datasets.fetch_atlas_craddock_2012><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_atlas_craddock_2012</span></code></a>([data_dir, url, …])</p></td><td><p>Download and return file names for the Craddock 2012 parcellation.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_atlas_destrieux_2009.html#nilearn.datasets.fetch_atlas_destrieux_2009 title=nilearn.datasets.fetch_atlas_destrieux_2009><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_atlas_destrieux_2009</span></code></a>([lateralized, …])</p></td><td><p>Download and load the Destrieux cortical <a class="reference internal"href=../glossary.html#term-Deterministic-atlas><span class="xref std std-term">deterministic atlas</span></a> (dated 2009).</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_atlas_difumo.html#nilearn.datasets.fetch_atlas_difumo title=nilearn.datasets.fetch_atlas_difumo><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_atlas_difumo</span></code></a>([dimension, …])</p></td><td><p>Fetch DiFuMo brain atlas.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_atlas_harvard_oxford.html#nilearn.datasets.fetch_atlas_harvard_oxford title=nilearn.datasets.fetch_atlas_harvard_oxford><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_atlas_harvard_oxford</span></code></a>(atlas_name[, …])</p></td><td><p>Load Harvard-Oxford parcellations from FSL.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_atlas_juelich.html#nilearn.datasets.fetch_atlas_juelich title=nilearn.datasets.fetch_atlas_juelich><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_atlas_juelich</span></code></a>(atlas_name[, data_dir, …])</p></td><td><p>Load Juelich parcellations from FSL.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_atlas_msdl.html#nilearn.datasets.fetch_atlas_msdl title=nilearn.datasets.fetch_atlas_msdl><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_atlas_msdl</span></code></a>([data_dir, url, resume, …])</p></td><td><p>Download and load the MSDL brain <a class="reference internal"href=../glossary.html#term-Probabilistic-atlas><span class="xref std std-term">Probabilistic atlas</span></a>.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_atlas_pauli_2017.html#nilearn.datasets.fetch_atlas_pauli_2017 title=nilearn.datasets.fetch_atlas_pauli_2017><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_atlas_pauli_2017</span></code></a>([version, data_dir, …])</p></td><td><p>Download the Pauli et al. (2017) atlas.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_atlas_schaefer_2018.html#nilearn.datasets.fetch_atlas_schaefer_2018 title=nilearn.datasets.fetch_atlas_schaefer_2018><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_atlas_schaefer_2018</span></code></a>([n_rois, …])</p></td><td><p>Download and return file names for the Schaefer 2018 parcellation.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_atlas_smith_2009.html#nilearn.datasets.fetch_atlas_smith_2009 title=nilearn.datasets.fetch_atlas_smith_2009><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_atlas_smith_2009</span></code></a>([data_dir, mirror, …])</p></td><td><p>Download and load the Smith <a class="reference internal"href=../glossary.html#term-ICA><span class="xref std std-term">ICA</span></a> and BrainMap <a class="reference internal"href=../glossary.html#term-Probabilistic-atlas><span class="xref std std-term">Probabilistic atlas</span></a> (2009).</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_atlas_surf_destrieux.html#nilearn.datasets.fetch_atlas_surf_destrieux title=nilearn.datasets.fetch_atlas_surf_destrieux><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_atlas_surf_destrieux</span></code></a>([data_dir, url, …])</p></td><td><p>Download and load Destrieux et al, 2010 cortical <a class="reference internal"href=../glossary.html#term-Deterministic-atlas><span class="xref std std-term">Deterministic atlas</span></a>.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_atlas_talairach.html#nilearn.datasets.fetch_atlas_talairach title=nilearn.datasets.fetch_atlas_talairach><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_atlas_talairach</span></code></a>(level_name[, …])</p></td><td><p>Download the Talairach <a class="reference internal"href=../glossary.html#term-Deterministic-atlas><span class="xref std std-term">Deterministic atlas</span></a>.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_atlas_yeo_2011.html#nilearn.datasets.fetch_atlas_yeo_2011 title=nilearn.datasets.fetch_atlas_yeo_2011><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_atlas_yeo_2011</span></code></a>([data_dir, url, …])</p></td><td><p>Download and return file names for the Yeo 2011 parcellation.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_coords_dosenbach_2010.html#nilearn.datasets.fetch_coords_dosenbach_2010 title=nilearn.datasets.fetch_coords_dosenbach_2010><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_coords_dosenbach_2010</span></code></a>([…])</p></td><td><p>Load the Dosenbach et al. 160 ROIs.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_coords_power_2011.html#nilearn.datasets.fetch_coords_power_2011 title=nilearn.datasets.fetch_coords_power_2011><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_coords_power_2011</span></code></a>([legacy_format])</p></td><td><p>Download and load the Power et al. brain atlas composed of 264 ROIs.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_coords_seitzman_2018.html#nilearn.datasets.fetch_coords_seitzman_2018 title=nilearn.datasets.fetch_coords_seitzman_2018><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_coords_seitzman_2018</span></code></a>([…])</p></td><td><p>Load the Seitzman et al. 300 ROIs.</p></td></tr></tbody></table></div><div class=section id=preprocessed-datasets><h3><a class=toc-backref href=#id8><span class=section-number>8.2.3. </span>Preprocessed datasets</a><a title="Permalink to this headline"class=headerlink href=#preprocessed-datasets>¶</a></h3><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_abide_pcp.html#nilearn.datasets.fetch_abide_pcp title=nilearn.datasets.fetch_abide_pcp><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_abide_pcp</span></code></a>([data_dir, n_subjects, …])</p></td><td><p>Fetch ABIDE dataset.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_adhd.html#nilearn.datasets.fetch_adhd title=nilearn.datasets.fetch_adhd><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_adhd</span></code></a>([n_subjects, data_dir, url, …])</p></td><td><p>Download and load the ADHD resting-state dataset.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_bids_langloc_dataset.html#nilearn.datasets.fetch_bids_langloc_dataset title=nilearn.datasets.fetch_bids_langloc_dataset><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_bids_langloc_dataset</span></code></a>([data_dir, verbose])</p></td><td><p>Download language localizer example <a class="reference internal"href=../glossary.html#term-BIDS><span class="xref std std-term">bids</span></a> dataset.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_development_fmri.html#nilearn.datasets.fetch_development_fmri title=nilearn.datasets.fetch_development_fmri><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_development_fmri</span></code></a>([n_subjects, …])</p></td><td><p>Fetch movie watching based brain development dataset (fMRI)</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_fiac_first_level.html#nilearn.datasets.fetch_fiac_first_level title=nilearn.datasets.fetch_fiac_first_level><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_fiac_first_level</span></code></a>([data_dir, verbose])</p></td><td><p>Download a first-level fiac fMRI dataset (2 sessions)</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_haxby.html#nilearn.datasets.fetch_haxby title=nilearn.datasets.fetch_haxby><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_haxby</span></code></a>([data_dir, subjects, …])</p></td><td><p>Download and loads complete haxby dataset.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_language_localizer_demo_dataset.html#nilearn.datasets.fetch_language_localizer_demo_dataset title=nilearn.datasets.fetch_language_localizer_demo_dataset><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_language_localizer_demo_dataset</span></code></a>([…])</p></td><td><p>Download language localizer demo dataset.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_localizer_first_level.html#nilearn.datasets.fetch_localizer_first_level title=nilearn.datasets.fetch_localizer_first_level><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_localizer_first_level</span></code></a>([data_dir, verbose])</p></td><td><p>Download a first-level localizer fMRI dataset</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_miyawaki2008.html#nilearn.datasets.fetch_miyawaki2008 title=nilearn.datasets.fetch_miyawaki2008><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_miyawaki2008</span></code></a>([data_dir, url, resume, …])</p></td><td><p>Download and loads Miyawaki et al. 2008 dataset (153MB).</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_openneuro_dataset_index.html#nilearn.datasets.fetch_openneuro_dataset_index title=nilearn.datasets.fetch_openneuro_dataset_index><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_openneuro_dataset_index</span></code></a>([data_dir, …])</p></td><td><p>Download a file with OpenNeuro <a class="reference internal"href=../glossary.html#term-BIDS><span class="xref std std-term">BIDS</span></a> dataset index.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_spm_auditory.html#nilearn.datasets.fetch_spm_auditory title=nilearn.datasets.fetch_spm_auditory><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_spm_auditory</span></code></a>([data_dir, data_name, …])</p></td><td><p>Function to fetch SPM auditory single-subject data.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_spm_multimodal_fmri.html#nilearn.datasets.fetch_spm_multimodal_fmri title=nilearn.datasets.fetch_spm_multimodal_fmri><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_spm_multimodal_fmri</span></code></a>([data_dir, …])</p></td><td><p>Fetcher for Multi-modal Face Dataset.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_surf_nki_enhanced.html#nilearn.datasets.fetch_surf_nki_enhanced title=nilearn.datasets.fetch_surf_nki_enhanced><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_surf_nki_enhanced</span></code></a>([n_subjects, …])</p></td><td><p>Download and load the NKI enhanced resting-state dataset, preprocessed and projected to the fsaverage5 space surface.</p></td></tr></tbody></table></div><div class=section id=statistical-maps-derivatives><h3><a class=toc-backref href=#id9><span class=section-number>8.2.4. </span>Statistical maps/derivatives</a><a title="Permalink to this headline"class=headerlink href=#statistical-maps-derivatives>¶</a></h3><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_localizer_button_task.html#nilearn.datasets.fetch_localizer_button_task title=nilearn.datasets.fetch_localizer_button_task><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_localizer_button_task</span></code></a>([data_dir, url, …])</p></td><td><p>Fetch left vs right button press contrast maps from the localizer.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_localizer_calculation_task.html#nilearn.datasets.fetch_localizer_calculation_task title=nilearn.datasets.fetch_localizer_calculation_task><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_localizer_calculation_task</span></code></a>([…])</p></td><td><p>Fetch calculation task contrast maps from the localizer.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_localizer_contrasts.html#nilearn.datasets.fetch_localizer_contrasts title=nilearn.datasets.fetch_localizer_contrasts><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_localizer_contrasts</span></code></a>(contrasts[, …])</p></td><td><p>Download and load Brainomics/Localizer dataset (94 subjects).</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_megatrawls_netmats.html#nilearn.datasets.fetch_megatrawls_netmats title=nilearn.datasets.fetch_megatrawls_netmats><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_megatrawls_netmats</span></code></a>([dimensionality, …])</p></td><td><p>Downloads and returns Network Matrices data from MegaTrawls release in HCP.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_mixed_gambles.html#nilearn.datasets.fetch_mixed_gambles title=nilearn.datasets.fetch_mixed_gambles><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_mixed_gambles</span></code></a>([n_subjects, data_dir, …])</p></td><td><p>Fetch Jimura “mixed gambles” dataset.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_oasis_vbm.html#nilearn.datasets.fetch_oasis_vbm title=nilearn.datasets.fetch_oasis_vbm><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_oasis_vbm</span></code></a>([n_subjects, …])</p></td><td><p>Download and load Oasis “cross-sectional MRI” dataset (416 subjects).</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_neurovault_auditory_computation_task.html#nilearn.datasets.fetch_neurovault_auditory_computation_task title=nilearn.datasets.fetch_neurovault_auditory_computation_task><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_neurovault_auditory_computation_task</span></code></a>([…])</p></td><td><p>Fetch a contrast map from NeuroVault showing the effect of mental subtraction upon auditory instructions</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_neurovault_motor_task.html#nilearn.datasets.fetch_neurovault_motor_task title=nilearn.datasets.fetch_neurovault_motor_task><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_neurovault_motor_task</span></code></a>([data_dir, verbose])</p></td><td><p>Fetch left vs right button press group contrast map from NeuroVault.</p></td></tr></tbody></table></div><div class=section id=general-functions><h3><a class=toc-backref href=#id10><span class=section-number>8.2.5. </span>General functions</a><a title="Permalink to this headline"class=headerlink href=#general-functions>¶</a></h3><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_neurovault.html#nilearn.datasets.fetch_neurovault title=nilearn.datasets.fetch_neurovault><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_neurovault</span></code></a>([max_images, …])</p></td><td><p>Download data from neurovault.org that match certain criteria.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_neurovault_ids.html#nilearn.datasets.fetch_neurovault_ids title=nilearn.datasets.fetch_neurovault_ids><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_neurovault_ids</span></code></a>([collection_ids, …])</p></td><td><p>Download specific images and collections from neurovault.org.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.fetch_openneuro_dataset.html#nilearn.datasets.fetch_openneuro_dataset title=nilearn.datasets.fetch_openneuro_dataset><code class="xref py py-obj docutils literal notranslate"><span class=pre>fetch_openneuro_dataset</span></code></a>([urls, data_dir, …])</p></td><td><p>Download OpenNeuro <a class="reference internal"href=../glossary.html#term-BIDS><span class="xref std std-term">BIDS</span></a> dataset.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.get_data_dirs.html#nilearn.datasets.get_data_dirs title=nilearn.datasets.get_data_dirs><code class="xref py py-obj docutils literal notranslate"><span class=pre>get_data_dirs</span></code></a>([data_dir])</p></td><td><p>Returns the directories in which nilearn looks for data.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.datasets.patch_openneuro_dataset.html#nilearn.datasets.patch_openneuro_dataset title=nilearn.datasets.patch_openneuro_dataset><code class="xref py py-obj docutils literal notranslate"><span class=pre>patch_openneuro_dataset</span></code></a>(file_list)</p></td><td><p>Add symlinks for files not named according to latest <a class="reference internal"href=../glossary.html#term-BIDS><span class="xref std std-term">BIDS</span></a> conventions.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.datasets.select_from_index.html#nilearn.datasets.select_from_index title=nilearn.datasets.select_from_index><code class="xref py py-obj docutils literal notranslate"><span class=pre>select_from_index</span></code></a>(urls[, inclusion_filters, …])</p></td><td><p>Select subset of urls with given filters.</p></td></tr></tbody></table></div></div><div class=section id=module-nilearn.decoding><span id=nilearn-decoding-decoding></span><span id=decoding-ref></span><h2><a class=toc-backref href=#id11><span class=section-number>8.3. </span><a class="reference internal"href=#module-nilearn.decoding title=nilearn.decoding><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.decoding</span></code></a>: Decoding</a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.decoding>¶</a></h2><p>Decoding tools and algorithms.</p><p><strong>Classes</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.decoding.Decoder.html#nilearn.decoding.Decoder title=nilearn.decoding.Decoder><code class="xref py py-obj docutils literal notranslate"><span class=pre>Decoder</span></code></a>([estimator, mask, cv, param_grid, …])</p></td><td><p>A wrapper for popular classification strategies in neuroimaging.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.decoding.DecoderRegressor.html#nilearn.decoding.DecoderRegressor title=nilearn.decoding.DecoderRegressor><code class="xref py py-obj docutils literal notranslate"><span class=pre>DecoderRegressor</span></code></a>([estimator, mask, cv, …])</p></td><td><p>A wrapper for popular regression strategies in neuroimaging.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.decoding.FREMClassifier.html#nilearn.decoding.FREMClassifier title=nilearn.decoding.FREMClassifier><code class="xref py py-obj docutils literal notranslate"><span class=pre>FREMClassifier</span></code></a>([estimator, mask, cv, …])</p></td><td><p>State of the art decoding scheme applied to usual classifiers.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.decoding.FREMRegressor.html#nilearn.decoding.FREMRegressor title=nilearn.decoding.FREMRegressor><code class="xref py py-obj docutils literal notranslate"><span class=pre>FREMRegressor</span></code></a>([estimator, mask, cv, …])</p></td><td><p>State of the art decoding scheme applied to usual regression estimators.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.decoding.SpaceNetClassifier.html#nilearn.decoding.SpaceNetClassifier title=nilearn.decoding.SpaceNetClassifier><code class="xref py py-obj docutils literal notranslate"><span class=pre>SpaceNetClassifier</span></code></a>([penalty, loss, …])</p></td><td><p>Classification learners with sparsity and spatial priors.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.decoding.SpaceNetRegressor.html#nilearn.decoding.SpaceNetRegressor title=nilearn.decoding.SpaceNetRegressor><code class="xref py py-obj docutils literal notranslate"><span class=pre>SpaceNetRegressor</span></code></a>([penalty, l1_ratios, …])</p></td><td><p>Regression learners with sparsity and spatial priors.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.decoding.SearchLight.html#nilearn.decoding.SearchLight title=nilearn.decoding.SearchLight><code class="xref py py-obj docutils literal notranslate"><span class=pre>SearchLight</span></code></a>(mask_img[, process_mask_img, …])</p></td><td><p>Implement search_light analysis using an arbitrary type of classifier.</p></td></tr></tbody></table></div><div class=section id=module-nilearn.decomposition><span id=nilearn-decomposition-multivariate-decompositions></span><span id=decomposition-ref></span><h2><a class=toc-backref href=#id12><span class=section-number>8.4. </span><a class="reference internal"href=#module-nilearn.decomposition title=nilearn.decomposition><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.decomposition</span></code></a>: Multivariate Decompositions</a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.decomposition>¶</a></h2><p>The <a class="reference internal"href=#module-nilearn.decomposition title=nilearn.decomposition><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.decomposition</span></code></a> module includes a subject level variant of the ICA called Canonical ICA.</p><p><strong>Classes</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.decomposition.CanICA.html#nilearn.decomposition.CanICA title=nilearn.decomposition.CanICA><code class="xref py py-obj docutils literal notranslate"><span class=pre>CanICA</span></code></a>([mask, n_components, smoothing_fwhm, …])</p></td><td><p>Perform Canonical Independent Component Analysis <a class="reference internal"href=generated/nilearn.decomposition.CanICA.html#r637c2563345c-1 id=id1><span>[R637c2563345c-1]</span></a> <a class="reference internal"href=generated/nilearn.decomposition.CanICA.html#r637c2563345c-2 id=id2><span>[R637c2563345c-2]</span></a>.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.decomposition.DictLearning.html#nilearn.decomposition.DictLearning title=nilearn.decomposition.DictLearning><code class="xref py py-obj docutils literal notranslate"><span class=pre>DictLearning</span></code></a>([n_components, n_epochs, …])</p></td><td><p>Perform a map learning algorithm based on spatial component sparsity, over a <a class="reference internal"href=../glossary.html#term-CanICA><span class="xref std std-term">CanICA</span></a> initialization <a class="reference internal"href=generated/nilearn.decomposition.DictLearning.html#rd0eec3116114-1 id=id3><span>[Rd0eec3116114-1]</span></a>.</p></td></tr></tbody></table></div><div class=section id=module-nilearn.image><span id=nilearn-image-image-processing-and-resampling-utilities></span><span id=image-ref></span><h2><a class=toc-backref href=#id13><span class=section-number>8.5. </span><a class="reference internal"href=#module-nilearn.image title=nilearn.image><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.image</span></code></a>: Image Processing and Resampling Utilities</a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.image>¶</a></h2><p>Mathematical operations working on Niimg-like objects like a (3+)D block of data, and an affine.</p><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.image.binarize_img.html#nilearn.image.binarize_img title=nilearn.image.binarize_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>binarize_img</span></code></a>(img[, threshold, mask_img])</p></td><td><p>Binarize an image such that its values are either 0 or 1.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.image.clean_img.html#nilearn.image.clean_img title=nilearn.image.clean_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>clean_img</span></code></a>(imgs[, runs, detrend, …])</p></td><td><p>Improve SNR on masked fMRI signals.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.image.concat_imgs.html#nilearn.image.concat_imgs title=nilearn.image.concat_imgs><code class="xref py py-obj docutils literal notranslate"><span class=pre>concat_imgs</span></code></a>(niimgs[, dtype, ensure_ndim, …])</p></td><td><p>Concatenate a list of 3D/4D niimgs of varying lengths.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.image.coord_transform.html#nilearn.image.coord_transform title=nilearn.image.coord_transform><code class="xref py py-obj docutils literal notranslate"><span class=pre>coord_transform</span></code></a>(x, y, z, affine)</p></td><td><p>Convert the x, y, z coordinates from one image space to another</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.image.copy_img.html#nilearn.image.copy_img title=nilearn.image.copy_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>copy_img</span></code></a>(img)</p></td><td><p>Copy an image to a nibabel.Nifti1Image.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.image.crop_img.html#nilearn.image.crop_img title=nilearn.image.crop_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>crop_img</span></code></a>(img[, rtol, copy, pad, return_offset])</p></td><td><p>Crops an image as much as possible.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.image.get_data.html#nilearn.image.get_data title=nilearn.image.get_data><code class="xref py py-obj docutils literal notranslate"><span class=pre>get_data</span></code></a>(img)</p></td><td><p>Get the image data as a <a class="reference external"title="(in NumPy v1.22)"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray><code class="xref py py-class docutils literal notranslate"><span class=pre>numpy.ndarray</span></code></a>.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.image.high_variance_confounds.html#nilearn.image.high_variance_confounds title=nilearn.image.high_variance_confounds><code class="xref py py-obj docutils literal notranslate"><span class=pre>high_variance_confounds</span></code></a>(imgs[, n_confounds, …])</p></td><td><p>Return confounds signals extracted from input signals with highest variance.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.image.index_img.html#nilearn.image.index_img title=nilearn.image.index_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>index_img</span></code></a>(imgs, index)</p></td><td><p>Indexes into a 4D Niimg-like object in the fourth dimension.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.image.iter_img.html#nilearn.image.iter_img title=nilearn.image.iter_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>iter_img</span></code></a>(imgs)</p></td><td><p>Iterates over a 4D Niimg-like object in the fourth dimension.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.image.largest_connected_component_img.html#nilearn.image.largest_connected_component_img title=nilearn.image.largest_connected_component_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>largest_connected_component_img</span></code></a>(imgs)</p></td><td><p>Return the largest connected component of an image or list of images.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.image.load_img.html#nilearn.image.load_img title=nilearn.image.load_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>load_img</span></code></a>(img[, wildcards, dtype])</p></td><td><p>Load a Niimg-like object from filenames or list of filenames.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.image.math_img.html#nilearn.image.math_img title=nilearn.image.math_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>math_img</span></code></a>(formula, **imgs)</p></td><td><p>Interpret a numpy based string formula using niimg in named parameters.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.image.mean_img.html#nilearn.image.mean_img title=nilearn.image.mean_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>mean_img</span></code></a>(imgs[, target_affine, …])</p></td><td><p>Compute the mean of the images over time or the 4th dimension.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.image.new_img_like.html#nilearn.image.new_img_like title=nilearn.image.new_img_like><code class="xref py py-obj docutils literal notranslate"><span class=pre>new_img_like</span></code></a>(ref_niimg, data[, affine, …])</p></td><td><p>Create a new image of the same class as the reference image</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.image.resample_img.html#nilearn.image.resample_img title=nilearn.image.resample_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>resample_img</span></code></a>(img[, target_affine, …])</p></td><td><p>Resample a Niimg-like object</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.image.resample_to_img.html#nilearn.image.resample_to_img title=nilearn.image.resample_to_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>resample_to_img</span></code></a>(source_img, target_img[, …])</p></td><td><p>Resample a Niimg-like source image on a target Niimg-like image (no registration is performed: the image should already be aligned).</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.image.reorder_img.html#nilearn.image.reorder_img title=nilearn.image.reorder_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>reorder_img</span></code></a>(img[, resample])</p></td><td><p>Returns an image with the affine diagonal (by permuting axes).</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.image.smooth_img.html#nilearn.image.smooth_img title=nilearn.image.smooth_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>smooth_img</span></code></a>(imgs, fwhm)</p></td><td><p>Smooth images by applying a Gaussian filter.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.image.swap_img_hemispheres.html#nilearn.image.swap_img_hemispheres title=nilearn.image.swap_img_hemispheres><code class="xref py py-obj docutils literal notranslate"><span class=pre>swap_img_hemispheres</span></code></a>(img)</p></td><td><p>Performs swapping of hemispheres in the indicated NIfTI image.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.image.threshold_img.html#nilearn.image.threshold_img title=nilearn.image.threshold_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>threshold_img</span></code></a>(img, threshold[, …])</p></td><td><p>Threshold the given input image, mostly statistical or atlas images.</p></td></tr></tbody></table></div><div class=section id=module-nilearn.interfaces><span id=nilearn-interfaces-loading-components-from-interfaces></span><span id=interfaces-ref></span><h2><a class=toc-backref href=#id14><span class=section-number>8.6. </span><a class="reference internal"href=#module-nilearn.interfaces title=nilearn.interfaces><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.interfaces</span></code></a>: Loading components from interfaces</a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.interfaces>¶</a></h2><p>Interfaces for Nilearn.</p><div class=section id=module-nilearn.interfaces.bids><span id=nilearn-interfaces-bids></span><h3><a class=toc-backref href=#id15><span class=section-number>8.6.1. </span><a class="reference internal"href=#module-nilearn.interfaces.bids title=nilearn.interfaces.bids><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.interfaces.bids</span></code></a></a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.interfaces.bids>¶</a></h3><p>Functions for working with BIDS datasets.</p><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.interfaces.bids.get_bids_files.html#nilearn.interfaces.bids.get_bids_files title=nilearn.interfaces.bids.get_bids_files><code class="xref py py-obj docutils literal notranslate"><span class=pre>get_bids_files</span></code></a>(main_path[, file_tag, …])</p></td><td><p>Search for files in a <a class="reference internal"href=../glossary.html#term-BIDS><span class="xref std std-term">BIDS</span></a> dataset following given constraints.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.interfaces.bids.parse_bids_filename.html#nilearn.interfaces.bids.parse_bids_filename title=nilearn.interfaces.bids.parse_bids_filename><code class="xref py py-obj docutils literal notranslate"><span class=pre>parse_bids_filename</span></code></a>(img_path)</p></td><td><p>Return dictionary with parsed information from file path.</p></td></tr></tbody></table></div><div class=section id=module-nilearn.interfaces.fmriprep><span id=nilearn-interfaces-fmriprep></span><h3><a class=toc-backref href=#id16><span class=section-number>8.6.2. </span><a class="reference internal"href=#module-nilearn.interfaces.fmriprep title=nilearn.interfaces.fmriprep><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.interfaces.fmriprep</span></code></a></a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.interfaces.fmriprep>¶</a></h3><p>The <a class="reference internal"href=#module-nilearn.interfaces.fmriprep title=nilearn.interfaces.fmriprep><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.interfaces.fmriprep</span></code></a> module includes tools to preprocess neuroimaging data and access <a class="reference internal"href=../glossary.html#term-fMRIPrep><span class="xref std std-term">fMRIPrep</span></a> generated confounds.</p><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.interfaces.fmriprep.load_confounds.html#nilearn.interfaces.fmriprep.load_confounds title=nilearn.interfaces.fmriprep.load_confounds><code class="xref py py-obj docutils literal notranslate"><span class=pre>load_confounds</span></code></a>(img_files[, strategy, …])</p></td><td><p>Use confounds from <a class="reference internal"href=../glossary.html#term-fMRIPrep><span class="xref std std-term">fMRIPrep</span></a>.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.interfaces.fmriprep.load_confounds_strategy.html#nilearn.interfaces.fmriprep.load_confounds_strategy title=nilearn.interfaces.fmriprep.load_confounds_strategy><code class="xref py py-obj docutils literal notranslate"><span class=pre>load_confounds_strategy</span></code></a>(img_files[, …])</p></td><td><p>Use preset strategy to load confounds from <a class="reference internal"href=../glossary.html#term-fMRIPrep><span class="xref std std-term">fMRIPrep</span></a>.</p></td></tr></tbody></table></div><div class=section id=module-nilearn.interfaces.fsl><span id=nilearn-interfaces-fsl></span><h3><a class=toc-backref href=#id17><span class=section-number>8.6.3. </span><a class="reference internal"href=#module-nilearn.interfaces.fsl title=nilearn.interfaces.fsl><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.interfaces.fsl</span></code></a></a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.interfaces.fsl>¶</a></h3><p>Functions for working with the FSL library.</p><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.interfaces.fsl.get_design_from_fslmat.html#nilearn.interfaces.fsl.get_design_from_fslmat title=nilearn.interfaces.fsl.get_design_from_fslmat><code class="xref py py-obj docutils literal notranslate"><span class=pre>get_design_from_fslmat</span></code></a>(fsl_design_matrix_path)</p></td><td><p>Extract design matrix dataframe from FSL mat file.</p></td></tr></tbody></table></div></div><div class=section id=module-nilearn.maskers><span id=nilearn-maskers-extracting-signals-from-brain-images></span><span id=maskers-ref></span><h2><a class=toc-backref href=#id18><span class=section-number>8.7. </span><a class="reference internal"href=#module-nilearn.maskers title=nilearn.maskers><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.maskers</span></code></a>: Extracting Signals from Brain Images</a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.maskers>¶</a></h2><p>The <a class="reference internal"href=#module-nilearn.maskers title=nilearn.maskers><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.maskers</span></code></a> contains masker objects.</p><p><strong>User guide:</strong> See the <a class="reference internal"href=../manipulating_images/masker_objects.html#nifti-masker><span class="std std-ref">NiftiMasker: applying a mask to load time-series</span></a> section for further details.</p><p><strong>Classes</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.maskers.BaseMasker.html#nilearn.maskers.BaseMasker title=nilearn.maskers.BaseMasker><code class="xref py py-obj docutils literal notranslate"><span class=pre>BaseMasker</span></code></a>()</p></td><td><p>Base class for NiftiMaskers.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker title=nilearn.maskers.NiftiMasker><code class="xref py py-obj docutils literal notranslate"><span class=pre>NiftiMasker</span></code></a>([mask_img, runs, …])</p></td><td><p>Applying a mask to extract time-series from Niimg-like objects.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.maskers.MultiNiftiMasker.html#nilearn.maskers.MultiNiftiMasker title=nilearn.maskers.MultiNiftiMasker><code class="xref py py-obj docutils literal notranslate"><span class=pre>MultiNiftiMasker</span></code></a>([mask_img, smoothing_fwhm, …])</p></td><td><p>Class for masking of Niimg-like objects.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.maskers.NiftiLabelsMasker.html#nilearn.maskers.NiftiLabelsMasker title=nilearn.maskers.NiftiLabelsMasker><code class="xref py py-obj docutils literal notranslate"><span class=pre>NiftiLabelsMasker</span></code></a>(labels_img[, labels, …])</p></td><td><p>Class for masking of Niimg-like objects.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.maskers.NiftiMapsMasker.html#nilearn.maskers.NiftiMapsMasker title=nilearn.maskers.NiftiMapsMasker><code class="xref py py-obj docutils literal notranslate"><span class=pre>NiftiMapsMasker</span></code></a>(maps_img[, mask_img, …])</p></td><td><p>Class for masking of Niimg-like objects.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.maskers.NiftiSpheresMasker.html#nilearn.maskers.NiftiSpheresMasker title=nilearn.maskers.NiftiSpheresMasker><code class="xref py py-obj docutils literal notranslate"><span class=pre>NiftiSpheresMasker</span></code></a>(seeds[, radius, …])</p></td><td><p>Class for masking of Niimg-like objects using seeds.</p></td></tr></tbody></table></div><div class=section id=module-nilearn.masking><span id=nilearn-masking-data-masking-utilities></span><span id=masking-ref></span><h2><a class=toc-backref href=#id19><span class=section-number>8.8. </span><a class="reference internal"href=#module-nilearn.masking title=nilearn.masking><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.masking</span></code></a>: Data Masking Utilities</a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.masking>¶</a></h2><p>Utilities to compute and operate on brain masks</p><p><strong>User guide:</strong> See the <a class="reference internal"href=../building_blocks/manual_pipeline.html#masking><span class="std std-ref">Masking the data: from 4D image to 2D array</span></a> section for further details.</p><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.masking.compute_epi_mask.html#nilearn.masking.compute_epi_mask title=nilearn.masking.compute_epi_mask><code class="xref py py-obj docutils literal notranslate"><span class=pre>compute_epi_mask</span></code></a>(epi_img[, lower_cutoff, …])</p></td><td><p>Compute a brain mask from <a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a> data in 3D or 4D <a class="reference external"title="(in NumPy v1.22)"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray><code class="xref py py-class docutils literal notranslate"><span class=pre>numpy.ndarray</span></code></a>.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.masking.compute_multi_epi_mask.html#nilearn.masking.compute_multi_epi_mask title=nilearn.masking.compute_multi_epi_mask><code class="xref py py-obj docutils literal notranslate"><span class=pre>compute_multi_epi_mask</span></code></a>(epi_imgs[, …])</p></td><td><p>Compute a common mask for several sessions or subjects of <a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a> data.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.masking.compute_brain_mask.html#nilearn.masking.compute_brain_mask title=nilearn.masking.compute_brain_mask><code class="xref py py-obj docutils literal notranslate"><span class=pre>compute_brain_mask</span></code></a>(target_img[, threshold, …])</p></td><td><p>Compute the whole-brain, grey-matter or white-matter mask.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.masking.compute_multi_brain_mask.html#nilearn.masking.compute_multi_brain_mask title=nilearn.masking.compute_multi_brain_mask><code class="xref py py-obj docutils literal notranslate"><span class=pre>compute_multi_brain_mask</span></code></a>(target_imgs[, …])</p></td><td><p>Compute the whole-brain, grey-matter or white-matter mask for a list of images.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.masking.compute_background_mask.html#nilearn.masking.compute_background_mask title=nilearn.masking.compute_background_mask><code class="xref py py-obj docutils literal notranslate"><span class=pre>compute_background_mask</span></code></a>(data_imgs[, …])</p></td><td><p>Compute a brain mask for the images by guessing the value of the background from the border of the image.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.masking.compute_multi_background_mask.html#nilearn.masking.compute_multi_background_mask title=nilearn.masking.compute_multi_background_mask><code class="xref py py-obj docutils literal notranslate"><span class=pre>compute_multi_background_mask</span></code></a>(data_imgs[, …])</p></td><td><p>Compute a common mask for several sessions or subjects of data.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.masking.intersect_masks.html#nilearn.masking.intersect_masks title=nilearn.masking.intersect_masks><code class="xref py py-obj docutils literal notranslate"><span class=pre>intersect_masks</span></code></a>(mask_imgs[, threshold, …])</p></td><td><p>Compute intersection of several masks.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.masking.apply_mask.html#nilearn.masking.apply_mask title=nilearn.masking.apply_mask><code class="xref py py-obj docutils literal notranslate"><span class=pre>apply_mask</span></code></a>(imgs, mask_img[, dtype, …])</p></td><td><p>Extract signals from images using specified mask.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.masking.unmask.html#nilearn.masking.unmask title=nilearn.masking.unmask><code class="xref py py-obj docutils literal notranslate"><span class=pre>unmask</span></code></a>(X, mask_img[, order])</p></td><td><p>Take masked data and bring them back into 3D/4D.</p></td></tr></tbody></table></div><div class=section id=module-nilearn.regions><span id=nilearn-regions-operating-on-regions></span><h2><a class=toc-backref href=#id20><span class=section-number>8.9. </span><a class="reference internal"href=#module-nilearn.regions title=nilearn.regions><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.regions</span></code></a>: Operating on Regions</a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.regions>¶</a></h2><p>The <a class="reference internal"href=#module-nilearn.regions title=nilearn.regions><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.regions</span></code></a> class module includes region extraction procedure on a 4D statistical/atlas maps and its function.</p><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.regions.connected_regions.html#nilearn.regions.connected_regions title=nilearn.regions.connected_regions><code class="xref py py-obj docutils literal notranslate"><span class=pre>connected_regions</span></code></a>(maps_img[, …])</p></td><td><p>Extraction of brain connected regions into separate regions.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.regions.connected_label_regions.html#nilearn.regions.connected_label_regions title=nilearn.regions.connected_label_regions><code class="xref py py-obj docutils literal notranslate"><span class=pre>connected_label_regions</span></code></a>(labels_img[, …])</p></td><td><p>Extract connected regions from a brain atlas image defined by labels (integers).</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.regions.img_to_signals_labels.html#nilearn.regions.img_to_signals_labels title=nilearn.regions.img_to_signals_labels><code class="xref py py-obj docutils literal notranslate"><span class=pre>img_to_signals_labels</span></code></a>(imgs, labels_img[, …])</p></td><td><p>Extract region signals from image.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.regions.signals_to_img_labels.html#nilearn.regions.signals_to_img_labels title=nilearn.regions.signals_to_img_labels><code class="xref py py-obj docutils literal notranslate"><span class=pre>signals_to_img_labels</span></code></a>(signals, labels_img[, …])</p></td><td><p>Create image from region signals defined as labels.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.regions.img_to_signals_maps.html#nilearn.regions.img_to_signals_maps title=nilearn.regions.img_to_signals_maps><code class="xref py py-obj docutils literal notranslate"><span class=pre>img_to_signals_maps</span></code></a>(imgs, maps_img[, mask_img])</p></td><td><p>Extract region signals from image.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.regions.signals_to_img_maps.html#nilearn.regions.signals_to_img_maps title=nilearn.regions.signals_to_img_maps><code class="xref py py-obj docutils literal notranslate"><span class=pre>signals_to_img_maps</span></code></a>(region_signals, maps_img)</p></td><td><p>Create image from region signals defined as maps.</p></td></tr></tbody></table><p><strong>Classes</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.regions.RegionExtractor.html#nilearn.regions.RegionExtractor title=nilearn.regions.RegionExtractor><code class="xref py py-obj docutils literal notranslate"><span class=pre>RegionExtractor</span></code></a>(maps_img[, mask_img, …])</p></td><td><p>Class for brain region extraction.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations title=nilearn.regions.Parcellations><code class="xref py py-obj docutils literal notranslate"><span class=pre>Parcellations</span></code></a>(method[, n_parcels, …])</p></td><td><p>Learn <a class="reference internal"href=../glossary.html#term-parcellation><span class="xref std std-term">parcellations</span></a> on <a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a> images.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.regions.ReNA.html#nilearn.regions.ReNA title=nilearn.regions.ReNA><code class="xref py py-obj docutils literal notranslate"><span class=pre>ReNA</span></code></a>(mask_img[, n_clusters, scaling, …])</p></td><td><p>Recursive Neighbor Agglomeration (<a class="reference internal"href=../glossary.html#term-ReNA><span class="xref std std-term">ReNA</span></a>): Recursively merges the pair of clusters according to 1-nearest neighbors criterion.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.regions.HierarchicalKMeans.html#nilearn.regions.HierarchicalKMeans title=nilearn.regions.HierarchicalKMeans><code class="xref py py-obj docutils literal notranslate"><span class=pre>HierarchicalKMeans</span></code></a>(n_clusters[, init, …])</p></td><td><p>Hierarchical KMeans: First clusterize the samples into big clusters.</p></td></tr></tbody></table></div><div class=section id=module-nilearn.mass_univariate><span id=nilearn-mass-univariate-mass-univariate-analysis></span><h2><a class=toc-backref href=#id21><span class=section-number>8.10. </span><a class="reference internal"href=#module-nilearn.mass_univariate title=nilearn.mass_univariate><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.mass_univariate</span></code></a>: Mass-Univariate Analysis</a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.mass_univariate>¶</a></h2><p>Defines a Massively Univariate Linear Model estimated with OLS and permutation test</p><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.mass_univariate.permuted_ols.html#nilearn.mass_univariate.permuted_ols title=nilearn.mass_univariate.permuted_ols><code class="xref py py-obj docutils literal notranslate"><span class=pre>permuted_ols</span></code></a>(tested_vars, target_vars[, …])</p></td><td><p>Massively univariate group analysis with permuted OLS.</p></td></tr></tbody></table></div><div class=section id=module-nilearn.plotting><span id=nilearn-plotting-plotting-brain-data></span><span id=plotting-ref></span><h2><a class=toc-backref href=#id22><span class=section-number>8.11. </span><a class="reference internal"href=#module-nilearn.plotting title=nilearn.plotting><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.plotting</span></code></a>: Plotting Brain Data</a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.plotting>¶</a></h2><p>Plotting code for nilearn</p><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.find_cut_slices.html#nilearn.plotting.find_cut_slices title=nilearn.plotting.find_cut_slices><code class="xref py py-obj docutils literal notranslate"><span class=pre>find_cut_slices</span></code></a>(img[, direction, n_cuts, …])</p></td><td><p>Find ‘good’ cross-section slicing positions along a given axis.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.find_xyz_cut_coords.html#nilearn.plotting.find_xyz_cut_coords title=nilearn.plotting.find_xyz_cut_coords><code class="xref py py-obj docutils literal notranslate"><span class=pre>find_xyz_cut_coords</span></code></a>(img[, mask_img, …])</p></td><td><p>Find the center of the largest activation connected component.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.find_parcellation_cut_coords.html#nilearn.plotting.find_parcellation_cut_coords title=nilearn.plotting.find_parcellation_cut_coords><code class="xref py py-obj docutils literal notranslate"><span class=pre>find_parcellation_cut_coords</span></code></a>(labels_img[, …])</p></td><td><p>Return coordinates of center of mass of 3D parcellation atlas.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.find_probabilistic_atlas_cut_coords.html#nilearn.plotting.find_probabilistic_atlas_cut_coords title=nilearn.plotting.find_probabilistic_atlas_cut_coords><code class="xref py py-obj docutils literal notranslate"><span class=pre>find_probabilistic_atlas_cut_coords</span></code></a>(maps_img)</p></td><td><p>Return coordinates of center probabilistic atlas 4D image.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_anat.html#nilearn.plotting.plot_anat title=nilearn.plotting.plot_anat><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_anat</span></code></a>([anat_img, cut_coords, …])</p></td><td><p>Plot cuts of an anatomical image (by default 3 cuts: Frontal, Axial, and Lateral)</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img title=nilearn.plotting.plot_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_img</span></code></a>(img[, cut_coords, output_file, …])</p></td><td><p>Plot cuts of a given image (by default Frontal, Axial, and Lateral)</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_epi.html#nilearn.plotting.plot_epi title=nilearn.plotting.plot_epi><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_epi</span></code></a>([epi_img, cut_coords, output_file, …])</p></td><td><p>Plot cuts of an EPI image (by default 3 cuts: Frontal, Axial, and Lateral)</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_matrix.html#nilearn.plotting.plot_matrix title=nilearn.plotting.plot_matrix><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_matrix</span></code></a>(mat[, title, labels, figure, …])</p></td><td><p>Plot the given matrix.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_roi.html#nilearn.plotting.plot_roi title=nilearn.plotting.plot_roi><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_roi</span></code></a>(roi_img[, bg_img, cut_coords, …])</p></td><td><p>Plot cuts of an ROI/mask image (by default 3 cuts: Frontal, Axial, and Lateral)</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map title=nilearn.plotting.plot_stat_map><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_stat_map</span></code></a>(stat_map_img[, bg_img, …])</p></td><td><p>Plot cuts of an ROI/mask image (by default 3 cuts: Frontal, Axial, and Lateral)</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain title=nilearn.plotting.plot_glass_brain><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_glass_brain</span></code></a>(stat_map_img[, …])</p></td><td><p>Plot 2d projections of an ROI/mask image (by default 3 projections: Frontal, Axial, and Lateral).</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_connectome.html#nilearn.plotting.plot_connectome title=nilearn.plotting.plot_connectome><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_connectome</span></code></a>(adjacency_matrix, node_coords)</p></td><td><p>Plot connectome on top of the brain glass schematics.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_markers.html#nilearn.plotting.plot_markers title=nilearn.plotting.plot_markers><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_markers</span></code></a>(node_values, node_coords[, …])</p></td><td><p>Plot network nodes (markers) on top of the brain glass schematics.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_prob_atlas.html#nilearn.plotting.plot_prob_atlas title=nilearn.plotting.plot_prob_atlas><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_prob_atlas</span></code></a>(maps_img[, bg_img, …])</p></td><td><p>Plot the probabilistic atlases onto the anatomical image by default MNI template</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_carpet.html#nilearn.plotting.plot_carpet title=nilearn.plotting.plot_carpet><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_carpet</span></code></a>(img[, mask_img, mask_labels, …])</p></td><td><p>Plot an image representation of voxel intensities across time.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_surf.html#nilearn.plotting.plot_surf title=nilearn.plotting.plot_surf><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_surf</span></code></a>(surf_mesh[, surf_map, bg_map, …])</p></td><td><p>Plotting of surfaces with optional background and data</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_surf_roi.html#nilearn.plotting.plot_surf_roi title=nilearn.plotting.plot_surf_roi><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_surf_roi</span></code></a>(surf_mesh, roi_map[, bg_map, …])</p></td><td><p>Plotting ROI on a surface mesh with optional background</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_surf_contours.html#nilearn.plotting.plot_surf_contours title=nilearn.plotting.plot_surf_contours><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_surf_contours</span></code></a>(surf_mesh, roi_map[, …])</p></td><td><p>Plotting contours of ROIs on a surface, optionally over a statistical map.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_surf_stat_map.html#nilearn.plotting.plot_surf_stat_map title=nilearn.plotting.plot_surf_stat_map><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_surf_stat_map</span></code></a>(surf_mesh, stat_map[, …])</p></td><td><p>Plotting a stats map on a surface mesh with optional background</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_img_on_surf.html#nilearn.plotting.plot_img_on_surf title=nilearn.plotting.plot_img_on_surf><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_img_on_surf</span></code></a>(stat_map[, surf_mesh, …])</p></td><td><p>Convenience function to plot multiple views of plot_surf_stat_map in a single figure.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_img_comparison.html#nilearn.plotting.plot_img_comparison title=nilearn.plotting.plot_img_comparison><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_img_comparison</span></code></a>(ref_imgs, src_imgs, masker)</p></td><td><p>Creates plots to compare two lists of images and measure correlation.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_design_matrix.html#nilearn.plotting.plot_design_matrix title=nilearn.plotting.plot_design_matrix><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_design_matrix</span></code></a>(design_matrix[, rescale, …])</p></td><td><p>Plot a design matrix provided as a <a class="reference external"title="(in pandas v1.4.2)"href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame><code class="xref py py-class docutils literal notranslate"><span class=pre>pandas.DataFrame</span></code></a>.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_event.html#nilearn.plotting.plot_event title=nilearn.plotting.plot_event><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_event</span></code></a>(model_event[, cmap, output_file])</p></td><td><p>Creates plot for event visualization.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.plot_contrast_matrix.html#nilearn.plotting.plot_contrast_matrix title=nilearn.plotting.plot_contrast_matrix><code class="xref py py-obj docutils literal notranslate"><span class=pre>plot_contrast_matrix</span></code></a>(contrast_def, design_matrix)</p></td><td><p>Creates plot for contrast definition.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.view_surf.html#nilearn.plotting.view_surf title=nilearn.plotting.view_surf><code class="xref py py-obj docutils literal notranslate"><span class=pre>view_surf</span></code></a>(surf_mesh[, surf_map, bg_map, …])</p></td><td><p>Insert a surface plot of a surface map into an HTML page.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.view_img_on_surf.html#nilearn.plotting.view_img_on_surf title=nilearn.plotting.view_img_on_surf><code class="xref py py-obj docutils literal notranslate"><span class=pre>view_img_on_surf</span></code></a>(stat_map_img[, surf_mesh, …])</p></td><td><p>Insert a surface plot of a statistical map into an HTML page.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.view_connectome.html#nilearn.plotting.view_connectome title=nilearn.plotting.view_connectome><code class="xref py py-obj docutils literal notranslate"><span class=pre>view_connectome</span></code></a>(adjacency_matrix, node_coords)</p></td><td><p>Insert a 3d plot of a connectome into an HTML page.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.view_markers.html#nilearn.plotting.view_markers title=nilearn.plotting.view_markers><code class="xref py py-obj docutils literal notranslate"><span class=pre>view_markers</span></code></a>(marker_coords[, marker_color, …])</p></td><td><p>Insert a 3d plot of markers in a brain into an HTML page.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.view_img.html#nilearn.plotting.view_img title=nilearn.plotting.view_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>view_img</span></code></a>(stat_map_img[, bg_img, cut_coords, …])</p></td><td><p>Interactive html viewer of a statistical map, with optional background.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.show.html#nilearn.plotting.show title=nilearn.plotting.show><code class="xref py py-obj docutils literal notranslate"><span class=pre>show</span></code></a>()</p></td><td><p>Show all the figures generated by nilearn and/or matplotlib.</p></td></tr></tbody></table><div class=section id=module-nilearn.plotting.displays><span id=nilearn-plotting-displays-interacting-with-figures></span><h3><a class=toc-backref href=#id23><span class=section-number>8.11.31. </span><a class="reference internal"href=#module-nilearn.plotting.displays title=nilearn.plotting.displays><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.plotting.displays</span></code></a>: Interacting with figures</a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.plotting.displays>¶</a></h3><p>Display objects and utilities.</p><p>These objects are returned by plotting functions from the <a class="reference internal"href=#module-nilearn.plotting title=nilearn.plotting><code class="xref py py-mod docutils literal notranslate"><span class=pre>plotting</span></code></a> module.</p><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.get_projector.html#nilearn.plotting.displays.get_projector title=nilearn.plotting.displays.get_projector><code class="xref py py-obj docutils literal notranslate"><span class=pre>get_projector</span></code></a>(display_mode)</p></td><td><p>Retrieve a projector from a given display mode.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.get_slicer.html#nilearn.plotting.displays.get_slicer title=nilearn.plotting.displays.get_slicer><code class="xref py py-obj docutils literal notranslate"><span class=pre>get_slicer</span></code></a>(display_mode)</p></td><td><p>Retrieve a slicer from a given display mode.</p></td></tr></tbody></table><p><strong>Classes</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.OrthoProjector.html#nilearn.plotting.displays.OrthoProjector title=nilearn.plotting.displays.OrthoProjector><code class="xref py py-obj docutils literal notranslate"><span class=pre>OrthoProjector</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>A class to create linked axes for plotting orthogonal projections of 3D maps.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.XZProjector.html#nilearn.plotting.displays.XZProjector title=nilearn.plotting.displays.XZProjector><code class="xref py py-obj docutils literal notranslate"><span class=pre>XZProjector</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>XZProjector</span></code> class enables to combine sagittal and axial views on the same figure through 2D projections with <a class="reference internal"href=generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain title=nilearn.plotting.plot_glass_brain><code class="xref py py-func docutils literal notranslate"><span class=pre>plot_glass_brain</span></code></a>.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.YZProjector.html#nilearn.plotting.displays.YZProjector title=nilearn.plotting.displays.YZProjector><code class="xref py py-obj docutils literal notranslate"><span class=pre>YZProjector</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>YZProjector</span></code> class enables to combine coronal and axial views on the same figure through 2D projections with <a class="reference internal"href=generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain title=nilearn.plotting.plot_glass_brain><code class="xref py py-func docutils literal notranslate"><span class=pre>plot_glass_brain</span></code></a>.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.YXProjector.html#nilearn.plotting.displays.YXProjector title=nilearn.plotting.displays.YXProjector><code class="xref py py-obj docutils literal notranslate"><span class=pre>YXProjector</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>YXProjector</span></code> class enables to combine coronal and sagittal views on the same figure through 2D projections with <a class="reference internal"href=generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain title=nilearn.plotting.plot_glass_brain><code class="xref py py-func docutils literal notranslate"><span class=pre>plot_glass_brain</span></code></a>.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.XProjector.html#nilearn.plotting.displays.XProjector title=nilearn.plotting.displays.XProjector><code class="xref py py-obj docutils literal notranslate"><span class=pre>XProjector</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>XProjector</span></code> class enables sagittal visualization through 2D projections with <a class="reference internal"href=generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain title=nilearn.plotting.plot_glass_brain><code class="xref py py-func docutils literal notranslate"><span class=pre>plot_glass_brain</span></code></a>.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.YProjector.html#nilearn.plotting.displays.YProjector title=nilearn.plotting.displays.YProjector><code class="xref py py-obj docutils literal notranslate"><span class=pre>YProjector</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>YProjector</span></code> class enables coronal visualization through 2D projections with <a class="reference internal"href=generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain title=nilearn.plotting.plot_glass_brain><code class="xref py py-func docutils literal notranslate"><span class=pre>plot_glass_brain</span></code></a>.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.ZProjector.html#nilearn.plotting.displays.ZProjector title=nilearn.plotting.displays.ZProjector><code class="xref py py-obj docutils literal notranslate"><span class=pre>ZProjector</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>ZProjector</span></code> class enables axial visualization through 2D projections with <a class="reference internal"href=generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain title=nilearn.plotting.plot_glass_brain><code class="xref py py-func docutils literal notranslate"><span class=pre>plot_glass_brain</span></code></a>.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.LZRYProjector.html#nilearn.plotting.displays.LZRYProjector title=nilearn.plotting.displays.LZRYProjector><code class="xref py py-obj docutils literal notranslate"><span class=pre>LZRYProjector</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>LZRYProjector</span></code> class enables ? visualization on the same figure through 2D projections with <a class="reference internal"href=generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain title=nilearn.plotting.plot_glass_brain><code class="xref py py-func docutils literal notranslate"><span class=pre>plot_glass_brain</span></code></a>.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.LYRZProjector.html#nilearn.plotting.displays.LYRZProjector title=nilearn.plotting.displays.LYRZProjector><code class="xref py py-obj docutils literal notranslate"><span class=pre>LYRZProjector</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>LYRZProjector</span></code> class enables ? visualization on the same figure through 2D projections with <a class="reference internal"href=generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain title=nilearn.plotting.plot_glass_brain><code class="xref py py-func docutils literal notranslate"><span class=pre>plot_glass_brain</span></code></a>.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.LYRProjector.html#nilearn.plotting.displays.LYRProjector title=nilearn.plotting.displays.LYRProjector><code class="xref py py-obj docutils literal notranslate"><span class=pre>LYRProjector</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>LYRProjector</span></code> class enables ? visualization on the same figure through 2D projections with <a class="reference internal"href=generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain title=nilearn.plotting.plot_glass_brain><code class="xref py py-func docutils literal notranslate"><span class=pre>plot_glass_brain</span></code></a>.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.LZRProjector.html#nilearn.plotting.displays.LZRProjector title=nilearn.plotting.displays.LZRProjector><code class="xref py py-obj docutils literal notranslate"><span class=pre>LZRProjector</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>LZRProjector</span></code> class enables hemispheric sagittal visualization on the same figure through 2D projections with <a class="reference internal"href=generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain title=nilearn.plotting.plot_glass_brain><code class="xref py py-func docutils literal notranslate"><span class=pre>plot_glass_brain</span></code></a>.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.LRProjector.html#nilearn.plotting.displays.LRProjector title=nilearn.plotting.displays.LRProjector><code class="xref py py-obj docutils literal notranslate"><span class=pre>LRProjector</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>LRProjector</span></code> class enables left-right visualization on the same figure through 2D projections with <a class="reference internal"href=generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain title=nilearn.plotting.plot_glass_brain><code class="xref py py-func docutils literal notranslate"><span class=pre>plot_glass_brain</span></code></a>.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.LProjector.html#nilearn.plotting.displays.LProjector title=nilearn.plotting.displays.LProjector><code class="xref py py-obj docutils literal notranslate"><span class=pre>LProjector</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>LProjector</span></code> class enables the visualization of left 2D projection with <a class="reference internal"href=generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain title=nilearn.plotting.plot_glass_brain><code class="xref py py-func docutils literal notranslate"><span class=pre>plot_glass_brain</span></code></a>.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.RProjector.html#nilearn.plotting.displays.RProjector title=nilearn.plotting.displays.RProjector><code class="xref py py-obj docutils literal notranslate"><span class=pre>RProjector</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>RProjector</span></code> class enables the visualization of right 2D projection with <a class="reference internal"href=generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain title=nilearn.plotting.plot_glass_brain><code class="xref py py-func docutils literal notranslate"><span class=pre>plot_glass_brain</span></code></a>.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.BaseAxes.html#nilearn.plotting.displays.BaseAxes title=nilearn.plotting.displays.BaseAxes><code class="xref py py-obj docutils literal notranslate"><span class=pre>BaseAxes</span></code></a>(ax, direction, coord)</p></td><td><p>An MPL axis-like object that displays a 2D view of 3D volumes.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.CutAxes.html#nilearn.plotting.displays.CutAxes title=nilearn.plotting.displays.CutAxes><code class="xref py py-obj docutils literal notranslate"><span class=pre>CutAxes</span></code></a>(ax, direction, coord)</p></td><td><p>An MPL axis-like object that displays a cut of 3D volumes.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.GlassBrainAxes.html#nilearn.plotting.displays.GlassBrainAxes title=nilearn.plotting.displays.GlassBrainAxes><code class="xref py py-obj docutils literal notranslate"><span class=pre>GlassBrainAxes</span></code></a>(ax, direction, coord[, plot_abs])</p></td><td><p>An MPL axis-like object that displays a 2D projection of 3D volumes with a schematic view of the brain.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.BaseSlicer.html#nilearn.plotting.displays.BaseSlicer title=nilearn.plotting.displays.BaseSlicer><code class="xref py py-obj docutils literal notranslate"><span class=pre>BaseSlicer</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>BaseSlicer implementation which main purpose is to auto adjust the axes size to the data with different layout of cuts.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.OrthoSlicer.html#nilearn.plotting.displays.OrthoSlicer title=nilearn.plotting.displays.OrthoSlicer><code class="xref py py-obj docutils literal notranslate"><span class=pre>OrthoSlicer</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>A class to create 3 linked axes for plotting orthogonal cuts of 3D maps.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.PlotlySurfaceFigure.html#nilearn.plotting.displays.PlotlySurfaceFigure title=nilearn.plotting.displays.PlotlySurfaceFigure><code class="xref py py-obj docutils literal notranslate"><span class=pre>PlotlySurfaceFigure</span></code></a>([figure, output_file])</p></td><td><p>Implementation of a surface figure obtained with <cite>plotly</cite> engine.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.TiledSlicer.html#nilearn.plotting.displays.TiledSlicer title=nilearn.plotting.displays.TiledSlicer><code class="xref py py-obj docutils literal notranslate"><span class=pre>TiledSlicer</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>A class to create 3 axes for plotting orthogonal cuts of 3D maps, organized in a 2x2 grid.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.MosaicSlicer.html#nilearn.plotting.displays.MosaicSlicer title=nilearn.plotting.displays.MosaicSlicer><code class="xref py py-obj docutils literal notranslate"><span class=pre>MosaicSlicer</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>A class to create 3 <a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/axes_api.html#matplotlib.axes.Axes><code class="xref py py-class docutils literal notranslate"><span class=pre>Axes</span></code></a> for plotting cuts of 3D maps, in multiple rows and columns.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.XZSlicer.html#nilearn.plotting.displays.XZSlicer title=nilearn.plotting.displays.XZSlicer><code class="xref py py-obj docutils literal notranslate"><span class=pre>XZSlicer</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>XZSlicer</span></code> class enables to combine sagittal and axial views on the same figure with plotting functions of Nilearn like <a class="reference internal"href=generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img title=nilearn.plotting.plot_img><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.plotting.plot_img</span></code></a>.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.YZSlicer.html#nilearn.plotting.displays.YZSlicer title=nilearn.plotting.displays.YZSlicer><code class="xref py py-obj docutils literal notranslate"><span class=pre>YZSlicer</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>YZSlicer</span></code> class enables to combine coronal and axial views on the same figure with plotting functions of Nilearn like <a class="reference internal"href=generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img title=nilearn.plotting.plot_img><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.plotting.plot_img</span></code></a>.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.YXSlicer.html#nilearn.plotting.displays.YXSlicer title=nilearn.plotting.displays.YXSlicer><code class="xref py py-obj docutils literal notranslate"><span class=pre>YXSlicer</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>YXSlicer</span></code> class enables to combine coronal and sagittal views on the same figure with plotting functions of Nilearn like <a class="reference internal"href=generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img title=nilearn.plotting.plot_img><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.plotting.plot_img</span></code></a>.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.XSlicer.html#nilearn.plotting.displays.XSlicer title=nilearn.plotting.displays.XSlicer><code class="xref py py-obj docutils literal notranslate"><span class=pre>XSlicer</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>XSlicer</span></code> class enables sagittal visualization with plotting functions of Nilearn like <a class="reference internal"href=generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img title=nilearn.plotting.plot_img><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.plotting.plot_img</span></code></a>.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.YSlicer.html#nilearn.plotting.displays.YSlicer title=nilearn.plotting.displays.YSlicer><code class="xref py py-obj docutils literal notranslate"><span class=pre>YSlicer</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>YSlicer</span></code> class enables coronal visualization with plotting functions of Nilearn like <a class="reference internal"href=generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img title=nilearn.plotting.plot_img><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.plotting.plot_img</span></code></a>.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.plotting.displays.ZSlicer.html#nilearn.plotting.displays.ZSlicer title=nilearn.plotting.displays.ZSlicer><code class="xref py py-obj docutils literal notranslate"><span class=pre>ZSlicer</span></code></a>(cut_coords[, axes, black_bg, …])</p></td><td><p>The <code class="docutils literal notranslate"><span class=pre>ZSlicer</span></code> class enables axial visualization with plotting functions of Nilearn like <a class="reference internal"href=generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img title=nilearn.plotting.plot_img><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.plotting.plot_img</span></code></a>.</p></td></tr></tbody></table></div></div><div class=section id=module-nilearn.signal><span id=nilearn-signal-preprocessing-time-series></span><span id=signal-ref></span><h2><a class=toc-backref href=#id24><span class=section-number>8.12. </span><a class="reference internal"href=#module-nilearn.signal title=nilearn.signal><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.signal</span></code></a>: Preprocessing Time Series</a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.signal>¶</a></h2><p>Preprocessing functions for time series.</p><p>All functions in this module should take X matrices with samples x features</p><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.signal.butterworth.html#nilearn.signal.butterworth title=nilearn.signal.butterworth><code class="xref py py-obj docutils literal notranslate"><span class=pre>butterworth</span></code></a>(signals, sampling_rate[, …])</p></td><td><p>Apply a low-pass, high-pass or band-pass <a class="reference external"href=https://en.wikipedia.org/wiki/Butterworth_filter>Butterworth filter</a>.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.signal.clean.html#nilearn.signal.clean title=nilearn.signal.clean><code class="xref py py-obj docutils literal notranslate"><span class=pre>clean</span></code></a>(signals[, runs, detrend, standardize, …])</p></td><td><p>Improve <a class="reference internal"href=../glossary.html#term-SNR><span class="xref std std-term">SNR</span></a> on masked <a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a> signals.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.signal.high_variance_confounds.html#nilearn.signal.high_variance_confounds title=nilearn.signal.high_variance_confounds><code class="xref py py-obj docutils literal notranslate"><span class=pre>high_variance_confounds</span></code></a>(series[, …])</p></td><td><p>Return confounds time series extracted from series with highest variance.</p></td></tr></tbody></table></div><div class=section id=module-nilearn.glm><span id=nilearn-glm-generalized-linear-models></span><span id=stats-ref></span><h2><a class=toc-backref href=#id25><span class=section-number>8.13. </span><a class="reference internal"href=#module-nilearn.glm title=nilearn.glm><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.glm</span></code></a>: Generalized Linear Models</a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.glm>¶</a></h2><p>Analysing fMRI data using GLMs.</p><dl class=simple><dt>Note that the nilearn.glm module is experimental.</dt><dd><p>It may change in any future (>0.7.0) release of Nilearn.</p></dd></dl><p><strong>Classes</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.glm.Contrast.html#nilearn.glm.Contrast title=nilearn.glm.Contrast><code class="xref py py-obj docutils literal notranslate"><span class=pre>Contrast</span></code></a>(effect, variance[, dim, dof, …])</p></td><td><p>The contrast class handles the estimation of statistical contrasts on a given model: student (t) or Fisher (F).</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.glm.FContrastResults.html#nilearn.glm.FContrastResults title=nilearn.glm.FContrastResults><code class="xref py py-obj docutils literal notranslate"><span class=pre>FContrastResults</span></code></a>(effect, covariance, F, df_num)</p></td><td><p>Results from an F contrast of coefficients in a parametric model.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.glm.TContrastResults.html#nilearn.glm.TContrastResults title=nilearn.glm.TContrastResults><code class="xref py py-obj docutils literal notranslate"><span class=pre>TContrastResults</span></code></a>(t, sd, effect[, df_den])</p></td><td><p>Results from a t contrast of coefficients in a parametric model.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.glm.ARModel.html#nilearn.glm.ARModel title=nilearn.glm.ARModel><code class="xref py py-obj docutils literal notranslate"><span class=pre>ARModel</span></code></a>(design, rho)</p></td><td><p>A regression model with an AR(p) covariance structure.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.glm.OLSModel.html#nilearn.glm.OLSModel title=nilearn.glm.OLSModel><code class="xref py py-obj docutils literal notranslate"><span class=pre>OLSModel</span></code></a>(design)</p></td><td><p>A simple ordinary least squares model.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.glm.LikelihoodModelResults.html#nilearn.glm.LikelihoodModelResults title=nilearn.glm.LikelihoodModelResults><code class="xref py py-obj docutils literal notranslate"><span class=pre>LikelihoodModelResults</span></code></a>(theta, Y, model[, …])</p></td><td><p>Class to contain results from likelihood models.</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.glm.RegressionResults.html#nilearn.glm.RegressionResults title=nilearn.glm.RegressionResults><code class="xref py py-obj docutils literal notranslate"><span class=pre>RegressionResults</span></code></a>(theta, Y, model, …[, …])</p></td><td><p>This class summarizes the fit of a linear regression model.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.glm.SimpleRegressionResults.html#nilearn.glm.SimpleRegressionResults title=nilearn.glm.SimpleRegressionResults><code class="xref py py-obj docutils literal notranslate"><span class=pre>SimpleRegressionResults</span></code></a>(results)</p></td><td><p>This class contains only information of the model fit necessary for contrast computation.</p></td></tr></tbody></table><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.glm.compute_contrast.html#nilearn.glm.compute_contrast title=nilearn.glm.compute_contrast><code class="xref py py-obj docutils literal notranslate"><span class=pre>compute_contrast</span></code></a>(labels, regression_result, …)</p></td><td><p>Compute the specified contrast given an estimated glm</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.glm.compute_fixed_effects.html#nilearn.glm.compute_fixed_effects title=nilearn.glm.compute_fixed_effects><code class="xref py py-obj docutils literal notranslate"><span class=pre>compute_fixed_effects</span></code></a>(contrast_imgs, …[, …])</p></td><td><p>Compute the fixed effects, given images of effects and variance</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.glm.expression_to_contrast_vector.html#nilearn.glm.expression_to_contrast_vector title=nilearn.glm.expression_to_contrast_vector><code class="xref py py-obj docutils literal notranslate"><span class=pre>expression_to_contrast_vector</span></code></a>(expression, …)</p></td><td><p>Converts a string describing a contrast to a contrast vector</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.glm.fdr_threshold.html#nilearn.glm.fdr_threshold title=nilearn.glm.fdr_threshold><code class="xref py py-obj docutils literal notranslate"><span class=pre>fdr_threshold</span></code></a>(z_vals, alpha)</p></td><td><p>Return the Benjamini-Hochberg FDR threshold for the input z_vals</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.glm.cluster_level_inference.html#nilearn.glm.cluster_level_inference title=nilearn.glm.cluster_level_inference><code class="xref py py-obj docutils literal notranslate"><span class=pre>cluster_level_inference</span></code></a>(stat_img[, …])</p></td><td><p>Report the proportion of active voxels for all clusters defined by the input threshold.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.glm.threshold_stats_img.html#nilearn.glm.threshold_stats_img title=nilearn.glm.threshold_stats_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>threshold_stats_img</span></code></a>([stat_img, mask_img, …])</p></td><td><p>Compute the required threshold level and return the thresholded map</p></td></tr></tbody></table><div class=section id=module-nilearn.glm.first_level><span id=nilearn-glm-first-level></span><h3><a class=toc-backref href=#id26><span class=section-number>8.13.15. </span><a class="reference internal"href=#module-nilearn.glm.first_level title=nilearn.glm.first_level><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.glm.first_level</span></code></a></a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.glm.first_level>¶</a></h3><p><strong>Classes</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.glm.first_level.FirstLevelModel.html#nilearn.glm.first_level.FirstLevelModel title=nilearn.glm.first_level.FirstLevelModel><code class="xref py py-obj docutils literal notranslate"><span class=pre>FirstLevelModel</span></code></a>([t_r, slice_time_ref, …])</p></td><td><p>Implementation of the General Linear Model for single session fMRI data.</p></td></tr></tbody></table><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.glm.first_level.check_design_matrix.html#nilearn.glm.first_level.check_design_matrix title=nilearn.glm.first_level.check_design_matrix><code class="xref py py-obj docutils literal notranslate"><span class=pre>check_design_matrix</span></code></a>(design_matrix)</p></td><td><p>Check that the provided DataFrame is indeed a valid design matrix descriptor, and returns a triplet of fields</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.glm.first_level.compute_regressor.html#nilearn.glm.first_level.compute_regressor title=nilearn.glm.first_level.compute_regressor><code class="xref py py-obj docutils literal notranslate"><span class=pre>compute_regressor</span></code></a>(exp_condition, hrf_model, …)</p></td><td><p>This is the main function to convolve regressors with hrf model</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.glm.first_level.first_level_from_bids.html#nilearn.glm.first_level.first_level_from_bids title=nilearn.glm.first_level.first_level_from_bids><code class="xref py py-obj docutils literal notranslate"><span class=pre>first_level_from_bids</span></code></a>(dataset_path, task_label)</p></td><td><p>Create FirstLevelModel objects and fit arguments from a BIDS dataset.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.glm.first_level.glover_dispersion_derivative.html#nilearn.glm.first_level.glover_dispersion_derivative title=nilearn.glm.first_level.glover_dispersion_derivative><code class="xref py py-obj docutils literal notranslate"><span class=pre>glover_dispersion_derivative</span></code></a>(tr[, …])</p></td><td><p>Implementation of the Glover dispersion derivative hrf model</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.glm.first_level.glover_hrf.html#nilearn.glm.first_level.glover_hrf title=nilearn.glm.first_level.glover_hrf><code class="xref py py-obj docutils literal notranslate"><span class=pre>glover_hrf</span></code></a>(tr[, oversampling, time_length, …])</p></td><td><p>Implementation of the Glover hrf model</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.glm.first_level.glover_time_derivative.html#nilearn.glm.first_level.glover_time_derivative title=nilearn.glm.first_level.glover_time_derivative><code class="xref py py-obj docutils literal notranslate"><span class=pre>glover_time_derivative</span></code></a>(tr[, oversampling, …])</p></td><td><p>Implementation of the Glover time derivative hrf (dhrf) model</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.glm.first_level.make_first_level_design_matrix.html#nilearn.glm.first_level.make_first_level_design_matrix title=nilearn.glm.first_level.make_first_level_design_matrix><code class="xref py py-obj docutils literal notranslate"><span class=pre>make_first_level_design_matrix</span></code></a>(frame_times)</p></td><td><p>Generate a design matrix from the input parameters</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.glm.first_level.mean_scaling.html#nilearn.glm.first_level.mean_scaling title=nilearn.glm.first_level.mean_scaling><code class="xref py py-obj docutils literal notranslate"><span class=pre>mean_scaling</span></code></a>(Y[, axis])</p></td><td><p>Scaling of the data to have percent of baseline change along the specified axis</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.glm.first_level.run_glm.html#nilearn.glm.first_level.run_glm title=nilearn.glm.first_level.run_glm><code class="xref py py-obj docutils literal notranslate"><span class=pre>run_glm</span></code></a>(Y, X[, noise_model, bins, n_jobs, …])</p></td><td><p>GLM fit for an fMRI data matrix</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.glm.first_level.spm_dispersion_derivative.html#nilearn.glm.first_level.spm_dispersion_derivative title=nilearn.glm.first_level.spm_dispersion_derivative><code class="xref py py-obj docutils literal notranslate"><span class=pre>spm_dispersion_derivative</span></code></a>(tr[, …])</p></td><td><p>Implementation of the SPM dispersion derivative hrf model</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.glm.first_level.spm_hrf.html#nilearn.glm.first_level.spm_hrf title=nilearn.glm.first_level.spm_hrf><code class="xref py py-obj docutils literal notranslate"><span class=pre>spm_hrf</span></code></a>(tr[, oversampling, time_length, onset])</p></td><td><p>Implementation of the SPM hrf model</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.glm.first_level.spm_time_derivative.html#nilearn.glm.first_level.spm_time_derivative title=nilearn.glm.first_level.spm_time_derivative><code class="xref py py-obj docutils literal notranslate"><span class=pre>spm_time_derivative</span></code></a>(tr[, oversampling, …])</p></td><td><p>Implementation of the SPM time derivative hrf (dhrf) model</p></td></tr></tbody></table></div><div class=section id=module-nilearn.glm.second_level><span id=nilearn-glm-second-level></span><h3><a class=toc-backref href=#id27><span class=section-number>8.13.16. </span><a class="reference internal"href=#module-nilearn.glm.second_level title=nilearn.glm.second_level><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.glm.second_level</span></code></a></a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.glm.second_level>¶</a></h3><p><strong>Classes</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel title=nilearn.glm.second_level.SecondLevelModel><code class="xref py py-obj docutils literal notranslate"><span class=pre>SecondLevelModel</span></code></a>([mask_img, target_affine, …])</p></td><td><p>Implementation of the General Linear Model for multiple subject fMRI data</p></td></tr></tbody></table><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.glm.second_level.make_second_level_design_matrix.html#nilearn.glm.second_level.make_second_level_design_matrix title=nilearn.glm.second_level.make_second_level_design_matrix><code class="xref py py-obj docutils literal notranslate"><span class=pre>make_second_level_design_matrix</span></code></a>(subjects_label)</p></td><td><p>Sets up a second level design.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.glm.second_level.non_parametric_inference.html#nilearn.glm.second_level.non_parametric_inference title=nilearn.glm.second_level.non_parametric_inference><code class="xref py py-obj docutils literal notranslate"><span class=pre>non_parametric_inference</span></code></a>(second_level_input)</p></td><td><p>Generate p-values corresponding to the contrasts provided based on permutation testing.</p></td></tr></tbody></table></div></div><div class=section id=module-nilearn.reporting><span id=nilearn-reporting-reporting-functions></span><span id=reporting-ref></span><h2><a class=toc-backref href=#id28><span class=section-number>8.14. </span><a class="reference internal"href=#module-nilearn.reporting title=nilearn.reporting><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.reporting</span></code></a>: Reporting Functions</a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.reporting>¶</a></h2><p>Reporting code for nilearn</p><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.reporting.get_clusters_table.html#nilearn.reporting.get_clusters_table title=nilearn.reporting.get_clusters_table><code class="xref py py-obj docutils literal notranslate"><span class=pre>get_clusters_table</span></code></a>(stat_img, stat_threshold)</p></td><td><p>Creates pandas dataframe with img cluster statistics.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.reporting.make_glm_report.html#nilearn.reporting.make_glm_report title=nilearn.reporting.make_glm_report><code class="xref py py-obj docutils literal notranslate"><span class=pre>make_glm_report</span></code></a>(model, contrasts[, title, …])</p></td><td><p>Returns HTMLReport object for a report which shows all important aspects of a fitted GLM.</p></td></tr></tbody></table></div><div class=section id=module-nilearn.surface><span id=nilearn-surface-manipulating-surface-data></span><h2><a class=toc-backref href=#id29><span class=section-number>8.15. </span><a class="reference internal"href=#module-nilearn.surface title=nilearn.surface><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.surface</span></code></a>: Manipulating Surface Data</a><a title="Permalink to this headline"class=headerlink href=#module-nilearn.surface>¶</a></h2><p>Functions for surface manipulation.</p><p><strong>Functions</strong>:</p><table class="longtable docutils align-default"><colgroup><col style=width:10%><col style=width:90%></colgroup><tbody><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.surface.load_surf_data.html#nilearn.surface.load_surf_data title=nilearn.surface.load_surf_data><code class="xref py py-obj docutils literal notranslate"><span class=pre>load_surf_data</span></code></a>(surf_data)</p></td><td><p>Loading data to be represented on a surface mesh.</p></td></tr><tr class=row-even><td><p><a class="reference internal"href=generated/nilearn.surface.load_surf_mesh.html#nilearn.surface.load_surf_mesh title=nilearn.surface.load_surf_mesh><code class="xref py py-obj docutils literal notranslate"><span class=pre>load_surf_mesh</span></code></a>(surf_mesh)</p></td><td><p>Loading a surface mesh geometry</p></td></tr><tr class=row-odd><td><p><a class="reference internal"href=generated/nilearn.surface.vol_to_surf.html#nilearn.surface.vol_to_surf title=nilearn.surface.vol_to_surf><code class="xref py py-obj docutils literal notranslate"><span class=pre>vol_to_surf</span></code></a>(img, surf_mesh[, radius, …])</p></td><td><p>Extract surface data from a Nifti image.</p></td></tr></tbody></table></div></div><div class=clearer></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>8. Reference documentation: all nilearn functions</a><ul><li><a class="reference internal"href=#module-nilearn.connectome>8.1. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.connectome</span></code>: Functional Connectivity</a><ul></ul></li><li><a class="reference internal"href=#module-nilearn.datasets>8.2. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.datasets</span></code>: Automatic Dataset Fetching</a><ul><li><a class="reference internal"href=#templates>8.2.1. Templates</a></li><li><a class="reference internal"href=#atlases>8.2.2. Atlases</a></li><li><a class="reference internal"href=#preprocessed-datasets>8.2.3. Preprocessed datasets</a></li><li><a class="reference internal"href=#statistical-maps-derivatives>8.2.4. Statistical maps/derivatives</a></li><li><a class="reference internal"href=#general-functions>8.2.5. General functions</a></li></ul></li><li><a class="reference internal"href=#module-nilearn.decoding>8.3. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.decoding</span></code>: Decoding</a></li><li><a class="reference internal"href=#module-nilearn.decomposition>8.4. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.decomposition</span></code>: Multivariate Decompositions</a></li><li><a class="reference internal"href=#module-nilearn.image>8.5. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.image</span></code>: Image Processing and Resampling Utilities</a></li><li><a class="reference internal"href=#module-nilearn.interfaces>8.6. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.interfaces</span></code>: Loading components from interfaces</a><ul><li><a class="reference internal"href=#module-nilearn.interfaces.bids>8.6.1. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.interfaces.bids</span></code></a></li><li><a class="reference internal"href=#module-nilearn.interfaces.fmriprep>8.6.2. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.interfaces.fmriprep</span></code></a></li><li><a class="reference internal"href=#module-nilearn.interfaces.fsl>8.6.3. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.interfaces.fsl</span></code></a></li></ul></li><li><a class="reference internal"href=#module-nilearn.maskers>8.7. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.maskers</span></code>: Extracting Signals from Brain Images</a></li><li><a class="reference internal"href=#module-nilearn.masking>8.8. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.masking</span></code>: Data Masking Utilities</a></li><li><a class="reference internal"href=#module-nilearn.regions>8.9. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.regions</span></code>: Operating on Regions</a><ul></ul></li><li><a class="reference internal"href=#module-nilearn.mass_univariate>8.10. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.mass_univariate</span></code>: Mass-Univariate Analysis</a></li><li><a class="reference internal"href=#module-nilearn.plotting>8.11. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.plotting</span></code>: Plotting Brain Data</a><ul><li><a class="reference internal"href=#module-nilearn.plotting.displays>8.11.31. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.plotting.displays</span></code>: Interacting with figures</a><ul></ul></li></ul></li><li><a class="reference internal"href=#module-nilearn.signal>8.12. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.signal</span></code>: Preprocessing Time Series</a></li><li><a class="reference internal"href=#module-nilearn.glm>8.13. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.glm</span></code>: Generalized Linear Models</a><ul><li><a class="reference internal"href=#module-nilearn.glm.first_level>8.13.15. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.glm.first_level</span></code></a><ul></ul></li><li><a class="reference internal"href=#module-nilearn.glm.second_level>8.13.16. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.glm.second_level</span></code></a><ul></ul></li></ul></li><li><a class="reference internal"href=#module-nilearn.reporting>8.14. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.reporting</span></code>: Reporting Functions</a></li><li><a class="reference internal"href=#module-nilearn.surface>8.15. <code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.surface</span></code>: Manipulating Surface Data</a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=../building_blocks/neurovault.html><span class=section-number>7.2. </span>Downloading statistical maps from the Neurovault repository</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=generated/nilearn.connectome.ConnectivityMeasure.html><span class=section-number>8.1.1. </span>nilearn.connectome.ConnectivityMeasure</a></p><div id=searchbox role=search style=display:none><h3 id=searchlabel>Quick search</h3><div class=searchformwrapper><form action=../search.html class=search><input aria-labelledby=searchlabel name=q><input type=submit value=Go></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2022. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 4.0.2. <span style=padding-left:5ex> <a href=../_sources/modules/reference.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>