<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1.0 name=viewport><meta content="8.14.2. nilearn.reporting.make_glm_report"property=og:title><meta content=website property=og:type><meta content=https://nilearn.github.io/modules/generated/nilearn.reporting.make_glm_report.html property=og:url><meta content=Nilearn property=og:site_name><meta content="Examples using nilearn.reporting.make_glm_report: Decoding of a dataset after GLM fit for signal extraction Decoding of a dataset after GLM fit for signal extraction, Default Mode Network extractio..."property=og:description><meta content=../../_images/sphx_glr_plot_haxby_glm_decoding_thumb.png property=og:image><meta content="Decoding of a dataset after GLM fit for signal extraction"property=og:image:alt><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/copybutton.css rel=stylesheet><link href=../../_static/sg_gallery.css rel=stylesheet><link href=../../_static/sg_gallery-binder.css rel=stylesheet><link href=../../_static/sg_gallery-dataframe.css rel=stylesheet><link href=../../_static/sg_gallery-rendered-html.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/clipboard.min.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="8.15.1. nilearn.surface.load_surf_data"href=nilearn.surface.load_surf_data.html rel=next><link title="8.14.1. nilearn.reporting.get_clusters_table"href=nilearn.reporting.get_clusters_table.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="8.15.1. nilearn.surface.load_surf_data"accesskey=N href=nilearn.surface.load_surf_data.html>next</a> |</li><li class=right><a title="8.14.1. nilearn.reporting.get_clusters_table"accesskey=P href=nilearn.reporting.get_clusters_table.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../../auto_examples/index.html>Examples</a> | </li><li><a href=../reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li><a href=../../glossary.html>Glossary</a>| </li><li><a href=../../bibliography.html>Bibliography</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../reference.html><span class=section-number>8. </span>Reference documentation: all nilearn functions</a> »</li><li class="nav-item nav-item-this"><a href>Nilearn: Statistical Analysis for NeuroImaging in Python</a></li></ul></div></div><div class=stable-banner>This is the <em>stable</em> documentation for the latest release of Nilearn, the current development version is available <a href=https://nilearn.github.io/dev/index.html>here</a>.</div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="admonition note"><p class=admonition-title>Note</p><p>This page is a reference documentation. It only explains the function signature, and not how to use it. Please refer to the <a class="reference internal"href=../../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for the big picture.</p></div><div class=section id=nilearn-reporting-make-glm-report><h1><span class=section-number>8.14.2. </span>nilearn.reporting.make_glm_report<a title="Permalink to this headline"class=headerlink href=#nilearn-reporting-make-glm-report>¶</a></h1><dl class="py function"><dt class="sig sig-object py"id=nilearn.reporting.make_glm_report><span class="sig-prename descclassname"><span class=pre>nilearn.reporting.</span></span><span class="sig-name descname"><span class=pre>make_glm_report</span></span><span class=sig-paren>(</span><em class=sig-param><span class=n><span class=pre>model</span></span></em>, <em class=sig-param><span class=n><span class=pre>contrasts</span></span></em>, <em class=sig-param><span class=n><span class=pre>title</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>bg_img</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>'MNI152TEMPLATE'</span></span></em>, <em class=sig-param><span class=n><span class=pre>threshold</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>3.09</span></span></em>, <em class=sig-param><span class=n><span class=pre>alpha</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>0.001</span></span></em>, <em class=sig-param><span class=n><span class=pre>cluster_threshold</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>0</span></span></em>, <em class=sig-param><span class=n><span class=pre>height_control</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>'fpr'</span></span></em>, <em class=sig-param><span class=n><span class=pre>two_sided</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>False</span></span></em>, <em class=sig-param><span class=n><span class=pre>min_distance</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>8.0</span></span></em>, <em class=sig-param><span class=n><span class=pre>plot_type</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>'slice'</span></span></em>, <em class=sig-param><span class=n><span class=pre>display_mode</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>report_dims</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>(1600,</span> <span class=pre>800)</span></span></em><span class=sig-paren>)</span><a class="reference external"href=https://github.com/nilearn/nilearn/blob/9ddfa7259/nilearn/reporting/glm_reporter.py#L51><span class=viewcode-link><span class=pre>[source]</span></span></a><a title="Permalink to this definition"class=headerlink href=#nilearn.reporting.make_glm_report>¶</a></dt><dd><p>Returns HTMLReport object for a report which shows all important aspects of a fitted GLM. The object can be opened in a browser, displayed in a notebook, or saved to disk as a standalone HTML file.</p> <dl class=field-list><dt class=field-odd>Parameters</dt><dd class=field-odd><dl><dt><strong>model</strong><span class=classifier>FirstLevelModel or SecondLevelModel object</span></dt><dd><p>A fitted first or second level model object. Must have the computed design matrix(ces).</p></dd><dt><strong>contrasts</strong><span class=classifier>Dict[string, ndarray] or String or List[String] or ndarray or</span></dt><dd><p>List[ndarray]</p> <p>Contrasts information for a first or second level model.</p> <p>Example:</p> <blockquote><div><p>Dict of contrast names and coefficients, or list of contrast names or list of contrast coefficients or contrast name or contrast coefficient</p><p>Each contrast name must be a string. Each contrast coefficient must be a list or numpy array of ints.</p></div></blockquote> <p>Contrasts are passed to <code class="docutils literal notranslate"><span class=pre>contrast_def</span></code> for FirstLevelModel (<a class="reference internal"href=nilearn.glm.first_level.FirstLevelModel.html#nilearn.glm.first_level.FirstLevelModel.compute_contrast title=nilearn.glm.first_level.FirstLevelModel.compute_contrast><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.glm.first_level.FirstLevelModel.compute_contrast</span></code></a>) & second_level_contrast for SecondLevelModel (<a class="reference internal"href=nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel.compute_contrast title=nilearn.glm.second_level.SecondLevelModel.compute_contrast><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.glm.second_level.SecondLevelModel.compute_contrast</span></code></a>)</p></dd><dt><strong>title</strong><span class=classifier>String, optional</span></dt><dd><p>If string, represents the web page’s title and primary heading, model type is sub-heading. If None, page titles and headings are autogenerated using contrast names.</p></dd><dt><strong>bg_img</strong><span class=classifier>Niimg-like object, optional</span></dt><dd><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> The background image for mask and stat maps to be plotted on upon. To turn off background image, just pass “bg_img=None”. Default=’MNI152TEMPLATE’.</p></dd><dt><strong>threshold</strong><span class=classifier>float, optional</span></dt><dd><p>Cluster forming threshold in same scale as <cite>stat_img</cite> (either a t-scale or z-scale value). Used only if height_control is None. Default=3.09.</p></dd><dt><strong>alpha</strong><span class=classifier>float, optional</span></dt><dd><p>Number controlling the thresholding (either a p-value or q-value). Its actual meaning depends on the height_control parameter. This function translates alpha to a z-scale threshold. Default=0.001.</p></dd><dt><strong>cluster_threshold</strong><span class=classifier>int, optional</span></dt><dd><p>Cluster size threshold, in voxels. Default=0.</p></dd><dt><strong>height_control</strong><span class=classifier>string, optional</span></dt><dd><p>false positive control meaning of cluster forming threshold: ‘fpr’ (default) or ‘fdr’ or ‘bonferroni’ or None. Default=’fpr’.</p></dd><dt><strong>two_sided</strong><span class=classifier><cite>bool</cite>, optional</span></dt><dd><p>Whether to employ two-sided thresholding or to evaluate positive values only. Default=False.</p></dd><dt><strong>min_distance</strong><span class=classifier>float, optional</span></dt><dd><p>For display purposes only. Minimum distance between subpeaks in mm. Default=8mm.</p></dd><dt><strong>plot_type</strong><span class=classifier>String, {‘slice’, ‘glass’}, optional</span></dt><dd><p>Specifies the type of plot to be drawn for the statistical maps. Default=’slice’.</p></dd><dt><strong>display_mode</strong><span class=classifier>string, optional</span></dt><dd><p>Default is ‘z’ if plot_type is ‘slice’; ‘ ortho’ if plot_type is ‘glass’.</p> <p>Choose the direction of the cuts: ‘x’ - sagittal, ‘y’ - coronal, ‘z’ - axial, ‘l’ - sagittal left hemisphere only, ‘r’ - sagittal right hemisphere only, ‘ortho’ - three cuts are performed in orthogonal directions.</p> <p>Possible values are: ‘ortho’, ‘x’, ‘y’, ‘z’, ‘xz’, ‘yx’, ‘yz’, ‘l’, ‘r’, ‘lr’, ‘lzr’, ‘lyr’, ‘lzry’, ‘lyrz’.</p></dd><dt><strong>report_dims</strong><span class=classifier>Sequence[int, int], optional</span></dt><dd><p>Specifies width, height (in pixels) of report window within a notebook. Only applicable when inserting the report into a Jupyter notebook. Can be set after report creation using report.width, report.height. Default is (1600, 800) pixels.</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>report_text</strong><span class=classifier>HTMLReport Object</span></dt><dd><p>Contains the HTML code for the GLM Report.</p></dd></dl></dd></dl> <p class=rubric>Examples</p> <p>report = make_glm_report(model, contrasts) report.open_in_browser() report.save_as_html(destination_path)</p></dd></dl><div class=section id=examples-using-nilearn-reporting-make-glm-report><h2><span class=section-number>8.14.2.1. </span>Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.reporting.make_glm_report</span></code><a title="Permalink to this headline"class=headerlink href=#examples-using-nilearn-reporting-make-glm-report>¶</a></h2><div tooltip="Full step-by-step example of fitting a GLM to perform a decoding experiment. We use the data fr..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id1><img alt="Decoding of a dataset after GLM fit for signal extraction"src=../../_images/sphx_glr_plot_haxby_glm_decoding_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/02_decoding/plot_haxby_glm_decoding.html#sphx-glr-auto-examples-02-decoding-plot-haxby-glm-decoding-py><span class="std std-ref">Decoding of a dataset after GLM fit for signal extraction</span></a></span><a title="Permalink to this image"class=headerlink href=#id1>¶</a></p></div></div><div tooltip="This example shows a full step-by-step workflow of fitting a GLM to data extracted from a seed ..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id2><img alt="Default Mode Network extraction of AHDH dataset"src=../../_images/sphx_glr_plot_adhd_dmn_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/04_glm_first_level/plot_adhd_dmn.html#sphx-glr-auto-examples-04-glm-first-level-plot-adhd-dmn-py><span class="std std-ref">Default Mode Network extraction of AHDH dataset</span></a></span><a title="Permalink to this image"class=headerlink href=#id2>¶</a></p></div></div><div tooltip="Here, we will go through a full step-by-step example of fitting a GLM to experimental data and ..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id3><img alt="Simple example of two-session fMRI model fitting"src=../../_images/sphx_glr_plot_fiac_analysis_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/04_glm_first_level/plot_fiac_analysis.html#sphx-glr-auto-examples-04-glm-first-level-plot-fiac-analysis-py><span class="std std-ref">Simple example of two-session fMRI model fitting</span></a></span><a title="Permalink to this image"class=headerlink href=#id3>¶</a></p></div></div><div tooltip=" Full step-by-step example of fitting a GLM to perform a first level analysis in an openneuro B..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id4><img alt="First level analysis of a complete BIDS dataset from openneuro"src=../../_images/sphx_glr_plot_bids_features_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/04_glm_first_level/plot_bids_features.html#sphx-glr-auto-examples-04-glm-first-level-plot-bids-features-py><span class="std std-ref">First level analysis of a complete BIDS dataset from openneuro</span></a></span><a title="Permalink to this image"class=headerlink href=#id4>¶</a></p></div></div><div tooltip="This example uses Voxel-Based Morphometry (VBM) to study the relationship between aging, sex an..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id5><img alt="Voxel-Based Morphometry on Oasis dataset"src=../../_images/sphx_glr_plot_oasis_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/05_glm_second_level/plot_oasis.html#sphx-glr-auto-examples-05-glm-second-level-plot-oasis-py><span class="std std-ref">Voxel-Based Morphometry on Oasis dataset</span></a></span><a title="Permalink to this image"class=headerlink href=#id5>¶</a></p></div></div><div style=clear:both></div></div></div><div class=clearer></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>8.14.2. nilearn.reporting.make_glm_report</a><ul><li><a class="reference internal"href=#examples-using-nilearn-reporting-make-glm-report>8.14.2.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.reporting.make_glm_report</span></code></a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=nilearn.reporting.get_clusters_table.html><span class=section-number>8.14.1. </span>nilearn.reporting.get_clusters_table</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=nilearn.surface.load_surf_data.html><span class=section-number>8.15.1. </span>nilearn.surface.load_surf_data</a></p><div id=searchbox role=search style=display:none><h3 id=searchlabel>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input aria-labelledby=searchlabel name=q><input type=submit value=Go></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2022. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 4.0.2. <span style=padding-left:5ex> <a href=../../_sources/modules/generated/nilearn.reporting.make_glm_report.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>