<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1.0 name=viewport><meta content="8.11.9. nilearn.plotting.plot_roi"property=og:title><meta content=website property=og:type><meta content=https://nilearn.github.io/modules/generated/nilearn.plotting.plot_roi.html property=og:url><meta content=Nilearn property=og:site_name><meta content="Examples using nilearn.plotting.plot_roi: A introduction tutorial to fMRI decoding A introduction tutorial to fMRI decoding, Basic Atlas plotting Basic Atlas plotting, Visualizing multiscale functi..."property=og:description><meta content=../../_images/sphx_glr_plot_decoding_tutorial_thumb.png property=og:image><meta content="A introduction tutorial to fMRI decoding"property=og:image:alt><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/copybutton.css rel=stylesheet><link href=../../_static/sg_gallery.css rel=stylesheet><link href=../../_static/sg_gallery-binder.css rel=stylesheet><link href=../../_static/sg_gallery-dataframe.css rel=stylesheet><link href=../../_static/sg_gallery-rendered-html.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/clipboard.min.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="8.11.10. nilearn.plotting.plot_stat_map"href=nilearn.plotting.plot_stat_map.html rel=next><link title="8.11.8. nilearn.plotting.plot_matrix"href=nilearn.plotting.plot_matrix.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="8.11.10. nilearn.plotting.plot_stat_map"accesskey=N href=nilearn.plotting.plot_stat_map.html>next</a> |</li><li class=right><a title="8.11.8. nilearn.plotting.plot_matrix"accesskey=P href=nilearn.plotting.plot_matrix.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../../auto_examples/index.html>Examples</a> | </li><li><a href=../reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li><a href=../../glossary.html>Glossary</a>| </li><li><a href=../../bibliography.html>Bibliography</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../reference.html><span class=section-number>8. </span>Reference documentation: all nilearn functions</a> »</li><li class="nav-item nav-item-this"><a href>Nilearn: Statistical Analysis for NeuroImaging in Python</a></li></ul></div></div><div class=stable-banner>This is the <em>stable</em> documentation for the latest release of Nilearn, the current development version is available <a href=https://nilearn.github.io/dev/index.html>here</a>.</div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="admonition note"><p class=admonition-title>Note</p><p>This page is a reference documentation. It only explains the function signature, and not how to use it. Please refer to the <a class="reference internal"href=../../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for the big picture.</p></div><div class=section id=nilearn-plotting-plot-roi><h1><span class=section-number>8.11.9. </span>nilearn.plotting.plot_roi<a title="Permalink to this headline"class=headerlink href=#nilearn-plotting-plot-roi>¶</a></h1><dl class="py function"><dt class="sig sig-object py"id=nilearn.plotting.plot_roi><span class="sig-prename descclassname"><span class=pre>nilearn.plotting.</span></span><span class="sig-name descname"><span class=pre>plot_roi</span></span><span class=sig-paren>(</span><em class=sig-param><span class=pre>roi_img</span></em>, <em class=sig-param><span class=pre>bg_img=&LTMNI152Template></span></em>, <em class=sig-param><span class=pre>cut_coords=None</span></em>, <em class=sig-param><span class=pre>output_file=None</span></em>, <em class=sig-param><span class=pre>display_mode='ortho'</span></em>, <em class=sig-param><span class=pre>figure=None</span></em>, <em class=sig-param><span class=pre>axes=None</span></em>, <em class=sig-param><span class=pre>title=None</span></em>, <em class=sig-param><span class=pre>annotate=True</span></em>, <em class=sig-param><span class=pre>draw_cross=True</span></em>, <em class=sig-param><span class=pre>black_bg='auto'</span></em>, <em class=sig-param><span class=pre>threshold=0.5</span></em>, <em class=sig-param><span class=pre>alpha=0.7</span></em>, <em class=sig-param><span class=pre>cmap=&LTmatplotlib.colors.LinearSegmentedColormap</span> <span class=pre>object></span></em>, <em class=sig-param><span class=pre>dim='auto'</span></em>, <em class=sig-param><span class=pre>colorbar=False</span></em>, <em class=sig-param><span class=pre>cbar_tick_format='%i'</span></em>, <em class=sig-param><span class=pre>vmin=None</span></em>, <em class=sig-param><span class=pre>vmax=None</span></em>, <em class=sig-param><span class=pre>resampling_interpolation='nearest'</span></em>, <em class=sig-param><span class=pre>view_type='continuous'</span></em>, <em class=sig-param><span class=pre>linewidths=2.5</span></em>, <em class=sig-param><span class=pre>**kwargs</span></em><span class=sig-paren>)</span><a class="reference external"href=https://github.com/nilearn/nilearn/blob/9ddfa7259/nilearn/plotting/img_plotting.py#L580><span class=viewcode-link><span class=pre>[source]</span></span></a><a title="Permalink to this definition"class=headerlink href=#nilearn.plotting.plot_roi>¶</a></dt><dd><p>Plot cuts of an ROI/mask image (by default 3 cuts: Frontal, Axial, and Lateral)</p> <dl class=field-list><dt class=field-odd>Parameters</dt><dd class=field-odd><dl><dt><strong>roi_img</strong><span class=classifier>Niimg-like object</span></dt><dd><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> The ROI/mask image, it could be binary mask or an atlas or ROIs with integer values.</p></dd><dt><strong>bg_img</strong><span class=classifier>Niimg-like object, optional</span></dt><dd><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>input_output</a>. The background image to plot on top of. If nothing is specified, the MNI152 template will be used. To turn off background image, just pass “bg_img=None”. Default=MNI152TEMPLATE.</p></dd><dt><strong>cut_coords</strong><span class=classifier>None, a <a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/stdtypes.html#tuple><code class="xref py py-obj docutils literal notranslate"><span class=pre>tuple</span></code></a> of <a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#float><code class="xref py py-obj docutils literal notranslate"><span class=pre>float</span></code></a>, or <a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#int><code class="xref py py-obj docutils literal notranslate"><span class=pre>int</span></code></a>, optional</span></dt><dd><p>The MNI coordinates of the point where the cut is performed.</p> <blockquote><div><ul class=simple><li><p>If <code class="docutils literal notranslate"><span class=pre>display_mode</span></code> is ‘ortho’ or ‘tiled’, this should be a 3-tuple: <code class="docutils literal notranslate"><span class=pre>(x,</span> <span class=pre>y,</span> <span class=pre>z)</span></code></p></li><li><p>For <code class="docutils literal notranslate"><span class=pre>display_mode</span> <span class=pre>==</span> <span class=pre>'x'</span></code>, ‘y’, or ‘z’, then these are the coordinates of each cut in the corresponding direction.</p></li><li><p>If <code class="docutils literal notranslate"><span class=pre>None</span></code> is given, the cuts are calculated automatically.</p></li><li><p>If <code class="docutils literal notranslate"><span class=pre>display_mode</span></code> is ‘mosaic’, and the number of cuts is the same for all directions, <code class="docutils literal notranslate"><span class=pre>cut_coords</span></code> can be specified as an integer. It can also be a length 3 tuple specifying the number of cuts for every direction if these are different.</p></li></ul><div class="admonition note"><p class=admonition-title>Note</p><p>If <code class="docutils literal notranslate"><span class=pre>display_mode</span></code> is ‘x’, ‘y’ or ‘z’, <code class="docutils literal notranslate"><span class=pre>cut_coords</span></code> can be an integer, in which case it specifies the number of cuts to perform.</p></div></div></blockquote></dd><dt><strong>output_file</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/stdtypes.html#str><code class="xref py py-obj docutils literal notranslate"><span class=pre>str</span></code></a>, or None, optional</span></dt><dd><p>The name of an image file to export the plot to. Valid extensions are .png, .pdf, .svg. If <code class="docutils literal notranslate"><span class=pre>output_file</span></code> is not None, the plot is saved to a file, and the display is closed.</p></dd><dt><strong>display_mode</strong><span class=classifier>{‘ortho’, ‘tiled’, ‘mosaic’,’x’,’y’, ‘z’, ‘yx’, ‘xz’, ‘yz’}, optional</span></dt><dd><p>Choose the direction of the cuts:</p> <blockquote><div><ul class=simple><li><p>‘x’: sagital</p></li><li><p>‘y’: coronal</p></li><li><p>‘z’: axial</p></li><li><p>‘ortho’: three cuts are performed in orthogonal directions</p></li><li><p>‘tiled’: three cuts are performed and arranged in a 2x2 grid</p></li><li><p>‘mosaic’: three cuts are performed along multiple rows and columns</p></li></ul></div></blockquote> <p>Default=’ortho’.</p></dd><dt><strong>figure</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#int><code class="xref py py-obj docutils literal notranslate"><span class=pre>int</span></code></a>, or <a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure><code class="xref py py-class docutils literal notranslate"><span class=pre>matplotlib.figure.Figure</span></code></a>, or None, optional</span></dt><dd><p>Matplotlib figure used or its number. If <code class="docutils literal notranslate"><span class=pre>None</span></code> is given, a new figure is created.</p></dd><dt><strong>axes</strong><span class=classifier><a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/axes_api.html#matplotlib.axes.Axes><code class="xref py py-class docutils literal notranslate"><span class=pre>matplotlib.axes.Axes</span></code></a>, or 4 tupleof <a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#float><code class="xref py py-obj docutils literal notranslate"><span class=pre>float</span></code></a>: (xmin, ymin, width, height), optional</span></dt><dd><p>The axes, or the coordinates, in matplotlib figure space, of the axes used to display the plot. If <code class="docutils literal notranslate"><span class=pre>None</span></code>, the complete figure is used.</p></dd><dt><strong>title</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/stdtypes.html#str><code class="xref py py-obj docutils literal notranslate"><span class=pre>str</span></code></a>, or None, optional</span></dt><dd><p>The title displayed on the figure. Default=None.</p></dd><dt><strong>annotate</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#bool><code class="xref py py-obj docutils literal notranslate"><span class=pre>bool</span></code></a>, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class=pre>annotate</span></code> is <code class="docutils literal notranslate"><span class=pre>True</span></code>, positions and left/right annotation are added to the plot. Default=True.</p></dd><dt><strong>draw_cross</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#bool><code class="xref py py-obj docutils literal notranslate"><span class=pre>bool</span></code></a>, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class=pre>draw_cross</span></code> is <code class="docutils literal notranslate"><span class=pre>True</span></code>, a cross is drawn on the plot to indicate the cut position. Default=True.</p></dd><dt><strong>black_bg</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#bool><code class="xref py py-obj docutils literal notranslate"><span class=pre>bool</span></code></a>, or ‘auto’, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class=pre>True</span></code>, the background of the image is set to be black. If you wish to save figures with a black background, you will need to pass facecolor=’k’, edgecolor=’k’ to <a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html#matplotlib.pyplot.savefig><code class="xref py py-func docutils literal notranslate"><span class=pre>matplotlib.pyplot.savefig</span></code></a>. Default=’auto’.</p></dd><dt><strong>threshold</strong><span class=classifier>a number, None, or ‘auto’, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class=pre>None</span></code> is given, the image is not thresholded. If a number is given, it is used to threshold the image: values below the threshold (in absolute value) are plotted as transparent. If ‘auto’ is given, the threshold is determined magically by analysis of the image. Default=0.5.</p></dd><dt><strong>alpha</strong><span class=classifier>float between 0 and 1, optional</span></dt><dd><p>Alpha sets the transparency of the color inside the filled contours. Default=0.7.</p></dd><dt><strong>cmap</strong><span class=classifier><a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/_as_gen/matplotlib.colors.Colormap.html#matplotlib.colors.Colormap><code class="xref py py-class docutils literal notranslate"><span class=pre>matplotlib.colors.Colormap</span></code></a>, or <a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/stdtypes.html#str><code class="xref py py-obj docutils literal notranslate"><span class=pre>str</span></code></a>, optional</span></dt><dd><p>The colormap to use. Either a string which is a name of a matplotlib colormap, or a matplotlib colormap object. Default=`plt.cm.gist_ncar`.</p></dd><dt><strong>dim</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#float><code class="xref py py-obj docutils literal notranslate"><span class=pre>float</span></code></a>, or ‘auto’, optional</span></dt><dd><p>Dimming factor applied to background image. By default, automatic heuristics are applied based upon the background image intensity. Accepted float values, where a typical span is between -2 and 2 (-2 = increase contrast; 2 = decrease contrast), but larger values can be used for a more pronounced effect. 0 means no dimming. Default=’auto’.</p></dd><dt><strong>colorbar</strong><span class=classifier>boolean, optional</span></dt><dd><p>If True, display a colorbar on the right of the plots. Default=False.</p></dd><dt><strong>cbar_tick_format: str, optional</strong></dt><dd><p>Controls how to format the tick labels of the colorbar. Ex: use “%.2g” to use scientific notation. Default is ‘%i’ to display as integers.</p></dd><dt><strong>vmin</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#float><code class="xref py py-obj docutils literal notranslate"><span class=pre>float</span></code></a>, optional</span></dt><dd><p>Lower bound of the colormap. If <code class="docutils literal notranslate"><span class=pre>None</span></code>, the min of the image is used. Passed to <a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html#matplotlib.pyplot.imshow><code class="xref py py-func docutils literal notranslate"><span class=pre>matplotlib.pyplot.imshow</span></code></a>.</p></dd><dt><strong>vmax</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#float><code class="xref py py-obj docutils literal notranslate"><span class=pre>float</span></code></a>, optional</span></dt><dd><p>Upper bound of the colormap. If <code class="docutils literal notranslate"><span class=pre>None</span></code>, the max of the image is used. Passed to <a class="reference external"title="(in Matplotlib v3.5.1)"href=https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html#matplotlib.pyplot.imshow><code class="xref py py-func docutils literal notranslate"><span class=pre>matplotlib.pyplot.imshow</span></code></a>.</p></dd><dt><strong>resampling_interpolation</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/stdtypes.html#str><code class="xref py py-obj docutils literal notranslate"><span class=pre>str</span></code></a>, optional</span></dt><dd><p>Interpolation to use when resampling the image to the destination space. Can be:</p> <blockquote><div><ul><li><p>“continuous”: use 3rd-order spline interpolation</p></li><li><p>“nearest”: use nearest-neighbor mapping.</p> <blockquote><div><div class="admonition note"><p class=admonition-title>Note</p><p>“nearest” is faster but can be noisier in some cases.</p></div></div></blockquote></li></ul></div></blockquote> <p>Default=’nearest’.</p></dd><dt><strong>view_type</strong><span class=classifier>{‘continuous’, ‘contours’}, optional</span></dt><dd><p>By default view_type == ‘continuous’, rois are shown as continuous colors. If view_type == ‘contours’, maps are shown as contours. For this type, label denoted as 0 is considered as background and not shown. Default=’continuous’.</p></dd><dt><strong>linewidths</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#float><code class="xref py py-obj docutils literal notranslate"><span class=pre>float</span></code></a>, optional</span></dt><dd><p>Set the boundary thickness of the contours. Only reflects when <code class="docutils literal notranslate"><span class=pre>view_type=contours</span></code>. Default=2.5.</p></dd></dl></dd></dl> <div class="admonition seealso"><p class=admonition-title>See also</p><dl class=simple><dt><a class="reference internal"href=nilearn.plotting.plot_prob_atlas.html#nilearn.plotting.plot_prob_atlas title=nilearn.plotting.plot_prob_atlas><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.plotting.plot_prob_atlas</span></code></a></dt><dd><p>To simply plot probabilistic atlases (4D images)</p></dd></dl></div> <p class=rubric>Notes</p> <p>A small threshold is applied by default to eliminate numerical background noise.</p> <p>For visualization, non-finite values found in passed ‘roi_img’ or ‘bg_img’ are set to zero.</p></dd></dl><div class=section id=examples-using-nilearn-plotting-plot-roi><h2><span class=section-number>8.11.9.1. </span>Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.plotting.plot_roi</span></code><a title="Permalink to this headline"class=headerlink href=#examples-using-nilearn-plotting-plot-roi>¶</a></h2><div tooltip="Here is a simple tutorial on decoding with nilearn. It reproduces the Haxby 2001 study on a fac..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id1><img alt="A introduction tutorial to fMRI decoding"src=../../_images/sphx_glr_plot_decoding_tutorial_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/plot_decoding_tutorial.html#sphx-glr-auto-examples-plot-decoding-tutorial-py><span class="std std-ref">A introduction tutorial to fMRI decoding</span></a></span><a title="Permalink to this image"class=headerlink href=#id1>¶</a></p></div></div><div tooltip="Plot the regions of a reference atlas (Harvard-Oxford and Juelich atlases)."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id2><img alt="Basic Atlas plotting"src=../../_images/sphx_glr_plot_atlas_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_atlas.html#sphx-glr-auto-examples-01-plotting-plot-atlas-py><span class="std std-ref">Basic Atlas plotting</span></a></span><a title="Permalink to this image"class=headerlink href=#id2>¶</a></p></div></div><div tooltip="This example shows how to download and fetch brain parcellations of multiple networks using nil..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id3><img alt="Visualizing multiscale functional brain parcellations"src=../../_images/sphx_glr_plot_multiscale_parcellations_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_multiscale_parcellations.html#sphx-glr-auto-examples-01-plotting-plot-multiscale-parcellations-py><span class="std std-ref">Visualizing multiscale functional brain parcellations</span></a></span><a title="Permalink to this image"class=headerlink href=#id3>¶</a></p></div></div><div tooltip="Simple example to show Nifti data visualization."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id4><img alt="NeuroImaging volumes visualization"src=../../_images/sphx_glr_plot_visualization_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_visualization.html#sphx-glr-auto-examples-01-plotting-plot-visualization-py><span class="std std-ref">NeuroImaging volumes visualization</span></a></span><a title="Permalink to this image"class=headerlink href=#id4>¶</a></p></div></div><div tooltip="Nilearn comes with a set of plotting functions for easy visualization of Nifti-like images such..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id5><img alt="Plotting tools in nilearn"src=../../_images/sphx_glr_plot_demo_plotting_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_demo_plotting.html#sphx-glr-auto-examples-01-plotting-plot-demo-plotting-py><span class="std std-ref">Plotting tools in nilearn</span></a></span><a title="Permalink to this image"class=headerlink href=#id5>¶</a></p></div></div><div tooltip="We use spatially-constrained Ward-clustering, KMeans, Hierarchical KMeans and Recursive Neighbo..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id6><img alt="Clustering methods to learn a brain parcellation from fMRI"src=../../_images/sphx_glr_plot_data_driven_parcellations_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_data_driven_parcellations.html#sphx-glr-auto-examples-03-connectivity-plot-data-driven-parcellations-py><span class="std std-ref">Clustering methods to learn a brain parcellation from fMRI</span></a></span><a title="Permalink to this image"class=headerlink href=#id6>¶</a></p></div></div><div tooltip="In this tutorial, we study how first-level models are parametrized for fMRI data analysis and c..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id7><img alt="Understanding parameters of the first-level model"src=../../_images/sphx_glr_plot_first_level_details_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/04_glm_first_level/plot_first_level_details.html#sphx-glr-auto-examples-04-glm-first-level-plot-first-level-details-py><span class="std std-ref">Understanding parameters of the first-level model</span></a></span><a title="Permalink to this image"class=headerlink href=#id7>¶</a></p></div></div><div tooltip="This example shows how to use nilearn.regions.connected_label_regions to assign each spatially-..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id8><img alt="Breaking an atlas of labels in separated regions"src=../../_images/sphx_glr_plot_extract_regions_labels_image_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/06_manipulating_images/plot_extract_regions_labels_image.html#sphx-glr-auto-examples-06-manipulating-images-plot-extract-regions-labels-image-py><span class="std std-ref">Breaking an atlas of labels in separated regions</span></a></span><a title="Permalink to this image"class=headerlink href=#id8>¶</a></p></div></div><div tooltip="Here is a simple example of automatic mask computation using the nifti masker. The mask is comp..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id9><img alt="Simple example of NiftiMasker use"src=../../_images/sphx_glr_plot_nifti_simple_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/06_manipulating_images/plot_nifti_simple.html#sphx-glr-auto-examples-06-manipulating-images-plot-nifti-simple-py><span class="std std-ref">Simple example of NiftiMasker use</span></a></span><a title="Permalink to this image"class=headerlink href=#id9>¶</a></p></div></div><div tooltip="In this example, the Nifti masker is used to automatically compute a mask."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id10><img alt="Understanding NiftiMasker and mask computation"src=../../_images/sphx_glr_plot_mask_computation_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/06_manipulating_images/plot_mask_computation.html#sphx-glr-auto-examples-06-manipulating-images-plot-mask-computation-py><span class="std std-ref">Understanding NiftiMasker and mask computation</span></a></span><a title="Permalink to this image"class=headerlink href=#id10>¶</a></p></div></div><div tooltip="This example shows manual steps to create and further modify an ROI spatial mask. They represen..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id11><img alt="Computing a Region of Interest (ROI) mask manually"src=../../_images/sphx_glr_plot_roi_extraction_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/06_manipulating_images/plot_roi_extraction.html#sphx-glr-auto-examples-06-manipulating-images-plot-roi-extraction-py><span class="std std-ref">Computing a Region of Interest (ROI) mask manually</span></a></span><a title="Permalink to this image"class=headerlink href=#id11>¶</a></p></div></div><div style=clear:both></div></div></div><div class=clearer></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>8.11.9. nilearn.plotting.plot_roi</a><ul><li><a class="reference internal"href=#examples-using-nilearn-plotting-plot-roi>8.11.9.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.plotting.plot_roi</span></code></a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=nilearn.plotting.plot_matrix.html><span class=section-number>8.11.8. </span>nilearn.plotting.plot_matrix</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=nilearn.plotting.plot_stat_map.html><span class=section-number>8.11.10. </span>nilearn.plotting.plot_stat_map</a></p><div id=searchbox role=search style=display:none><h3 id=searchlabel>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input aria-labelledby=searchlabel name=q><input type=submit value=Go></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2022. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 4.0.2. <span style=padding-left:5ex> <a href=../../_sources/modules/generated/nilearn.plotting.plot_roi.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>