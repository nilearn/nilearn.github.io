<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1.0 name=viewport><meta content="9.6.3. Statistical testing of a second-level analysis"property=og:title><meta content=website property=og:type><meta content=https://nilearn.github.io/auto_examples/05_glm_second_level/plot_thresholding.html property=og:url><meta content=Nilearn property=og:site_name><meta content="Perform a one-sample t-test on a bunch of images (a.k.a. second-level analysis in fMRI) and threshold the resulting statistical map. This example is based on the so-called localizer dataset. It sho..."property=og:description><meta content=https://nilearn.github.io/_static/nilearn-logo.png property=og:image><meta content=Nilearn property=og:image:alt><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/copybutton.css rel=stylesheet><link href=../../_static/sg_gallery.css rel=stylesheet><link href=../../_static/sg_gallery-binder.css rel=stylesheet><link href=../../_static/sg_gallery-dataframe.css rel=stylesheet><link href=../../_static/sg_gallery-rendered-html.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/clipboard.min.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="9.6.4. Voxel-Based Morphometry on Oasis dataset"href=plot_oasis.html rel=next><link title="9.6.2. Second-level fMRI model: true positive proportion in clusters"href=plot_proportion_activated_voxels.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../../modules/reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="9.6.4. Voxel-Based Morphometry on Oasis dataset"accesskey=N href=plot_oasis.html>next</a> |</li><li class=right><a title="9.6.2. Second-level fMRI model: true positive proportion in clusters"accesskey=P href=plot_proportion_activated_voxels.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../index.html>Examples</a> | </li><li><a href=../../modules/reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li><a href=../../glossary.html>Glossary</a>| </li><li><a href=../../bibliography.html>Bibliography</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../index.html><span class=section-number>9. </span>Nilearn usage examples</a> »</li><li class="nav-item nav-item-this"><a href>Nilearn: Statistical Analysis for NeuroImaging in Python</a></li></ul></div></div><div class=stable-banner>This is the <em>stable</em> documentation for the latest release of Nilearn, the current development version is available <a href=https://nilearn.github.io/dev/index.html>here</a>.</div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="sphx-glr-download-link-note admonition note"><p class=admonition-title>Note</p><p>Click <a class="reference internal"href=#sphx-glr-download-auto-examples-05-glm-second-level-plot-thresholding-py><span class="std std-ref">here</span></a> to download the full example code or to run this example in your browser via Binder</p></div><div class="sphx-glr-example-title section"id=statistical-testing-of-a-second-level-analysis><span id=sphx-glr-auto-examples-05-glm-second-level-plot-thresholding-py></span><h1><span class=section-number>9.6.3. </span>Statistical testing of a second-level analysis<a title="Permalink to this headline"class=headerlink href=#statistical-testing-of-a-second-level-analysis>¶</a></h1><p>Perform a one-sample t-test on a bunch of images (a.k.a. second-level analysis in fMRI) and threshold the resulting statistical map.</p><p>This example is based on the so-called localizer dataset. It shows activation related to a mental computation task, as opposed to narrative sentence reading/listening.</p><div class=section id=prepare-some-images-for-a-simple-t-test><h2><span class=section-number>9.6.3.1. </span>Prepare some images for a simple t test<a title="Permalink to this headline"class=headerlink href=#prepare-some-images-for-a-simple-t-test>¶</a></h2><p>This is a simple manually performed second level analysis.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn</span> <span class=kn>import</span> <span class=n>datasets</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/functions.html#int title=builtins.int><span class=n>n_samples</span></a> <span class=o>=</span> <span class=mi>20</span>
<a class="sphx-glr-backref-module-sklearn-utils sphx-glr-backref-type-py-function"href=https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch title=sklearn.utils.Bunch><span class=n>localizer_dataset</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-datasets sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.datasets.fetch_localizer_calculation_task.html#nilearn.datasets.fetch_localizer_calculation_task title=nilearn.datasets.fetch_localizer_calculation_task><span class=n>datasets</span><span class=o>.</span><span class=n>fetch_localizer_calculation_task</span></a><span class=p>(</span>
    <span class=n>n_subjects</span><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/functions.html#int title=builtins.int><span class=n>n_samples</span></a><span class=p>,</span> <span class=n>legacy_format</span><span class=o>=</span><span class=kc>False</span>
<span class=p>)</span>
</pre></div></div><p>Get the set of individual statstical maps (contrast estimates)</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#list title=builtins.list><span class=n>cmap_filenames</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#list title=builtins.list><span class=n>localizer_dataset</span><span class=o>.</span><span class=n>cmaps</span></a>
</pre></div></div></div><div class=section id=perform-the-second-level-analysis><h2><span class=section-number>9.6.3.2. </span>Perform the second level analysis<a title="Permalink to this headline"class=headerlink href=#perform-the-second-level-analysis>¶</a></h2><p>First, we define a design matrix for the model. As the model is trivial (one-sample test), the design matrix is just one column with ones.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
<a class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame title=pandas.core.frame.DataFrame><span class=n>design_matrix</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class"href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame title=pandas.core.frame.DataFrame><span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span></a><span class=p>([</span><span class=mi>1</span><span class=p>]</span> <span class=o>*</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/functions.html#int title=builtins.int><span class=n>n_samples</span></a><span class=p>,</span> <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s1>'intercept'</span><span class=p>])</span>
</pre></div></div><p>Next, we specify and estimate the model.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn.glm.second_level</span> <span class=kn>import</span> <a class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-class"href=../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel title=nilearn.glm.second_level.SecondLevelModel><span class=n>SecondLevelModel</span></a>
<a class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel title=nilearn.glm.second_level.SecondLevelModel><span class=n>second_level_model</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-class"href=../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel title=nilearn.glm.second_level.SecondLevelModel><span class=n>SecondLevelModel</span></a><span class=p>()</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span>
    <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#list title=builtins.list><span class=n>cmap_filenames</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame title=pandas.core.frame.DataFrame><span class=n>design_matrix</span></a><span class=o>=</span><a class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame title=pandas.core.frame.DataFrame><span class=n>design_matrix</span></a><span class=p>)</span>
</pre></div></div><p>Compute the only possible contrast: the one-sample test. Since there is only one possible contrast, we don’t need to specify it in detail.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>z_map</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-glm-second_level sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel.compute_contrast title=nilearn.glm.second_level.SecondLevelModel.compute_contrast><span class=n>second_level_model</span><span class=o>.</span><span class=n>compute_contrast</span></a><span class=p>(</span><span class=n>output_type</span><span class=o>=</span><span class=s1>'z_score'</span><span class=p>)</span>
</pre></div></div><p>Threshold the resulting map without multiple comparisons correction, abs(z) > 3.29 (equivalent to p < 0.001), cluster size > 10 voxels.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn.image</span> <span class=kn>import</span> <a class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.image.threshold_img.html#nilearn.image.threshold_img title=nilearn.image.threshold_img><span class=n>threshold_img</span></a>
<a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>thresholded_map</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.image.threshold_img.html#nilearn.image.threshold_img title=nilearn.image.threshold_img><span class=n>threshold_img</span></a><span class=p>(</span>
    <a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>z_map</span></a><span class=p>,</span>
    <span class=n>threshold</span><span class=o>=</span><span class=mf>3.29</span><span class=p>,</span>
    <span class=n>cluster_threshold</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
    <span class=n>two_sided</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
<span class=p>)</span>
</pre></div></div><p>This is equivalent to thresholding a z-statistic image with a false positive rate < .001, cluster size > 10 voxels.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn.glm</span> <span class=kn>import</span> <a class="sphx-glr-backref-module-nilearn-glm sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.glm.threshold_stats_img.html#nilearn.glm.threshold_stats_img title=nilearn.glm.threshold_stats_img><span class=n>threshold_stats_img</span></a>
<a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>thresholded_map1</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"href=https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64 title=numpy.float64><span class=n>threshold1</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-glm sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.glm.threshold_stats_img.html#nilearn.glm.threshold_stats_img title=nilearn.glm.threshold_stats_img><span class=n>threshold_stats_img</span></a><span class=p>(</span>
    <a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>z_map</span></a><span class=p>,</span>
    <span class=n>alpha</span><span class=o>=.</span><span class=mi>001</span><span class=p>,</span>
    <span class=n>height_control</span><span class=o>=</span><span class=s1>'fpr'</span><span class=p>,</span>
    <span class=n>cluster_threshold</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
    <span class=n>two_sided</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
<span class=p>)</span>
</pre></div></div><p>Now use FDR <.05 (False Discovery Rate) and no cluster-level threshold.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>thresholded_map2</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"href=https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64 title=numpy.float64><span class=n>threshold2</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-glm sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.glm.threshold_stats_img.html#nilearn.glm.threshold_stats_img title=nilearn.glm.threshold_stats_img><span class=n>threshold_stats_img</span></a><span class=p>(</span>
    <a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>z_map</span></a><span class=p>,</span> <span class=n>alpha</span><span class=o>=.</span><span class=mi>05</span><span class=p>,</span> <span class=n>height_control</span><span class=o>=</span><span class=s1>'fdr'</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>'The FDR=.05 threshold is </span><span class=si>%.3g</span><span class=s1>'</span> <span class=o>%</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"href=https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64 title=numpy.float64><span class=n>threshold2</span></a><span class=p>)</span>
</pre></div></div><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>The FDR=.05 threshold is 2.37
</pre></div></div><p>Now use FWER <.05 (Family-Wise Error Rate) and no cluster-level threshold. As the data has not been intensively smoothed, we can use a simple Bonferroni correction.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>thresholded_map3</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"href=https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64 title=numpy.float64><span class=n>threshold3</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-glm sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.glm.threshold_stats_img.html#nilearn.glm.threshold_stats_img title=nilearn.glm.threshold_stats_img><span class=n>threshold_stats_img</span></a><span class=p>(</span>
    <a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>z_map</span></a><span class=p>,</span> <span class=n>alpha</span><span class=o>=.</span><span class=mi>05</span><span class=p>,</span> <span class=n>height_control</span><span class=o>=</span><span class=s1>'bonferroni'</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>'The p<.05 Bonferroni-corrected threshold is </span><span class=si>%.3g</span><span class=s1>'</span> <span class=o>%</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"href=https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64 title=numpy.float64><span class=n>threshold3</span></a><span class=p>)</span>
</pre></div></div><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>The p<.05 Bonferroni-corrected threshold is 4.88
</pre></div></div></div><div class=section id=visualize-the-results><h2><span class=section-number>9.6.3.3. </span>Visualize the results<a title="Permalink to this headline"class=headerlink href=#visualize-the-results>¶</a></h2><p>First, the unthresholded map.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn</span> <span class=kn>import</span> <span class=n>plotting</span>
<a class="sphx-glr-backref-module-nilearn-plotting-displays sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=../../modules/generated/nilearn.plotting.displays.OrthoSlicer.html#nilearn.plotting.displays.OrthoSlicer title=nilearn.plotting.displays.OrthoSlicer><span class=n>display</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map title=nilearn.plotting.plot_stat_map><span class=n>plotting</span><span class=o>.</span><span class=n>plot_stat_map</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>z_map</span></a><span class=p>,</span> <span class=n>title</span><span class=o>=</span><span class=s1>'Raw z map'</span><span class=p>)</span>
</pre></div></div><img alt="plot thresholding"class=sphx-glr-single-img src=../../_images/sphx_glr_plot_thresholding_001.png srcset=../../_images/sphx_glr_plot_thresholding_001.png><p>Second, the p<.001 uncorrected-thresholded map (with only clusters > 10 voxels).</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map title=nilearn.plotting.plot_stat_map><span class=n>plotting</span><span class=o>.</span><span class=n>plot_stat_map</span></a><span class=p>(</span>
    <a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>thresholded_map1</span></a><span class=p>,</span> <span class=n>cut_coords</span><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#list title=builtins.list><span class=n>display</span><span class=o>.</span><span class=n>cut_coords</span></a><span class=p>,</span> <span class=n>threshold</span><span class=o>=</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"href=https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64 title=numpy.float64><span class=n>threshold1</span></a><span class=p>,</span>
    <span class=n>title</span><span class=o>=</span><span class=s1>'Thresholded z map, fpr <.001, clusters > 10 voxels'</span><span class=p>)</span>
</pre></div></div><img alt="plot thresholding"class=sphx-glr-single-img src=../../_images/sphx_glr_plot_thresholding_002.png srcset=../../_images/sphx_glr_plot_thresholding_002.png><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>&LTnilearn.plotting.displays._slicers.OrthoSlicer object at 0x7fa50ce94a90>
</pre></div></div><p>Third, the fdr-thresholded map.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map title=nilearn.plotting.plot_stat_map><span class=n>plotting</span><span class=o>.</span><span class=n>plot_stat_map</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>thresholded_map2</span></a><span class=p>,</span> <span class=n>cut_coords</span><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#list title=builtins.list><span class=n>display</span><span class=o>.</span><span class=n>cut_coords</span></a><span class=p>,</span>
                       <span class=n>title</span><span class=o>=</span><span class=s1>'Thresholded z map, expected fdr = .05'</span><span class=p>,</span>
                       <span class=n>threshold</span><span class=o>=</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"href=https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64 title=numpy.float64><span class=n>threshold2</span></a><span class=p>)</span>
</pre></div></div><img alt="plot thresholding"class=sphx-glr-single-img src=../../_images/sphx_glr_plot_thresholding_003.png srcset=../../_images/sphx_glr_plot_thresholding_003.png><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>&LTnilearn.plotting.displays._slicers.OrthoSlicer object at 0x7fa50d47a040>
</pre></div></div><p>Fourth, the Bonferroni-thresholded map.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map title=nilearn.plotting.plot_stat_map><span class=n>plotting</span><span class=o>.</span><span class=n>plot_stat_map</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>thresholded_map3</span></a><span class=p>,</span> <span class=n>cut_coords</span><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.8/library/stdtypes.html#list title=builtins.list><span class=n>display</span><span class=o>.</span><span class=n>cut_coords</span></a><span class=p>,</span>
                       <span class=n>title</span><span class=o>=</span><span class=s1>'Thresholded z map, expected fwer < .05'</span><span class=p>,</span>
                       <span class=n>threshold</span><span class=o>=</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"href=https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64 title=numpy.float64><span class=n>threshold3</span></a><span class=p>)</span>
</pre></div></div><img alt="plot thresholding"class=sphx-glr-single-img src=../../_images/sphx_glr_plot_thresholding_004.png srcset=../../_images/sphx_glr_plot_thresholding_004.png><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>&LTnilearn.plotting.displays._slicers.OrthoSlicer object at 0x7fa50d5a4e50>
</pre></div></div><p>These different thresholds correspond to different statistical guarantees: in the FWER-corrected image there is only a probability smaller than .05 of observing any false positive voxel. In the FDR-corrected image, 5% of the voxels found are likely to be false positive. In the uncorrected image, one expects a few tens of false positive voxels.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.show.html#nilearn.plotting.show title=nilearn.plotting.show><span class=n>plotting</span><span class=o>.</span><span class=n>show</span></a><span class=p>()</span>
</pre></div></div><p class=sphx-glr-timing><strong>Total running time of the script:</strong> ( 0 minutes 23.246 seconds)</p><p><strong>Estimated memory usage:</strong> 9 MB</p><div class="sphx-glr-footer class sphx-glr-footer-example docutils container"id=sphx-glr-download-auto-examples-05-glm-second-level-plot-thresholding-py><div class="binder-badge docutils container"><a class="reference external image-reference"href=https://mybinder.org/v2/gh/nilearn/nilearn.github.io/main?filepath=examples/auto_examples/05_glm_second_level/plot_thresholding.ipynb><img alt="Launch binder"src=../../_images/binder_badge_logo4.svg width=150px></a></div><div class="sphx-glr-download sphx-glr-download-python docutils container"><p><a class="reference download internal"download href=../../_downloads/7bc11af283a9481265b20a41074605dd/plot_thresholding.py><code class="xref download docutils literal notranslate"><span class=pre>Download</span> <span class=pre>Python</span> <span class=pre>source</span> <span class=pre>code:</span> <span class=pre>plot_thresholding.py</span></code></a></p></div><div class="sphx-glr-download sphx-glr-download-jupyter docutils container"><p><a class="reference download internal"download href=../../_downloads/1d42c0d3bb75a871fe352f634b6ce6c7/plot_thresholding.ipynb><code class="xref download docutils literal notranslate"><span class=pre>Download</span> <span class=pre>Jupyter</span> <span class=pre>notebook:</span> <span class=pre>plot_thresholding.ipynb</span></code></a></p></div></div><p class=sphx-glr-signature><a class="reference external"href=https://sphinx-gallery.github.io>Gallery generated by Sphinx-Gallery</a></p></div></div><div class=clearer></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>9.6.3. Statistical testing of a second-level analysis</a><ul><li><a class="reference internal"href=#prepare-some-images-for-a-simple-t-test>9.6.3.1. Prepare some images for a simple t test</a></li><li><a class="reference internal"href=#perform-the-second-level-analysis>9.6.3.2. Perform the second level analysis</a></li><li><a class="reference internal"href=#visualize-the-results>9.6.3.3. Visualize the results</a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=plot_proportion_activated_voxels.html><span class=section-number>9.6.2. </span>Second-level fMRI model: true positive proportion in clusters</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=plot_oasis.html><span class=section-number>9.6.4. </span>Voxel-Based Morphometry on Oasis dataset</a></p><div id=searchbox role=search style=display:none><h3 id=searchlabel>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input aria-labelledby=searchlabel name=q><input type=submit value=Go></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2022. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 4.0.2. <span style=padding-left:5ex> <a href=../../_sources/auto_examples/05_glm_second_level/plot_thresholding.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>