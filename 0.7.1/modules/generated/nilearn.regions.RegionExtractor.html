<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1.0 name=viewport><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/gallery.css rel=stylesheet><link href=../../_static/gallery-binder.css rel=stylesheet><link href=../../_static/gallery-dataframe.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="8.8.8. nilearn.regions.Parcellations"href=nilearn.regions.Parcellations.html rel=next><link title="8.8.6. nilearn.regions.signals_to_img_maps"href=nilearn.regions.signals_to_img_maps.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="8.8.8. nilearn.regions.Parcellations"accesskey=N href=nilearn.regions.Parcellations.html>next</a> |</li><li class=right><a title="8.8.6. nilearn.regions.signals_to_img_maps"accesskey=P href=nilearn.regions.signals_to_img_maps.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../../auto_examples/index.html>Examples</a> | </li><li><a href=../reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../reference.html><span class=section-number>8. </span>Reference documentation: all nilearn functions</a> »</li><li class="nav-item nav-item-this"><a href>Nilearn: Statistical Analysis for NeuroImaging in Python</a></li></ul></div></div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="admonition note"><p class=admonition-title>Note</p><p>This page is a reference documentation. It only explains the class signature, and not how to use it. Please refer to the <a class="reference internal"href=../../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for the big picture.</p></div><div class=section id=nilearn-regions-regionextractor><h1><span class=section-number>8.8.7. </span>nilearn.regions.RegionExtractor<a title="Permalink to this headline"class=headerlink href=#nilearn-regions-regionextractor>¶</a></h1><dl class="py class"><dt id=nilearn.regions.RegionExtractor><em class=property>class </em><code class="sig-prename descclassname">nilearn.regions.</code><code class="sig-name descname">RegionExtractor</code><span class=sig-paren>(</span><em class=sig-param><span class=n>maps_img</span></em>, <em class=sig-param><span class=n>mask_img</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>min_region_size</span><span class=o>=</span><span class=default_value>1350</span></em>, <em class=sig-param><span class=n>threshold</span><span class=o>=</span><span class=default_value>1.0</span></em>, <em class=sig-param><span class=n>thresholding_strategy</span><span class=o>=</span><span class=default_value>'ratio_n_voxels'</span></em>, <em class=sig-param><span class=n>extractor</span><span class=o>=</span><span class=default_value>'local_regions'</span></em>, <em class=sig-param><span class=n>smoothing_fwhm</span><span class=o>=</span><span class=default_value>6</span></em>, <em class=sig-param><span class=n>standardize</span><span class=o>=</span><span class=default_value>False</span></em>, <em class=sig-param><span class=n>detrend</span><span class=o>=</span><span class=default_value>False</span></em>, <em class=sig-param><span class=n>low_pass</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>high_pass</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>t_r</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>memory</span><span class=o>=</span><span class=default_value>Memory(location=None)</span></em>, <em class=sig-param><span class=n>memory_level</span><span class=o>=</span><span class=default_value>0</span></em>, <em class=sig-param><span class=n>verbose</span><span class=o>=</span><span class=default_value>0</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.regions.RegionExtractor>¶</a></dt><dd><p>Class for brain region extraction.</p> <p>Region Extraction is a post processing technique which is implemented to automatically segment each brain atlas maps into different set of separated brain activated region. Particularly, to show that each decomposed brain maps can be used to focus on a target specific Regions of Interest analysis.</p> <p>See <a class="reference internal"href=#r140e2ce14873-1 id=id1>[1]</a>.</p> <div class=versionadded><p><span class="versionmodified added">New in version 0.2.</span></p></div> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>maps_img</strong><span class=classifier>4D Niimg-like object</span></dt><dd><p>Image containing a set of whole brain atlas maps or statistically decomposed brain maps.</p></dd><dt><strong>mask_img</strong><span class=classifier>Niimg-like object or None, optional</span></dt><dd><p>Mask to be applied to input data, passed to NiftiMapsMasker. If None, no masking is applied.</p></dd><dt><strong>min_region_size</strong><span class=classifier>float, optional</span></dt><dd><p>Minimum volume in mm3 for a region to be kept. For example, if the voxel size is 3x3x3 mm then the volume of the voxel is 27mm^3. Default=1350mm^3, which means we take minimum size of 1350 / 27 = 50 voxels.</p></dd><dt><strong>threshold</strong><span class=classifier>number, optional</span></dt><dd><p>A value used either in ratio_n_voxels or img_value or percentile <cite>thresholding_strategy</cite> based upon the choice of selection. Default=1.0.</p></dd><dt><strong>thresholding_strategy</strong><span class=classifier>str {‘ratio_n_voxels’, ‘img_value’, ‘percentile’}, optional</span></dt><dd><p>If default ‘ratio_n_voxels’, we apply thresholding that will keep the more intense nonzero brain voxels (denoted as n_voxels) across all maps (n_voxels being the number of voxels in the brain volume). A float value given in <cite>threshold</cite> parameter indicates the ratio of voxels to keep meaning (if float=2. then maps will together have 2. x n_voxels non-zero voxels). If set to ‘percentile’, images are thresholded based on the score obtained with the given percentile on the data and the voxel intensities which are survived above this obtained score will be kept. If set to ‘img_value’, we apply thresholding based on the non-zero voxel intensities across all maps. A value given in <cite>threshold</cite> parameter indicates that we keep only those voxels which have intensities more than this value. Default=’ratio_n_voxels’.</p></dd><dt><strong>extractor</strong><span class=classifier>str {‘local_regions’, ‘connected_components’}, optional</span></dt><dd><p>If ‘connected_components’, each component/region in the image is extracted automatically by labelling each region based upon the presence of unique features in their respective regions. If ‘local_regions’, each component/region is extracted based on their maximum peak value to define a seed marker and then using random walker segementation algorithm on these markers for region separation. Default=’local_regions’.</p></dd><dt><strong>smoothing_fwhm</strong><span class=classifier>scalar, optional</span></dt><dd><p>To smooth an image to extract most sparser regions. This parameter is passed to <cite>connected_regions</cite> and exists only for extractor ‘local_regions’. Please set this parameter according to maps resolution, otherwise extraction will fail. Default=6mm.</p></dd><dt><strong>standardize</strong><span class=classifier>bool, optional</span></dt><dd><p>If True, the time series signals are centered and normalized by putting their mean to 0 and variance to 1. Recommended to set as True if signals are not already standardized. passed to class NiftiMapsMasker. Default=False.</p></dd><dt><strong>detrend</strong><span class=classifier>bool, optional</span></dt><dd><p>This parameter is passed to nilearn.signal.clean basically indicates whether to detrend timeseries signals or not. passed to class NiftiMapsMasker. Default=False.</p></dd><dt><strong>low_pass</strong><span class=classifier>float, optional</span></dt><dd><p>This value will be applied on the signals by passing to signal.clean Please see the related documentation signal.clean for more details. passed to class NiftiMapsMasker.</p></dd><dt><strong>high_pass</strong><span class=classifier>float, optional</span></dt><dd><p>This value will be applied on the signals by passing to signal.clean Please see the related documentation signal.clean for more details. passed to NiftiMapsMasker.</p></dd><dt><strong>t_r</strong><span class=classifier>float, optional</span></dt><dd><p>Repetition time in sec. This value is given to signal.clean Please see the related documentation for details. passed to NiftiMapsMasker.</p></dd><dt><strong>memory</strong><span class=classifier>instance of joblib.Memory or string, optional</span></dt><dd><p>Used to cache the masking process. If a string is given, the path is set with this string as a folder name in the directory. passed to NiftiMapsMasker.</p></dd><dt><strong>memory_level</strong><span class=classifier>int, optional</span></dt><dd><p>Aggressiveness of memory catching. The higher the number, the higher the number of functions that will be cached. Zero mean no caching. passed to NiftiMapsMasker. Default=0.</p></dd><dt><strong>verbose</strong><span class=classifier>int, optional</span></dt><dd><p>Indicates the level of verbosity by printing the message. Zero indicates nothing is printed. Default=0.</p></dd></dl></dd></dl> <div class="admonition seealso"><p class=admonition-title>See also</p><dl class=simple><dt><a class="reference internal"href=nilearn.regions.connected_label_regions.html#nilearn.regions.connected_label_regions title=nilearn.regions.connected_label_regions><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.regions.connected_label_regions</span></code></a></dt><dd><p>A function can be readily used for extraction of regions on labels based atlas images.</p></dd></dl></div> <p class=rubric>References</p> <dl class=citation><dt class=label id=r140e2ce14873-1><span class=brackets><a class=fn-backref href=#id1>1</a></span></dt><dd><p>Abraham et al. “Region segmentation for sparse decompositions: better brain parcellations from rest fMRI”, Sparsity Techniques in Medical Imaging, Sep 2014, Boston, United States. pp.8</p></dd></dl> <dl class="field-list simple"><dt class=field-odd>Attributes</dt><dd class=field-odd><dl class=simple><dt><strong>`index_`</strong><span class=classifier>numpy array</span></dt><dd><p>Array of list of indices where each index value is assigned to each separate region of its corresponding family of brain maps.</p></dd><dt><strong>`regions_img_`</strong><span class=classifier>Nifti1Image</span></dt><dd><p>List of separated regions with each region lying on an original volume concatenated into a 4D image.</p></dd></dl></dd></dl> <dl class="py method"><dt id=nilearn.regions.RegionExtractor.__init__><code class="sig-name descname">__init__</code><span class=sig-paren>(</span><em class=sig-param><span class=n>maps_img</span></em>, <em class=sig-param><span class=n>mask_img</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>min_region_size</span><span class=o>=</span><span class=default_value>1350</span></em>, <em class=sig-param><span class=n>threshold</span><span class=o>=</span><span class=default_value>1.0</span></em>, <em class=sig-param><span class=n>thresholding_strategy</span><span class=o>=</span><span class=default_value>'ratio_n_voxels'</span></em>, <em class=sig-param><span class=n>extractor</span><span class=o>=</span><span class=default_value>'local_regions'</span></em>, <em class=sig-param><span class=n>smoothing_fwhm</span><span class=o>=</span><span class=default_value>6</span></em>, <em class=sig-param><span class=n>standardize</span><span class=o>=</span><span class=default_value>False</span></em>, <em class=sig-param><span class=n>detrend</span><span class=o>=</span><span class=default_value>False</span></em>, <em class=sig-param><span class=n>low_pass</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>high_pass</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>t_r</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>memory</span><span class=o>=</span><span class=default_value>Memory(location=None)</span></em>, <em class=sig-param><span class=n>memory_level</span><span class=o>=</span><span class=default_value>0</span></em>, <em class=sig-param><span class=n>verbose</span><span class=o>=</span><span class=default_value>0</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.regions.RegionExtractor.__init__>¶</a></dt><dd><p>Initialize self. See help(type(self)) for accurate signature.</p></dd></dl> <dl class="py method"><dt id=nilearn.regions.RegionExtractor.fit><code class="sig-name descname">fit</code><span class=sig-paren>(</span><em class=sig-param><span class=n>X</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>y</span><span class=o>=</span><span class=default_value>None</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.regions.RegionExtractor.fit>¶</a></dt><dd><p>Prepare the data and setup for the region extraction</p></dd></dl> <dl class="py method"><dt id=nilearn.regions.RegionExtractor.fit_transform><code class="sig-name descname">fit_transform</code><span class=sig-paren>(</span><em class=sig-param><span class=n>imgs</span></em>, <em class=sig-param><span class=n>confounds</span><span class=o>=</span><span class=default_value>None</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.regions.RegionExtractor.fit_transform>¶</a></dt><dd><p>Prepare and perform signal extraction.</p></dd></dl> <dl class="py method"><dt id=nilearn.regions.RegionExtractor.get_params><code class="sig-name descname">get_params</code><span class=sig-paren>(</span><em class=sig-param><span class=n>deep</span><span class=o>=</span><span class=default_value>True</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.regions.RegionExtractor.get_params>¶</a></dt><dd><p>Get parameters for this estimator.</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>deep</strong><span class=classifier>bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>params</strong><span class=classifier>dict</span></dt><dd><p>Parameter names mapped to their values.</p></dd></dl></dd></dl></dd></dl> <dl class="py method"><dt id=nilearn.regions.RegionExtractor.inverse_transform><code class="sig-name descname">inverse_transform</code><span class=sig-paren>(</span><em class=sig-param><span class=n>region_signals</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.regions.RegionExtractor.inverse_transform>¶</a></dt><dd><p>Compute voxel signals from region signals</p> <p>Any mask given at initialization is taken into account.</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>region_signals</strong><span class=classifier>2D numpy.ndarray</span></dt><dd><p>Signal for each region. shape: (number of scans, number of regions)</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>voxel_signals</strong><span class=classifier>nibabel.Nifti1Image</span></dt><dd><p>Signal for each voxel. shape: that of maps.</p></dd></dl></dd></dl></dd></dl> <dl class="py method"><dt id=nilearn.regions.RegionExtractor.set_params><code class="sig-name descname">set_params</code><span class=sig-paren>(</span><em class=sig-param><span class=o>**</span><span class=n>params</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.regions.RegionExtractor.set_params>¶</a></dt><dd><p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as <a class="reference external"title="(in scikit-learn v0.24)"href=https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline><code class="xref py py-class docutils literal notranslate"><span class=pre>Pipeline</span></code></a>). The latter have parameters of the form <code class="docutils literal notranslate"><span class=pre>&LTcomponent>__&LTparameter></span></code> so that it’s possible to update each component of a nested object.</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>**params</strong><span class=classifier>dict</span></dt><dd><p>Estimator parameters.</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>self</strong><span class=classifier>estimator instance</span></dt><dd><p>Estimator instance.</p></dd></dl></dd></dl></dd></dl> <dl class="py method"><dt id=nilearn.regions.RegionExtractor.transform><code class="sig-name descname">transform</code><span class=sig-paren>(</span><em class=sig-param><span class=n>imgs</span></em>, <em class=sig-param><span class=n>confounds</span><span class=o>=</span><span class=default_value>None</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.regions.RegionExtractor.transform>¶</a></dt><dd><p>Apply mask, spatial and temporal preprocessing</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>imgs</strong><span class=classifier>3D/4D Niimg-like object</span></dt><dd><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> Images to process. It must boil down to a 4D image with scans number as last dimension.</p></dd><dt><strong>confounds</strong><span class=classifier>CSV file or array-like, optional</span></dt><dd><p>This parameter is passed to signal.clean. Please see the related documentation for details. shape: (number of scans, number of confounds)</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>region_signals</strong><span class=classifier>2D numpy.ndarray</span></dt><dd><p>Signal for each element. shape: (number of scans, number of elements)</p></dd></dl></dd></dl></dd></dl> <dl class="py method"><dt id=nilearn.regions.RegionExtractor.transform_single_imgs><code class="sig-name descname">transform_single_imgs</code><span class=sig-paren>(</span><em class=sig-param><span class=n>imgs</span></em>, <em class=sig-param><span class=n>confounds</span><span class=o>=</span><span class=default_value>None</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.regions.RegionExtractor.transform_single_imgs>¶</a></dt><dd><p>Extract signals from a single 4D niimg.</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>imgs</strong><span class=classifier>3D/4D Niimg-like object</span></dt><dd><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> Images to process. It must boil down to a 4D image with scans number as last dimension.</p></dd><dt><strong>confounds</strong><span class=classifier>CSV file or array-like, optional</span></dt><dd><p>This parameter is passed to signal.clean. Please see the related documentation for details. shape: (number of scans, number of confounds)</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>region_signals</strong><span class=classifier>2D numpy.ndarray</span></dt><dd><p>Signal for each map. shape: (number of scans, number of maps)</p></dd></dl></dd></dl></dd></dl></dd></dl><div class=section id=examples-using-nilearn-regions-regionextractor><h2><span class=section-number>8.8.7.1. </span>Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.regions.RegionExtractor</span></code><a title="Permalink to this headline"class=headerlink href=#examples-using-nilearn-regions-regionextractor>¶</a></h2><div tooltip="This example shows how to use nilearn.regions.RegionExtractor to extract spatially constrained ..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id3><img alt="Regions extraction using Dictionary Learning and functional connectomes"src=../../_images/sphx_glr_plot_extract_regions_dictlearning_maps_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html#sphx-glr-auto-examples-03-connectivity-plot-extract-regions-dictlearning-maps-py><span class="std std-ref">Regions extraction using Dictionary Learning and functional connectomes</span></a></span><a title="Permalink to this image"class=headerlink href=#id3>¶</a></p></div></div><div tooltip="This simple example shows how to extract regions from Smith atlas resting state networks."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id4><img alt="Regions Extraction of Default Mode Networks using Smith Atlas"src=../../_images/sphx_glr_plot_extract_rois_smith_atlas_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/06_manipulating_images/plot_extract_rois_smith_atlas.html#sphx-glr-auto-examples-06-manipulating-images-plot-extract-rois-smith-atlas-py><span class="std std-ref">Regions Extraction of Default Mode Networks using Smith Atlas</span></a></span><a title="Permalink to this image"class=headerlink href=#id4>¶</a></p></div></div><div style=clear:both></div></div></div><div class=clearer></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>8.8.7. nilearn.regions.RegionExtractor</a><ul><li><a class="reference internal"href=#examples-using-nilearn-regions-regionextractor>8.8.7.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.regions.RegionExtractor</span></code></a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=nilearn.regions.signals_to_img_maps.html><span class=section-number>8.8.6. </span>nilearn.regions.signals_to_img_maps</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=nilearn.regions.Parcellations.html><span class=section-number>8.8.8. </span>nilearn.regions.Parcellations</a></p><div id=searchbox role=search style=display:none><h3 id=searchlabel>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input aria-labelledby=searchlabel name=q><input type=submit value=Go></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2020. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 3.4.2. <span style=padding-left:5ex> <a href=../../_sources/modules/generated/nilearn.regions.RegionExtractor.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>