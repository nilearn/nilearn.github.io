<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1.0 name=viewport><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/gallery.css rel=stylesheet><link href=../../_static/gallery-binder.css rel=stylesheet><link href=../../_static/gallery-dataframe.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="8.2.32. nilearn.datasets.fetch_megatrawls_netmats"href=nilearn.datasets.fetch_megatrawls_netmats.html rel=next><link title="8.2.30. nilearn.datasets.fetch_atlas_schaefer_2018"href=nilearn.datasets.fetch_atlas_schaefer_2018.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="8.2.32. nilearn.datasets.fetch_megatrawls_netmats"accesskey=N href=nilearn.datasets.fetch_megatrawls_netmats.html>next</a> |</li><li class=right><a title="8.2.30. nilearn.datasets.fetch_atlas_schaefer_2018"accesskey=P href=nilearn.datasets.fetch_atlas_schaefer_2018.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../../auto_examples/index.html>Examples</a> | </li><li><a href=../reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../reference.html><span class=section-number>8. </span>Reference documentation: all nilearn functions</a> »</li><li class="nav-item nav-item-this"><a href>Nilearn: Statistical Analysis for NeuroImaging in Python</a></li></ul></div></div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="admonition note"><p class=admonition-title>Note</p><p>This page is a reference documentation. It only explains the function signature, and not how to use it. Please refer to the <a class="reference internal"href=../../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for the big picture.</p></div><div class=section id=nilearn-datasets-fetch-oasis-vbm><h1><span class=section-number>8.2.31. </span>nilearn.datasets.fetch_oasis_vbm<a title="Permalink to this headline"class=headerlink href=#nilearn-datasets-fetch-oasis-vbm>¶</a></h1><dl class="py function"><dt id=nilearn.datasets.fetch_oasis_vbm><code class="sig-prename descclassname">nilearn.datasets.</code><code class="sig-name descname">fetch_oasis_vbm</code><span class=sig-paren>(</span><em class=sig-param><span class=n>n_subjects</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>dartel_version</span><span class=o>=</span><span class=default_value>True</span></em>, <em class=sig-param><span class=n>data_dir</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>url</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>resume</span><span class=o>=</span><span class=default_value>True</span></em>, <em class=sig-param><span class=n>verbose</span><span class=o>=</span><span class=default_value>1</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.datasets.fetch_oasis_vbm>¶</a></dt><dd><p>Download and load Oasis “cross-sectional MRI” dataset (416 subjects).</p> <p>For more information, see <a class="reference internal"href=#rcfc4d1e25df9-1 id=id1>[1]</a> and <a class="reference internal"href=#rcfc4d1e25df9-2 id=id2>[2]</a>.</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>n_subjects</strong><span class=classifier>int, optional</span></dt><dd><p>The number of subjects to load. If None is given, all the subjects are used.</p></dd><dt><strong>dartel_version</strong><span class=classifier>boolean, optional</span></dt><dd><p>Whether or not to use data normalized with DARTEL instead of standard SPM8 normalization. Default=True.</p></dd><dt><strong>data_dir</strong><span class=classifier>string, optional</span></dt><dd><p>Path of the data directory. Used to force data storage in a specified location. Default: None</p></dd><dt><strong>url</strong><span class=classifier>string, optional</span></dt><dd><p>Override download URL. Used for test only (or if you setup a mirror of the data).</p></dd><dt><strong>resume</strong><span class=classifier>bool, optional</span></dt><dd><p>If true, try resuming download if possible. Default=True.</p></dd><dt><strong>verbose</strong><span class=classifier>int, optional</span></dt><dd><p>Verbosity level (0 means no message). Default=1.</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>data</strong><span class=classifier>Bunch</span></dt><dd><p>Dictionary-like object, the interest attributes are :</p> <ul class=simple><li><p>‘gray_matter_maps’: string list Paths to nifti gray matter density probability maps</p></li><li><p>‘white_matter_maps’ string list Paths to nifti white matter density probability maps</p></li><li><p>‘ext_vars’: np.recarray Data from the .csv file with information about selected subjects</p></li><li><p>‘data_usage_agreement’: string Path to the .txt file containing the data usage agreement.</p></li></ul></dd></dl></dd></dl> <p class=rubric>Notes</p> <p>In the DARTEL version, original Oasis data have been preprocessed with the following steps:</p> <blockquote><div><ol class="arabic simple"><li><p>Dimension swapping (technically required for subsequent steps)</p></li><li><p>Brain Extraction</p></li><li><p>Segmentation with SPM8</p></li><li><p>Normalization using DARTEL algorithm</p></li><li><p>Modulation</p></li><li><p>Replacement of NaN values with 0 in gray/white matter density maps.</p></li><li><p>Resampling to reduce shape and make it correspond to the shape of the non-DARTEL data (fetched with dartel_version=False).</p></li><li><p>Replacement of values < 1e-4 with zeros to reduce the file size.</p></li></ol></div></blockquote> <p>In the non-DARTEL version, the following steps have been performed instead:</p> <blockquote><div><ol class="arabic simple"><li><p>Dimension swapping (technically required for subsequent steps)</p></li><li><p>Brain Extraction</p></li><li><p>Segmentation and normalization to a template with SPM8</p></li><li><p>Modulation</p></li><li><p>Replacement of NaN values with 0 in gray/white matter density maps.</p></li></ol></div></blockquote> <p>An archive containing the gray and white matter density probability maps for the 416 available subjects is provided. Gross outliers are removed and filtered by this data fetcher (DARTEL: 13 outliers; non-DARTEL: 1 outlier) Externals variates (age, gender, estimated intracranial volume, years of education, socioeconomic status, dementia score) are provided in a CSV file that is a copy of the original Oasis CSV file. The current downloader loads the CSV file and keeps only the lines corresponding to the subjects that are actually demanded.</p> <p>The Open Access Structural Imaging Series (OASIS) is a project dedicated to making brain imaging data openly available to the public. Using data available through the OASIS project requires agreeing with the Data Usage Agreement that can be found at <a class="reference external"href=http://www.oasis-brains.org/app/template/UsageAgreement.vm>http://www.oasis-brains.org/app/template/UsageAgreement.vm</a></p> <p class=rubric>References</p> <dl class=citation><dt class=label id=rcfc4d1e25df9-1><span class=brackets><a class=fn-backref href=#id1>1</a></span></dt><dd><p><a class="reference external"href=http://www.oasis-brains.org/>http://www.oasis-brains.org/</a></p></dd><dt class=label id=rcfc4d1e25df9-2><span class=brackets><a class=fn-backref href=#id2>2</a></span></dt><dd><p>Open Access Series of Imaging Studies (OASIS): Cross-sectional MRI Data in Young, Middle Aged, Nondemented, and Demented Older Adults. Marcus, D. S and al., 2007, Journal of Cognitive Neuroscience.</p></dd></dl></dd></dl><div class=section id=examples-using-nilearn-datasets-fetch-oasis-vbm><h2><span class=section-number>8.2.31.1. </span>Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.datasets.fetch_oasis_vbm</span></code><a title="Permalink to this headline"class=headerlink href=#examples-using-nilearn-datasets-fetch-oasis-vbm>¶</a></h2><div tooltip="Predicting age from gray-matter concentration maps from OASIS dataset. Note that age is a conti..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id5><img alt="Voxel-Based Morphometry on Oasis dataset with Space-Net prior"src=../../_images/sphx_glr_plot_oasis_vbm_space_net_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/02_decoding/plot_oasis_vbm_space_net.html#sphx-glr-auto-examples-02-decoding-plot-oasis-vbm-space-net-py><span class="std std-ref">Voxel-Based Morphometry on Oasis dataset with Space-Net prior</span></a></span><a title="Permalink to this image"class=headerlink href=#id5>¶</a></p></div></div><div tooltip="This example uses Voxel-Based Morphometry (VBM) to study the relationship between aging and gra..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id6><img alt="Voxel-Based Morphometry on Oasis dataset"src=../../_images/sphx_glr_plot_oasis_vbm_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/02_decoding/plot_oasis_vbm.html#sphx-glr-auto-examples-02-decoding-plot-oasis-vbm-py><span class="std std-ref">Voxel-Based Morphometry on Oasis dataset</span></a></span><a title="Permalink to this image"class=headerlink href=#id6>¶</a></p></div></div><div tooltip="This example uses Voxel-Based Morphometry (VBM) to study the relationship between aging, sex an..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id7><img alt="Voxel-Based Morphometry on Oasis dataset"src=../../_images/sphx_glr_plot_oasis_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/05_glm_second_level/plot_oasis.html#sphx-glr-auto-examples-05-glm-second-level-plot-oasis-py><span class="std std-ref">Voxel-Based Morphometry on Oasis dataset</span></a></span><a title="Permalink to this image"class=headerlink href=#id7>¶</a></p></div></div><div style=clear:both></div></div></div><div class=clearer></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>8.2.31. nilearn.datasets.fetch_oasis_vbm</a><ul><li><a class="reference internal"href=#examples-using-nilearn-datasets-fetch-oasis-vbm>8.2.31.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.datasets.fetch_oasis_vbm</span></code></a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=nilearn.datasets.fetch_atlas_schaefer_2018.html><span class=section-number>8.2.30. </span>nilearn.datasets.fetch_atlas_schaefer_2018</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=nilearn.datasets.fetch_megatrawls_netmats.html><span class=section-number>8.2.32. </span>nilearn.datasets.fetch_megatrawls_netmats</a></p><div id=searchbox role=search style=display:none><h3 id=searchlabel>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input aria-labelledby=searchlabel name=q><input type=submit value=Go></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2020. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 3.4.2. <span style=padding-left:5ex> <a href=../../_sources/modules/generated/nilearn.datasets.fetch_oasis_vbm.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>