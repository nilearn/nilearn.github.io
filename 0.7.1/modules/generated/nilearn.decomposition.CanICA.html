<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1.0 name=viewport><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/gallery.css rel=stylesheet><link href=../../_static/gallery-binder.css rel=stylesheet><link href=../../_static/gallery-dataframe.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="8.4.2. nilearn.decomposition.DictLearning"href=nilearn.decomposition.DictLearning.html rel=next><link title="8.3.7. nilearn.decoding.SearchLight"href=nilearn.decoding.SearchLight.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="8.4.2. nilearn.decomposition.DictLearning"accesskey=N href=nilearn.decomposition.DictLearning.html>next</a> |</li><li class=right><a title="8.3.7. nilearn.decoding.SearchLight"accesskey=P href=nilearn.decoding.SearchLight.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../../auto_examples/index.html>Examples</a> | </li><li><a href=../reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../reference.html><span class=section-number>8. </span>Reference documentation: all nilearn functions</a> »</li><li class="nav-item nav-item-this"><a href>Nilearn: Statistical Analysis for NeuroImaging in Python</a></li></ul></div></div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="admonition note"><p class=admonition-title>Note</p><p>This page is a reference documentation. It only explains the class signature, and not how to use it. Please refer to the <a class="reference internal"href=../../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for the big picture.</p></div><div class=section id=nilearn-decomposition-canica><h1><span class=section-number>8.4.1. </span>nilearn.decomposition.CanICA<a title="Permalink to this headline"class=headerlink href=#nilearn-decomposition-canica>¶</a></h1><dl class="py class"><dt id=nilearn.decomposition.CanICA><em class=property>class </em><code class="sig-prename descclassname">nilearn.decomposition.</code><code class="sig-name descname">CanICA</code><span class=sig-paren>(</span><em class=sig-param><span class=n>mask</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>n_components</span><span class=o>=</span><span class=default_value>20</span></em>, <em class=sig-param><span class=n>smoothing_fwhm</span><span class=o>=</span><span class=default_value>6</span></em>, <em class=sig-param><span class=n>do_cca</span><span class=o>=</span><span class=default_value>True</span></em>, <em class=sig-param><span class=n>threshold</span><span class=o>=</span><span class=default_value>'auto'</span></em>, <em class=sig-param><span class=n>n_init</span><span class=o>=</span><span class=default_value>10</span></em>, <em class=sig-param><span class=n>random_state</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>standardize</span><span class=o>=</span><span class=default_value>True</span></em>, <em class=sig-param><span class=n>standardize_confounds</span><span class=o>=</span><span class=default_value>True</span></em>, <em class=sig-param><span class=n>detrend</span><span class=o>=</span><span class=default_value>True</span></em>, <em class=sig-param><span class=n>low_pass</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>high_pass</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>t_r</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>target_affine</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>target_shape</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>mask_strategy</span><span class=o>=</span><span class=default_value>'epi'</span></em>, <em class=sig-param><span class=n>mask_args</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>memory</span><span class=o>=</span><span class=default_value>Memory(location=None)</span></em>, <em class=sig-param><span class=n>memory_level</span><span class=o>=</span><span class=default_value>0</span></em>, <em class=sig-param><span class=n>n_jobs</span><span class=o>=</span><span class=default_value>1</span></em>, <em class=sig-param><span class=n>verbose</span><span class=o>=</span><span class=default_value>0</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.CanICA>¶</a></dt><dd><p>Perform Canonical Independent Component Analysis <a class="reference internal"href=#r637c2563345c-1 id=id1>[1]</a> <a class="reference internal"href=#r637c2563345c-2 id=id2>[2]</a>.</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>mask</strong><span class=classifier>Niimg-like object or MultiNiftiMasker instance, optional</span></dt><dd><p>Mask to be used on data. If an instance of masker is passed, then its mask will be used. If no mask is given, it will be computed automatically by a MultiNiftiMasker with default parameters.</p></dd><dt><strong>n_components</strong><span class=classifier>int, optional</span></dt><dd><p>Number of components to extract. Default=20.</p></dd><dt><strong>smoothing_fwhm</strong><span class=classifier>float, optional</span></dt><dd><p>If smoothing_fwhm is not None, it gives the size in millimeters of the spatial smoothing to apply to the signal. Default=6mm.</p></dd><dt><strong>do_cca</strong><span class=classifier>boolean, optional</span></dt><dd><p>Indicate if a Canonical Correlation Analysis must be run after the PCA. Default=True.</p></dd><dt><strong>standardize</strong><span class=classifier>boolean, optional</span></dt><dd><p>If standardize is True, the time-series are centered and normed: their mean is put to 0 and their variance to 1 in the time dimension. Default=True.</p></dd><dt><strong>standardize_confounds</strong><span class=classifier>boolean, optional</span></dt><dd><p>If standardize_confounds is True, the confounds are zscored: their mean is put to 0 and their variance to 1 in the time dimension. Default=True.</p></dd><dt><strong>detrend</strong><span class=classifier>boolean, optional</span></dt><dd><p>If detrend is True, the time-series will be detrended before components extraction. Default=True.</p></dd><dt><strong>threshold</strong><span class=classifier>None, ‘auto’ or float, optional</span></dt><dd><p>If None, no thresholding is applied. If ‘auto’, then we apply a thresholding that will keep the n_voxels, more intense voxels across all the maps, n_voxels being the number of voxels in a brain volume. A float value indicates the ratio of voxels to keep (2. means that the maps will together have 2 x n_voxels non-zero voxels ). The float value must be bounded by [0. and n_components]. Default=’auto’.</p></dd><dt><strong>n_init</strong><span class=classifier>int, optional</span></dt><dd><p>The number of times the fastICA algorithm is restarted Default=10.</p></dd><dt><strong>random_state</strong><span class=classifier>int or RandomState, optional</span></dt><dd><p>Pseudo number generator state used for random sampling.</p></dd><dt><strong>target_affine</strong><span class=classifier>3x3 or 4x4 matrix, optional</span></dt><dd><p>This parameter is passed to image.resample_img. Please see the related documentation for details.</p></dd><dt><strong>target_shape</strong><span class=classifier>3-tuple of integers, optional</span></dt><dd><p>This parameter is passed to image.resample_img. Please see the related documentation for details.</p></dd><dt><strong>low_pass</strong><span class=classifier>None or float, optional</span></dt><dd><p>This parameter is passed to signal.clean. Please see the related documentation for details</p></dd><dt><strong>high_pass</strong><span class=classifier>None or float, optional</span></dt><dd><p>This parameter is passed to signal.clean. Please see the related documentation for details</p></dd><dt><strong>t_r</strong><span class=classifier>float, optional</span></dt><dd><p>This parameter is passed to signal.clean. Please see the related documentation for details</p></dd><dt><strong>mask_strategy</strong><span class=classifier>{‘epi’, ‘background’, or ‘template’}, optional</span></dt><dd><p>The strategy used to compute the mask: use ‘background’ if your images present a clear homogeneous background, ‘epi’ if they are raw EPI images, or you could use ‘template’ which will extract the gray matter part of your data by resampling the MNI152 brain mask for your data’s field of view. Depending on this value, the mask will be computed from masking.compute_background_mask, masking.compute_epi_mask or masking.compute_brain_mask. Default=’epi’.</p></dd><dt><strong>mask_args</strong><span class=classifier>dict, optional</span></dt><dd><p>If mask is None, these are additional parameters passed to masking.compute_background_mask or masking.compute_epi_mask to fine-tune mask computation. Please see the related documentation for details.</p></dd><dt><strong>memory</strong><span class=classifier>instance of joblib.Memory or string, optional</span></dt><dd><p>Used to cache the masking process. By default, no caching is done. If a string is given, it is the path to the caching directory. Default=Memory(location=None).</p></dd><dt><strong>memory_level</strong><span class=classifier>integer, optional</span></dt><dd><p>Rough estimator of the amount of memory used by caching. Higher value means more memory for caching. Default=0.</p></dd><dt><strong>n_jobs</strong><span class=classifier>integer, optional</span></dt><dd><p>The number of CPUs to use to do the computation. -1 means ‘all CPUs’, -2 ‘all CPUs but one’, and so on. Default=1.</p></dd><dt><strong>verbose</strong><span class=classifier>integer, optional</span></dt><dd><p>Indicate the level of verbosity. By default, nothing is printed Default=0.</p></dd></dl></dd></dl> <p class=rubric>References</p> <dl class=citation><dt class=label id=r637c2563345c-1><span class=brackets><a class=fn-backref href=#id1>1</a></span></dt><dd><p>G. Varoquaux et al. “A group model for stable multi-subject ICA on fMRI datasets”, NeuroImage Vol 51 (2010), p. 288-299</p></dd><dt class=label id=r637c2563345c-2><span class=brackets><a class=fn-backref href=#id2>2</a></span></dt><dd><p>G. Varoquaux et al. “ICA-based sparse features recovery from fMRI datasets”, IEEE ISBI 2010, p. 1177</p></dd></dl> <dl class=field-list><dt class=field-odd>Attributes</dt><dd class=field-odd><dl><dt><strong>`components_`</strong><span class=classifier>2D numpy array (n_components x n-voxels)</span></dt><dd><p>Masked ICA components extracted from the input images. They can be unmasked thanks to the <cite>masker_</cite> attribute.</p> <p>Deprecated since version 0.4.1. Use <cite>components_img_</cite> instead.</p></dd><dt><strong>`components_img_`</strong><span class=classifier>4D Nifti image</span></dt><dd><p>4D image giving the extracted ICA components. Each 3D image is a component.</p> <p>New in version 0.4.1.</p></dd><dt><strong>`masker_`</strong><span class=classifier>instance of MultiNiftiMasker</span></dt><dd><p>Masker used to filter and mask data as first step. If an instance of MultiNiftiMasker is given in <cite>mask</cite> parameter, this is a copy of it. Otherwise, a masker is created using the value of <cite>mask</cite> and other NiftiMasker related parameters as initialization.</p></dd><dt><strong>`mask_img_`</strong><span class=classifier>Niimg-like object</span></dt><dd><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> The mask of the data. If no mask was given at masker creation, contains the automatically computed mask.</p></dd></dl></dd></dl> <dl class="py method"><dt id=nilearn.decomposition.CanICA.__init__><code class="sig-name descname">__init__</code><span class=sig-paren>(</span><em class=sig-param><span class=n>mask</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>n_components</span><span class=o>=</span><span class=default_value>20</span></em>, <em class=sig-param><span class=n>smoothing_fwhm</span><span class=o>=</span><span class=default_value>6</span></em>, <em class=sig-param><span class=n>do_cca</span><span class=o>=</span><span class=default_value>True</span></em>, <em class=sig-param><span class=n>threshold</span><span class=o>=</span><span class=default_value>'auto'</span></em>, <em class=sig-param><span class=n>n_init</span><span class=o>=</span><span class=default_value>10</span></em>, <em class=sig-param><span class=n>random_state</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>standardize</span><span class=o>=</span><span class=default_value>True</span></em>, <em class=sig-param><span class=n>standardize_confounds</span><span class=o>=</span><span class=default_value>True</span></em>, <em class=sig-param><span class=n>detrend</span><span class=o>=</span><span class=default_value>True</span></em>, <em class=sig-param><span class=n>low_pass</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>high_pass</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>t_r</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>target_affine</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>target_shape</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>mask_strategy</span><span class=o>=</span><span class=default_value>'epi'</span></em>, <em class=sig-param><span class=n>mask_args</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>memory</span><span class=o>=</span><span class=default_value>Memory(location=None)</span></em>, <em class=sig-param><span class=n>memory_level</span><span class=o>=</span><span class=default_value>0</span></em>, <em class=sig-param><span class=n>n_jobs</span><span class=o>=</span><span class=default_value>1</span></em>, <em class=sig-param><span class=n>verbose</span><span class=o>=</span><span class=default_value>0</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.CanICA.__init__>¶</a></dt><dd><p>Initialize self. See help(type(self)) for accurate signature.</p></dd></dl> <dl class="py method"><dt id=nilearn.decomposition.CanICA.fit><code class="sig-name descname">fit</code><span class=sig-paren>(</span><em class=sig-param><span class=n>imgs</span></em>, <em class=sig-param><span class=n>y</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>confounds</span><span class=o>=</span><span class=default_value>None</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.CanICA.fit>¶</a></dt><dd><p>Compute the mask and the components across subjects</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>imgs</strong><span class=classifier>list of Niimg-like objects</span></dt><dd><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> Data on which the mask is calculated. If this is a list, the affine is considered the same for all.</p></dd><dt><strong>confounds</strong><span class=classifier>list of CSV file paths or numpy.ndarrays or pandas DataFrames, optional</span></dt><dd><p>This parameter is passed to nilearn.signal.clean. Please see the related documentation for details. Should match with the list of imgs given.</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>self</strong><span class=classifier>object</span></dt><dd><p>Returns the instance itself. Contains attributes listed at the object level.</p></dd></dl></dd></dl></dd></dl> <dl class="py method"><dt id=nilearn.decomposition.CanICA.fit_transform><code class="sig-name descname">fit_transform</code><span class=sig-paren>(</span><em class=sig-param><span class=n>X</span></em>, <em class=sig-param><span class=n>y</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=o>**</span><span class=n>fit_params</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.CanICA.fit_transform>¶</a></dt><dd><p>Fit to data, then transform it.</p> <p>Fits transformer to <cite>X</cite> and <cite>y</cite> with optional parameters <cite>fit_params</cite> and returns a transformed version of <cite>X</cite>.</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>X</strong><span class=classifier>array-like of shape (n_samples, n_features)</span></dt><dd><p>Input samples.</p></dd><dt><strong>y</strong><span class=classifier>array-like of shape (n_samples,) or (n_samples, n_outputs), default=None</span></dt><dd><p>Target values (None for unsupervised transformations).</p></dd><dt><strong>**fit_params</strong><span class=classifier>dict</span></dt><dd><p>Additional fit parameters.</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>X_new</strong><span class=classifier>ndarray array of shape (n_samples, n_features_new)</span></dt><dd><p>Transformed array.</p></dd></dl></dd></dl></dd></dl> <dl class="py method"><dt id=nilearn.decomposition.CanICA.get_params><code class="sig-name descname">get_params</code><span class=sig-paren>(</span><em class=sig-param><span class=n>deep</span><span class=o>=</span><span class=default_value>True</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.CanICA.get_params>¶</a></dt><dd><p>Get parameters for this estimator.</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>deep</strong><span class=classifier>bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>params</strong><span class=classifier>dict</span></dt><dd><p>Parameter names mapped to their values.</p></dd></dl></dd></dl></dd></dl> <dl class="py method"><dt id=nilearn.decomposition.CanICA.inverse_transform><code class="sig-name descname">inverse_transform</code><span class=sig-paren>(</span><em class=sig-param><span class=n>loadings</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.CanICA.inverse_transform>¶</a></dt><dd><p>Use provided loadings to compute corresponding linear component combination in whole-brain voxel space</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>loadings</strong><span class=classifier>list of numpy array (n_samples x n_components)</span></dt><dd><p>Component signals to tranform back into voxel signals</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>reconstructed_imgs</strong><span class=classifier>list of nibabel.Nifti1Image</span></dt><dd><p>For each loading, reconstructed Nifti1Image</p></dd></dl></dd></dl></dd></dl> <dl class="py method"><dt id=nilearn.decomposition.CanICA.score><code class="sig-name descname">score</code><span class=sig-paren>(</span><em class=sig-param><span class=n>imgs</span></em>, <em class=sig-param><span class=n>confounds</span><span class=o>=</span><span class=default_value>None</span></em>, <em class=sig-param><span class=n>per_component</span><span class=o>=</span><span class=default_value>False</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.CanICA.score>¶</a></dt><dd><p>Score function based on explained variance on imgs.</p> <p>Should only be used by DecompositionEstimator derived classes</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>imgs</strong><span class=classifier>iterable of Niimg-like objects</span></dt><dd><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> Data to be scored</p></dd><dt><strong>confounds</strong><span class=classifier>CSV file path or numpy.ndarray or pandas DataFrame, optional</span></dt><dd><p>This parameter is passed to nilearn.signal.clean. Please see the related documentation for details</p></dd><dt><strong>per_component</strong><span class=classifier>bool, optional</span></dt><dd><p>Specify whether the explained variance ratio is desired for each map or for the global set of components. Default=False.</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>score</strong><span class=classifier>float</span></dt><dd><p>Holds the score for each subjects. Score is two dimensional if per_component is True. First dimension is squeezed if the number of subjects is one</p></dd></dl></dd></dl></dd></dl> <dl class="py method"><dt id=nilearn.decomposition.CanICA.set_params><code class="sig-name descname">set_params</code><span class=sig-paren>(</span><em class=sig-param><span class=o>**</span><span class=n>params</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.CanICA.set_params>¶</a></dt><dd><p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as <a class="reference external"title="(in scikit-learn v0.24)"href=https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline><code class="xref py py-class docutils literal notranslate"><span class=pre>Pipeline</span></code></a>). The latter have parameters of the form <code class="docutils literal notranslate"><span class=pre>&LTcomponent>__&LTparameter></span></code> so that it’s possible to update each component of a nested object.</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>**params</strong><span class=classifier>dict</span></dt><dd><p>Estimator parameters.</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>self</strong><span class=classifier>estimator instance</span></dt><dd><p>Estimator instance.</p></dd></dl></dd></dl></dd></dl> <dl class="py method"><dt id=nilearn.decomposition.CanICA.transform><code class="sig-name descname">transform</code><span class=sig-paren>(</span><em class=sig-param><span class=n>imgs</span></em>, <em class=sig-param><span class=n>confounds</span><span class=o>=</span><span class=default_value>None</span></em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.decomposition.CanICA.transform>¶</a></dt><dd><p>Project the data into a reduced representation</p> <dl class="field-list simple"><dt class=field-odd>Parameters</dt><dd class=field-odd><dl class=simple><dt><strong>imgs</strong><span class=classifier>iterable of Niimg-like objects</span></dt><dd><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> Data to be projected</p></dd><dt><strong>confounds</strong><span class=classifier>CSV file path or numpy.ndarray or pandas DataFrame, optional</span></dt><dd><p>This parameter is passed to nilearn.signal.clean. Please see the related documentation for details</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>loadings</strong><span class=classifier>list of 2D ndarray,</span></dt><dd><p>For each subject, each sample, loadings for each decomposition components shape: number of subjects * (number of scans, number of regions)</p></dd></dl></dd></dl></dd></dl></dd></dl><div class=section id=examples-using-nilearn-decomposition-canica><h2><span class=section-number>8.4.1.1. </span>Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.decomposition.CanICA</span></code><a title="Permalink to this headline"class=headerlink href=#examples-using-nilearn-decomposition-canica>¶</a></h2><div tooltip="Various approaches exist to derive spatial maps or networks from group fmr data. The methods ex..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id5><img alt="Deriving spatial maps from group fMRI data using ICA and Dictionary Learning"src=../../_images/sphx_glr_plot_compare_decomposition_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_compare_decomposition.html#sphx-glr-auto-examples-03-connectivity-plot-compare-decomposition-py><span class="std std-ref">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</span></a></span><a title="Permalink to this image"class=headerlink href=#id5>¶</a></p></div></div><div tooltip="This example shows how to use nilearn.regions.RegionExtractor to extract spatially constrained ..."class=sphx-glr-thumbcontainer><div class="figure align-default"id=id6><img alt="Regions extraction using Dictionary Learning and functional connectomes"src=../../_images/sphx_glr_plot_extract_regions_dictlearning_maps_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html#sphx-glr-auto-examples-03-connectivity-plot-extract-regions-dictlearning-maps-py><span class="std std-ref">Regions extraction using Dictionary Learning and functional connectomes</span></a></span><a title="Permalink to this image"class=headerlink href=#id6>¶</a></p></div></div><div style=clear:both></div></div></div><div class=clearer></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>8.4.1. nilearn.decomposition.CanICA</a><ul><li><a class="reference internal"href=#examples-using-nilearn-decomposition-canica>8.4.1.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.decomposition.CanICA</span></code></a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=nilearn.decoding.SearchLight.html><span class=section-number>8.3.7. </span>nilearn.decoding.SearchLight</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=nilearn.decomposition.DictLearning.html><span class=section-number>8.4.2. </span>nilearn.decomposition.DictLearning</a></p><div id=searchbox role=search style=display:none><h3 id=searchlabel>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input aria-labelledby=searchlabel name=q><input type=submit value=Go></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2020. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 3.4.2. <span style=padding-left:5ex> <a href=../../_sources/modules/generated/nilearn.decomposition.CanICA.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>