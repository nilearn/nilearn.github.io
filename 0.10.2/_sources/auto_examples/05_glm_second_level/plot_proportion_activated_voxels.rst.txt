
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/05_glm_second_level/plot_proportion_activated_voxels.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_05_glm_second_level_plot_proportion_activated_voxels.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_05_glm_second_level_plot_proportion_activated_voxels.py:


Second-level fMRI model: true positive proportion in clusters
=============================================================

This script showcases the so-called "All resolution inference" procedure, in
which the proportion of true discoveries in arbitrary clusters is estimated.
The clusters can be defined from the input image, i.e. in a circular way, as
the error control accounts for arbitrary cluster selection.

Rosenblatt JD, Finos L, Weeda WD, Solari A, Goeman JJ. All-Resolutions
Inference for brain imaging. Neuroimage. 2018 Nov 1;181:786-796. doi:
10.1016/j.neuroimage.2018.07.060

.. GENERATED FROM PYTHON SOURCE LINES 17-22

Fetch dataset
--------------
We download a list of left vs right button press contrasts from a
localizer dataset. Note that we fetch individual t-maps that represent the
BOLD activity estimate divided by the uncertainty about this estimate.

.. GENERATED FROM PYTHON SOURCE LINES 22-31

.. code-block:: default

    from nilearn.datasets import fetch_localizer_contrasts

    n_subjects = 16
    data = fetch_localizer_contrasts(
        ["left vs right button press"],
        n_subjects,
        get_tmaps=True,
        legacy_format=False,
    )




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading data from https://osf.io/download/5d27cb281c5b4a001aa07e29/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27ca3d1c5b4a001b9eeddb/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27e787114a420016059c22/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27eba2114a420016059fbf/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27efab1c5b4a001aa0a0c2/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d27f296114a42001704a5d9/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28095545253a001c3e59a2/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d280608a26b3400180868d1/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28144c114a42001804739e/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d2811d0114a42001704b988/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d281e3d114a42001605cb02/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d281f851c5b4a001b9f2315/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28375345253a001c3e90a2/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d282d9045253a001c3e80a1/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d283f021c5b4a001aa100cb/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d283ee0a26b34001609f58e/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d2852caa26b340018089ae5/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d285263114a4200160602c6/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28660b1c5b4a001aa122c7/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d285d61114a42001904a343/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d2868f9114a42001704f6a5/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28709e114a420016061aa1/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28847d114a42001904b87b/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d287b3a45253a00193d145e/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d289736114a4200170518d7/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28966345253a00193d2e27/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28b135a26b3400160a648e/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28a431a26b340019090fa2/ ...
     ...done. (2 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28c0a81c5b4a001b9fb89a/ ...
     ...done. (1 seconds, 0 min)
    Downloading data from https://osf.io/download/5d28b761a26b3400160a6ba8/ ...
     ...done. (2 seconds, 0 min)




.. GENERATED FROM PYTHON SOURCE LINES 32-36

Estimate second level model
---------------------------
We define the input maps and the design matrix for the second level model
and fit it.

.. GENERATED FROM PYTHON SOURCE LINES 36-43

.. code-block:: default

    import pandas as pd

    second_level_input = data["cmaps"]
    design_matrix = pd.DataFrame(
        [1] * len(second_level_input), columns=["intercept"]
    )








.. GENERATED FROM PYTHON SOURCE LINES 44-45

Model specification and fit

.. GENERATED FROM PYTHON SOURCE LINES 45-52

.. code-block:: default

    from nilearn.glm.second_level import SecondLevelModel

    second_level_model = SecondLevelModel(smoothing_fwhm=8.0)
    second_level_model = second_level_model.fit(
        second_level_input, design_matrix=design_matrix
    )








.. GENERATED FROM PYTHON SOURCE LINES 53-55

To estimate the contrast is very simple. We can just provide the column
name of the design matrix.

.. GENERATED FROM PYTHON SOURCE LINES 55-57

.. code-block:: default

    z_map = second_level_model.compute_contrast(output_type="z_score")








.. GENERATED FROM PYTHON SOURCE LINES 58-59

We threshold the second level contrast at uncorrected p < 0.001 and plot

.. GENERATED FROM PYTHON SOURCE LINES 59-90

.. code-block:: default

    from scipy.stats import norm

    p_val = 0.001
    p001_uncorrected = norm.isf(p_val)

    from nilearn.glm import cluster_level_inference

    proportion_true_discoveries_img = cluster_level_inference(
        z_map, threshold=[3, 4, 5], alpha=0.05
    )

    from nilearn import plotting

    plotting.plot_stat_map(
        proportion_true_discoveries_img,
        threshold=0.0,
        display_mode="z",
        vmax=1,
        colorbar=True,
        title="group left-right button press, proportion true positives",
    )

    plotting.plot_stat_map(
        z_map,
        threshold=p001_uncorrected,
        colorbar=True,
        display_mode="z",
        title="group left-right button press (uncorrected p < 0.001)",
    )

    plotting.show()



.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/05_glm_second_level/images/sphx_glr_plot_proportion_activated_voxels_001.png
         :alt: plot proportion activated voxels
         :srcset: /auto_examples/05_glm_second_level/images/sphx_glr_plot_proportion_activated_voxels_001.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/05_glm_second_level/images/sphx_glr_plot_proportion_activated_voxels_002.png
         :alt: plot proportion activated voxels
         :srcset: /auto_examples/05_glm_second_level/images/sphx_glr_plot_proportion_activated_voxels_002.png
         :class: sphx-glr-multi-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 53.725 seconds)

**Estimated memory usage:**  8 MB


.. _sphx_glr_download_auto_examples_05_glm_second_level_plot_proportion_activated_voxels.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/nilearn/nilearn/0.10.2?urlpath=lab/tree/notebooks/auto_examples/05_glm_second_level/plot_proportion_activated_voxels.ipynb
        :alt: Launch binder
        :width: 150 px



    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_proportion_activated_voxels.py <plot_proportion_activated_voxels.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_proportion_activated_voxels.ipynb <plot_proportion_activated_voxels.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
