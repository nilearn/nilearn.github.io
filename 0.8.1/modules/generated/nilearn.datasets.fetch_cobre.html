<!doctypehtml><html lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1.0 name=viewport><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/copybutton.css rel=stylesheet><link href=../../_static/gallery.css rel=stylesheet><link href=../../_static/gallery-binder.css rel=stylesheet><link href=../../_static/gallery-dataframe.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/clipboard.min.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="8.2.34. nilearn.datasets.fetch_neurovault"href=nilearn.datasets.fetch_neurovault.html rel=next><link title="8.2.32. nilearn.datasets.fetch_megatrawls_netmats"href=nilearn.datasets.fetch_megatrawls_netmats.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="8.2.34. nilearn.datasets.fetch_neurovault"accesskey=N href=nilearn.datasets.fetch_neurovault.html>next</a> |</li><li class=right><a title="8.2.32. nilearn.datasets.fetch_megatrawls_netmats"accesskey=P href=nilearn.datasets.fetch_megatrawls_netmats.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../../auto_examples/index.html>Examples</a> | </li><li><a href=../reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li><a href=../../glossary.html>Glossary</a>| </li><li><a href=../../bibliography.html>Bibliography</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../reference.html><span class=section-number>8. </span>Reference documentation: all nilearn functions</a> »</li><li class="nav-item nav-item-this"><a href>Nilearn: Statistical Analysis for NeuroImaging in Python</a></li></ul></div></div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="admonition note"><p class=admonition-title>Note</p><p>This page is a reference documentation. It only explains the function signature, and not how to use it. Please refer to the <a class="reference internal"href=../../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for the big picture.</p></div><div class=section id=nilearn-datasets-fetch-cobre><h1><span class=section-number>8.2.33. </span>nilearn.datasets.fetch_cobre<a title="Permalink to this headline"class=headerlink href=#nilearn-datasets-fetch-cobre>¶</a></h1><dl class="py function"><dt class="sig sig-object py"id=nilearn.datasets.fetch_cobre><span class="sig-prename descclassname"><span class=pre>nilearn.datasets.</span></span><span class="sig-name descname"><span class=pre>fetch_cobre</span></span><span class=sig-paren>(</span><em class=sig-param><span class=n><span class=pre>n_subjects</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>10</span></span></em>, <em class=sig-param><span class=n><span class=pre>data_dir</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>url</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>None</span></span></em>, <em class=sig-param><span class=n><span class=pre>verbose</span></span><span class=o><span class=pre>=</span></span><span class=default_value><span class=pre>1</span></span></em><span class=sig-paren>)</span><a class="reference external"href=https://github.com/nilearn/nilearn/blob/2fd66656/nilearn/datasets/func.py#L1235><span class=viewcode-link><span class=pre>[source]</span></span></a><a title="Permalink to this definition"class=headerlink href=#nilearn.datasets.fetch_cobre>¶</a></dt><dd><p>DEPRECATED: ‘fetch_cobre’ has been deprecated and will be removed in release 0.9 . Please consider using a different datasets or downloading it with a different tool than nilearn.</p> <p>Fetch COBRE datasets preprocessed using NIAK 0.17 under CentOS version 6.3 with Octave version 4.0.2 and the Minc toolkit version 0.3.18.</p> <p>Downloads and returns COBRE preprocessed resting state fMRI datasets, covariates and phenotypic information such as demographic, clinical variables, measure of frame displacement FD (an average FD for all the time frames left after censoring).</p> <p>Each subject <cite>fmri_XXXXXXX.nii.gz</cite> is a 3D+t nifti volume (150 volumes). WARNING: no confounds were actually regressed from the data, so it can be done interactively by the user who will be able to explore different analytical paths easily.</p> <p>For each subject, there is <cite>fmri_XXXXXXX.tsv</cite> files which contains the covariates such as motion parameters, mean CSF signal that should to be regressed out of the functional data.</p> <p><cite>keys_confounds.json</cite>: a json file, that describes each variable mentioned in the files <cite>fmri_XXXXXXX.tsv.gz</cite>. It also contains a list of time frames that have been removed from the time series by censoring for high motion.</p> <p><cite>phenotypic_data.tsv</cite> contains the data of clinical variables that explained in <cite>keys_phenotypic_data.json</cite></p> <div class=versionadded><p><span class="versionmodified added">New in version 0.3.</span></p></div> <dl class=field-list><dt class=field-odd>Parameters</dt><dd class=field-odd><dl><dt><strong>n_subjects</strong><span class=classifier>int, optional</span></dt><dd><p>The number of subjects to load from maximum of 146 subjects. By default, 10 subjects will be loaded. If n_subjects=None, all subjects will be loaded. Default=10.</p></dd><dt><strong>data_dir</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/pathlib.html#pathlib.Path><code class="xref py py-obj docutils literal notranslate"><span class=pre>pathlib.Path</span></code></a> or <a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/stdtypes.html#str><code class="xref py py-obj docutils literal notranslate"><span class=pre>str</span></code></a>, optional</span></dt><dd><p>Path where data should be downloaded. By default, files are downloaded in home directory.</p></dd><dt><strong>url</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/stdtypes.html#str><code class="xref py py-obj docutils literal notranslate"><span class=pre>str</span></code></a>, optional</span></dt><dd><p>URL of file to download. Override download URL. Used for test only (or if you setup a mirror of the data). Default=None.</p></dd><dt><strong>verbose</strong><span class=classifier><a class="reference external"title="(in Python v3.8)"href=https://docs.python.org/3.8/library/functions.html#int><code class="xref py py-obj docutils literal notranslate"><span class=pre>int</span></code></a>, optional</span></dt><dd><p>Verbosity level (0 means no message). Default=1.</p></dd></dl></dd><dt class=field-even>Returns</dt><dd class=field-even><dl class=simple><dt><strong>data</strong><span class=classifier>Bunch</span></dt><dd><p>Dictionary-like object, the attributes are:</p> <ul class=simple><li><dl class=simple><dt>‘func’: string list</dt><dd><p>Paths to Nifti images.</p></dd></dl></li><li><dl class=simple><dt>‘confounds’: string list</dt><dd><p>Paths to .tsv files of each subject, confounds.</p></dd></dl></li><li><dl class=simple><dt>‘phenotypic’: numpy.recarray</dt><dd><p>Contains data of clinical variables, sex, age, FD.</p></dd></dl></li><li><p>‘description’: data description of the release and references.</p></li><li><dl class=simple><dt>‘desc_con’: str</dt><dd><p>description of the confounds variables</p></dd></dl></li><li><dl class=simple><dt>‘desc_phenotypic’: str</dt><dd><p>description of the phenotypic variables.</p></dd></dl></li></ul></dd></dl></dd></dl> <div class="admonition warning"><p class=admonition-title>Warning</p><p>‘fetch_cobre’ has been deprecated and will be removed in release 0.9.</p></div> <p class=rubric>Notes</p> <p>See <a class="reference external"href=https://figshare.com/articles/COBRE_preprocessed_with_NIAK_0_17_-_lightweight_release/4197885>more information about datasets structure</a></p></dd></dl><div style=clear:both></div></div><div class=clearer></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=nilearn.datasets.fetch_megatrawls_netmats.html><span class=section-number>8.2.32. </span>nilearn.datasets.fetch_megatrawls_netmats</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=nilearn.datasets.fetch_neurovault.html><span class=section-number>8.2.34. </span>nilearn.datasets.fetch_neurovault</a></p><div id=searchbox role=search style=display:none><h3 id=searchlabel>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input aria-labelledby=searchlabel name=q><input type=submit value=Go></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2021. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 4.0.2. <span style=padding-left:5ex> <a href=../../_sources/modules/generated/nilearn.datasets.fetch_cobre.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>