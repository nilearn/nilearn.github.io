<!doctypehtml><html class=no-js data-content_root=../ lang=en><meta charset=utf-8><meta content=width=device-width,initial-scale=1 name=viewport><meta content="light dark"name=color-scheme><meta content=width=device-width,initial-scale=1 name=viewport><meta content="8.1. An introduction to GLMs in fMRI statistical analysis"property=og:title><meta content=website property=og:type><meta content=https://nilearn.github.io/glm/glm_intro.html property=og:url><meta content=Nilearn property=og:site_name><meta content="A primer on BOLD-fMRI data analysis: What is fMRI ?: Functional magnetic resonance imaging ( fMRI) is based on the fact that when local neural activity increases, increases in metabolism and blood ..."property=og:description><meta content=https://nilearn.github.io/_images/stimulation-time-diagram.png property=og:image><meta content=Nilearn property=og:image:alt><meta content="A primer on BOLD-fMRI data analysis: What is fMRI ?: Functional magnetic resonance imaging ( fMRI) is based on the fact that when local neural activity increases, increases in metabolism and blood ..."name=description><link href=../search.html rel=search title=Search><link title="8.2. First level models"href=first_level_model.html rel=next><link title="8. Analyzing fMRI using GLMs"href=index.html rel=prev><link rel="shortcut icon"href=../_static/favicon.ico><title>8.1. An introduction to GLMs in fMRI statistical analysis - Nilearn</title><link href=../_static/pygments.css?v=045299b1 rel=stylesheet><link href=../_static/styles/furo.css?v=135e06be rel=stylesheet><link href=../_static/copybutton.css?v=76b2166b rel=stylesheet><link href=../_static/sg_gallery.css?v=61a4c737 rel=stylesheet><link href=../_static/sg_gallery-binder.css?v=f4aeca0c rel=stylesheet><link href=../_static/sg_gallery-dataframe.css?v=2082cf3c rel=stylesheet><link href=../_static/sg_gallery-rendered-html.css?v=1277b6f3 rel=stylesheet><link href=../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7 rel=stylesheet><link href=../_static/styles/furo-extensions.css?v=36a5483c rel=stylesheet><link href=../_static/custom.css?v=486f7390 rel=stylesheet><link href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css rel=stylesheet><link href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/fontawesome.min.css rel=stylesheet><link href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/solid.min.css rel=stylesheet><link href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/brands.min.css rel=stylesheet><style>body{--color-code-background:#fff;--color-code-foreground:black;--admonition-font-size:100%;--admonition-title-font-size:100%;--color-announcement-background:#fbb360;--color-announcement-text:#111418;--color-admonition-title--note:#448aff;--color-admonition-title-background--note:#448aff10}@media not print{body[data-theme=dark]{--color-code-background:#232629;--color-code-foreground:#ccc;--color-announcement-background:#935610;--color-announcement-text:#fff}@media (prefers-color-scheme:dark){body:not([data-theme=light]){--color-code-background:#232629;--color-code-foreground:#ccc;--color-announcement-background:#935610;--color-announcement-text:#fff}}}</style><body><script>document.body.dataset.theme = localStorage.getItem("theme") || "auto";</script><svg style=display:none xmlns=http://www.w3.org/2000/svg><symbol viewbox="0 0 24 24"id=svg-toc><title>Contents</title><svg viewbox="0 0 1024 1024"fill=currentColor stroke=currentColor stroke-width=0><path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/></svg></symbol><symbol viewbox="0 0 24 24"id=svg-menu><title>Menu</title><svg viewbox="0 0 24 24"class=feather-menu fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 xmlns=http://www.w3.org/2000/svg><line x1=3 x2=21 y1=12 y2=12></line><line x1=3 x2=21 y1=6 y2=6></line><line x1=3 x2=21 y1=18 y2=18></line></svg></symbol><symbol viewbox="0 0 24 24"id=svg-arrow-right><title>Expand</title><svg viewbox="0 0 24 24"class=feather-chevron-right fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 xmlns=http://www.w3.org/2000/svg><polyline points="9 18 15 12 9 6"></polyline></svg></symbol><symbol viewbox="0 0 24 24"id=svg-sun><title>Light mode</title><svg viewbox="0 0 24 24"class=feather-sun fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=1.5 xmlns=http://www.w3.org/2000/svg><circle cx=12 cy=12 r=5></circle><line x1=12 x2=12 y1=1 y2=3></line><line x1=12 x2=12 y1=21 y2=23></line><line x1=4.22 x2=5.64 y1=4.22 y2=5.64></line><line x1=18.36 x2=19.78 y1=18.36 y2=19.78></line><line x1=1 x2=3 y1=12 y2=12></line><line x1=21 x2=23 y1=12 y2=12></line><line x1=4.22 x2=5.64 y1=19.78 y2=18.36></line><line x1=18.36 x2=19.78 y1=5.64 y2=4.22></line></svg></symbol><symbol viewbox="0 0 24 24"id=svg-moon><title>Dark mode</title><svg viewbox="0 0 24 24"class=icon-tabler-moon fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=1.5 xmlns=http://www.w3.org/2000/svg><path d="M0 0h24v24H0z"fill=none stroke=none /><path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z"/></svg></symbol><symbol viewbox="0 0 24 24"id=svg-sun-half><title>Auto light/dark mode</title><svg viewbox="0 0 24 24"class=icon-tabler-shadow fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=1.5 xmlns=http://www.w3.org/2000/svg><path d="M0 0h24v24H0z"fill=none stroke=none /><circle cx=12 cy=12 r=9 /><path d="M13 12h5"/><path d="M13 15h4"/><path d="M13 18h1"/><path d="M13 9h4"/><path d="M13 6h1"/></svg></symbol></svg><input class=sidebar-toggle id=__navigation name=__navigation type=checkbox><input class=sidebar-toggle id=__toc name=__toc type=checkbox><label class="overlay sidebar-overlay"for=__navigation><div class=visually-hidden>Hide navigation sidebar</div></label><label class="overlay toc-overlay"for=__toc><div class=visually-hidden>Hide table of contents sidebar</div></label><div class=page><header class=mobile-header><div class=header-left><label class=nav-overlay-icon for=__navigation><div class=visually-hidden>Toggle site navigation sidebar</div> <i class=icon><svg><use href=#svg-menu></use></svg></i></label></div><div class=header-center><a href=../index.html><div class=brand>Nilearn</div></a></div><div class=header-right><div class="theme-toggle-container theme-toggle-header"><button class=theme-toggle><div class=visually-hidden>Toggle Light / Dark / Auto color theme</div> <svg class=theme-icon-when-auto><use href=#svg-sun-half></use></svg> <svg class=theme-icon-when-dark><use href=#svg-moon></use></svg> <svg class=theme-icon-when-light><use href=#svg-sun></use></svg></button></div><label class="toc-overlay-icon toc-header-icon"for=__toc><div class=visually-hidden>Toggle table of contents sidebar</div> <i class=icon><svg><use href=#svg-toc></use></svg></i></label></div></header><aside class=sidebar-drawer><div class=sidebar-container><div class=sidebar-sticky><a class=sidebar-brand href=../index.html> <div class=sidebar-logo-container><img alt=Logo class=sidebar-logo src=../_static/nilearn-transparent.png></div> <span class=sidebar-brand-text>Nilearn</span> </a><form action=../search.html class=sidebar-search-container role=search><input aria-label=Search class=sidebar-search name=q placeholder=Search><input name=check_keywords type=hidden value=yes><input name=area type=hidden value=default></form><div id=searchbox></div><div class=sidebar-scroll><div class=sidebar-tree><ul class=current><li class=toctree-l1><a class="reference internal"href=../quickstart.html>Quickstart</a></li><li class="toctree-l1 has-children"><a class="reference internal"href=../auto_examples/index.html>Examples</a><input class=toctree-checkbox id=toctree-checkbox-1 name=toctree-checkbox-1 role=switch type=checkbox><label for=toctree-checkbox-1><div class=visually-hidden>Toggle navigation of Examples</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class="toctree-l2 has-children"><a class="reference internal"href=../auto_examples/00_tutorials/index.html>Basic tutorials</a><input class=toctree-checkbox id=toctree-checkbox-2 name=toctree-checkbox-2 role=switch type=checkbox><label for=toctree-checkbox-2><div class=visually-hidden>Toggle navigation of Basic tutorials</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../auto_examples/00_tutorials/plot_python_101.html>Basic numerics and plotting with Python</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/00_tutorials/plot_3d_and_4d_niimg.html>3D and 4D niimgs: handling and visualizing</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/00_tutorials/plot_nilearn_101.html>Basic nilearn example: manipulating and looking at data</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/00_tutorials/plot_decoding_tutorial.html>A introduction tutorial to fMRI decoding</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/00_tutorials/plot_single_subject_single_run.html>Intro to GLM Analysis: a single-run, single-subject fMRI dataset</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../auto_examples/01_plotting/index.html>Visualization of brain images</a><input class=toctree-checkbox id=toctree-checkbox-3 name=toctree-checkbox-3 role=switch type=checkbox><label for=toctree-checkbox-3><div class=visually-hidden>Toggle navigation of Visualization of brain images</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_demo_glass_brain.html>Glass brain plotting in nilearn</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_visualize_megatrawls_netmats.html>Visualizing Megatrawls Network Matrices from Human Connectome Project</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_prob_atlas.html>Visualizing 4D probabilistic atlas maps</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_atlas.html>Basic Atlas plotting</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_overlay.html>Visualizing a probabilistic atlas: the default mode in the MSDL atlas</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_dim_plotting.html>Controlling the contrast of the background when plotting</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_multiscale_parcellations.html>Visualizing multiscale functional brain parcellations</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_colormaps.html>Matplotlib colormaps in Nilearn</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_visualization.html>NeuroImaging volumes visualization</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_carpet.html>Visualizing global patterns with a carpet plot</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_haxby_masks.html>Plot Haxby masks</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_surface_projection_strategies.html>Technical point: Illustration of the volume to surface sampling schemes</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_demo_plotting.html>Plotting tools in nilearn</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_surf_atlas.html>Loading and plotting of a cortical surface atlas</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_3d_map_to_surface_projection.html>Making a surface plot of a 3D statistical map</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_demo_more_plotting.html>More plotting tools from nilearn</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_demo_glass_brain_extensive.html>Glass brain plotting in nilearn (all options)</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/01_plotting/plot_surf_stat_map.html>Seed-based connectivity on the surface</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../auto_examples/02_decoding/index.html>Decoding and predicting from brain images</a><input class=toctree-checkbox id=toctree-checkbox-4 name=toctree-checkbox-4 role=switch type=checkbox><label for=toctree-checkbox-4><div class=visually-hidden>Toggle navigation of Decoding and predicting from brain images</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../auto_examples/02_decoding/plot_haxby_stimuli.html>Show stimuli of Haxby et al. dataset</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/02_decoding/plot_mixed_gambles_frem.html>FREM on Jimura et al “mixed gambles” dataset</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/02_decoding/plot_oasis_vbm_space_net.html>Voxel-Based Morphometry on Oasis dataset with Space-Net prior</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/02_decoding/plot_haxby_searchlight_surface.html>Cortical surface-based searchlight decoding</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/02_decoding/plot_haxby_frem.html>Decoding with FREM: face vs house vs chair object recognition</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/02_decoding/plot_haxby_anova_svm.html>Decoding with ANOVA + SVM: face vs house in the Haxby dataset</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/02_decoding/plot_haxby_multiclass.html>The haxby dataset: different multi-class strategies</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/02_decoding/plot_haxby_searchlight.html>Searchlight analysis of face vs house recognition</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/02_decoding/plot_haxby_glm_decoding.html>Decoding of a dataset after GLM fit for signal extraction</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/02_decoding/plot_haxby_full_analysis.html>ROI-based decoding analysis in Haxby et al. dataset</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/02_decoding/plot_haxby_grid_search.html>Setting a parameter by cross-validation</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/02_decoding/plot_oasis_vbm.html>Voxel-Based Morphometry on Oasis dataset</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/02_decoding/plot_haxby_different_estimators.html>Different classifiers in decoding the Haxby dataset</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/02_decoding/plot_simulated_data.html>Example of pattern recognition on simulated data</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/02_decoding/plot_miyawaki_encoding.html>Encoding models for visual stimuli from Miyawaki et al. 2008</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/02_decoding/plot_miyawaki_reconstruction.html>Reconstruction of visual stimuli from Miyawaki et al. 2008</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../auto_examples/03_connectivity/index.html>Functional connectivity</a><input class=toctree-checkbox id=toctree-checkbox-5 name=toctree-checkbox-5 role=switch type=checkbox><label for=toctree-checkbox-5><div class=visually-hidden>Toggle navigation of Functional connectivity</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../auto_examples/03_connectivity/plot_inverse_covariance_connectome.html>Computing a connectome with sparse inverse covariance</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/03_connectivity/plot_probabilistic_atlas_extraction.html>Extracting signals of a probabilistic atlas of functional regions</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/03_connectivity/plot_simulated_connectome.html>Connectivity structure estimation on simulated data</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/03_connectivity/plot_multi_subject_connectome.html>Group Sparse inverse covariance for multi-subject connectome</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html>Producing single subject maps of seed-to-voxel correlation</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/03_connectivity/plot_compare_decomposition.html>Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html>Regions extraction using dictionary learning and functional connectomes</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/03_connectivity/plot_atlas_comparison.html>Comparing connectomes on different reference atlases</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/03_connectivity/plot_group_level_connectivity.html>Classification of age groups using functional connectivity</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/03_connectivity/plot_signal_extraction.html>Extracting signals from a brain parcellation</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/03_connectivity/plot_sphere_based_connectome.html>Extract signals on spheres and plot a connectome</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/03_connectivity/plot_data_driven_parcellations.html>Clustering methods to learn a brain parcellation from fMRI</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../auto_examples/04_glm_first_level/index.html>GLM: First level analysis</a><input class=toctree-checkbox id=toctree-checkbox-6 name=toctree-checkbox-6 role=switch type=checkbox><label for=toctree-checkbox-6><div class=visually-hidden>Toggle navigation of GLM: First level analysis</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../auto_examples/04_glm_first_level/plot_design_matrix.html>Examples of design matrices</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/04_glm_first_level/plot_write_events_file.html>Generate an events.tsv file for the NeuroSpin localizer task</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/04_glm_first_level/plot_adhd_dmn.html>Default Mode Network extraction of ADHD dataset</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/04_glm_first_level/plot_fir_model.html>Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/04_glm_first_level/plot_spm_multimodal_faces.html>Single-subject data (two runs) in native space</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/04_glm_first_level/plot_hrf.html>Example of MRI response functions</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/04_glm_first_level/plot_predictions_residuals.html>Predicted time series and residuals</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/04_glm_first_level/plot_bids_features.html>First level analysis of a complete BIDS dataset from openneuro</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/04_glm_first_level/plot_localizer_surface_analysis.html>Example of surface-based first-level analysis</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/04_glm_first_level/plot_two_runs_model.html>Simple example of two-runs fMRI model fitting</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/04_glm_first_level/plot_first_level_details.html>Understanding parameters of the first-level model</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../auto_examples/05_glm_second_level/index.html>GLM: Second level analysis</a><input class=toctree-checkbox id=toctree-checkbox-7 name=toctree-checkbox-7 role=switch type=checkbox><label for=toctree-checkbox-7><div class=visually-hidden>Toggle navigation of GLM: Second level analysis</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../auto_examples/05_glm_second_level/plot_second_level_design_matrix.html>Example of second level design matrix</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/05_glm_second_level/plot_proportion_activated_voxels.html>Second-level fMRI model: true positive proportion in clusters</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/05_glm_second_level/plot_thresholding.html>Statistical testing of a second-level analysis</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/05_glm_second_level/plot_oasis.html>Voxel-Based Morphometry on OASIS dataset</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/05_glm_second_level/plot_second_level_two_sample_test.html>Second-level fMRI model: two-sample test, unpaired and paired</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html>Second-level fMRI model: one sample test</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/05_glm_second_level/plot_second_level_association_test.html>Example of generic design in second-level models</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../auto_examples/06_manipulating_images/index.html>Manipulating brain image volumes</a><input class=toctree-checkbox id=toctree-checkbox-8 name=toctree-checkbox-8 role=switch type=checkbox><label for=toctree-checkbox-8><div class=visually-hidden>Toggle navigation of Manipulating brain image volumes</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../auto_examples/06_manipulating_images/plot_negate_image.html>Negating an image with math_img</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/06_manipulating_images/plot_compare_mean_image.html>Comparing the means of 2 images</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/06_manipulating_images/plot_smooth_mean_image.html>Smoothing an image</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/06_manipulating_images/plot_extract_regions_labels_image.html>Breaking an atlas of labels in separated regions</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/06_manipulating_images/plot_resample_to_template.html>Resample an image to a template</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/06_manipulating_images/plot_extract_rois_smith_atlas.html>Regions Extraction of Default Mode Networks using Smith Atlas</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/06_manipulating_images/plot_nifti_simple.html>Simple example of NiftiMasker use</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/06_manipulating_images/plot_extract_rois_statistical_maps.html>Region Extraction using a t-statistical map (3D)</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/06_manipulating_images/plot_nifti_labels_simple.html>Extracting signals from brain regions using the NiftiLabelsMasker</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/06_manipulating_images/plot_mask_computation.html>Understanding NiftiMasker and mask computation</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/06_manipulating_images/plot_affine_transformation.html>Visualization of affine resamplings</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/06_manipulating_images/plot_roi_extraction.html>Computing a Region of Interest (ROI) mask manually</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../auto_examples/07_advanced/index.html>Advanced statistical analysis of brain images</a><input class=toctree-checkbox id=toctree-checkbox-9 name=toctree-checkbox-9 role=switch type=checkbox><label for=toctree-checkbox-9><div class=visually-hidden>Toggle navigation of Advanced statistical analysis of brain images</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../auto_examples/07_advanced/plot_ica_resting_state.html>Multivariate decompositions: Independent component analysis of fMRI</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/07_advanced/plot_localizer_simple_analysis.html>Massively univariate analysis of a calculation task from the Localizer dataset</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/07_advanced/plot_bids_analysis.html>BIDS dataset first and second level analysis</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/07_advanced/plot_neurovault_meta_analysis.html>NeuroVault meta-analysis of stop-go paradigm studies</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/07_advanced/plot_age_group_prediction_cross_val.html>Functional connectivity predicts age group</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/07_advanced/plot_surface_bids_analysis.html>Surface-based dataset first and second level analysis of a dataset</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/07_advanced/plot_localizer_mass_univariate_methods.html>Massively univariate analysis of a motor task from the Localizer dataset</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/07_advanced/plot_ica_neurovault.html>NeuroVault cross-study ICA maps</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/07_advanced/plot_haxby_mass_univariate.html>Massively univariate analysis of face vs house recognition</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/07_advanced/plot_advanced_decoding_scikit.html>Advanced decoding using scikit learn</a></li><li class=toctree-l3><a class="reference internal"href=../auto_examples/07_advanced/plot_beta_series.html>Beta-Series Modeling for Task-Based Functional Connectivity and Decoding</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../auto_examples/08_experimental/index.html>Examples for experimental modules</a><input class=toctree-checkbox id=toctree-checkbox-10 name=toctree-checkbox-10 role=switch type=checkbox><label for=toctree-checkbox-10><div class=visually-hidden>Toggle navigation of Examples for experimental modules</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../auto_examples/08_experimental/plot_surface_image_and_maskers.html>A short demo of the surface images & maskers</a></li></ul></li></ul></li><li class="toctree-l1 current has-children"><a class="reference internal"href=../user_guide.html>User guide</a><input checked class=toctree-checkbox id=toctree-checkbox-11 name=toctree-checkbox-11 role=switch type=checkbox><label for=toctree-checkbox-11><div class=visually-hidden>Toggle navigation of User guide</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul class=current><li class=toctree-l2><a class="reference internal"href=../introduction.html>1. Introduction</a></li><li class=toctree-l2><a class="reference internal"href=../introduction.html#what-is-nilearn>2. What is <code class="docutils literal notranslate"><span class=pre>nilearn</span></code>?</a></li><li class=toctree-l2><a class="reference internal"href=../introduction.html#using-nilearn-for-the-first-time>3. Using <code class="docutils literal notranslate"><span class=pre>nilearn</span></code> for the first time</a></li><li class=toctree-l2><a class="reference internal"href=../introduction.html#machine-learning-applications-to-neuroimaging>4. Machine learning applications to Neuroimaging</a></li><li class="toctree-l2 has-children"><a class="reference internal"href=../decoding/index.html>5. Decoding and MVPA: predicting from brain images</a><input class=toctree-checkbox id=toctree-checkbox-12 name=toctree-checkbox-12 role=switch type=checkbox><label for=toctree-checkbox-12><div class=visually-hidden>Toggle navigation of 5. Decoding and MVPA: predicting from brain images</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../decoding/decoding_intro.html>5.1. An introduction to decoding</a></li><li class=toctree-l3><a class="reference internal"href=../decoding/estimator_choice.html>5.2. Choosing the right predictive model for neuroimaging</a></li><li class=toctree-l3><a class="reference internal"href=../decoding/frem.html>5.3. FREM: fast ensembling of regularized models for robust decoding</a></li><li class=toctree-l3><a class="reference internal"href=../decoding/space_net.html>5.4. SpaceNet: decoding with spatial structure for better maps</a></li><li class=toctree-l3><a class="reference internal"href=../decoding/searchlight.html>5.5. Searchlight : finding voxels containing information</a></li><li class=toctree-l3><a class="reference internal"href=../decoding/going_further.html>5.6. Running scikit-learn functions for more control on the analysis</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../connectivity/index.html>6. Functional connectivity and resting state</a><input class=toctree-checkbox id=toctree-checkbox-13 name=toctree-checkbox-13 role=switch type=checkbox><label for=toctree-checkbox-13><div class=visually-hidden>Toggle navigation of 6. Functional connectivity and resting state</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../connectivity/functional_connectomes.html>6.1. Extracting times series to build a functional connectome</a></li><li class="toctree-l3 has-children"><a class="reference internal"href=../connectivity/connectome_extraction.html>6.2. Connectome extraction: inverse covariance for direct connections</a><input class=toctree-checkbox id=toctree-checkbox-14 name=toctree-checkbox-14 role=switch type=checkbox><label for=toctree-checkbox-14><div class=visually-hidden>Toggle navigation of 6.2. Connectome extraction: inverse covariance for direct connections</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l4><a class="reference internal"href=../developers/group_sparse_covariance.html>6.2.3.1. Group-sparse covariance estimation</a></li></ul></li><li class=toctree-l3><a class="reference internal"href=../connectivity/resting_state_networks.html>6.3. Extracting functional brain networks: ICA and related</a></li><li class=toctree-l3><a class="reference internal"href=../connectivity/region_extraction.html>6.4. Region Extraction for better brain parcellations</a></li><li class=toctree-l3><a class="reference internal"href=../connectivity/parcellating.html>6.5. Clustering to parcellate the brain in regions</a></li></ul></li><li class=toctree-l2><a class="reference internal"href=../plotting/index.html>7. Plotting brain images</a></li><li class="toctree-l2 current has-children"><a class="reference internal"href=index.html>8. Analyzing fMRI using GLMs</a><input checked class=toctree-checkbox id=toctree-checkbox-15 name=toctree-checkbox-15 role=switch type=checkbox><label for=toctree-checkbox-15><div class=visually-hidden>Toggle navigation of 8. Analyzing fMRI using GLMs</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul class=current><li class="toctree-l3 current current-page"><a class="current reference internal"href=#>8.1. An introduction to GLMs in fMRI statistical analysis</a></li><li class=toctree-l3><a class="reference internal"href=first_level_model.html>8.2. First level models</a></li><li class=toctree-l3><a class="reference internal"href=second_level_model.html>8.3. Second level models</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../manipulating_images/index.html>9. Manipulation brain volumes with nilearn</a><input class=toctree-checkbox id=toctree-checkbox-16 name=toctree-checkbox-16 role=switch type=checkbox><label for=toctree-checkbox-16><div class=visually-hidden>Toggle navigation of 9. Manipulation brain volumes with nilearn</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../manipulating_images/input_output.html>9.1. Input and output: neuroimaging data representation</a></li><li class=toctree-l3><a class="reference internal"href=../manipulating_images/manipulating_images.html>9.2. Manipulating images: resampling, smoothing, masking, ROIs…</a></li><li class=toctree-l3><a class="reference internal"href=../manipulating_images/masker_objects.html>9.3. From neuroimaging volumes to data matrices: the masker objects</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../building_blocks/index.html>10. Advanced usage: manual pipelines and scaling up</a><input class=toctree-checkbox id=toctree-checkbox-17 name=toctree-checkbox-17 role=switch type=checkbox><label for=toctree-checkbox-17><div class=visually-hidden>Toggle navigation of 10. Advanced usage: manual pipelines and scaling up</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../building_blocks/manual_pipeline.html>10.1. Building your own neuroimaging machine-learning pipeline</a></li><li class=toctree-l3><a class="reference internal"href=../building_blocks/neurovault.html>10.2. Downloading statistical maps from the Neurovault repository</a></li></ul></li></ul></li><li class="toctree-l1 has-children"><a class="reference internal"href=../modules/index.html>API References</a><input class=toctree-checkbox id=toctree-checkbox-18 name=toctree-checkbox-18 role=switch type=checkbox><label for=toctree-checkbox-18><div class=visually-hidden>Toggle navigation of API References</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class="toctree-l2 has-children"><a class="reference internal"href=../modules/connectome.html><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.connectome</span></code>: Functional Connectivity</a><input class=toctree-checkbox id=toctree-checkbox-19 name=toctree-checkbox-19 role=switch type=checkbox><label for=toctree-checkbox-19><div class=visually-hidden>Toggle navigation of nilearn.connectome: Functional Connectivity</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.connectome.ConnectivityMeasure.html>nilearn.connectome.ConnectivityMeasure</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.connectome.GroupSparseCovariance.html>nilearn.connectome.GroupSparseCovariance</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.connectome.GroupSparseCovarianceCV.html>nilearn.connectome.GroupSparseCovarianceCV</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.connectome.sym_matrix_to_vec.html>nilearn.connectome.sym_matrix_to_vec</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.connectome.vec_to_sym_matrix.html>nilearn.connectome.vec_to_sym_matrix</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.connectome.group_sparse_covariance.html>nilearn.connectome.group_sparse_covariance</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.connectome.cov_to_corr.html>nilearn.connectome.cov_to_corr</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.connectome.prec_to_partial.html>nilearn.connectome.prec_to_partial</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../modules/datasets.html><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.datasets</span></code>: Automatic Dataset Fetching</a><input class=toctree-checkbox id=toctree-checkbox-20 name=toctree-checkbox-20 role=switch type=checkbox><label for=toctree-checkbox-20><div class=visually-hidden>Toggle navigation of nilearn.datasets: Automatic Dataset Fetching</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_icbm152_2009.html>nilearn.datasets.fetch_icbm152_2009</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_icbm152_brain_gm_mask.html>nilearn.datasets.fetch_icbm152_brain_gm_mask</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_surf_fsaverage.html>nilearn.datasets.fetch_surf_fsaverage</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.load_mni152_brain_mask.html>nilearn.datasets.load_mni152_brain_mask</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.load_mni152_gm_mask.html>nilearn.datasets.load_mni152_gm_mask</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.load_mni152_gm_template.html>nilearn.datasets.load_mni152_gm_template</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.load_mni152_template.html>nilearn.datasets.load_mni152_template</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.load_mni152_wm_mask.html>nilearn.datasets.load_mni152_wm_mask</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.load_mni152_wm_template.html>nilearn.datasets.load_mni152_wm_template</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_atlas_aal.html>nilearn.datasets.fetch_atlas_aal</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_atlas_allen_2011.html>nilearn.datasets.fetch_atlas_allen_2011</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_atlas_basc_multiscale_2015.html>nilearn.datasets.fetch_atlas_basc_multiscale_2015</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_atlas_craddock_2012.html>nilearn.datasets.fetch_atlas_craddock_2012</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_atlas_destrieux_2009.html>nilearn.datasets.fetch_atlas_destrieux_2009</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_atlas_difumo.html>nilearn.datasets.fetch_atlas_difumo</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_atlas_harvard_oxford.html>nilearn.datasets.fetch_atlas_harvard_oxford</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_atlas_juelich.html>nilearn.datasets.fetch_atlas_juelich</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_atlas_msdl.html>nilearn.datasets.fetch_atlas_msdl</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_atlas_pauli_2017.html>nilearn.datasets.fetch_atlas_pauli_2017</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_atlas_schaefer_2018.html>nilearn.datasets.fetch_atlas_schaefer_2018</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_atlas_smith_2009.html>nilearn.datasets.fetch_atlas_smith_2009</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_atlas_surf_destrieux.html>nilearn.datasets.fetch_atlas_surf_destrieux</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_atlas_talairach.html>nilearn.datasets.fetch_atlas_talairach</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_atlas_yeo_2011.html>nilearn.datasets.fetch_atlas_yeo_2011</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_coords_dosenbach_2010.html>nilearn.datasets.fetch_coords_dosenbach_2010</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_coords_power_2011.html>nilearn.datasets.fetch_coords_power_2011</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_coords_seitzman_2018.html>nilearn.datasets.fetch_coords_seitzman_2018</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_abide_pcp.html>nilearn.datasets.fetch_abide_pcp</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_adhd.html>nilearn.datasets.fetch_adhd</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_bids_langloc_dataset.html>nilearn.datasets.fetch_bids_langloc_dataset</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_development_fmri.html>nilearn.datasets.fetch_development_fmri</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_ds000030_urls.html>nilearn.datasets.fetch_ds000030_urls</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_fiac_first_level.html>nilearn.datasets.fetch_fiac_first_level</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_haxby.html>nilearn.datasets.fetch_haxby</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_language_localizer_demo_dataset.html>nilearn.datasets.fetch_language_localizer_demo_dataset</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_localizer_first_level.html>nilearn.datasets.fetch_localizer_first_level</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_miyawaki2008.html>nilearn.datasets.fetch_miyawaki2008</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_openneuro_dataset_index.html>nilearn.datasets.fetch_openneuro_dataset_index</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_spm_auditory.html>nilearn.datasets.fetch_spm_auditory</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_spm_multimodal_fmri.html>nilearn.datasets.fetch_spm_multimodal_fmri</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_surf_nki_enhanced.html>nilearn.datasets.fetch_surf_nki_enhanced</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_localizer_button_task.html>nilearn.datasets.fetch_localizer_button_task</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_localizer_calculation_task.html>nilearn.datasets.fetch_localizer_calculation_task</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_localizer_contrasts.html>nilearn.datasets.fetch_localizer_contrasts</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_megatrawls_netmats.html>nilearn.datasets.fetch_megatrawls_netmats</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_mixed_gambles.html>nilearn.datasets.fetch_mixed_gambles</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_oasis_vbm.html>nilearn.datasets.fetch_oasis_vbm</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_neurovault_auditory_computation_task.html>nilearn.datasets.fetch_neurovault_auditory_computation_task</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_neurovault_motor_task.html>nilearn.datasets.fetch_neurovault_motor_task</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_neurovault.html>nilearn.datasets.fetch_neurovault</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_neurovault_ids.html>nilearn.datasets.fetch_neurovault_ids</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.fetch_openneuro_dataset.html>nilearn.datasets.fetch_openneuro_dataset</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.get_data_dirs.html>nilearn.datasets.get_data_dirs</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.patch_openneuro_dataset.html>nilearn.datasets.patch_openneuro_dataset</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.select_from_index.html>nilearn.datasets.select_from_index</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.datasets.load_sample_motor_activation_image.html>nilearn.datasets.load_sample_motor_activation_image</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../modules/decoding.html><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.decoding</span></code>: Decoding</a><input class=toctree-checkbox id=toctree-checkbox-21 name=toctree-checkbox-21 role=switch type=checkbox><label for=toctree-checkbox-21><div class=visually-hidden>Toggle navigation of nilearn.decoding: Decoding</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.decoding.Decoder.html>nilearn.decoding.Decoder</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.decoding.DecoderRegressor.html>nilearn.decoding.DecoderRegressor</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.decoding.FREMClassifier.html>nilearn.decoding.FREMClassifier</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.decoding.FREMRegressor.html>nilearn.decoding.FREMRegressor</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.decoding.SpaceNetClassifier.html>nilearn.decoding.SpaceNetClassifier</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.decoding.SpaceNetRegressor.html>nilearn.decoding.SpaceNetRegressor</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.decoding.SearchLight.html>nilearn.decoding.SearchLight</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../modules/decomposition.html><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.decomposition</span></code>: Multivariate Decompositions</a><input class=toctree-checkbox id=toctree-checkbox-22 name=toctree-checkbox-22 role=switch type=checkbox><label for=toctree-checkbox-22><div class=visually-hidden>Toggle navigation of nilearn.decomposition: Multivariate Decompositions</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.decomposition.CanICA.html>nilearn.decomposition.CanICA</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.decomposition.DictLearning.html>nilearn.decomposition.DictLearning</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../modules/experimental.html><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.experimental</span></code>: Experimental Modules</a><input class=toctree-checkbox id=toctree-checkbox-23 name=toctree-checkbox-23 role=switch type=checkbox><label for=toctree-checkbox-23><div class=visually-hidden>Toggle navigation of nilearn.experimental: Experimental Modules</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.experimental.surface.FileMesh.html>nilearn.experimental.surface.FileMesh</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.experimental.surface.InMemoryMesh.html>nilearn.experimental.surface.InMemoryMesh</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.experimental.surface.Mesh.html>nilearn.experimental.surface.Mesh</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.experimental.surface.PolyMesh.html>nilearn.experimental.surface.PolyMesh</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.experimental.surface.SurfaceImage.html>nilearn.experimental.surface.SurfaceImage</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.experimental.surface.SurfaceLabelsMasker.html>nilearn.experimental.surface.SurfaceLabelsMasker</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.experimental.surface.SurfaceMasker.html>nilearn.experimental.surface.SurfaceMasker</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.experimental.surface.fetch_destrieux.html>nilearn.experimental.surface.fetch_destrieux</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.experimental.surface.fetch_nki.html>nilearn.experimental.surface.fetch_nki</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.experimental.surface.load_fsaverage.html>nilearn.experimental.surface.load_fsaverage</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../modules/glm.html><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.glm</span></code>: Generalized Linear Models</a><input class=toctree-checkbox id=toctree-checkbox-24 name=toctree-checkbox-24 role=switch type=checkbox><label for=toctree-checkbox-24><div class=visually-hidden>Toggle navigation of nilearn.glm: Generalized Linear Models</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.Contrast.html>nilearn.glm.Contrast</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.FContrastResults.html>nilearn.glm.FContrastResults</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.TContrastResults.html>nilearn.glm.TContrastResults</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.ARModel.html>nilearn.glm.ARModel</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.OLSModel.html>nilearn.glm.OLSModel</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.LikelihoodModelResults.html>nilearn.glm.LikelihoodModelResults</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.RegressionResults.html>nilearn.glm.RegressionResults</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.SimpleRegressionResults.html>nilearn.glm.SimpleRegressionResults</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.compute_contrast.html>nilearn.glm.compute_contrast</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.compute_fixed_effects.html>nilearn.glm.compute_fixed_effects</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.expression_to_contrast_vector.html>nilearn.glm.expression_to_contrast_vector</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.fdr_threshold.html>nilearn.glm.fdr_threshold</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.cluster_level_inference.html>nilearn.glm.cluster_level_inference</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.threshold_stats_img.html>nilearn.glm.threshold_stats_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.first_level.FirstLevelModel.html>nilearn.glm.first_level.FirstLevelModel</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.first_level.check_design_matrix.html>nilearn.glm.first_level.check_design_matrix</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.first_level.compute_regressor.html>nilearn.glm.first_level.compute_regressor</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.first_level.first_level_from_bids.html>nilearn.glm.first_level.first_level_from_bids</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.first_level.glover_dispersion_derivative.html>nilearn.glm.first_level.glover_dispersion_derivative</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.first_level.glover_hrf.html>nilearn.glm.first_level.glover_hrf</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.first_level.glover_time_derivative.html>nilearn.glm.first_level.glover_time_derivative</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.first_level.make_first_level_design_matrix.html>nilearn.glm.first_level.make_first_level_design_matrix</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.first_level.mean_scaling.html>nilearn.glm.first_level.mean_scaling</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.first_level.run_glm.html>nilearn.glm.first_level.run_glm</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.first_level.spm_dispersion_derivative.html>nilearn.glm.first_level.spm_dispersion_derivative</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.first_level.spm_hrf.html>nilearn.glm.first_level.spm_hrf</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.first_level.spm_time_derivative.html>nilearn.glm.first_level.spm_time_derivative</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.second_level.SecondLevelModel.html>nilearn.glm.second_level.SecondLevelModel</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.second_level.make_second_level_design_matrix.html>nilearn.glm.second_level.make_second_level_design_matrix</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.glm.second_level.non_parametric_inference.html>nilearn.glm.second_level.non_parametric_inference</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../modules/image.html><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.image</span></code>: Image Processing and Resampling Utilities</a><input class=toctree-checkbox id=toctree-checkbox-25 name=toctree-checkbox-25 role=switch type=checkbox><label for=toctree-checkbox-25><div class=visually-hidden>Toggle navigation of nilearn.image: Image Processing and Resampling Utilities</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.binarize_img.html>nilearn.image.binarize_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.clean_img.html>nilearn.image.clean_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.concat_imgs.html>nilearn.image.concat_imgs</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.coord_transform.html>nilearn.image.coord_transform</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.copy_img.html>nilearn.image.copy_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.crop_img.html>nilearn.image.crop_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.get_data.html>nilearn.image.get_data</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.high_variance_confounds.html>nilearn.image.high_variance_confounds</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.index_img.html>nilearn.image.index_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.iter_img.html>nilearn.image.iter_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.largest_connected_component_img.html>nilearn.image.largest_connected_component_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.load_img.html>nilearn.image.load_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.math_img.html>nilearn.image.math_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.mean_img.html>nilearn.image.mean_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.new_img_like.html>nilearn.image.new_img_like</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.resample_img.html>nilearn.image.resample_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.resample_to_img.html>nilearn.image.resample_to_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.reorder_img.html>nilearn.image.reorder_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.smooth_img.html>nilearn.image.smooth_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.swap_img_hemispheres.html>nilearn.image.swap_img_hemispheres</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.image.threshold_img.html>nilearn.image.threshold_img</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../modules/interfaces.html><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.interfaces</span></code>: Loading components from interfaces</a><input class=toctree-checkbox id=toctree-checkbox-26 name=toctree-checkbox-26 role=switch type=checkbox><label for=toctree-checkbox-26><div class=visually-hidden>Toggle navigation of nilearn.interfaces: Loading components from interfaces</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.interfaces.bids.get_bids_files.html>nilearn.interfaces.bids.get_bids_files</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.interfaces.bids.parse_bids_filename.html>nilearn.interfaces.bids.parse_bids_filename</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.interfaces.bids.save_glm_to_bids.html>nilearn.interfaces.bids.save_glm_to_bids</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.interfaces.fmriprep.load_confounds.html>nilearn.interfaces.fmriprep.load_confounds</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.interfaces.fmriprep.load_confounds_strategy.html>nilearn.interfaces.fmriprep.load_confounds_strategy</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.interfaces.fsl.get_design_from_fslmat.html>nilearn.interfaces.fsl.get_design_from_fslmat</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../modules/maskers.html><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.maskers</span></code>: Extracting Signals from Brain Images</a><input class=toctree-checkbox id=toctree-checkbox-27 name=toctree-checkbox-27 role=switch type=checkbox><label for=toctree-checkbox-27><div class=visually-hidden>Toggle navigation of nilearn.maskers: Extracting Signals from Brain Images</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.maskers.BaseMasker.html>nilearn.maskers.BaseMasker</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.maskers.NiftiMasker.html>nilearn.maskers.NiftiMasker</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.maskers.MultiNiftiMasker.html>nilearn.maskers.MultiNiftiMasker</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.maskers.NiftiLabelsMasker.html>nilearn.maskers.NiftiLabelsMasker</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.maskers.MultiNiftiLabelsMasker.html>nilearn.maskers.MultiNiftiLabelsMasker</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.maskers.NiftiMapsMasker.html>nilearn.maskers.NiftiMapsMasker</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.maskers.MultiNiftiMapsMasker.html>nilearn.maskers.MultiNiftiMapsMasker</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.maskers.NiftiSpheresMasker.html>nilearn.maskers.NiftiSpheresMasker</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../modules/masking.html><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.masking</span></code>: Data Masking Utilities</a><input class=toctree-checkbox id=toctree-checkbox-28 name=toctree-checkbox-28 role=switch type=checkbox><label for=toctree-checkbox-28><div class=visually-hidden>Toggle navigation of nilearn.masking: Data Masking Utilities</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.masking.compute_epi_mask.html>nilearn.masking.compute_epi_mask</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.masking.compute_multi_epi_mask.html>nilearn.masking.compute_multi_epi_mask</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.masking.compute_brain_mask.html>nilearn.masking.compute_brain_mask</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.masking.compute_multi_brain_mask.html>nilearn.masking.compute_multi_brain_mask</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.masking.compute_background_mask.html>nilearn.masking.compute_background_mask</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.masking.compute_multi_background_mask.html>nilearn.masking.compute_multi_background_mask</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.masking.intersect_masks.html>nilearn.masking.intersect_masks</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.masking.apply_mask.html>nilearn.masking.apply_mask</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.masking.unmask.html>nilearn.masking.unmask</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../modules/mass_univariate.html><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.mass_univariate</span></code>: Mass-Univariate Analysis</a><input class=toctree-checkbox id=toctree-checkbox-29 name=toctree-checkbox-29 role=switch type=checkbox><label for=toctree-checkbox-29><div class=visually-hidden>Toggle navigation of nilearn.mass_univariate: Mass-Univariate Analysis</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.mass_univariate.permuted_ols.html>nilearn.mass_univariate.permuted_ols</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../modules/plotting.html><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.plotting</span></code>: Plotting Brain Data</a><input class=toctree-checkbox id=toctree-checkbox-30 name=toctree-checkbox-30 role=switch type=checkbox><label for=toctree-checkbox-30><div class=visually-hidden>Toggle navigation of nilearn.plotting: Plotting Brain Data</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.find_cut_slices.html>nilearn.plotting.find_cut_slices</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.find_xyz_cut_coords.html>nilearn.plotting.find_xyz_cut_coords</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.find_parcellation_cut_coords.html>nilearn.plotting.find_parcellation_cut_coords</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.find_probabilistic_atlas_cut_coords.html>nilearn.plotting.find_probabilistic_atlas_cut_coords</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_anat.html>nilearn.plotting.plot_anat</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_img.html>nilearn.plotting.plot_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_epi.html>nilearn.plotting.plot_epi</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_matrix.html>nilearn.plotting.plot_matrix</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_roi.html>nilearn.plotting.plot_roi</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_stat_map.html>nilearn.plotting.plot_stat_map</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_glass_brain.html>nilearn.plotting.plot_glass_brain</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_connectome.html>nilearn.plotting.plot_connectome</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_markers.html>nilearn.plotting.plot_markers</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_prob_atlas.html>nilearn.plotting.plot_prob_atlas</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_carpet.html>nilearn.plotting.plot_carpet</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_surf.html>nilearn.plotting.plot_surf</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_surf_roi.html>nilearn.plotting.plot_surf_roi</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_surf_contours.html>nilearn.plotting.plot_surf_contours</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_surf_stat_map.html>nilearn.plotting.plot_surf_stat_map</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_img_on_surf.html>nilearn.plotting.plot_img_on_surf</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_img_comparison.html>nilearn.plotting.plot_img_comparison</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_design_matrix.html>nilearn.plotting.plot_design_matrix</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_event.html>nilearn.plotting.plot_event</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.plot_contrast_matrix.html>nilearn.plotting.plot_contrast_matrix</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.view_surf.html>nilearn.plotting.view_surf</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.view_img_on_surf.html>nilearn.plotting.view_img_on_surf</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.view_connectome.html>nilearn.plotting.view_connectome</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.view_markers.html>nilearn.plotting.view_markers</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.view_img.html>nilearn.plotting.view_img</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.show.html>nilearn.plotting.show</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.get_projector.html>nilearn.plotting.displays.get_projector</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.get_slicer.html>nilearn.plotting.displays.get_slicer</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.OrthoProjector.html>nilearn.plotting.displays.OrthoProjector</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.XZProjector.html>nilearn.plotting.displays.XZProjector</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.YZProjector.html>nilearn.plotting.displays.YZProjector</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.YXProjector.html>nilearn.plotting.displays.YXProjector</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.XProjector.html>nilearn.plotting.displays.XProjector</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.YProjector.html>nilearn.plotting.displays.YProjector</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.ZProjector.html>nilearn.plotting.displays.ZProjector</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.LZRYProjector.html>nilearn.plotting.displays.LZRYProjector</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.LYRZProjector.html>nilearn.plotting.displays.LYRZProjector</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.LYRProjector.html>nilearn.plotting.displays.LYRProjector</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.LZRProjector.html>nilearn.plotting.displays.LZRProjector</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.LRProjector.html>nilearn.plotting.displays.LRProjector</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.LProjector.html>nilearn.plotting.displays.LProjector</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.RProjector.html>nilearn.plotting.displays.RProjector</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.BaseAxes.html>nilearn.plotting.displays.BaseAxes</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.CutAxes.html>nilearn.plotting.displays.CutAxes</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.GlassBrainAxes.html>nilearn.plotting.displays.GlassBrainAxes</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.BaseSlicer.html>nilearn.plotting.displays.BaseSlicer</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.OrthoSlicer.html>nilearn.plotting.displays.OrthoSlicer</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.PlotlySurfaceFigure.html>nilearn.plotting.displays.PlotlySurfaceFigure</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.TiledSlicer.html>nilearn.plotting.displays.TiledSlicer</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.MosaicSlicer.html>nilearn.plotting.displays.MosaicSlicer</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.XZSlicer.html>nilearn.plotting.displays.XZSlicer</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.YZSlicer.html>nilearn.plotting.displays.YZSlicer</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.YXSlicer.html>nilearn.plotting.displays.YXSlicer</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.XSlicer.html>nilearn.plotting.displays.XSlicer</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.YSlicer.html>nilearn.plotting.displays.YSlicer</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.plotting.displays.ZSlicer.html>nilearn.plotting.displays.ZSlicer</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../modules/regions.html><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.regions</span></code>: Operating on Regions</a><input class=toctree-checkbox id=toctree-checkbox-31 name=toctree-checkbox-31 role=switch type=checkbox><label for=toctree-checkbox-31><div class=visually-hidden>Toggle navigation of nilearn.regions: Operating on Regions</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.regions.connected_regions.html>nilearn.regions.connected_regions</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.regions.connected_label_regions.html>nilearn.regions.connected_label_regions</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.regions.img_to_signals_labels.html>nilearn.regions.img_to_signals_labels</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.regions.signals_to_img_labels.html>nilearn.regions.signals_to_img_labels</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.regions.img_to_signals_maps.html>nilearn.regions.img_to_signals_maps</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.regions.signals_to_img_maps.html>nilearn.regions.signals_to_img_maps</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.regions.recursive_neighbor_agglomeration.html>nilearn.regions.recursive_neighbor_agglomeration</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.regions.RegionExtractor.html>nilearn.regions.RegionExtractor</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.regions.Parcellations.html>nilearn.regions.Parcellations</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.regions.ReNA.html>nilearn.regions.ReNA</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.regions.HierarchicalKMeans.html>nilearn.regions.HierarchicalKMeans</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../modules/reporting.html><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.reporting</span></code>: Reporting Functions</a><input class=toctree-checkbox id=toctree-checkbox-32 name=toctree-checkbox-32 role=switch type=checkbox><label for=toctree-checkbox-32><div class=visually-hidden>Toggle navigation of nilearn.reporting: Reporting Functions</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.reporting.HTMLReport.html>nilearn.reporting.HTMLReport</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.reporting.get_clusters_table.html>nilearn.reporting.get_clusters_table</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.reporting.make_glm_report.html>nilearn.reporting.make_glm_report</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../modules/signal.html><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.signal</span></code>: Preprocessing Time Series</a><input class=toctree-checkbox id=toctree-checkbox-33 name=toctree-checkbox-33 role=switch type=checkbox><label for=toctree-checkbox-33><div class=visually-hidden>Toggle navigation of nilearn.signal: Preprocessing Time Series</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.signal.butterworth.html>nilearn.signal.butterworth</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.signal.clean.html>nilearn.signal.clean</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.signal.high_variance_confounds.html>nilearn.signal.high_variance_confounds</a></li></ul></li><li class="toctree-l2 has-children"><a class="reference internal"href=../modules/surface.html><code class="xref py py-mod docutils literal notranslate"><span class=pre>nilearn.surface</span></code>: Manipulating Surface Data</a><input class=toctree-checkbox id=toctree-checkbox-34 name=toctree-checkbox-34 role=switch type=checkbox><label for=toctree-checkbox-34><div class=visually-hidden>Toggle navigation of nilearn.surface: Manipulating Surface Data</div><i class=icon><svg><use href=#svg-arrow-right></use></svg></i></label><ul><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.surface.load_surf_data.html>nilearn.surface.load_surf_data</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.surface.load_surf_mesh.html>nilearn.surface.load_surf_mesh</a></li><li class=toctree-l3><a class="reference internal"href=../modules/generated/nilearn.surface.vol_to_surf.html>nilearn.surface.vol_to_surf</a></li></ul></li></ul></li><li class=toctree-l1><a class="reference internal"href=../glossary.html>Glossary</a></li></ul><p class=caption role=heading><span class=caption-text>Development</span></p><ul><li class=toctree-l1><a class="reference internal"href=../development.html>Contributing</a></li><li class=toctree-l1><a class="reference internal"href=../maintenance.html>Maintenance</a></li><li class=toctree-l1><a class="reference internal"href=../changes/whats_new.html>What’s new</a></li><li class=toctree-l1><a class="reference internal"href=../authors.html>Team</a></li><li class=toctree-l1><a class="reference external"href=https://github.com/nilearn/nilearn>GitHub Repository</a></li></ul></div></div></div></div></aside><div class=main><div class=content><div class=article-container><a class="back-to-top muted-link"href=#> <svg viewbox="0 0 24 24"xmlns=http://www.w3.org/2000/svg><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path></svg> <span>Back to top</span> </a><div class=content-icon-container><div class=edit-this-page><a title="Edit this page"class=muted-link href=https://github.com/nilearn/nilearn/edit/main/doc/glm/glm_intro.rst target=_blank> <svg viewbox="0 0 24 24"aria-hidden=true fill=none stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=1.5><path d="M0 0h24v24H0z"fill=none stroke=none /><path d="M4 20h4l10.5 -10.5a1.5 1.5 0 0 0 -4 -4l-10.5 10.5v4"/><line x1=13.5 x2=17.5 y1=6.5 y2=10.5 /></svg> <span class=visually-hidden>Edit this page</span> </a></div><div class="theme-toggle-container theme-toggle-content"><button class=theme-toggle><div class=visually-hidden>Toggle Light / Dark / Auto color theme</div> <svg class=theme-icon-when-auto><use href=#svg-sun-half></use></svg> <svg class=theme-icon-when-dark><use href=#svg-moon></use></svg> <svg class=theme-icon-when-light><use href=#svg-sun></use></svg></button></div><label class="toc-overlay-icon toc-content-icon"for=__toc><div class=visually-hidden>Toggle table of contents sidebar</div> <i class=icon><svg><use href=#svg-toc></use></svg></i></label></div><article role=main><section id=an-introduction-to-glms-in-fmri-statistical-analysis><span id=glm-intro></span><h1><span class=section-number>8.1. </span>An introduction to GLMs in fMRI statistical analysis<a title="Link to this heading"class=headerlink href=#an-introduction-to-glms-in-fmri-statistical-analysis>#</a></h1><section id=a-primer-on-bold-fmri-data-analysis><h2><span class=section-number>8.1.1. </span>A primer on BOLD-fMRI data analysis<a title="Link to this heading"class=headerlink href=#a-primer-on-bold-fmri-data-analysis>#</a></h2><section id=what-is-fmri><h3><span class=section-number>8.1.1.1. </span>What is fMRI ?<a title="Link to this heading"class=headerlink href=#what-is-fmri>#</a></h3><p>Functional magnetic resonance imaging (<a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a>) is based on the fact that when local neural activity increases, increases in metabolism and blood flow lead to fluctuations of the relative concentrations of oxyhaemoglobin (the red cells in the blood that carry oxygen) and deoxyhaemoglobin (the same red cells after they have delivered the oxygen). Oxyhaemoglobin and deoxyhaemoglobin have different magnetic properties (diamagnetic and paramagnetic, respectively), and they affect the local magnetic field in different ways. The signal picked up by the MRI scanner is sensitive to these modifications of the local magnetic field. To record cerebral activity during functional runs, the scanner is tuned to detect this “Blood Oxygen Level Dependent” (<a class="reference internal"href=../glossary.html#term-BOLD><span class="xref std std-term">BOLD</span></a>) signal.</p><p>Brain activity is measured in runs that span several minutes, during which the participant performs some cognitive task and the scanner acquires brain images, typically every 2 or 3 seconds (the time between two successive image acquisition is called the Repetition time, or <a class="reference internal"href=../glossary.html#term-TR><span class="xref std std-term">TR</span></a>).</p><p>A cerebral MR image provides a 3D image of the brain that can be decomposed into <a class="reference external"href=https://en.wikipedia.org/wiki/Voxel>voxels</a> (the equivalent of pixels, but in 3 dimensions). The series of images acquired during a functional run provides, in each voxel, a time series of positive real number representing the MRI signal, sampled at the <a class="reference internal"href=../glossary.html#term-TR><span class="xref std std-term">TR</span></a>.</p><div class="admonition note"><p class=admonition-title>Note</p><p>Before <a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a> images can be used to do meaningful comparisons, they must be processed to ensure that the voxels that are being compared represent the same brain regions, irrespective of the variability in size and shape of the brain and its microarchitecture across different subjects in the experiment. The process is called spatial registration or spatial normalization. During this procedure, the voxels of all the brain images are ‘registered’ to correspond to the same region of the brain. Usually, the images (their voxels) are registered to a standard ‘template’ brain image (its voxels). One often used standard template is the MNI152 template from the Montreal Neurological Institute. Once this is done, the coordinates of a <a class="reference internal"href=../glossary.html#term-voxel><span class="xref std std-term">voxel</span></a> are in the same space as the template and can be used to estimate its brain location using brain atlases based on that same template. As previously mentioned, the nilearn package does not perform spatial preprocessing; it only does statistical analyses on the voxel time series. For preprocessing functions, users are referred to <a class="reference external"href=https://nipype.readthedocs.io/en/latest/>Nipype</a> or <a class="reference external"href=https://fmriprep.readthedocs.io/en/stable/>fMRIPrep</a>.</p></div></section><section id=fmri-data-modelling><h3><span class=section-number>8.1.1.2. </span>fMRI data modelling<a title="Link to this heading"class=headerlink href=#fmri-data-modelling>#</a></h3><p>One way to analyze times series consists in comparing them to a <em>model</em> built from our knowledge of the events that occurred during the functional run. Events can correspond to actions of the participant (e.g. button presses), presentations of sensory stimui (e.g. sound, images), or hypothesized internal processes (e.g. memorization of a stimulus), …</p><figure class=align-default><img alt=../_images/stimulation-time-diagram.png src=../_images/stimulation-time-diagram.png></figure><p>One expects that a brain region involved in the processing of a certain type of event (e.g. the auditory cortex for sounds) would show a time course of activation that correlates with the time-diagram of these events. If the <a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a> signal directly showed neural activity and did not contain any noise, we could just look at it in various voxels and detect those that conform to the time-diagrams.</p><p>But we know from previous measurements that the <a class="reference internal"href=../glossary.html#term-BOLD><span class="xref std std-term">BOLD</span></a> signal does not follow the exact time course of stimulus processing and the underlying neural activity. The <a class="reference internal"href=../glossary.html#term-BOLD><span class="xref std std-term">BOLD</span></a> response reflects changes in blood flow and concentrations in oxy-deoxy haemoglobin, all together forming a <a class="reference external"href=https://en.wikipedia.org/wiki/Haemodynamic_response>haemodynamic response</a> which is sluggish and long-lasting, as can be seen in the following figure showing the response to an impulsive event (for example, an auditory click played to the participants).</p><figure class=align-default><img alt=../_images/spm_iHRF.png src=../_images/spm_iHRF.png></figure><p>Using our knowledge of the haemodynamic response, we can build a predicted time course from the time-diagram of the event (the operation is known as <a class="reference external"href=https://en.wikipedia.org/wiki/Convolution>convolution</a>; simply stated, it measures how the shape of one function’s plot affects the shape of another function’s plot. <strong>Remark:</strong> it assumes linearity of the <a class="reference internal"href=../glossary.html#term-BOLD><span class="xref std std-term">BOLD</span></a> response, an assumption that may be wrong in some scenarios). It is this predicted time course, also known as a <em>predictor</em>, that is compared to the actual <a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a> signal. If the correlation between the predictor and the signal is higher than expected by chance, the voxel is said to exhibit a significant response to the event type.</p><figure class=align-default><img alt=../_images/time-course-and-model-fit-in-a-voxel.png src=../_images/time-course-and-model-fit-in-a-voxel.png></figure><p>Correlations are computed separately at each <a class="reference internal"href=../glossary.html#term-voxel><span class="xref std std-term">voxel</span></a> and a correlation map can be produced displaying the values of correlations (real numbers between -1 and +1) at each <a class="reference internal"href=../glossary.html#term-voxel><span class="xref std std-term">voxel</span></a>. Generally, however, the maps presented in the papers report the significance of the correlations at each <a class="reference internal"href=../glossary.html#term-voxel><span class="xref std std-term">voxel</span></a>, using T, Z or p values for the null hypothesis test of no correlation (see below). For example, the following figure displays a Z-map showing voxels responding to auditory events. Large (positive or negative) values are unlikely to be due to chance alone. The map is thresholded so that only voxels with a p-value less than 1/1000 are coloured.</p><div class="admonition note"><p class=admonition-title>Note</p><p>In this approach, hypothesis tests are conducted in parallel at many voxels, increasing the likelihood of False Positives. This is known as the Problem of <a class="reference internal"href=#multiple-comparisons>Multiple Comparisons</a>. Some common strategies for dealing with this are discussed later in this page. This issue can be addressed in nilearn using permutations tests.</p></div><figure class=align-default><img alt=../_images/example-spmZ_map.png src=../_images/example-spmZ_map.png></figure><p>In most <a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a> experiments, several predictors are needed to fully describe the events occurring during the run – for example, the experimenter may want to distinguish brain activities linked to the perception of auditory stimuli and to button presses. To find the effect specific to each predictor, a multiple <a class="reference external"href=https://en.wikipedia.org/wiki/Linear_regression>linear regression</a> approach is typically used: all predictors are entered as columns in a <em>design matrix</em> and the software finds the linear combination of these columns that best fits the signal. The weights assigned to each predictor by this linear combination are estimates of the contribution of this predictor to the response in the voxel. One can plot this using effect size maps or, maps showing their statistical significance (how unlikely they are under the null hypothesis of no effect).</p><p>In brief, the analysis of <a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a> images involves:</p><ol class="arabic simple"><li><p>Describing the paradigm in terms of events grouped by type, occurring at certain times and having specific durations.</p></li><li><p>Creating predictors for each type of event, typically using a convolution by the haemodynamic response.</p></li><li><p>Assembling these predictors in a design matrix, providing a <em>linear model</em>.</p></li><li><p>Estimating the parameters of the model, i.e., the weights associated with each predictor at each voxel, using linear regression.</p></li><li><p>Displaying the coefficients or their linear combination, and/or their statistical significance.</p></li></ol></section><section id=fmri-statistical-analysis><h3><span class=section-number>8.1.1.3. </span>fMRI statistical analysis<a title="Link to this heading"class=headerlink href=#fmri-statistical-analysis>#</a></h3><p>As explained in the previous section, the basic statistical analysis of <a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a> is conceptually a correlation analysis, where one identifies whether a certain combination (<a class="reference internal"href=../glossary.html#term-contrast><span class="xref std std-term">contrast</span></a>) of columns of the design matrix fits a significant proportion of the <a class="reference internal"href=../glossary.html#term-fMRI><span class="xref std std-term">fMRI</span></a> signal at a given location.</p><p>It can be shown that this is equivalent to studying whether the estimated <a class="reference internal"href=../glossary.html#term-contrast><span class="xref std std-term">contrast</span></a> effect is large with respect to the uncertainty about its exact value. Concretely, we compute the effect size estimate and the uncertainty about its value and divide the two. The resulting number has no physical dimension, it is a statistic – a Student or t-statistic, which we denote by <code class="docutils literal notranslate"><span class=pre>t</span></code>. Next, based on <code class="docutils literal notranslate"><span class=pre>t</span></code>, we want to decide whether the true effect was indeed greater than zero or not.</p><p><code class="docutils literal notranslate"><span class=pre>t</span></code> would not necessarily be 0 if the true effect were zero: by chance, noise in the data may be partly explained by the <a class="reference internal"href=../glossary.html#term-contrast><span class="xref std std-term">contrast</span></a> of interest. However, if we assume that the noise is Gaussian and that the model is correctly specified, then we know that <code class="docutils literal notranslate"><span class=pre>t</span></code> should follow a Student distribution with <code class="docutils literal notranslate"><span class=pre>dof</span></code> degrees of freedom, where <code class="docutils literal notranslate"><span class=pre>dof</span></code> is the number of free parameters in the model: in practice, the number of observations (i.e. the number of time points), <code class="docutils literal notranslate"><span class=pre>n_scans</span></code> minus the number of effects modelled (i.e. the number of columns <code class="docutils literal notranslate"><span class=pre>n_columns</span></code>) of the design matrix:</p><blockquote><div><p><img alt="dof = n\_scans - n\_columns"class=math src=../_images/math/499002493613ac62a752d5f805fbb1f9e893facd.png></p></div></blockquote><p>With this we can do statistical inference. Given a pre-defined error rate <img alt=\alpha class=math src=../_images/math/2f5aa019312e1bbc969deab8dca8b00f76025404.png>, we compare the observed <code class="docutils literal notranslate"><span class=pre>t</span></code> to the <img alt=(1-\alpha) class=math src=../_images/math/c87d80a9ca1dd2540182b6d20843ecc568241c87.png> quantile of the Student distribution with <code class="docutils literal notranslate"><span class=pre>dof</span></code> degrees of freedom. If <code class="docutils literal notranslate"><span class=pre>t</span></code> is greater than this number we can reject the null hypothesis with a <em>p-value</em> <img alt=\alpha class=math src=../_images/math/2f5aa019312e1bbc969deab8dca8b00f76025404.png>; meaning, if there were no effect, the probability of observing an effect as large as <code class="docutils literal notranslate"><span class=pre>t</span></code> would be less than <img alt=\alpha class=math src=../_images/math/2f5aa019312e1bbc969deab8dca8b00f76025404.png>.</p><figure class=align-default><img alt=../_images/student.png src=../_images/student.png></figure><div class="admonition note"><p class=admonition-title>Note</p><p>A frequent misconception consists in interpreting <img alt="1- \alpha"class=math src=../_images/math/70e890167882143be3c8d9371e4b427448601348.png> as the probability that there is indeed an effect: this is not true! Here we rely on a frequentist approach, that does not support Bayesian interpretation. See e.g. <a class="reference external"href=https://en.wikipedia.org/wiki/Frequentist_inference>https://en.wikipedia.org/wiki/Frequentist_inference</a></p></div><div class="admonition note"><p class=admonition-title>Note</p><p>It is cumbersome to work with Student distributions, since these always require to specify the degrees of freedom. To avoid this, we can transform <code class="docutils literal notranslate"><span class=pre>t</span></code> to another variable <code class="docutils literal notranslate"><span class=pre>z</span></code> such that comparing <code class="docutils literal notranslate"><span class=pre>t</span></code> to the Student distribution with <code class="docutils literal notranslate"><span class=pre>dof</span></code> degrees of freedom is equivalent to comparing <code class="docutils literal notranslate"><span class=pre>z</span></code> to a standard normal distribution. We call this the z-transform of <code class="docutils literal notranslate"><span class=pre>t</span></code>. We call the <img alt=(1-\alpha) class=math src=../_images/math/c87d80a9ca1dd2540182b6d20843ecc568241c87.png> quantile of the normal distribution the <em>threshold</em>, since we use this value to declare voxels active or not.</p></div></section><section id=multiple-comparisons><span id=id1></span><h3><span class=section-number>8.1.1.4. </span>Multiple Comparisons<a title="Link to this heading"class=headerlink href=#multiple-comparisons>#</a></h3><p>A well-known issue that arises here is that of multiple comparisons: when a statistical tests is repeated a large number times, say one for each voxel, i.e. <code class="docutils literal notranslate"><span class=pre>n_voxels</span></code> times, then one can expect that, in the absence of any effect, the number of detections – false detections since there is no effect – will be roughly <img alt=n\_voxels*\alpha class=math src=../_images/math/84e4cbe974a8f43192aa21fee564a713f5d1b1df.png>. If <img alt=\alpha=.001 class=math src=../_images/math/befff685f3ad4a25fe6d0faf8a48e18183d470f6.png> and <img alt=n=10^5 class=math src=../_images/math/3b29057dd09798d2669a9a5782924b36b16b6d91.png>, the number of false detections will be about 100. The danger is that one may no longer trust the detections, i.e. values of <code class="docutils literal notranslate"><span class=pre>z</span></code> larger than the <img alt=(1-\alpha) class=math src=../_images/math/c87d80a9ca1dd2540182b6d20843ecc568241c87.png>-quantile of the standard normal distribution.</p><p>The first idea that one might think of is to take a much smaller <img alt=\alpha class=math src=../_images/math/2f5aa019312e1bbc969deab8dca8b00f76025404.png>: for instance, if we take, <img alt=\alpha=\frac{0.05}{n\_voxels} class=math src=../_images/math/36526f645a36a408b0caf685b136abf903267333.png> then the expected number of false discoveries is only about 0.05, meaning that there is a 5% chance that a truly inactive <a class="reference internal"href=../glossary.html#term-voxel><span class="xref std std-term">voxel</span></a> is declared active. This correction on the significance is known as Bonferroni procedure. It is fairly accurate when the different tests are independent or close to independent, but becomes conservative if not. The problem with this approach is that a truly activate voxel may not surpass the corresponding threshold, which is typically very high because <code class="docutils literal notranslate"><span class=pre>n_voxels</span></code> is large.</p><p>A second possibility is to choose a threshold so that the proportion of true discoveries among the discoveries reaches a certain proportion <code class="docutils literal notranslate"><span class=pre>0&LTq&LT1</span></code>; typically <code class="docutils literal notranslate"><span class=pre>q=0.05</span></code>. This means that after statistical inference, one can trust the proportionate <code class="docutils literal notranslate"><span class=pre>1-q</span></code> of the discoveries made. The number <code class="docutils literal notranslate"><span class=pre>q</span></code> is the expected proportion of false discoveries and is known as the <em>false discovery rate</em>. Controlling the false discovery rate is a reasonable compromise in practice. The thresholding that yields this level of control is typically obtained using the so-called <a class="reference external"href=http://www.math.tau.ac.il/~ybenja/MyPapers/benjamini_hochberg1995.pdf>Benjamini-Hochberg</a> procedure.</p><div class="admonition note"><p class=admonition-title>Note</p><p>Note that <code class="docutils literal notranslate"><span class=pre>q</span></code> (as well as <img alt=\alpha class=math src=../_images/math/2f5aa019312e1bbc969deab8dca8b00f76025404.png>) are <em>arbitrary</em>. It is recommended to not rely on low values, otherwise the inference is meaningless. Ideally one should use <img alt=\alpha=\frac{0.05}{n\_voxels} class=math src=../_images/math/36526f645a36a408b0caf685b136abf903267333.png>, or <code class="docutils literal notranslate"><span class=pre>q=0.05</span></code>.</p></div><p>Note also that supra-threshold sets of voxels are often gathered into connected components (aka <em>clusters</em>), so that only large connected components are retained and isolated supra-threshold voxels are discarded. The rationale is that isolated voxels are unlikely to represent extended brain areas, and are most likely noise. Hence, discarding them most often improves the quality and the reliability of the results.</p></section></section></section></article></div><footer><div class=related-pages><a class=next-page href=first_level_model.html> <div class=page-info><div class=context><span>Next</span></div><div class=title><span class=section-number>8.2. </span>First level models</div></div> <svg class=furo-related-icon><use href=#svg-arrow-right></use></svg> </a><a class=prev-page href=index.html> <svg class=furo-related-icon><use href=#svg-arrow-right></use></svg> <div class=page-info><div class=context><span>Previous</span></div><div class=title><span class=section-number>8. </span>Analyzing fMRI using GLMs</div></div> </a></div><div class=bottom-of-page><div class=left-details><div class=copyright>Copyright © The nilearn developers 2010-2023</div> Made with <a href=https://www.sphinx-doc.org/>Sphinx</a> and <a class=muted-link href=https://pradyunsg.me>@pradyunsg</a>'s <a href=https://github.com/pradyunsg/furo>Furo</a></div><div class=right-details><div class=icons><a class="muted-link fa-brands fa-solid fa-github fa-2x"aria-label=GitHub href=https://github.com/nilearn/nilearn></a><a class="muted-link fa-brands fa-solid fa-twitter fa-2x"aria-label=Twitter href=https://twitter.com/nilearn></a><a class="muted-link fa-brands fa-solid fa-mastodon fa-2x"aria-label=Mastodon href=https://fosstodon.org/@nilearn></a><a class="muted-link fa-brands fa-solid fa-discord fa-2x"aria-label=Discord href=https://discord.gg/SsQABEJHkZ></a></div></div></div></footer></div><aside class=toc-drawer><div class="toc-sticky toc-scroll"><div class=toc-title-container><span class=toc-title> On this page </span></div><div class=toc-tree-container><div class=toc-tree><ul><li><a class="reference internal"href=#>8.1. An introduction to GLMs in fMRI statistical analysis</a><ul><li><a class="reference internal"href=#a-primer-on-bold-fmri-data-analysis>8.1.1. A primer on BOLD-fMRI data analysis</a><ul><li><a class="reference internal"href=#what-is-fmri>8.1.1.1. What is fMRI ?</a></li><li><a class="reference internal"href=#fmri-data-modelling>8.1.1.2. fMRI data modelling</a></li><li><a class="reference internal"href=#fmri-statistical-analysis>8.1.1.3. fMRI statistical analysis</a></li><li><a class="reference internal"href=#multiple-comparisons>8.1.1.4. Multiple Comparisons</a></li></ul></li></ul></li></ul></div></div></div></aside></div></div><script src=../_static/documentation_options.js?v=5929fcd5></script><script src=../_static/doctools.js?v=888ff710></script><script src=../_static/sphinx_highlight.js?v=dc90522c></script><script src=../_static/scripts/furo.js?v=32e29ea5></script><script src=../_static/clipboard.min.js?v=a7894cd8></script><script src=../_static/copybutton.js?v=4ea706d9></script><script src=../_static/design-tabs.js?v=36754332></script></body></html>