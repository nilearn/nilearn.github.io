
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nilearn: Statistical Analysis for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/nature.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="7. Advanced usage: manual pipelines and scaling up" href="../building_blocks/index.html" />
    <link rel="prev" title="6.2. Manipulating images: resampling, smoothing, masking, ROIs…" href="manipulating_images.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">


<script type="text/javascript">
function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});
</script>
<script type="text/javascript">
function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../index.html">
      <img src="../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../modules/reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Statistics for NeuroImaging in Python</h2>
  </div>
  <div class="search_form">
    <div class="gcse-search" id="cse" style="width: 100%;"></div>
    <script>
      (function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </div>
</div>



<div class=related-wrapper>
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="../building_blocks/index.html" title="7. Advanced usage: manual pipelines and scaling up"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="manipulating_images.html" title="6.2. Manipulating images: resampling, smoothing, masking, ROIs…"
             accesskey="P">previous</a> |</li>
<li><a href="../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../authors.html">About</a>|&nbsp;</li>
<li><a href="../glossary.html">Glossary</a>|&nbsp;</li>
<li><a href="../bibliography.html">Bibliography</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="index.html" accesskey="U"><span class="section-number">6. </span>Manipulation brain volumes with nilearn</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Nilearn: Statistical Analysis for NeuroImaging in Python</a></li> 
      </ul>
    </div>
</div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="from-neuroimaging-volumes-to-data-matrices-the-masker-objects">
<span id="masker-objects"></span><h1><span class="section-number">6.3. </span>From neuroimaging volumes to data matrices: the masker objects<a class="headerlink" href="#from-neuroimaging-volumes-to-data-matrices-the-masker-objects" title="Permalink to this headline">¶</a></h1>
<p>This chapter introduces the maskers: objects that go from
neuroimaging volumes, on the disk or in memory, to data matrices, eg of
time series.</p>
<div class="contents local topic" id="chapters-contents">
<p class="topic-title"><strong>Chapters contents</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="#the-concept-of-masker-objects" id="id2">The concept of “masker” objects</a></p></li>
<li><p><a class="reference internal" href="#niftimasker-applying-a-mask-to-load-time-series" id="id3"><a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a>: applying a mask to load time-series</a></p></li>
<li><p><a class="reference internal" href="#extraction-of-signals-from-regions-niftilabelsmasker-niftimapsmasker" id="id4">Extraction of signals from regions: <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiLabelsMasker.html#nilearn.input_data.NiftiLabelsMasker" title="nilearn.input_data.NiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a>, <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMapsMasker.html#nilearn.input_data.NiftiMapsMasker" title="nilearn.input_data.NiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a></a></p></li>
<li><p><a class="reference internal" href="#extraction-of-signals-from-seeds-niftispheresmasker" id="id5">Extraction of signals from seeds: <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiSpheresMasker.html#nilearn.input_data.NiftiSpheresMasker" title="nilearn.input_data.NiftiSpheresMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiSpheresMasker</span></code></a></a></p></li>
</ul>
</div>
<div class="section" id="the-concept-of-masker-objects">
<h2><a class="toc-backref" href="#id2"><span class="section-number">6.3.1. </span>The concept of “masker” objects</a><a class="headerlink" href="#the-concept-of-masker-objects" title="Permalink to this headline">¶</a></h2>
<p>In any analysis, the first step is to load the data.
It is often convenient to apply some basic data
transformations and to turn the data in a 2D (samples x features) matrix,
where the samples could be different time points, and the features derived
from different voxels (e.g., restrict analysis to the ventral visual stream),
regions of interest (e.g., extract local signals from spheres/cubes), or
pre-specified networks (e.g., look at data from all voxels of a set of
network nodes). Think of masker objects as swiss-army knifes for shaping
the raw neuroimaging data in 3D space into the units of observation
relevant for the research questions at hand.</p>
<p class="centered">
<strong><a class="reference internal" href="../_images/niimgs.jpg"><img alt="niimgs" src="../_images/niimgs.jpg" style="width: 367.0px; height: 163.5px;" /></a>  <span style="padding: .5em; font-size: 400%">&rarr;</span>  <a class="reference internal" href="../_images/feature_array.jpg"><img alt="arrays" src="../_images/feature_array.jpg" style="width: 115.14999999999999px; height: 167.29999999999998px;" /></a></strong></p><p>“masker” objects (found in modules <a class="reference internal" href="../modules/reference.html#module-nilearn.input_data" title="nilearn.input_data"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.input_data</span></code></a>)
simplify these “data folding” steps that often preceed the
statistical analysis.</p>
<p>Note that the masker objects may not cover all the image transformations
for specific tasks. Users who want to make some specific processing may
have to call <a class="reference internal" href="manipulating_images.html#preprocessing-functions"><span class="std std-ref">specific functions</span></a>
(modules <a class="reference internal" href="../modules/reference.html#module-nilearn.signal" title="nilearn.signal"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.signal</span></code></a>, <a class="reference internal" href="../modules/reference.html#module-nilearn.masking" title="nilearn.masking"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.masking</span></code></a>).</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="topic">
<p class="topic-title"><strong>Advanced: Design philosophy of “Maskers”</strong></p>
<p>The design of these classes is similar to <a class="reference external" href="http://scikit-learn.org">scikit-learn</a>‘s transformers. First, objects are
initialized with some parameters guiding the transformation
(unrelated to the data). Then the <cite>fit()</cite> method should be called,
possibly specifying some data-related information (such as number of
images to process), to perform some initial computation (e.g.,
fitting a mask based on the data). Finally, <cite>transform()</cite> can be
called, with the data as argument, to perform some computation on
data themselves (e.g., extracting time series from images).</p>
</div>
</div>
<div class="section" id="niftimasker-applying-a-mask-to-load-time-series">
<span id="nifti-masker"></span><h2><a class="toc-backref" href="#id3"><span class="section-number">6.3.2. </span><a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a>: applying a mask to load time-series</a><a class="headerlink" href="#niftimasker-applying-a-mask-to-load-time-series" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> is a powerful tool to load images and
extract voxel signals in the area defined by the mask.
It applies some basic preprocessing
steps with commonly used parameters as defaults.
But it is <em>very important</em> to look at your data to see the effects
of the preprocessings and validate them.</p>
<div class="topic">
<p class="topic-title"><strong>Advanced: scikit-learn Pipelines</strong></p>
<p><a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> is a <a class="reference external" href="http://scikit-learn.org">scikit-learn</a> compliant
transformer so that you can directly plug it into a <a class="reference external" href="http://scikit-learn.org/stable/modules/pipeline.html">scikit-learn
pipeline</a>.</p>
</div>
<div class="section" id="custom-data-loading-loading-only-the-first-100-time-points">
<h3><span class="section-number">6.3.2.1. </span>Custom data loading: loading only the first 100 time points<a class="headerlink" href="#custom-data-loading-loading-only-the-first-100-time-points" title="Permalink to this headline">¶</a></h3>
<p>Suppose we want to restrict a dataset to the first 100 frames. Below, we load
a movie-watching dataset with <a class="reference internal" href="../modules/generated/nilearn.datasets.fetch_development_fmri.html#nilearn.datasets.fetch_development_fmri" title="nilearn.datasets.fetch_development_fmri"><code class="xref py py-func docutils literal notranslate"><span class="pre">fetch_development_fmri()</span></code></a>, restrict it to 100 frames and
build a new niimg object that we can give to the masker. Although
possible, there is no need to save your data to a file to pass it to a
<a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a>. Simply use <a class="reference internal" href="../modules/generated/nilearn.image.index_img.html#nilearn.image.index_img" title="nilearn.image.index_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.image.index_img</span></code></a> to apply a
slice and create a <a class="reference internal" href="input_output.html#niimg"><span class="std std-ref">Niimg</span></a> in memory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_development_fmri</span><span class="p">(</span><span class="n">n_subjects</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">epi_filename</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">func</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Restrict to 100 frames to speed up computation</span>
<span class="kn">from</span> <span class="nn">nilearn.image</span> <span class="kn">import</span> <span class="n">index_img</span>
<span class="n">epi_img</span> <span class="o">=</span> <span class="n">index_img</span><span class="p">(</span><span class="n">epi_filename</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>

</pre></div>
</div>
</div>
<div class="section" id="controlling-how-the-mask-is-computed-from-the-data">
<h3><span class="section-number">6.3.2.2. </span>Controlling how the mask is computed from the data<a class="headerlink" href="#controlling-how-the-mask-is-computed-from-the-data" title="Permalink to this headline">¶</a></h3>
<p>In this section, we show how the masker object can compute a mask
automatically for subsequent statistical analysis.
On some datasets, the default algorithm may however perform poorly.
This is why it is very important to
<strong>always look at your data</strong> before and after feature
engineering using masker objects.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The full example described in this section can be found here:
<a class="reference internal" href="../auto_examples/06_manipulating_images/plot_mask_computation.html"><span class="doc">plot_mask_computation.py</span></a>.
It is also related to this example:
<a class="reference internal" href="../auto_examples/06_manipulating_images/plot_nifti_simple.html"><span class="doc">plot_nifti_simple.py</span></a>.</p>
</div>
<div class="section" id="visualizing-the-computed-mask">
<h4><span class="section-number">6.3.2.2.1. </span>Visualizing the computed mask<a class="headerlink" href="#visualizing-the-computed-mask" title="Permalink to this headline">¶</a></h4>
<p>If a mask is not specified as an argument, <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> will try to
compute one from the provided neuroimaging data.
It is <em>very important</em> to verify the quality of the generated mask by visualization.
This allows to see whether it is suitable for your data and intended analyses.
Alternatively, the mask computation parameters can still be modified.
See the <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> documentation for a complete list of
mask computation parameters.</p>
<p>The mask can be retrieved and visualized from the <cite>mask_img_</cite> attribute
of the masker:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">masker</span> <span class="o">=</span> <span class="n">NiftiMasker</span><span class="p">()</span>
<span class="n">masker</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">miyawaki_filename</span><span class="p">)</span>

<span class="c1"># Plot the generated mask using the mask_img_ attribute</span>
<span class="n">plot_roi</span><span class="p">(</span><span class="n">masker</span><span class="o">.</span><span class="n">mask_img_</span><span class="p">,</span> <span class="n">miyawaki_mean_img</span><span class="p">,</span>
         <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Mask from already masked data&quot;</span><span class="p">)</span>

<span class="c1">###############################################################################</span>
</pre></div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/06_manipulating_images/plot_mask_computation.html"><img alt="../_images/sphx_glr_plot_mask_computation_002.png" src="../_images/sphx_glr_plot_mask_computation_002.png" style="width: 264.0px; height: 104.0px;" /></a>
</div>
<p>Alternatively, the mask can be visualized using the <cite>generate_report</cite>
method of the masker. The generated report can be viewed in a Jupyter notebook,
opened in a new browser tab using <cite>report.open_in_browser()</cite>,
or saved as a portable HTML file <cite>report.save_as_html(output_filepath)</cite>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">masker</span> <span class="o">=</span> <span class="n">NiftiMasker</span><span class="p">(</span><span class="n">mask_strategy</span><span class="o">=</span><span class="s1">&#39;epi&#39;</span><span class="p">)</span>
<span class="n">masker</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">epi_img</span><span class="p">)</span>
<span class="n">report</span> <span class="o">=</span> <span class="n">masker</span><span class="o">.</span><span class="n">generate_report</span><span class="p">()</span>
<span class="n">report</span>

<span class="c1">###############################################################################</span>
</pre></div>
</div>
<div class="figure align-default">
<a class="reference external image-reference" href="../auto_examples/06_manipulating_images/plot_mask_computation.html"><img alt="../_images/niftimasker_report.png" src="../_images/niftimasker_report.png" style="width: 747.0px; height: 230.0px;" /></a>
</div>
</div>
<div class="section" id="different-masking-strategies">
<h4><span class="section-number">6.3.2.2.2. </span>Different masking strategies<a class="headerlink" href="#different-masking-strategies" title="Permalink to this headline">¶</a></h4>
<p>The <cite>mask_strategy</cite> argument controls how the mask is computed:</p>
<ul class="simple">
<li><p><cite>background</cite>: detects a continuous background</p></li>
<li><p><cite>epi</cite>: suitable for EPI images</p></li>
<li><p><cite>template</cite>: uses an MNI grey-matter template</p></li>
</ul>
</div>
<div class="section" id="extra-mask-parameters-opening-cutoff">
<h4><span class="section-number">6.3.2.2.3. </span>Extra mask parameters: opening, cutoff…<a class="headerlink" href="#extra-mask-parameters-opening-cutoff" title="Permalink to this headline">¶</a></h4>
<p>The underlying function is <a class="reference internal" href="../modules/generated/nilearn.masking.compute_epi_mask.html#nilearn.masking.compute_epi_mask" title="nilearn.masking.compute_epi_mask"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.masking.compute_epi_mask</span></code></a>
called using the <cite>mask_args</cite> argument of the <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a>.
Controling these arguments set the fine aspects of the mask. See the
functions documentation, or <a class="reference internal" href="../auto_examples/06_manipulating_images/plot_mask_computation.html"><span class="doc">the NiftiMasker example</span></a>.</p>
<div class="figure align-default">
<a class="reference external image-reference" href="../auto_examples/06_manipulating_images/plot_mask_computation.html"><img alt="../_images/niftimasker_report_params.png" src="../_images/niftimasker_report_params.png" style="width: 742.0px; height: 227.0px;" /></a>
</div>
</div>
</div>
<div class="section" id="common-data-preparation-steps-smoothing-filtering-resampling">
<span id="masker-preprocessing-steps"></span><h3><span class="section-number">6.3.2.3. </span>Common data preparation steps: smoothing, filtering, resampling<a class="headerlink" href="#common-data-preparation-steps-smoothing-filtering-resampling" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> comes with many parameters that enable data
preparation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">sklearn</span><span class="p">;</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">set_config</span><span class="p">(</span><span class="n">print_changed_only</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">input_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">masker</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">NiftiMasker</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">masker</span> 
<span class="go">NiftiMasker(detrend=False, dtype=None, high_pass=None,</span>
<span class="go">      high_variance_confounds=False, low_pass=None, mask_args=None,</span>
<span class="go">      mask_img=None, mask_strategy=&#39;background&#39;,</span>
<span class="go">      memory=Memory(location=None), memory_level=1, reports=True,</span>
<span class="go">      runs=None, sample_mask=None, smoothing_fwhm=None,</span>
<span class="go">      standardize=False, standardize_confounds=True, t_r=None,</span>
<span class="go">      target_affine=None, target_shape=None, verbose=0)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>From scikit-learn 0.20, the argument <cite>cachedir</cite> is deprecated in
favour of <cite>location</cite>. Hence <cite>cachedir</cite> might not be seen as here.</p>
</div>
<p>The meaning of each parameter is described in the documentation of
<a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> (click on the name <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a>), here we
comment on the most important.</p>
<div class="topic">
<p class="topic-title"><strong>`dtype` argument</strong></p>
<p>Forcing your data to have a <cite>dtype</cite> of <strong>float32</strong> can help
save memory and is often a good-enough numerical precision.
You can force this cast by choosing <cite>dtype</cite> to be ‘auto’.
In the future this cast will be the default behaviour.</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>If you do not want to use the <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> to perform these
simple operations on data, note that they can also be manually
accessed in nilearn such as in
<a class="reference internal" href="manipulating_images.html#preprocessing-functions"><span class="std std-ref">corresponding functions</span></a>.</p>
</div>
<div class="section" id="smoothing">
<h4><span class="section-number">6.3.2.3.1. </span>Smoothing<a class="headerlink" href="#smoothing" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> can apply Gaussian spatial smoothing to the
neuroimaging data, useful to fight noise or for inter-individual
differences in neuroanatomy. It is achieved by specifying the full-width
half maximum (FWHM; in millimeter scale) with the <cite>smoothing_fwhm</cite>
parameter. Anisotropic filtering is also possible by passing 3 scalars
<code class="docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">y,</span> <span class="pre">z)</span></code>, the FWHM along the x, y, and z direction.</p>
<p>The underlying function handles properly non-cubic voxels by scaling the
given widths appropriately.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="../modules/generated/nilearn.image.smooth_img.html#nilearn.image.smooth_img" title="nilearn.image.smooth_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.image.smooth_img</span></code></a></p>
</div>
</div>
<div class="section" id="temporal-filtering-and-confound-removal">
<span id="temporal-filtering"></span><h4><span class="section-number">6.3.2.3.2. </span>Temporal Filtering and confound removal<a class="headerlink" href="#temporal-filtering-and-confound-removal" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> can also improve aspects of temporal data
properties, before conversion to voxel signals.</p>
<ul class="simple">
<li><p><strong>Standardization</strong>. Parameter <code class="docutils literal notranslate"><span class="pre">standardize</span></code>: Signals can be
standardized (scaled to unit variance).</p></li>
<li><p><strong>Frequency filtering</strong>. Low-pass and high-pass filters can be used to
remove artifacts. Parameters: <code class="docutils literal notranslate"><span class="pre">high_pass</span></code> and <code class="docutils literal notranslate"><span class="pre">low_pass</span></code>, specified
in Hz (note that you must specific the sampling rate in seconds with
the <code class="docutils literal notranslate"><span class="pre">t_r</span></code> parameter: <code class="docutils literal notranslate"><span class="pre">loss_pass=.5,</span> <span class="pre">t_r=2.1</span></code>).</p></li>
<li><p><strong>Confound removal</strong>. Two ways of removing confounds are provided: simple
detrending or using prespecified confounds, such as behavioral or movement
information.</p>
<ul>
<li><p>Linear trends can be removed by activating the <cite>detrend</cite> parameter.
This accounts for slow (as opposed to abrupt or transient) changes
in voxel values along a series of brain images that are unrelated to the
signal of interest (e.g., the neural correlates of cognitive tasks).
It is not activated by default in <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> but is recommended
in almost all scenarios.</p></li>
<li><p>More complex confounds, measured during the acquision, can be removed
by passing them to <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker.transform" title="nilearn.input_data.NiftiMasker.transform"><code class="xref py py-meth docutils literal notranslate"><span class="pre">NiftiMasker.transform</span></code></a>. If the dataset
provides a confounds file, just pass its path to the masker.</p></li>
</ul>
</li>
</ul>
<div class="green topic">
<p class="topic-title"><strong>Exercise</strong></p>
<p>You can, more as a training than as an exercise, try to play with
the parameters in
<a class="reference internal" href="../auto_examples/plot_decoding_tutorial.html#sphx-glr-auto-examples-plot-decoding-tutorial-py"><span class="std std-ref">A introduction tutorial to fMRI decoding</span></a>.
Try to enable detrending and run the script:
does it have a big impact on the result?</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="../modules/generated/nilearn.signal.clean.html#nilearn.signal.clean" title="nilearn.signal.clean"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.signal.clean</span></code></a></p>
</div>
</div>
<div class="section" id="resampling-resizing-and-changing-resolutions-of-images">
<h4><span class="section-number">6.3.2.3.3. </span>Resampling: resizing and changing resolutions of images<a class="headerlink" href="#resampling-resizing-and-changing-resolutions-of-images" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker" title="nilearn.input_data.NiftiMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a> and many similar classes enable resampling
(recasting of images into different resolutions and transformations of
brain voxel data). Two parameters control resampling:</p>
<ul class="simple">
<li><p><cite>target_affine</cite> to resample (resize, rotate…) images in order to match
the spatial configuration defined by the new affine (i.e., matrix
transforming from voxel space into world space).</p></li>
<li><p>Additionally, a <cite>target_shape</cite> can be used to resize images
(i.e., cropping or padding with zeros) to match an expected data
image dimensions (shape composed of x, y, and z).</p></li>
</ul>
<p>How to combine these parameter to obtain the specific resampling desired
is explained in details in <a class="reference internal" href="manipulating_images.html#resampling"><span class="std std-ref">Resampling images</span></a>.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="../modules/generated/nilearn.image.resample_img.html#nilearn.image.resample_img" title="nilearn.image.resample_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.image.resample_img</span></code></a>, <a class="reference internal" href="../modules/generated/nilearn.image.resample_to_img.html#nilearn.image.resample_to_img" title="nilearn.image.resample_to_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.image.resample_to_img</span></code></a></p>
</div>
</div>
</div>
<div class="section" id="inverse-transform-unmasking-data">
<span id="unmasking-step"></span><h3><span class="section-number">6.3.2.4. </span>Inverse transform: unmasking data<a class="headerlink" href="#inverse-transform-unmasking-data" title="Permalink to this headline">¶</a></h3>
<p>Once voxel signals have been processed, the result can be visualized as
images after unmasking (masked-reduced data transformed back into
the original whole-brain space). This step is present in many
<a class="reference external" href="https://matplotlib.org/gallery/index.html#examples-index" title="(in Matplotlib v3.4.1)"><span class="xref std std-ref">examples</span></a> provided in nilearn. Below you will find
an excerpt of <a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_anova_svm.html#sphx-glr-auto-examples-02-decoding-plot-haxby-anova-svm-py"><span class="std std-ref">the example performing Anova-SVM on the Haxby data</span></a>):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># :class:`nilearn.plotting.plot_stat_map`</span>
<span class="n">weight_img</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">coef_img_</span><span class="p">[</span><span class="s1">&#39;face&#39;</span><span class="p">]</span>
<span class="kn">from</span> <span class="nn">nilearn.plotting</span> <span class="kn">import</span> <span class="n">plot_stat_map</span><span class="p">,</span> <span class="n">show</span>
<span class="n">plot_stat_map</span><span class="p">(</span><span class="n">weight_img</span><span class="p">,</span> <span class="n">bg_img</span><span class="o">=</span><span class="n">haxby_dataset</span><span class="o">.</span><span class="n">anat</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;SVM weights&#39;</span><span class="p">)</span>

<span class="n">show</span><span class="p">()</span>
<span class="c1">#############################################################################</span>
</pre></div>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="topic">
<p class="topic-title"><strong>Examples to better understand the NiftiMasker</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_nifti_simple.html#sphx-glr-auto-examples-06-manipulating-images-plot-nifti-simple-py"><span class="std std-ref">Simple example of NiftiMasker use</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_mask_computation.html#sphx-glr-auto-examples-06-manipulating-images-plot-mask-computation-py"><span class="std std-ref">Understanding NiftiMasker and mask computation</span></a></p></li>
</ul>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
</div>
<div class="section" id="extraction-of-signals-from-regions-niftilabelsmasker-niftimapsmasker">
<span id="region"></span><h2><a class="toc-backref" href="#id4"><span class="section-number">6.3.3. </span>Extraction of signals from regions: <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiLabelsMasker.html#nilearn.input_data.NiftiLabelsMasker" title="nilearn.input_data.NiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a>, <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMapsMasker.html#nilearn.input_data.NiftiMapsMasker" title="nilearn.input_data.NiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a></a><a class="headerlink" href="#extraction-of-signals-from-regions-niftilabelsmasker-niftimapsmasker" title="Permalink to this headline">¶</a></h2>
<p>The purpose of <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiLabelsMasker.html#nilearn.input_data.NiftiLabelsMasker" title="nilearn.input_data.NiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a> and <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMapsMasker.html#nilearn.input_data.NiftiMapsMasker" title="nilearn.input_data.NiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a> is to
compute signals from regions containing many voxels. They make it easy to get
these signals once you have an atlas or a parcellation into brain regions.</p>
<div class="section" id="regions-definition">
<h3><span class="section-number">6.3.3.1. </span>Regions definition<a class="headerlink" href="#regions-definition" title="Permalink to this headline">¶</a></h3>
<p>Nilearn understands two different ways of defining regions, which are called
labels and maps, handled by <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiLabelsMasker.html#nilearn.input_data.NiftiLabelsMasker" title="nilearn.input_data.NiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a> and
<a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMapsMasker.html#nilearn.input_data.NiftiMapsMasker" title="nilearn.input_data.NiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a>, respectively.</p>
<ul class="simple">
<li><p>labels: a single region is defined as the set of all the voxels that have a
common label (e.g., anatomical brain region definitions as integers)
in the region definition array. The set of
regions is defined by a single 3D array, containing a voxel-wise
dictionary of label numbers that denote what
region a given voxel belongs to. This technique has a big advantage: the
required memory load is independent of the number of regions, allowing
for a large number of regions. On the other hand, there are
several disadvantages: regions cannot spatially overlap
and are represented in a binary present/nonpresent coding (no weighting).</p></li>
<li><p>maps: a single region is defined as the set of all the voxels that have a
non-zero weight. A set of regions is thus defined by a set of 3D images (or a
single 4D image), one 3D image per region (as opposed to all regions in a
single 3D image such as for labels, cf. above).
While these defined weighted regions can exhibit spatial
overlap (as opposed to labels), storage cost scales linearly with the
number of regions. Handling a large number (e.g., thousands)
of regions will prove difficult with this data transformation of
whole-brain voxel data into weighted region-wise data.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These usage are illustrated in the section <a class="reference internal" href="../connectivity/functional_connectomes.html#functional-connectomes"><span class="std std-ref">Extracting times series to build a functional connectome</span></a>.</p>
</div>
</div>
<div class="section" id="niftilabelsmasker-usage">
<h3><span class="section-number">6.3.3.2. </span><a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiLabelsMasker.html#nilearn.input_data.NiftiLabelsMasker" title="nilearn.input_data.NiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a> Usage<a class="headerlink" href="#niftilabelsmasker-usage" title="Permalink to this headline">¶</a></h3>
<p>Usage of <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiLabelsMasker.html#nilearn.input_data.NiftiLabelsMasker" title="nilearn.input_data.NiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a> is similar to that of
<a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMapsMasker.html#nilearn.input_data.NiftiMapsMasker" title="nilearn.input_data.NiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a>. The main difference is that it requires a labels image
instead of a set of maps as input.</p>
<p>The <cite>background_label</cite> keyword of <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiLabelsMasker.html#nilearn.input_data.NiftiLabelsMasker" title="nilearn.input_data.NiftiLabelsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a> deserves
some explanation. The voxels that correspond to the brain or a region
of interest in an fMRI image do not fill the entire image.
Consequently, in the labels image, there must be a label value that corresponds
to “outside” the brain (for which no signal should be extracted).
By default, this label is set to zero in nilearn (refered to as “background”).
Should some non-zero value encoding be necessary, it is possible
to change the background value with the <cite>background_label</cite> keyword.</p>
<div class="topic">
<p class="topic-title"><strong>Examples</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/03_connectivity/plot_signal_extraction.html#sphx-glr-auto-examples-03-connectivity-plot-signal-extraction-py"><span class="std std-ref">Extracting signals from a brain parcellation</span></a></p></li>
</ul>
</div>
</div>
<div class="section" id="niftimapsmasker-usage">
<h3><span class="section-number">6.3.3.3. </span><a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMapsMasker.html#nilearn.input_data.NiftiMapsMasker" title="nilearn.input_data.NiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a> Usage<a class="headerlink" href="#niftimapsmasker-usage" title="Permalink to this headline">¶</a></h3>
<p>This atlas defines its regions using maps. The path to the corresponding
file is given in the <cite>maps_img</cite> argument.</p>
<p>One important thing that happens transparently during the execution of
<a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker.fit_transform" title="nilearn.input_data.NiftiMasker.fit_transform"><code class="xref py py-meth docutils literal notranslate"><span class="pre">NiftiMasker.fit_transform</span></code></a> is resampling. Initially, the images
and the atlas do typically not have the same shape nor the same affine.
Casting them into the same format is required for successful signal extraction
The keyword argument <cite>resampling_target</cite> specifies which format
(i.e., dimensions and affine) the data should be resampled to.
See the reference documentation for <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiMapsMasker.html#nilearn.input_data.NiftiMapsMasker" title="nilearn.input_data.NiftiMapsMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a> for every
possible option.</p>
<div class="topic">
<p class="topic-title"><strong>Examples</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/03_connectivity/plot_probabilistic_atlas_extraction.html#sphx-glr-auto-examples-03-connectivity-plot-probabilistic-atlas-extraction-py"><span class="std std-ref">Extracting signals of a probabilistic atlas of functional regions</span></a></p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="extraction-of-signals-from-seeds-niftispheresmasker">
<h2><a class="toc-backref" href="#id5"><span class="section-number">6.3.4. </span>Extraction of signals from seeds: <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiSpheresMasker.html#nilearn.input_data.NiftiSpheresMasker" title="nilearn.input_data.NiftiSpheresMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiSpheresMasker</span></code></a></a><a class="headerlink" href="#extraction-of-signals-from-seeds-niftispheresmasker" title="Permalink to this headline">¶</a></h2>
<p>The purpose of <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiSpheresMasker.html#nilearn.input_data.NiftiSpheresMasker" title="nilearn.input_data.NiftiSpheresMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiSpheresMasker</span></code></a> is to compute signals from
seeds containing voxels in spheres. It makes it easy to get these signals once
you have a list of coordinates.
A single seed is a sphere defined by the radius (in millimeters) and the
coordinates (typically MNI or TAL) of its center.</p>
<p>Using <a class="reference internal" href="../modules/generated/nilearn.input_data.NiftiSpheresMasker.html#nilearn.input_data.NiftiSpheresMasker" title="nilearn.input_data.NiftiSpheresMasker"><code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiSpheresMasker</span></code></a> needs to define a list of coordinates.
<cite>seeds</cite> argument takes a list of 3D coordinates (tuples) of the spheres centers,
they should be in the same space as the images.
Seeds can overlap spatially and are represented in a binary present/nonpresent
coding (no weighting).
Below is an example of a coordinates list of four seeds from the default mode network:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dmn_coords</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">52</span><span class="p">,</span> <span class="mi">18</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">46</span><span class="p">,</span> <span class="o">-</span><span class="mi">68</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="p">(</span><span class="mi">46</span><span class="p">,</span> <span class="o">-</span><span class="mi">68</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">)]</span>
</pre></div>
</div>
<p><cite>radius</cite> is an optional argument that takes a real value in millimeters.
If no value is given for the <cite>radius</cite> argument, the single voxel at the given
seed position is used.</p>
<div class="topic">
<p class="topic-title"><strong>Examples</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/03_connectivity/plot_sphere_based_connectome.html#sphx-glr-auto-examples-03-connectivity-plot-sphere-based-connectome-py"><span class="std std-ref">Extract signals on spheres and plot a connectome</span></a></p></li>
</ul>
</div>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">6.3. From neuroimaging volumes to data matrices: the masker objects</a><ul>
<li><a class="reference internal" href="#the-concept-of-masker-objects">6.3.1. The concept of “masker” objects</a></li>
<li><a class="reference internal" href="#niftimasker-applying-a-mask-to-load-time-series">6.3.2. <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code>: applying a mask to load time-series</a><ul>
<li><a class="reference internal" href="#custom-data-loading-loading-only-the-first-100-time-points">6.3.2.1. Custom data loading: loading only the first 100 time points</a></li>
<li><a class="reference internal" href="#controlling-how-the-mask-is-computed-from-the-data">6.3.2.2. Controlling how the mask is computed from the data</a><ul>
<li><a class="reference internal" href="#visualizing-the-computed-mask">6.3.2.2.1. Visualizing the computed mask</a></li>
<li><a class="reference internal" href="#different-masking-strategies">6.3.2.2.2. Different masking strategies</a></li>
<li><a class="reference internal" href="#extra-mask-parameters-opening-cutoff">6.3.2.2.3. Extra mask parameters: opening, cutoff…</a></li>
</ul>
</li>
<li><a class="reference internal" href="#common-data-preparation-steps-smoothing-filtering-resampling">6.3.2.3. Common data preparation steps: smoothing, filtering, resampling</a><ul>
<li><a class="reference internal" href="#smoothing">6.3.2.3.1. Smoothing</a></li>
<li><a class="reference internal" href="#temporal-filtering-and-confound-removal">6.3.2.3.2. Temporal Filtering and confound removal</a></li>
<li><a class="reference internal" href="#resampling-resizing-and-changing-resolutions-of-images">6.3.2.3.3. Resampling: resizing and changing resolutions of images</a></li>
</ul>
</li>
<li><a class="reference internal" href="#inverse-transform-unmasking-data">6.3.2.4. Inverse transform: unmasking data</a></li>
</ul>
</li>
<li><a class="reference internal" href="#extraction-of-signals-from-regions-niftilabelsmasker-niftimapsmasker">6.3.3. Extraction of signals from regions: <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a><ul>
<li><a class="reference internal" href="#regions-definition">6.3.3.1. Regions definition</a></li>
<li><a class="reference internal" href="#niftilabelsmasker-usage">6.3.3.2. <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code> Usage</a></li>
<li><a class="reference internal" href="#niftimapsmasker-usage">6.3.3.3. <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code> Usage</a></li>
</ul>
</li>
<li><a class="reference internal" href="#extraction-of-signals-from-seeds-niftispheresmasker">6.3.4. Extraction of signals from seeds: <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiSpheresMasker</span></code></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="manipulating_images.html"
                        title="previous chapter"><span class="section-number">6.2. </span>Manipulating images: resampling, smoothing, masking, ROIs…</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="../building_blocks/index.html"
                        title="next chapter"><span class="section-number">7. </span>Advanced usage: manual pipelines and scaling up</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
            &copy; The nilearn developers 2010-2021.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 4.0.2.
        <span style="padding-left: 5ex;">
          <a href="../_sources/manipulating_images/masker_objects.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>