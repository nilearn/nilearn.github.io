
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nilearn: Statistical Analysis for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/nature.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="6.2. Manipulating images: resampling, smoothing, masking, ROIs…" href="manipulating_images.html" />
    <link rel="prev" title="6. Manipulation brain volumes with nilearn" href="index.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">


<script type="text/javascript">
function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});
</script>
<script type="text/javascript">
function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../index.html">
      <img src="../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../modules/reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Statistics for NeuroImaging in Python</h2>
  </div>
  <div class="search_form">
    <div class="gcse-search" id="cse" style="width: 100%;"></div>
    <script>
      (function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </div>
</div>



<div class=related-wrapper>
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="manipulating_images.html" title="6.2. Manipulating images: resampling, smoothing, masking, ROIs…"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="index.html" title="6. Manipulation brain volumes with nilearn"
             accesskey="P">previous</a> |</li>
<li><a href="../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../modules/reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../authors.html">About</a>|&nbsp;</li>
<li><a href="../glossary.html">Glossary</a>|&nbsp;</li>
<li><a href="../bibliography.html">Bibliography</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="index.html" accesskey="U"><span class="section-number">6. </span>Manipulation brain volumes with nilearn</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Nilearn: Statistical Analysis for NeuroImaging in Python</a></li> 
      </ul>
    </div>
</div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="input-and-output-neuroimaging-data-representation">
<span id="extracting-data"></span><h1><span class="section-number">6.1. </span>Input and output: neuroimaging data representation<a class="headerlink" href="#input-and-output-neuroimaging-data-representation" title="Permalink to this headline">¶</a></h1>
<div class="contents local topic" id="contents">
<p class="topic-title"><strong>Contents</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="#inputing-data-file-names-or-image-objects" id="id1">Inputing data: file names or image objects</a></p></li>
<li><p><a class="reference internal" href="#fetching-open-datasets-from-internet" id="id2">Fetching open datasets from Internet</a></p></li>
<li><p><a class="reference internal" href="#understanding-neuroimaging-data" id="id3">Understanding neuroimaging data</a></p></li>
</ul>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="section" id="inputing-data-file-names-or-image-objects">
<span id="loading-data"></span><h2><a class="toc-backref" href="#id1"><span class="section-number">6.1.1. </span>Inputing data: file names or image objects</a><a class="headerlink" href="#inputing-data-file-names-or-image-objects" title="Permalink to this headline">¶</a></h2>
<div class="section" id="file-names-and-objects-3d-and-4d-images">
<h3><span class="section-number">6.1.1.1. </span>File names and objects, 3D and 4D images<a class="headerlink" href="#file-names-and-objects-3d-and-4d-images" title="Permalink to this headline">¶</a></h3>
<p>All Nilearn functions accept file names as arguments:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">image</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">smoothed_img</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">smooth_img</span><span class="p">(</span><span class="s1">&#39;/home/user/t_map001.nii&#39;</span><span class="p">)</span>  
</pre></div>
</div>
<p>Nilearn can operate on either file names or <a class="reference external" href="http://nipy.org/nibabel/nibabel_images.html">NiftiImage objects</a>. The later represent the
data loaded in memory. In the example above, the
function <a class="reference internal" href="../modules/generated/nilearn.image.smooth_img.html#nilearn.image.smooth_img" title="nilearn.image.smooth_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">smooth_img</span></code></a> returns a Nifti1Image object, which can then
be readily passed to other nilearn functions.</p>
<p>In nilearn, we often use the term <em>“niimg”</em> as abbreviation that denotes
either a file name or a <a class="reference external" href="http://nipy.org/nibabel/nibabel_images.html">NiftiImage object</a>.</p>
<p>Niimgs can be 3D or 4D. A 4D niimg may for instance represent a time
series of 3D images. It can be <strong>a list of file names</strong>, if these contain
3D information:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># dataset folder contains subject1.nii and subject2.nii</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nilearn.image</span> <span class="kn">import</span> <span class="n">smooth_img</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result_img</span> <span class="o">=</span> <span class="n">smooth_img</span><span class="p">([</span><span class="s1">&#39;dataset/subject1.nii&#39;</span><span class="p">,</span> <span class="s1">&#39;dataset/subject2.nii&#39;</span><span class="p">])</span> 
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">result_img</span></code> is a 4D in-memory image, containing the data of both
subjects.</p>
</div>
<div class="section" id="file-name-matching-globbing-and-user-path-expansion">
<span id="filename-matching"></span><h3><span class="section-number">6.1.1.2. </span>File name matching: “globbing” and user path expansion<a class="headerlink" href="#file-name-matching-globbing-and-user-path-expansion" title="Permalink to this headline">¶</a></h3>
<p>You can specify files with <em>wildcard</em> matching patterns (as in Unix
shell):</p>
<blockquote>
<div><ul>
<li><p><strong>Matching multiple files</strong>: suppose the dataset folder contains
subject_01.nii, subject_03.nii, and subject_03.nii;
<code class="docutils literal notranslate"><span class="pre">dataset/subject_*.nii</span></code> is a glob expression matching all filenames:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example with a smoothing process:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nilearn.image</span> <span class="kn">import</span> <span class="n">smooth_img</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result_img</span> <span class="o">=</span> <span class="n">smooth_img</span><span class="p">(</span><span class="s2">&quot;dataset/subject_*.nii&quot;</span><span class="p">)</span> 
</pre></div>
</div>
<p>Note that the resulting is a 4D image.</p>
</li>
<li><p><strong>Expanding the home directory</strong> <code class="docutils literal notranslate"><span class="pre">~</span></code> is expanded to your home
directory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">result_img</span> <span class="o">=</span> <span class="n">smooth_img</span><span class="p">(</span><span class="s2">&quot;~/dataset/subject_01.nii&quot;</span><span class="p">)</span> 
</pre></div>
</div>
<p>Using <code class="docutils literal notranslate"><span class="pre">~</span></code> rather than specifying the details of the path is good
practice, as it will make it more likely that your script work on
different computers.</p>
</li>
</ul>
</div></blockquote>
<div class="topic">
<p class="topic-title"><strong>Python globbing</strong></p>
<p>For more complicated use cases, Python also provides functions to work
with file paths, in particular, <a class="reference external" href="https://docs.python.org/3.8/library/glob.html#glob.glob" title="(in Python v3.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">glob.glob</span></code></a>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Unlike nilearn’s path expansion, the result of <a class="reference external" href="https://docs.python.org/3.8/library/glob.html#glob.glob" title="(in Python v3.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">glob.glob</span></code></a> is
not sorted and, depending on the computer you are running, they
might not be in alphabetic order. We advise you to rely on
nilearn’s path expansion.</p>
</div>
<p>To load data with globbing, we suggest that you use
<a class="reference internal" href="../modules/generated/nilearn.image.load_img.html#nilearn.image.load_img" title="nilearn.image.load_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.image.load_img</span></code></a>.</p>
</div>
</div>
</div>
<div class="section" id="fetching-open-datasets-from-internet">
<span id="datasets"></span><h2><a class="toc-backref" href="#id2"><span class="section-number">6.1.2. </span>Fetching open datasets from Internet</a><a class="headerlink" href="#fetching-open-datasets-from-internet" title="Permalink to this headline">¶</a></h2>
<p>Nilearn provides dataset fetching function that
automatically downloads reference
datasets and atlases. They can be imported from
<a class="reference internal" href="../modules/reference.html#module-nilearn.datasets" title="nilearn.datasets"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.datasets</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">haxby_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_haxby</span><span class="p">()</span>  
</pre></div>
</div>
<p>They return a data structure that contains different pieces of
information on the retrieved dataset, including the
file names on hard disk:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># The different files</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">haxby_dataset</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>  
<span class="go">[&#39;anat&#39;, &#39;description&#39;, &#39;func&#39;, &#39;mask&#39;, &#39;mask_face&#39;, &#39;mask_face_little&#39;,</span>
<span class="go">&#39;mask_house&#39;, &#39;mask_house_little&#39;, &#39;mask_vt&#39;, &#39;session_target&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Path to first functional file</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">haxby_dataset</span><span class="o">.</span><span class="n">func</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  
<span class="go">/.../nilearn_data/haxby2001/subj1/bold.nii.gz</span>
</pre></div>
</div>
<p>Explanation and further resources of the dataset at hand can be retrieved as
follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">haxby_dataset</span><span class="o">.</span><span class="n">description</span><span class="p">)</span>  
<span class="go">Haxby 2001 results</span>


<span class="go">Notes</span>
<span class="go">-----</span>
<span class="go">Results from a classical fMRI study that...</span>
</pre></div>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>For a list of all the data fetching functions in nilearn, see
<a class="reference internal" href="../modules/reference.html#datasets-ref"><span class="std std-ref">nilearn.datasets: Automatic Dataset Fetching</span></a>.</p>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="topic">
<p class="topic-title"><strong>nilearn_data: Where is the downloaded data stored?</strong></p>
<p>The fetching functions download the reference datasets to the disk.
They save it locally for future use, in one of the
following directories (in order of priority, if present):</p>
<blockquote>
<div><ul class="simple">
<li><p>the folder specified by <cite>data_dir</cite> parameter in the fetching function</p></li>
<li><p>the global environment variable <cite>NILEARN_SHARED_DATA</cite></p></li>
<li><p>the user environment variable <cite>NILEARN_DATA</cite></p></li>
<li><p>the <cite>nilearn_data</cite> folder in the user home folder</p></li>
</ul>
</div></blockquote>
<p>The two different environment variables (NILEARN_SHARED_DATA and
NILEARN_DATA) are provided for multi-user systems, to distinguish a
global dataset repository that may be read-only at the user-level.
Note that you can copy that folder to another user’s computers to
avoid the initial dataset download on the first fetching call.</p>
<p>You can check in which directory nilearn will store the data with the
function <a class="reference internal" href="../modules/generated/nilearn.datasets.get_data_dirs.html#nilearn.datasets.get_data_dirs" title="nilearn.datasets.get_data_dirs"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.datasets.get_data_dirs</span></code></a>.</p>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="understanding-neuroimaging-data">
<h2><a class="toc-backref" href="#id3"><span class="section-number">6.1.3. </span>Understanding neuroimaging data</a><a class="headerlink" href="#understanding-neuroimaging-data" title="Permalink to this headline">¶</a></h2>
<div class="section" id="nifti-and-analyze-data">
<h3><span class="section-number">6.1.3.1. </span>Nifti and Analyze data<a class="headerlink" href="#nifti-and-analyze-data" title="Permalink to this headline">¶</a></h3>
<p>For volumetric data, nilearn works with data stored as in the Nifti
structure (via the <a class="reference external" href="http://nipy.sourceforge.net/nibabel/">nibabel</a> package).</p>
<p>The <a class="reference external" href="http://nifti.nimh.nih.gov/">NifTi</a> data structure (also used in
Analyze files) is the standard way of sharing data in neuroimaging
research. Three main components are:</p>
<dl class="field-list simple">
<dt class="field-odd">data</dt>
<dd class="field-odd"><p>raw scans in form of a numpy array: <code class="docutils literal notranslate"><span class="pre">data</span> <span class="pre">=</span> <span class="pre">nilearn.image.get_data(img)</span></code></p>
</dd>
<dt class="field-even">affine</dt>
<dd class="field-even"><p>returns the transformation matrix that maps
from voxel indices of the numpy array to actual real-world
locations of the brain:
<code class="docutils literal notranslate"><span class="pre">affine</span> <span class="pre">=</span> <span class="pre">img.affine</span></code></p>
</dd>
<dt class="field-odd">header</dt>
<dd class="field-odd"><p>low-level informations about the data (slice duration, etc.):
<code class="docutils literal notranslate"><span class="pre">header</span> <span class="pre">=</span> <span class="pre">img.header</span></code></p>
</dd>
</dl>
<p>If you need to load the data without using nilearn, read the <a class="reference external" href="http://nipy.sourceforge.net/nibabel/">nibabel</a>
documentation.</p>
<p>Note: For older versions of <a class="reference external" href="http://nipy.sourceforge.net/nibabel/">nibabel</a>, affine and header can be retrieved
with <code class="docutils literal notranslate"><span class="pre">get_affine()</span></code> and <code class="docutils literal notranslate"><span class="pre">get_header()</span></code>.</p>
<div class="topic">
<p class="topic-title"><strong>Dataset formatting: data shape</strong></p>
<p>It is important to appreciate two main representations for
storing and accessing more than one Nifti images, that is sets
of MRI scans:</p>
<ul class="simple">
<li><p>a big 4D matrix representing (3D MRI + 1D for time), stored in a single
Nifti file.
<a class="reference external" href="http://www.fmrib.ox.ac.uk/fsl/">FSL</a> users tend to
prefer this format.</p></li>
<li><p>several 3D matrices representing each time point (single 3D volume) of the
session, stored in set of 3D Nifti or analyse files.
<a class="reference external" href="http://www.fil.ion.ucl.ac.uk/spm/">SPM</a> users tend
to prefer this format.</p></li>
</ul>
</div>
</div>
<div class="section" id="niimg-like-objects">
<span id="niimg"></span><h3><span class="section-number">6.1.3.2. </span>Niimg-like objects<a class="headerlink" href="#niimg-like-objects" title="Permalink to this headline">¶</a></h3>
<p>Nilearn functions take as input argument what we call “Niimg-like
objects”:</p>
<p><strong>Niimg:</strong> A Niimg-like object can be one of the following:</p>
<blockquote>
<div><ul class="simple">
<li><p>A string with a file path to a Nifti or Analyse image</p></li>
<li><p>An <code class="docutils literal notranslate"><span class="pre">SpatialImage</span></code> from nibabel, ie an object exposing <code class="docutils literal notranslate"><span class="pre">get_fdata()</span></code>
method and <code class="docutils literal notranslate"><span class="pre">affine</span></code> attribute, typically a <code class="docutils literal notranslate"><span class="pre">Nifti1Image</span></code> from <a class="reference external" href="http://nipy.sourceforge.net/nibabel/">nibabel</a>.</p></li>
</ul>
</div></blockquote>
<p><strong>Niimg-4D:</strong> Similarly, some functions require 4D Nifti-like
data, which we call Niimgs or Niimg-4D. Accepted input arguments are:</p>
<blockquote>
<div><ul class="simple">
<li><p>A path to a 4D Nifti image</p></li>
<li><p>List of paths to 3D Nifti images</p></li>
<li><p>4D Nifti-like object</p></li>
<li><p>List of 3D Nifti-like objects</p></li>
</ul>
</div></blockquote>
<div class="topic">
<p class="topic-title"><strong>Image affines</strong></p>
<p>If you provide a sequence of Nifti images, all of them must have the same
affine.</p>
</div>
<div class="topic">
<p class="topic-title"><strong>Decreasing memory used when loading Nifti images</strong></p>
<p>When Nifti images are stored compressed (.nii.gz), loading them directly
consumes more memory. As a result, large 4D images may
raise “MemoryError”, especially on smaller computers and when using Nilearn
routines that require intensive 4D matrix operations. One step to improve
the situation may be to decompress the data onto disk as an initial step.
If multiple images are loaded into memory sequentially, another solution may
be to <a class="reference external" href="https://nipy.org/nibabel/images_and_memory.html#using-uncache">uncache</a> one before loading and performing operations on another.</p>
</div>
</div>
<div class="section" id="text-files-phenotype-or-behavior">
<h3><span class="section-number">6.1.3.3. </span>Text files: phenotype or behavior<a class="headerlink" href="#text-files-phenotype-or-behavior" title="Permalink to this headline">¶</a></h3>
<p>Phenotypic or behavioral data are often provided as text or CSV
(Comma Separated Values) file. They
can be loaded with <cite>pd.read_csv</cite> but you may have to specify some options
(typically <cite>sep</cite> if fields aren’t delimited with a comma).</p>
<p>For the Haxby datasets, we can load the categories of the images
presented to the subject:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">haxby_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_haxby</span><span class="p">()</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">haxby_dataset</span><span class="o">.</span><span class="n">session_target</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">)</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="n">stimuli</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span>  
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">stimuli</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>  
<span class="go">[&#39;bottle&#39; &#39;cat&#39; &#39;chair&#39; &#39;face&#39; &#39;house&#39; &#39;rest&#39; &#39;scissors&#39; &#39;scrambledpix&#39;</span>
<span class="go"> &#39;shoe&#39;]</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title"><strong>Reading CSV with pandas</strong></p>
<p><a class="reference external" href="http://pandas.pydata.org/">Pandas</a> is a powerful package to read
data from CSV files and manipulate them.</p>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">6.1. Input and output: neuroimaging data representation</a><ul>
<li><a class="reference internal" href="#inputing-data-file-names-or-image-objects">6.1.1. Inputing data: file names or image objects</a><ul>
<li><a class="reference internal" href="#file-names-and-objects-3d-and-4d-images">6.1.1.1. File names and objects, 3D and 4D images</a></li>
<li><a class="reference internal" href="#file-name-matching-globbing-and-user-path-expansion">6.1.1.2. File name matching: “globbing” and user path expansion</a></li>
</ul>
</li>
<li><a class="reference internal" href="#fetching-open-datasets-from-internet">6.1.2. Fetching open datasets from Internet</a></li>
<li><a class="reference internal" href="#understanding-neuroimaging-data">6.1.3. Understanding neuroimaging data</a><ul>
<li><a class="reference internal" href="#nifti-and-analyze-data">6.1.3.1. Nifti and Analyze data</a></li>
<li><a class="reference internal" href="#niimg-like-objects">6.1.3.2. Niimg-like objects</a></li>
<li><a class="reference internal" href="#text-files-phenotype-or-behavior">6.1.3.3. Text files: phenotype or behavior</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="index.html"
                        title="previous chapter"><span class="section-number">6. </span>Manipulation brain volumes with nilearn</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="manipulating_images.html"
                        title="next chapter"><span class="section-number">6.2. </span>Manipulating images: resampling, smoothing, masking, ROIs…</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
            &copy; The nilearn developers 2010-2021.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 4.0.2.
        <span style="padding-left: 5ex;">
          <a href="../_sources/manipulating_images/input_output.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>