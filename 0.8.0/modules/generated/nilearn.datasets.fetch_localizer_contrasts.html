
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nilearn: Statistical Analysis for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/nature.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="8.2.23. nilearn.datasets.fetch_localizer_calculation_task" href="nilearn.datasets.fetch_localizer_calculation_task.html" />
    <link rel="prev" title="8.2.21. nilearn.datasets.fetch_localizer_button_task" href="nilearn.datasets.fetch_localizer_button_task.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">


<script type="text/javascript">
function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});
</script>
<script type="text/javascript">
function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../../index.html">
      <img src="../../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../../manipulating_images/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Statistics for NeuroImaging in Python</h2>
  </div>
  <div class="search_form">
    <div class="gcse-search" id="cse" style="width: 100%;"></div>
    <script>
      (function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </div>
</div>



<div class=related-wrapper>
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="nilearn.datasets.fetch_localizer_calculation_task.html" title="8.2.23. nilearn.datasets.fetch_localizer_calculation_task"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="nilearn.datasets.fetch_localizer_button_task.html" title="8.2.21. nilearn.datasets.fetch_localizer_button_task"
             accesskey="P">previous</a> |</li>
<li><a href="../../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li><a href="../../glossary.html">Glossary</a>|&nbsp;</li>
<li><a href="../../bibliography.html">Bibliography</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../reference.html" accesskey="U"><span class="section-number">8. </span>Reference documentation: all nilearn functions</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Nilearn: Statistical Analysis for NeuroImaging in Python</a></li> 
      </ul>
    </div>
</div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page is a reference documentation. It only explains the
function signature, and not how to use it. Please refer to the
<a class="reference internal" href="../../user_guide.html#user-guide"><span class="std std-ref">user guide</span></a> for the big picture.</p>
</div>
<div class="section" id="nilearn-datasets-fetch-localizer-contrasts">
<h1><span class="section-number">8.2.22. </span>nilearn.datasets.fetch_localizer_contrasts<a class="headerlink" href="#nilearn-datasets-fetch-localizer-contrasts" title="Permalink to this headline">Â¶</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="nilearn.datasets.fetch_localizer_contrasts">
<span class="sig-prename descclassname"><span class="pre">nilearn.datasets.</span></span><span class="sig-name descname"><span class="pre">fetch_localizer_contrasts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">contrasts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_subjects</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">get_tmaps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">get_masks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">get_anats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resume</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/297b1509/nilearn/datasets/func.py#L432"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.datasets.fetch_localizer_contrasts" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Download and load Brainomics/Localizer dataset (94 subjects).</p>
<p>âThe Functional Localizer is a simple and fast acquisition
procedure based on a 5-minute functional magnetic resonance
imaging (fMRI) sequence that can be run as easily and as
systematically as an anatomical scan. This protocol captures the
cerebral bases of auditory and visual perception, motor actions,
reading, language comprehension and mental calculation at an
individual level. Individual functional maps are reliable and
quite precise. The procedure is decribed in more detail on the
Functional Localizer page.â
(see <a class="reference external" href="http://brainomics.cea.fr/localizer/">http://brainomics.cea.fr/localizer/</a>)</p>
<p>You may cite <a class="footnote-reference brackets" href="#papadopoulosorfanos2017309" id="id1">1</a>
when using this dataset.</p>
<p>Scientific results obtained using this dataset are described
in <a class="footnote-reference brackets" href="#pinel2007fast" id="id2">2</a>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>contrasts</strong><span class="classifier">list of str</span></dt><dd><p>The contrasts to be fetched (for all 94 subjects available).
Allowed values are:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-</span> <span class="s2">&quot;checkerboard&quot;</span>
<span class="o">-</span> <span class="s2">&quot;horizontal checkerboard&quot;</span>
<span class="o">-</span> <span class="s2">&quot;vertical checkerboard&quot;</span>
<span class="o">-</span> <span class="s2">&quot;horizontal vs vertical checkerboard&quot;</span>
<span class="o">-</span> <span class="s2">&quot;vertical vs horizontal checkerboard&quot;</span>
<span class="o">-</span> <span class="s2">&quot;sentence listening&quot;</span>
<span class="o">-</span> <span class="s2">&quot;sentence reading&quot;</span>
<span class="o">-</span> <span class="s2">&quot;sentence listening and reading&quot;</span>
<span class="o">-</span> <span class="s2">&quot;sentence reading vs checkerboard&quot;</span>
<span class="o">-</span> <span class="s2">&quot;calculation (auditory cue)&quot;</span>
<span class="o">-</span> <span class="s2">&quot;calculation (visual cue)&quot;</span>
<span class="o">-</span> <span class="s2">&quot;calculation (auditory and visual cue)&quot;</span>
<span class="o">-</span> <span class="s2">&quot;calculation (auditory cue) vs sentence listening&quot;</span>
<span class="o">-</span> <span class="s2">&quot;calculation (visual cue) vs sentence reading&quot;</span>
<span class="o">-</span> <span class="s2">&quot;calculation vs sentences&quot;</span>
<span class="o">-</span> <span class="s2">&quot;calculation (auditory cue) and sentence listening&quot;</span>
<span class="o">-</span> <span class="s2">&quot;calculation (visual cue) and sentence reading&quot;</span>
<span class="o">-</span> <span class="s2">&quot;calculation and sentence listening/reading&quot;</span>
<span class="o">-</span> <span class="s2">&quot;calculation (auditory cue) and sentence listening vs &quot;</span>
<span class="o">-</span> <span class="s2">&quot;calculation (visual cue) and sentence reading&quot;</span>
<span class="o">-</span> <span class="s2">&quot;calculation (visual cue) and sentence reading vs checkerboard&quot;</span>
<span class="o">-</span> <span class="s2">&quot;calculation and sentence listening/reading vs button press&quot;</span>
<span class="o">-</span> <span class="s2">&quot;left button press (auditory cue)&quot;</span>
<span class="o">-</span> <span class="s2">&quot;left button press (visual cue)&quot;</span>
<span class="o">-</span> <span class="s2">&quot;left button press&quot;</span>
<span class="o">-</span> <span class="s2">&quot;left vs right button press&quot;</span>
<span class="o">-</span> <span class="s2">&quot;right button press (auditory cue)&quot;</span>
<span class="o">-</span> <span class="s2">&quot;right button press (visual cue)&quot;</span>
<span class="o">-</span> <span class="s2">&quot;right button press&quot;</span>
<span class="o">-</span> <span class="s2">&quot;right vs left button press&quot;</span>
<span class="o">-</span> <span class="s2">&quot;button press (auditory cue) vs sentence listening&quot;</span>
<span class="o">-</span> <span class="s2">&quot;button press (visual cue) vs sentence reading&quot;</span>
<span class="o">-</span> <span class="s2">&quot;button press vs calculation and sentence listening/reading&quot;</span>
</pre></div>
</div>
<p>or equivalently on can use the original names:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-</span> <span class="s2">&quot;checkerboard&quot;</span>
<span class="o">-</span> <span class="s2">&quot;horizontal checkerboard&quot;</span>
<span class="o">-</span> <span class="s2">&quot;vertical checkerboard&quot;</span>
<span class="o">-</span> <span class="s2">&quot;horizontal vs vertical checkerboard&quot;</span>
<span class="o">-</span> <span class="s2">&quot;vertical vs horizontal checkerboard&quot;</span>
<span class="o">-</span> <span class="s2">&quot;auditory sentences&quot;</span>
<span class="o">-</span> <span class="s2">&quot;visual sentences&quot;</span>
<span class="o">-</span> <span class="s2">&quot;auditory&amp;visual sentences&quot;</span>
<span class="o">-</span> <span class="s2">&quot;visual sentences vs checkerboard&quot;</span>
<span class="o">-</span> <span class="s2">&quot;auditory calculation&quot;</span>
<span class="o">-</span> <span class="s2">&quot;visual calculation&quot;</span>
<span class="o">-</span> <span class="s2">&quot;auditory&amp;visual calculation&quot;</span>
<span class="o">-</span> <span class="s2">&quot;auditory calculation vs auditory sentences&quot;</span>
<span class="o">-</span> <span class="s2">&quot;visual calculation vs sentences&quot;</span>
<span class="o">-</span> <span class="s2">&quot;auditory&amp;visual calculation vs sentences&quot;</span>
<span class="o">-</span> <span class="s2">&quot;auditory processing&quot;</span>
<span class="o">-</span> <span class="s2">&quot;visual processing&quot;</span>
<span class="o">-</span> <span class="s2">&quot;visual processing vs auditory processing&quot;</span>
<span class="o">-</span> <span class="s2">&quot;auditory processing vs visual processing&quot;</span>
<span class="o">-</span> <span class="s2">&quot;visual processing vs checkerboard&quot;</span>
<span class="o">-</span> <span class="s2">&quot;cognitive processing vs motor&quot;</span>
<span class="o">-</span> <span class="s2">&quot;left auditory click&quot;</span>
<span class="o">-</span> <span class="s2">&quot;left visual click&quot;</span>
<span class="o">-</span> <span class="s2">&quot;left auditory&amp;visual click&quot;</span>
<span class="o">-</span> <span class="s2">&quot;left auditory &amp; visual click vs right auditory&amp;visual click&quot;</span>
<span class="o">-</span> <span class="s2">&quot;right auditory click&quot;</span>
<span class="o">-</span> <span class="s2">&quot;right visual click&quot;</span>
<span class="o">-</span> <span class="s2">&quot;right auditory&amp;visual click&quot;</span>
<span class="o">-</span> <span class="s2">&quot;right auditory &amp; visual click vs left auditory&amp;visual click&quot;</span>
<span class="o">-</span> <span class="s2">&quot;auditory click vs auditory sentences&quot;</span>
<span class="o">-</span> <span class="s2">&quot;visual click vs visual sentences&quot;</span>
<span class="o">-</span> <span class="s2">&quot;auditory&amp;visual motor vs cognitive processing&quot;</span>
</pre></div>
</div>
</dd>
<dt><strong>n_subjects</strong><span class="classifier">int or list, optional</span></dt><dd><p>The number or list of subjects to load. If None is given,
all 94 subjects are used.</p>
</dd>
<dt><strong>get_tmaps</strong><span class="classifier">boolean, optional</span></dt><dd><p>Whether t maps should be fetched or not. Default=False.</p>
</dd>
<dt><strong>get_masks</strong><span class="classifier">boolean, optional</span></dt><dd><p>Whether individual masks should be fetched or not.
Default=False.</p>
</dd>
<dt><strong>get_anats</strong><span class="classifier">boolean, optional</span></dt><dd><p>Whether individual structural images should be fetched or not.
Default=False.</p>
</dd>
<dt><strong>data_dir</strong><span class="classifier">string, optional</span></dt><dd><p>Path of the data directory. Used to force data storage in a specified
location.</p>
</dd>
<dt><strong>url</strong><span class="classifier">string, optional</span></dt><dd><p>Override download URL. Used for test only (or if you setup a mirror of
the data).</p>
</dd>
<dt><strong>resume</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to resume download of a partly-downloaded file. Default=True.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">int, optional</span></dt><dd><p>Verbosity level (0 means no message). Default=1.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>data</strong><span class="classifier">Bunch</span></dt><dd><p>Dictionary-like object, the interest attributes are :</p>
<ul class="simple">
<li><dl class="simple">
<dt>âcmapsâ: string list</dt><dd><p>Paths to nifti contrast maps</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>âtmapsâ string list (if âget_tmapsâ set to True)</dt><dd><p>Paths to nifti t maps</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>âmasksâ: string list</dt><dd><p>Paths to nifti files corresponding to the subjects individual masks</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>âanatsâ: string</dt><dd><p>Path to nifti files corresponding to the subjects structural images</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="nilearn.datasets.fetch_localizer_calculation_task.html#nilearn.datasets.fetch_localizer_calculation_task" title="nilearn.datasets.fetch_localizer_calculation_task"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.datasets.fetch_localizer_calculation_task</span></code></a></dt><dd></dd>
<dt><a class="reference internal" href="nilearn.datasets.fetch_localizer_button_task.html#nilearn.datasets.fetch_localizer_button_task" title="nilearn.datasets.fetch_localizer_button_task"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nilearn.datasets.fetch_localizer_button_task</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">References</p>
<p><dl class="footnote brackets">
<dt class="label" id="papadopoulosorfanos2017309"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Dimitri Papadopoulos Orfanos, Vincent Michel, Yannick Schwartz, Philippe Pinel, Antonio Moreno, Denis Le Bihan, and Vincent Frouin. The brainomics/localizer database. <em>NeuroImage</em>, 144:309â314, 2017. Data Sharing Part II. URL: <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S1053811915008745">https://www.sciencedirect.com/science/article/pii/S1053811915008745</a>, <a class="reference external" href="https://doi.org/https://doi.org/10.1016/j.neuroimage.2015.09.052">doi:https://doi.org/10.1016/j.neuroimage.2015.09.052</a>.</p>
</dd>
<dt class="label" id="pinel2007fast"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Philippe Pinel, Bertrand Thirion, SÃ©bastien Meriaux, Antoinette Jobert, Julien Serres, Denis LeÂ Bihan, Jean-Baptiste Poline, and Stanislas Dehaene. Fast reproducible identification and large-scale databasing of individual functional cognitive networks. <em>BMC Neuroscience</em>, 2007.</p>
</dd>
</dl>
</p>
</dd></dl>

<div class="section" id="examples-using-nilearn-datasets-fetch-localizer-contrasts">
<h2><span class="section-number">8.2.22.1. </span>Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.datasets.fetch_localizer_contrasts</span></code><a class="headerlink" href="#examples-using-nilearn-datasets-fetch-localizer-contrasts" title="Permalink to this headline">Â¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="This script showcases the so-called &quot;All resolution inference&quot; procedure, in which the proporti..."><div class="figure align-default" id="id3">
<img alt="Second-level fMRI model: true positive proportion in clusters" src="../../_images/sphx_glr_plot_proportion_activated_voxels_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_proportion_activated_voxels.html#sphx-glr-auto-examples-05-glm-second-level-plot-proportion-activated-voxels-py"><span class="std std-ref">Second-level fMRI model: true positive proportion in clusters</span></a></span><a class="headerlink" href="#id3" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Full step-by-step example of fitting a GLM to perform a second level analysis in experimental d..."><div class="figure align-default" id="id4">
<img alt="Second-level fMRI model: two-sample test, unpaired and paired" src="../../_images/sphx_glr_plot_second_level_two_sample_test_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_second_level_two_sample_test.html#sphx-glr-auto-examples-05-glm-second-level-plot-second-level-two-sample-test-py"><span class="std std-ref">Second-level fMRI model: two-sample test, unpaired and paired</span></a></span><a class="headerlink" href="#id4" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Full step-by-step example of fitting a GLM to perform a second-level analysis (one-sample test)..."><div class="figure align-default" id="id5">
<img alt="Second-level fMRI model: one sample test" src="../../_images/sphx_glr_plot_second_level_one_sample_test_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html#sphx-glr-auto-examples-05-glm-second-level-plot-second-level-one-sample-test-py"><span class="std std-ref">Second-level fMRI model: one sample test</span></a></span><a class="headerlink" href="#id5" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows the results obtained in a group analysis using a more complex contrast than ..."><div class="figure align-default" id="id6">
<img alt="Example of generic design in second-level models" src="../../_images/sphx_glr_plot_second_level_association_test_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/05_glm_second_level/plot_second_level_association_test.html#sphx-glr-auto-examples-05-glm-second-level-plot-second-level-association-test-py"><span class="std std-ref">Example of generic design in second-level models</span></a></span><a class="headerlink" href="#id6" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows the results obtained in a massively univariate analysis performed at the int..."><div class="figure align-default" id="id7">
<img alt="Massively univariate analysis of a motor task from the Localizer dataset" src="../../_images/sphx_glr_plot_localizer_mass_univariate_methods_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/07_advanced/plot_localizer_mass_univariate_methods.html#sphx-glr-auto-examples-07-advanced-plot-localizer-mass-univariate-methods-py"><span class="std std-ref">Massively univariate analysis of a motor task from the Localizer dataset</span></a></span><a class="headerlink" href="#id7" title="Permalink to this image">Â¶</a></p>
</div>
</div><div style='clear:both'></div></div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">8.2.22. nilearn.datasets.fetch_localizer_contrasts</a><ul>
<li><a class="reference internal" href="#examples-using-nilearn-datasets-fetch-localizer-contrasts">8.2.22.1. Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.datasets.fetch_localizer_contrasts</span></code></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="nilearn.datasets.fetch_localizer_button_task.html"
                        title="previous chapter"><span class="section-number">8.2.21. </span>nilearn.datasets.fetch_localizer_button_task</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="nilearn.datasets.fetch_localizer_calculation_task.html"
                        title="next chapter"><span class="section-number">8.2.23. </span>nilearn.datasets.fetch_localizer_calculation_task</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
            &copy; The nilearn developers 2010-2021.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 4.0.2.
        <span style="padding-left: 5ex;">
          <a href="../../_sources/modules/generated/nilearn.datasets.fetch_localizer_contrasts.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>