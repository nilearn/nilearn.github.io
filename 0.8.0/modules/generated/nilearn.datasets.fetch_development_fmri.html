
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nilearn: Statistical Analysis for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/nature.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="8.2.18. nilearn.datasets.fetch_haxby" href="nilearn.datasets.fetch_haxby.html" />
    <link rel="prev" title="8.2.16. nilearn.datasets.fetch_adhd" href="nilearn.datasets.fetch_adhd.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">


<script type="text/javascript">
function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});
</script>
<script type="text/javascript">
function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../../index.html">
      <img src="../../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../../manipulating_images/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Statistics for NeuroImaging in Python</h2>
  </div>
  <div class="search_form">
    <div class="gcse-search" id="cse" style="width: 100%;"></div>
    <script>
      (function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </div>
</div>



<div class=related-wrapper>
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="nilearn.datasets.fetch_haxby.html" title="8.2.18. nilearn.datasets.fetch_haxby"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="nilearn.datasets.fetch_adhd.html" title="8.2.16. nilearn.datasets.fetch_adhd"
             accesskey="P">previous</a> |</li>
<li><a href="../../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li><a href="../../glossary.html">Glossary</a>|&nbsp;</li>
<li><a href="../../bibliography.html">Bibliography</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../reference.html" accesskey="U"><span class="section-number">8. </span>Reference documentation: all nilearn functions</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Nilearn: Statistical Analysis for NeuroImaging in Python</a></li> 
      </ul>
    </div>
</div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page is a reference documentation. It only explains the
function signature, and not how to use it. Please refer to the
<a class="reference internal" href="../../user_guide.html#user-guide"><span class="std std-ref">user guide</span></a> for the big picture.</p>
</div>
<div class="section" id="nilearn-datasets-fetch-development-fmri">
<h1><span class="section-number">8.2.17. </span>nilearn.datasets.fetch_development_fmri<a class="headerlink" href="#nilearn-datasets-fetch-development-fmri" title="Permalink to this headline">Â¶</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="nilearn.datasets.fetch_development_fmri">
<span class="sig-prename descclassname"><span class="pre">nilearn.datasets.</span></span><span class="sig-name descname"><span class="pre">fetch_development_fmri</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_subjects</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_confounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">resume</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">age_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'both'</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/297b1509/nilearn/datasets/func.py#L1755"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.datasets.fetch_development_fmri" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Fetch movie watching based brain development dataset (fMRI)</p>
<p>The data is downsampled to 4mm resolution for convenience with a repetition time (TR)
of 2 secs. The origin of the data is coming from OpenNeuro. See Notes below.</p>
<p>Please cite <a class="footnote-reference brackets" href="#richardson2018development" id="id1">1</a>
if you are using this dataset.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.5.2.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>n_subjects</strong><span class="classifier">int, optional</span></dt><dd><p>The number of subjects to load. If None, all the subjects are
loaded. Total 155 subjects.</p>
</dd>
<dt><strong>reduce_confounds</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, the returned confounds only include 6 motion parameters,
mean framewise displacement, signal from white matter, csf, and
6 anatomical compcor parameters. This selection only serves the
purpose of having realistic examples. Depending on your research
question, other confounds might be more appropriate.
If False, returns all fmriprep confounds.
Default=True.</p>
</dd>
<dt><strong>data_dir</strong><span class="classifier">str, optional</span></dt><dd><p>Path of the data directory. Used to force data storage in a specified
location. If None, data are stored in home directory.</p>
</dd>
<dt><strong>resume</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to resume download of a partly-downloaded file.
Default=True.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">int, optional</span></dt><dd><p>Defines the level of verbosity of the output. Default=1.</p>
</dd>
<dt><strong>age_group</strong><span class="classifier">str, optional</span></dt><dd><p>Default=âbothâ. Which age group to fetch</p>
<ul class="simple">
<li><p>âadultsâ = fetch adults only (n=33, ages 18-39)</p></li>
<li><p>âchildâ = fetch children only (n=122, ages 3-12)</p></li>
<li><p>âbothâ = fetch full sample (n=155)</p></li>
</ul>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>data</strong><span class="classifier">Bunch</span></dt><dd><p>Dictionary-like object, the interest attributes are :</p>
<ul class="simple">
<li><dl class="simple">
<dt>âfuncâ: list of str (Nifti files)</dt><dd><p>Paths to downsampled functional MRI data (4D) for each subject.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>âconfoundsâ: list of str (tsv files)</dt><dd><p>Paths to confounds related to each subject.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>âphenotypicâ: numpy.ndarray</dt><dd><p>Contains each subject age, age group, child or adult, gender,
handedness.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The original data is downloaded from OpenNeuro
<a class="reference external" href="https://openneuro.org/datasets/ds000228/versions/1.0.0">https://openneuro.org/datasets/ds000228/versions/1.0.0</a></p>
<p>This fetcher downloads downsampled data that are available on Open
Science Framework (OSF). Located here: <a class="reference external" href="https://osf.io/5hju4/files/">https://osf.io/5hju4/files/</a></p>
<p>Preprocessing details: <a class="reference external" href="https://osf.io/wjtyq/">https://osf.io/wjtyq/</a></p>
<p>Note that if n_subjects &gt; 2, and age_group is âbothâ,
fetcher will return a ratio of children and adults representative
of the total sample.</p>
<p class="rubric">References</p>
<p><dl class="footnote brackets">
<dt class="label" id="richardson2018development"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Hilary Richardson, Grace Lisandrelli, Alexa Riobueno-Naylor, and Rebecca Saxe. Development of the social brain from age three to twelve years. <em>Nature communications</em>, 9(1):1â12, 2018.</p>
</dd>
</dl>
</p>
</dd></dl>

<div class="section" id="examples-using-nilearn-datasets-fetch-development-fmri">
<h2><span class="section-number">8.2.17.1. </span>Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.datasets.fetch_development_fmri</span></code><a class="headerlink" href="#examples-using-nilearn-datasets-fetch-development-fmri" title="Permalink to this headline">Â¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="This example extracts the signal on regions defined via a probabilistic atlas, to construct a f..."><div class="figure align-default" id="id2">
<img alt="Extracting signals of a probabilistic atlas of functional regions" src="../../_images/sphx_glr_plot_probabilistic_atlas_extraction_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_probabilistic_atlas_extraction.html#sphx-glr-auto-examples-03-connectivity-plot-probabilistic-atlas-extraction-py"><span class="std std-ref">Extracting signals of a probabilistic atlas of functional regions</span></a></span><a class="headerlink" href="#id2" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we show how to extract signals from a brain parcellation and compute a correlation matrix."><div class="figure align-default" id="id3">
<img alt="Extracting signals from a brain parcellation" src="../../_images/sphx_glr_plot_signal_extraction_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_signal_extraction.html#sphx-glr-auto-examples-03-connectivity-plot-signal-extraction-py"><span class="std std-ref">Extracting signals from a brain parcellation</span></a></span><a class="headerlink" href="#id3" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example constructs a functional connectome using the sparse inverse covariance."><div class="figure align-default" id="id4">
<img alt="Computing a connectome with sparse inverse covariance" src="../../_images/sphx_glr_plot_inverse_covariance_connectome_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_inverse_covariance_connectome.html#sphx-glr-auto-examples-03-connectivity-plot-inverse-covariance-connectome-py"><span class="std std-ref">Computing a connectome with sparse inverse covariance</span></a></span><a class="headerlink" href="#id4" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Various approaches exist to derive spatial maps or networks from group fmr data. The methods ex..."><div class="figure align-default" id="id5">
<img alt="Deriving spatial maps from group fMRI data using ICA and Dictionary Learning" src="../../_images/sphx_glr_plot_compare_decomposition_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_compare_decomposition.html#sphx-glr-auto-examples-03-connectivity-plot-compare-decomposition-py"><span class="std std-ref">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</span></a></span><a class="headerlink" href="#id5" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to produce seed-to-voxel correlation maps for a single subject based on ..."><div class="figure align-default" id="id6">
<img alt="Producing single subject maps of seed-to-voxel correlation" src="../../_images/sphx_glr_plot_seed_to_voxel_correlation_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html#sphx-glr-auto-examples-03-connectivity-plot-seed-to-voxel-correlation-py"><span class="std std-ref">Producing single subject maps of seed-to-voxel correlation</span></a></span><a class="headerlink" href="#id6" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to estimate a connectome on a group of subjects using the group sparse i..."><div class="figure align-default" id="id7">
<img alt="Group Sparse inverse covariance for multi-subject connectome" src="../../_images/sphx_glr_plot_multi_subject_connectome_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_multi_subject_connectome.html#sphx-glr-auto-examples-03-connectivity-plot-multi-subject-connectome-py"><span class="std std-ref">Group Sparse inverse covariance for multi-subject connectome</span></a></span><a class="headerlink" href="#id7" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This examples shows how to turn a parcellation into connectome for visualization. This requires..."><div class="figure align-default" id="id8">
<img alt="Comparing connectomes on different reference atlases" src="../../_images/sphx_glr_plot_atlas_comparison_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_atlas_comparison.html#sphx-glr-auto-examples-03-connectivity-plot-atlas-comparison-py"><span class="std std-ref">Comparing connectomes on different reference atlases</span></a></span><a class="headerlink" href="#id8" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example compares different kinds of functional connectivity between regions of interest : ..."><div class="figure align-default" id="id9">
<img alt="Classification of age groups using functional connectivity" src="../../_images/sphx_glr_plot_group_level_connectivity_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_group_level_connectivity.html#sphx-glr-auto-examples-03-connectivity-plot-group-level-connectivity-py"><span class="std std-ref">Classification of age groups using functional connectivity</span></a></span><a class="headerlink" href="#id9" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to use nilearn.regions.RegionExtractor to extract spatially constrained ..."><div class="figure align-default" id="id10">
<img alt="Regions extraction using Dictionary Learning and functional connectomes" src="../../_images/sphx_glr_plot_extract_regions_dictlearning_maps_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html#sphx-glr-auto-examples-03-connectivity-plot-extract-regions-dictlearning-maps-py"><span class="std std-ref">Regions extraction using Dictionary Learning and functional connectomes</span></a></span><a class="headerlink" href="#id10" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="We use spatially-constrained Ward-clustering, KMeans, and Recursive Neighbor Agglomeration (ReN..."><div class="figure align-default" id="id11">
<img alt="Clustering methods to learn a brain parcellation from fMRI" src="../../_images/sphx_glr_plot_data_driven_parcellations_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_data_driven_parcellations.html#sphx-glr-auto-examples-03-connectivity-plot-data-driven-parcellations-py"><span class="std std-ref">Clustering methods to learn a brain parcellation from fMRI</span></a></span><a class="headerlink" href="#id11" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows how to extract signals from spherical regions. We show how to build spheres ..."><div class="figure align-default" id="id12">
<img alt="Extract signals on spheres and plot a connectome" src="../../_images/sphx_glr_plot_sphere_based_connectome_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/03_connectivity/plot_sphere_based_connectome.html#sphx-glr-auto-examples-03-connectivity-plot-sphere-based-connectome-py"><span class="std std-ref">Extract signals on spheres and plot a connectome</span></a></span><a class="headerlink" href="#id12" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The goal of this example is to illustrate the use of the function nilearn.image.math_img with a..."><div class="figure align-default" id="id13">
<img alt="Comparing the means of 2 images" src="../../_images/sphx_glr_plot_compare_mean_image_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_compare_mean_image.html#sphx-glr-auto-examples-06-manipulating-images-plot-compare-mean-image-py"><span class="std std-ref">Comparing the means of 2 images</span></a></span><a class="headerlink" href="#id13" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we smooth a mean EPI image and plot the result"><div class="figure align-default" id="id14">
<img alt="Smoothing an image" src="../../_images/sphx_glr_plot_smooth_mean_image_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_smooth_mean_image.html#sphx-glr-auto-examples-06-manipulating-images-plot-smooth-mean-image-py"><span class="std std-ref">Smoothing an image</span></a></span><a class="headerlink" href="#id14" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here is a simple example of automatic mask computation using the nifti masker. The mask is comp..."><div class="figure align-default" id="id15">
<img alt="Simple example of NiftiMasker use" src="../../_images/sphx_glr_plot_nifti_simple_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_nifti_simple.html#sphx-glr-auto-examples-06-manipulating-images-plot-nifti-simple-py"><span class="std std-ref">Simple example of NiftiMasker use</span></a></span><a class="headerlink" href="#id15" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This simple example shows how to extract signals from functional fmri data and brain regions de..."><div class="figure align-default" id="id16">
<img alt="Extracting signals from brain regions using the NiftiLabelsMasker" src="../../_images/sphx_glr_plot_nifti_labels_simple_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_nifti_labels_simple.html#sphx-glr-auto-examples-06-manipulating-images-plot-nifti-labels-simple-py"><span class="std std-ref">Extracting signals from brain regions using the NiftiLabelsMasker</span></a></span><a class="headerlink" href="#id16" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this example, the Nifti masker is used to automatically compute a mask."><div class="figure align-default" id="id17">
<img alt="Understanding NiftiMasker and mask computation" src="../../_images/sphx_glr_plot_mask_computation_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/06_manipulating_images/plot_mask_computation.html#sphx-glr-auto-examples-06-manipulating-images-plot-mask-computation-py"><span class="std std-ref">Understanding NiftiMasker and mask computation</span></a></span><a class="headerlink" href="#id17" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip=" This example is meant to demonstrate nilearn as a low-level tools used to combine feature extr..."><div class="figure align-default" id="id18">
<img alt="Multivariate decompositions: Independent component analysis of fMRI" src="../../_images/sphx_glr_plot_ica_resting_state_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/07_advanced/plot_ica_resting_state.html#sphx-glr-auto-examples-07-advanced-plot-ica-resting-state-py"><span class="std std-ref">Multivariate decompositions: Independent component analysis of fMRI</span></a></span><a class="headerlink" href="#id18" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example compares different kinds of functional connectivity between regions of interest : ..."><div class="figure align-default" id="id19">
<img alt="Functional connectivity predicts age group" src="../../_images/sphx_glr_plot_age_group_prediction_cross_val_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/07_advanced/plot_age_group_prediction_cross_val.html#sphx-glr-auto-examples-07-advanced-plot-age-group-prediction-cross-val-py"><span class="std std-ref">Functional connectivity predicts age group</span></a></span><a class="headerlink" href="#id19" title="Permalink to this image">Â¶</a></p>
</div>
</div><div style='clear:both'></div></div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">8.2.17. nilearn.datasets.fetch_development_fmri</a><ul>
<li><a class="reference internal" href="#examples-using-nilearn-datasets-fetch-development-fmri">8.2.17.1. Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.datasets.fetch_development_fmri</span></code></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="nilearn.datasets.fetch_adhd.html"
                        title="previous chapter"><span class="section-number">8.2.16. </span>nilearn.datasets.fetch_adhd</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="nilearn.datasets.fetch_haxby.html"
                        title="next chapter"><span class="section-number">8.2.18. </span>nilearn.datasets.fetch_haxby</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
            &copy; The nilearn developers 2010-2021.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 4.0.2.
        <span style="padding-left: 5ex;">
          <a href="../../_sources/modules/generated/nilearn.datasets.fetch_development_fmri.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>