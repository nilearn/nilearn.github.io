
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nilearn: Statistical Analysis for NeuroImaging in Python &#8212; Machine learning for NeuroImaging</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/nature.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="8.12.15.2. nilearn.glm.first_level.check_design_matrix" href="nilearn.glm.first_level.check_design_matrix.html" />
    <link rel="prev" title="8.12.14. nilearn.glm.threshold_stats_img" href="nilearn.glm.threshold_stats_img.html" />
<meta content="True" name="HandheldFriendly">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
<meta name="keywords" content="nilearn, neuroimaging, python, neuroscience, machinelearning">


<script type="text/javascript">
function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});
</script>
<script type="text/javascript">
function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});
</script>


<script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
    </script>

  </head><body>
<div id="logo-banner">
  <div class="logo">
    <a href="../../index.html">
      <img src="../../_static/nilearn-logo.png" alt="Nilearn logo"  border="0" />
    </a>
  </div>
  <!-- A tag cloud to make it easy for people to find what they are
                         looking for -->
 <div class="tags">
  <ul>
    <li>
      <big><a href="../../auto_examples/decoding/plot_haxby_anova_svm.html">SVM</a></big>
    </li>
    <li>
      <small><a href="../../connectivity/parcellating.html">Ward
          clustering</a></small>
    </li>
    <li>
      <a href="../../decoding/searchlight.html">Searchlight</a>
    </li>
    <li>
      <big><a href="../../connectivity/resting_state_networks.html">ICA</a></big>
    </li>
    <li>
      <a href="../../manipulating_images/data_preparation.html">Nifti IO</a>
    </li>
    <li>
      <a href="../reference.html#module-nilearn.datasets">Datasets</a>
    </li>
  </ul>
 </div>

  <div class="banner">
    <h1>Nilearn:</h1>
    <h2>Statistics for NeuroImaging in Python</h2>
  </div>
  <div class="search_form">
    <div class="gcse-search" id="cse" style="width: 100%;"></div>
    <script>
      (function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </div>
</div>



<div class=related-wrapper>
    
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a></li>
        <li class="right" >
          <a href="nilearn.glm.first_level.check_design_matrix.html" title="8.12.15.2. nilearn.glm.first_level.check_design_matrix"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="nilearn.glm.threshold_stats_img.html" title="8.12.14. nilearn.glm.threshold_stats_img"
             accesskey="P">previous</a> |</li>
<li><a href="../../index.html">Nilearn Home</a> |&nbsp;</li>
<li><a href="../../user_guide.html">User Guide</a> |&nbsp;</li>
<li><a href="../../auto_examples/index.html">Examples</a> |&nbsp;</li>
<li><a href="../reference.html">Reference</a> |&nbsp;</li>
<li id="navbar-about"><a href="../../authors.html">About</a>|&nbsp;</li>
<li><a href="../../glossary.html">Glossary</a>|&nbsp;</li>
<li><a href="../../bibliography.html">Bibliography</a>|&nbsp;</li>
<li id="navbar-ecosystem"><a href="http://www.nipy.org/">Nipy ecosystem</a></li>

          <li class="nav-item nav-item-1"><a href="../../user_guide.html" >User guide: table of contents</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../reference.html" accesskey="U"><span class="section-number">8. </span>Reference documentation: all nilearn functions</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Nilearn: Statistical Analysis for NeuroImaging in Python</a></li> 
      </ul>
    </div>
</div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page is a reference documentation. It only explains the class
signature, and not how to use it. Please refer to the
<a class="reference internal" href="../../user_guide.html#user-guide"><span class="std std-ref">user guide</span></a> for the big picture.</p>
</div>
<div class="section" id="nilearn-glm-first-level-firstlevelmodel">
<h1><span class="section-number">8.12.15.1. </span>nilearn.glm.first_level.FirstLevelModel<a class="headerlink" href="#nilearn-glm-first-level-firstlevelmodel" title="Permalink to this headline">Â¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="nilearn.glm.first_level.FirstLevelModel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">nilearn.glm.first_level.</span></span><span class="sig-name descname"><span class="pre">FirstLevelModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t_r</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slice_time_ref</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hrf_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'glover'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drift_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cosine'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high_pass</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drift_order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fir_delays</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_onset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">24</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_img</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_affine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smoothing_fwhm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Memory(location=None)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">standardize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">signal_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ar1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minimize_memory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subject_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/297b1509/nilearn/glm/first_level/first_level.py#L220"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.glm.first_level.FirstLevelModel" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Implementation of the General Linear Model
for single session fMRI data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>t_r</strong><span class="classifier">float</span></dt><dd><p>This parameter indicates repetition times of the experimental runs.
In seconds. It is necessary to correctly consider times in the design
matrix. This parameter is also passed to nilearn.signal.clean.
Please see the related documentation for details.</p>
</dd>
<dt><strong>slice_time_ref</strong><span class="classifier">float, optional</span></dt><dd><p>This parameter indicates the time of the reference slice used in the
slice timing preprocessing step of the experimental runs. It is
expressed as a percentage of the t_r (time repetition), so it can have
values between 0. and 1. Default=0.</p>
</dd>
<dt><strong>hrf_model</strong><span class="classifier">{âgloverâ, âspmâ, âspm + derivativeâ, âspm + derivative + dispersionâ,</span></dt><dd><p>âglover + derivativeâ, âglover + derivative + dispersionâ, âfirâ, None}, optional
String that specifies the hemodynamic response function.
Default=âgloverâ.</p>
</dd>
<dt><strong>drift_model</strong><span class="classifier">string, optional</span></dt><dd><p>This parameter specifies the desired drift model for the design
matrices. It can be âpolynomialâ, âcosineâ or None.
Default=âcosineâ.</p>
</dd>
<dt><strong>high_pass</strong><span class="classifier">float, optional</span></dt><dd><p>This parameter specifies the cut frequency of the high-pass filter in
Hz for the design matrices. Used only if drift_model is âcosineâ.
Default=0.01.</p>
</dd>
<dt><strong>drift_order</strong><span class="classifier">int, optional</span></dt><dd><p>This parameter specifices the order of the drift model (in case it is
polynomial) for the design matrices. Default=1.</p>
</dd>
<dt><strong>fir_delays</strong><span class="classifier">array of shape(n_onsets) or list, optional</span></dt><dd><p>In case of FIR design, yields the array of delays used in the FIR
model, in scans. Default=[0].</p>
</dd>
<dt><strong>min_onset</strong><span class="classifier">float, optional</span></dt><dd><p>This parameter specifies the minimal onset relative to the design
(in seconds). Events that start before (slice_time_ref * t_r +
min_onset) are not considered. Default=-24.</p>
</dd>
<dt><strong>mask_img</strong><span class="classifier">Niimg-like, NiftiMasker object or False, optional</span></dt><dd><p>Mask to be used on data. If an instance of masker is passed,
then its mask will be used. If no mask is given,
it will be computed automatically by a NiftiMasker with default
parameters. If False is given then the data will not be masked.</p>
</dd>
<dt><strong>target_affine</strong><span class="classifier">3x3 or 4x4 matrix, optional</span></dt><dd><p>This parameter is passed to nilearn.image.resample_img.
Please see the related documentation for details.</p>
</dd>
<dt><strong>target_shape</strong><span class="classifier">3-tuple of integers, optional</span></dt><dd><p>This parameter is passed to nilearn.image.resample_img.
Please see the related documentation for details.</p>
</dd>
<dt><strong>smoothing_fwhm</strong><span class="classifier">float, optional</span></dt><dd><p>If smoothing_fwhm is not None, it gives the size in millimeters of
the spatial smoothing to apply to the signal.</p>
</dd>
<dt><strong>memory</strong><span class="classifier">string, optional</span></dt><dd><p>Path to the directory used to cache the masking process and the glm
fit. By default, no caching is done.
Creates instance of joblib.Memory.</p>
</dd>
<dt><strong>memory_level</strong><span class="classifier">integer, optional</span></dt><dd><p>Rough estimator of the amount of memory used by caching. Higher value
means more memory for caching.</p>
</dd>
<dt><strong>standardize</strong><span class="classifier">boolean, optional</span></dt><dd><p>If standardize is True, the time-series are centered and normed:
their variance is put to 1 in the time dimension. Default=False.</p>
</dd>
<dt><strong>signal_scaling</strong><span class="classifier">False, int or (int, int), optional</span></dt><dd><p>If not False, fMRI signals are
scaled to the mean value of scaling_axis given,
which can be 0, 1 or (0, 1).
0 refers to mean scaling each voxel with respect to time,
1 refers to mean scaling each time point with respect to all voxels &amp;
(0, 1) refers to scaling with respect to voxels and time,
which is known as grand mean scaling.
Incompatible with standardize (standardize=False is enforced when
signal_scaling is not False).
Default=0.</p>
</dd>
<dt><strong>noise_model</strong><span class="classifier">{âar1â, âolsâ}, optional</span></dt><dd><p>The temporal variance model. Default=âar1â.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">integer, optional</span></dt><dd><p>Indicate the level of verbosity. By default, nothing is printed.
If 0 prints nothing. If 1 prints progress by computation of
each run. If 2 prints timing details of masker and GLM. If 3
prints masker computation details. Default=0.</p>
</dd>
<dt><strong>n_jobs</strong><span class="classifier">integer, optional</span></dt><dd><p>The number of CPUs to use to do the computation. -1 means
âall CPUsâ, -2 âall CPUs but oneâ, and so on.
Default=1.</p>
</dd>
<dt><strong>minimize_memory</strong><span class="classifier">boolean, optional</span></dt><dd><p>Gets rid of some variables on the model fit results that are not
necessary for contrast computation and would only be useful for
further inspection of model details. This has an important impact
on memory consumption. Default=True.</p>
</dd>
<dt><strong>subject_label</strong><span class="classifier">string, optional</span></dt><dd><p>This id will be used to identify a <cite>FirstLevelModel</cite> when passed to
a <cite>SecondLevelModel</cite> object.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This class is experimental.
It may change in any future release of Nilearn.</p>
<dl class="field-list simple">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>labels_</strong><span class="classifier">array of shape (n_voxels,),</span></dt><dd><p>a map of values on voxels used to identify the corresponding model</p>
</dd>
<dt><strong>results_</strong><span class="classifier">dict,</span></dt><dd><p>with keys corresponding to the different labels values.
Values are SimpleRegressionResults corresponding to the voxels,
if minimize_memory is True,
RegressionResults if minimize_memory is False</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.first_level.FirstLevelModel.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t_r</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slice_time_ref</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hrf_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'glover'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drift_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cosine'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high_pass</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drift_order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fir_delays</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_onset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">24</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_img</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_affine</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smoothing_fwhm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">Memory(location=None)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">standardize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">signal_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ar1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minimize_memory</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subject_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/297b1509/nilearn/glm/first_level/first_level.py#L350"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.glm.first_level.FirstLevelModel.__init__" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.first_level.FirstLevelModel.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">run_imgs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">events</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confounds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">design_matrices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bins</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/297b1509/nilearn/glm/first_level/first_level.py#L396"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.glm.first_level.FirstLevelModel.fit" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Fit the GLM</p>
<p>For each run:
1. create design matrix X
2. do a masker job: fMRI_data -&gt; Y
3. fit regression to (Y, X)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>run_imgs</strong><span class="classifier">Niimg-like object or list of Niimg-like objects,</span></dt><dd><p>Data on which the GLM will be fitted. If this is a list,
the affine is considered the same for all.</p>
</dd>
<dt><strong>events</strong><span class="classifier">pandas Dataframe or string or list of pandas DataFrames or strings, optional</span></dt><dd><p>fMRI events used to build design matrices. One events object
expected per run_img. Ignored in case designs is not None.
If string, then a path to a csv file is expected.</p>
</dd>
<dt><strong>confounds</strong><span class="classifier">pandas Dataframe, numpy array or string or</span></dt><dd><p>list of pandas DataFrames, numpy arays or strings, optional
Each column in a DataFrame corresponds to a confound variable
to be included in the regression model of the respective run_img.
The number of rows must match the number of volumes in the
respective run_img. Ignored in case designs is not None.
If string, then a path to a csv file is expected.</p>
</dd>
<dt><strong>design_matrices</strong><span class="classifier">pandas DataFrame or list of pandas DataFrames, optional</span></dt><dd><p>Design matrices that will be used to fit the GLM. If given it
takes precedence over events and confounds.</p>
</dd>
<dt><strong>bins</strong><span class="classifier">int, optional</span></dt><dd><p>Maximum number of discrete bins for the AR coef histogram.
If an autoregressive model with order greater than one is specified
then adaptive quantification is performed and the coefficients
will be clustered via K-means with <cite>bins</cite> number of clusters.
Default=100.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.first_level.FirstLevelModel.compute_contrast">
<span class="sig-name descname"><span class="pre">compute_contrast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">contrast_def</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stat_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'z_score'</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/297b1509/nilearn/glm/first_level/first_level.py#L603"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.glm.first_level.FirstLevelModel.compute_contrast" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Generate different outputs corresponding to
the contrasts provided e.g. z_map, t_map, effects and variance.
In multi-session case, outputs the fixed effects map.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>contrast_def</strong><span class="classifier">str or array of shape (n_col) or list of (string or</span></dt><dd><blockquote>
<div><p>array of shape (n_col))</p>
</div></blockquote>
<p>where <code class="docutils literal notranslate"><span class="pre">n_col</span></code> is the number of columns of the design matrix,
(one array per run). If only one array is provided when there
are several runs, it will be assumed that the same contrast is
desired for all runs. The string can be a formula compatible with
<cite>pandas.DataFrame.eval</cite>. Basically one can use the name of the
conditions as they appear in the design matrix of the fitted model
combined with operators +- and combined with numbers
with operators +-<cite>*</cite>/.</p>
</dd>
<dt><strong>stat_type</strong><span class="classifier">{âtâ, âFâ}, optional</span></dt><dd><p>type of the contrast</p>
</dd>
<dt><strong>output_type</strong><span class="classifier">str, optional</span></dt><dd><p>Type of the output map. Can be âz_scoreâ, âstatâ, âp_valueâ,
âeffect_sizeâ, âeffect_varianceâ or âallâ.
Default=âz-scoreâ.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>output</strong><span class="classifier">Nifti1Image or dict</span></dt><dd><p>The desired output image(s). If <code class="docutils literal notranslate"><span class="pre">output_type</span> <span class="pre">==</span> <span class="pre">'all'</span></code>, then
the output is a dictionary of images, keyed by the type of image.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.first_level.FirstLevelModel.residuals">
<span class="sig-name descname"><span class="pre">residuals</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/297b1509/nilearn/glm/first_level/first_level.py#L759"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.glm.first_level.FirstLevelModel.residuals" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Transform voxelwise residuals to the same shape
as the input Nifti1Image(s)</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>output</strong><span class="classifier">list</span></dt><dd><p>A list of Nifti1Image(s).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.first_level.FirstLevelModel.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">fit_params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.glm.first_level.FirstLevelModel.fit_transform" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to <cite>X</cite> and <cite>y</cite> with optional parameters <cite>fit_params</cite>
and returns a transformed version of <cite>X</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span></dt><dd><p>Input samples.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None</span></dt><dd><p>Target values (None for unsupervised transformations).</p>
</dd>
<dt><strong>**fit_params</strong><span class="classifier">dict</span></dt><dd><p>Additional fit parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X_new</strong><span class="classifier">ndarray array of shape (n_samples, n_features_new)</span></dt><dd><p>Transformed array.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.first_level.FirstLevelModel.generate_report">
<span class="sig-name descname"><span class="pre">generate_report</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">contrasts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bg_img</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'MNI152TEMPLATE'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3.09</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cluster_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">height_control</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'fpr'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_distance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plot_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'slice'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">display_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">report_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(1600,</span> <span class="pre">800)</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/297b1509/nilearn/glm/_base.py#L6"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.glm.first_level.FirstLevelModel.generate_report" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns HTMLDocument object
for a report which shows all important aspects of a fitted GLM.
The object can be opened in a browser, displayed in a notebook,
or saved to disk as a standalone HTML file.</p>
<p>The GLM must be fitted and have the computed design matrix(ces).</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>A fitted first or second level model object.</strong></dt><dd></dd>
<dt><strong>contrasts</strong><span class="classifier">Dict[string, ndarray] or String or List[String] or ndarray or</span></dt><dd><p>List[ndarray]</p>
<p>Contrasts information for a first or second level model.</p>
<p>Example:</p>
<blockquote>
<div><p>Dict of contrast names and coefficients,
or list of contrast names
or list of contrast coefficients
or contrast name
or contrast coefficient</p>
<p>Each contrast name must be a string.
Each contrast coefficient must be a list or numpy array of ints.</p>
</div></blockquote>
<p>Contrasts are passed to <code class="docutils literal notranslate"><span class="pre">contrast_def</span></code> for FirstLevelModel
(<a class="reference internal" href="#nilearn.glm.first_level.FirstLevelModel.compute_contrast" title="nilearn.glm.first_level.FirstLevelModel.compute_contrast"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.glm.first_level.FirstLevelModel.compute_contrast</span></code></a>)
&amp; second_level_contrast for SecondLevelModel
(<a class="reference internal" href="nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel.compute_contrast" title="nilearn.glm.second_level.SecondLevelModel.compute_contrast"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.glm.second_level.SecondLevelModel.compute_contrast</span></code></a>)</p>
</dd>
<dt><strong>title</strong><span class="classifier">String, optional</span></dt><dd><p>If string, represents the web pageâs title and primary heading,
model type is sub-heading.
If None, page titles and headings are autogenerated
using contrast names.</p>
</dd>
<dt><strong>bg_img</strong><span class="classifier">Niimg-like object, optional</span></dt><dd><p>Default is the MNI152 template (Default=âMNI152TEMPLATEâ)
See <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>
The background image for mask and stat maps to be plotted on upon.
To turn off background image, just pass âbg_img=Noneâ.</p>
</dd>
<dt><strong>threshold</strong><span class="classifier">float, optional</span></dt><dd><p>Cluster forming threshold in same scale as <cite>stat_img</cite> (either a
t-scale or z-scale value). Used only if height_control is None.
Default=3.09</p>
</dd>
<dt><strong>alpha</strong><span class="classifier">float, optional</span></dt><dd><p>Number controlling the thresholding (either a p-value or q-value).
Its actual meaning depends on the height_control parameter.
This function translates alpha to a z-scale threshold.
Default=0.001</p>
</dd>
<dt><strong>cluster_threshold</strong><span class="classifier">int, optional</span></dt><dd><p>Cluster size threshold, in voxels.
Default=0</p>
</dd>
<dt><strong>height_control</strong><span class="classifier">string or None, optional</span></dt><dd><p>false positive control meaning of cluster forming
threshold: âfprâ (default) or âfdrâ or âbonferroniâ or None
Default=âfprâ.</p>
</dd>
<dt><strong>min_distance</strong><span class="classifier">float, optional</span></dt><dd><p>For display purposes only.
Minimum distance between subpeaks in mm. Default=8mm.</p>
</dd>
<dt><strong>plot_type</strong><span class="classifier">String. [âsliceâ, âglassâ], optional</span></dt><dd><p>Specifies the type of plot to be drawn for the statistical maps.
Default=âsliceâ.</p>
</dd>
<dt><strong>display_mode</strong><span class="classifier">string, optional</span></dt><dd><p>Default is âzâ if plot_type is âsliceâ; â
orthoâ if plot_type is âglassâ.</p>
<p>Choose the direction of the cuts:
âxâ - sagittal, âyâ - coronal, âzâ - axial,
âlâ - sagittal left hemisphere only,
ârâ - sagittal right hemisphere only,
âorthoâ - three cuts are performed in orthogonal directions.</p>
<p>Possible values are:
âorthoâ, âxâ, âyâ, âzâ, âxzâ, âyxâ, âyzâ,
âlâ, ârâ, âlrâ, âlzrâ, âlyrâ, âlzryâ, âlyrzâ.</p>
</dd>
<dt><strong>report_dims</strong><span class="classifier">Sequence[int, int], optional</span></dt><dd><p>Default is (1600, 800) pixels.
Specifies width, height (in pixels) of report window within a notebook.
Only applicable when inserting the report into a Jupyter notebook.
Can be set after report creation using report.width, report.height.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>report_text</strong><span class="classifier">HTMLDocument Object</span></dt><dd><p>Contains the HTML code for the GLM Report.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.first_level.FirstLevelModel.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.glm.first_level.FirstLevelModel.get_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.first_level.FirstLevelModel.predicted">
<span class="sig-name descname"><span class="pre">predicted</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/297b1509/nilearn/glm/first_level/first_level.py#L773"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.glm.first_level.FirstLevelModel.predicted" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Transform voxelwise predicted values to the same shape
as the input Nifti1Image(s)</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>output</strong><span class="classifier">list</span></dt><dd><p>A list of Nifti1Image(s).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.first_level.FirstLevelModel.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#nilearn.glm.first_level.FirstLevelModel.set_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="(in scikit-learn v0.24)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>). The latter have
parameters of the form <code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that itâs
possible to update each component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Estimator parameters.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">estimator instance</span></dt><dd><p>Estimator instance.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="nilearn.glm.first_level.FirstLevelModel.r_square">
<span class="sig-name descname"><span class="pre">r_square</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/nilearn/nilearn/blob/297b1509/nilearn/glm/first_level/first_level.py#L787"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nilearn.glm.first_level.FirstLevelModel.r_square" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Transform voxelwise r-squared values to the same shape
as the input Nifti1Image(s)</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>output</strong><span class="classifier">list</span></dt><dd><p>A list of Nifti1Image(s).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="section" id="examples-using-nilearn-glm-first-level-firstlevelmodel">
<h2><span class="section-number">8.12.15.1.1. </span>Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.glm.first_level.FirstLevelModel</span></code><a class="headerlink" href="#examples-using-nilearn-glm-first-level-firstlevelmodel" title="Permalink to this headline">Â¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="In this tutorial, we use a General Linear Model (:term:`GLM`) to compare the fMRI signal during..."><div class="figure align-default" id="id1">
<img alt="Intro to GLM Analysis: a single-session, single-subject fMRI dataset" src="../../_images/sphx_glr_plot_single_subject_single_run_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/plot_single_subject_single_run.html#sphx-glr-auto-examples-plot-single-subject-single-run-py"><span class="std std-ref">Intro to GLM Analysis: a single-session, single-subject fMRI dataset</span></a></span><a class="headerlink" href="#id1" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Full step-by-step example of fitting a GLM to perform a decoding experiment. We use the data fr..."><div class="figure align-default" id="id2">
<img alt="Decoding of a dataset after GLM fit for signal extraction" src="../../_images/sphx_glr_plot_haxby_glm_decoding_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/02_decoding/plot_haxby_glm_decoding.html#sphx-glr-auto-examples-02-decoding-plot-haxby-glm-decoding-py"><span class="std std-ref">Decoding of a dataset after GLM fit for signal extraction</span></a></span><a class="headerlink" href="#id2" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to run a fixed effects model based on pre-computed statistics. Thi..."><div class="figure align-default" id="id3">
<img alt="Example of explicit fixed effects fMRI model fitting" src="../../_images/sphx_glr_plot_fixed_effects_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_fixed_effects.html#sphx-glr-auto-examples-04-glm-first-level-plot-fixed-effects-py"><span class="std std-ref">Example of explicit fixed effects fMRI model fitting</span></a></span><a class="headerlink" href="#id3" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows a full step-by-step workflow of fitting a GLM to data extracted from a seed ..."><div class="figure align-default" id="id4">
<img alt="Default Mode Network extraction of AHDH dataset" src="../../_images/sphx_glr_plot_adhd_dmn_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_adhd_dmn.html#sphx-glr-auto-examples-04-glm-first-level-plot-adhd-dmn-py"><span class="std std-ref">Default Mode Network extraction of AHDH dataset</span></a></span><a class="headerlink" href="#id4" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="FIR models are used to estimate the hemodyamic response non-parametrically. The example below s..."><div class="figure align-default" id="id5">
<img alt="Analysis of an fMRI dataset with a Finite Impule Response (FIR) model" src="../../_images/sphx_glr_plot_fir_model_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_fir_model.html#sphx-glr-auto-examples-04-glm-first-level-plot-fir-model-py"><span class="std std-ref">Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</span></a></span><a class="headerlink" href="#id5" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="The example shows the analysis of an SPM dataset studying face perception.  The anaylsis is per..."><div class="figure align-default" id="id6">
<img alt="Single-subject data (two sessions) in native space" src="../../_images/sphx_glr_plot_spm_multimodal_faces_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_spm_multimodal_faces.html#sphx-glr-auto-examples-04-glm-first-level-plot-spm-multimodal-faces-py"><span class="std std-ref">Single-subject data (two sessions) in native space</span></a></span><a class="headerlink" href="#id6" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here, we will go through a full step-by-step example of fitting a GLM to experimental data and ..."><div class="figure align-default" id="id7">
<img alt="Simple example of two-session fMRI model fitting" src="../../_images/sphx_glr_plot_fiac_analysis_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_fiac_analysis.html#sphx-glr-auto-examples-04-glm-first-level-plot-fiac-analysis-py"><span class="std std-ref">Simple example of two-session fMRI model fitting</span></a></span><a class="headerlink" href="#id7" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip=" Full step-by-step example of fitting a GLM to perform a first level analysis in an openneuro B..."><div class="figure align-default" id="id8">
<img alt="First level analysis of a complete BIDS dataset from openneuro" src="../../_images/sphx_glr_plot_bids_features_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_bids_features.html#sphx-glr-auto-examples-04-glm-first-level-plot-bids-features-py"><span class="std std-ref">First level analysis of a complete BIDS dataset from openneuro</span></a></span><a class="headerlink" href="#id8" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="Here we fit a First Level GLM with the minimize_memory-argument set to False. By doing so, the ..."><div class="figure align-default" id="id9">
<img alt="Predicted time series and residuals" src="../../_images/sphx_glr_plot_predictions_residuals_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_predictions_residuals.html#sphx-glr-auto-examples-04-glm-first-level-plot-predictions-residuals-py"><span class="std std-ref">Predicted time series and residuals</span></a></span><a class="headerlink" href="#id9" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="In this tutorial, we study how first-level models are parametrized for fMRI data analysis and c..."><div class="figure align-default" id="id10">
<img alt="Understanding parameters of the first-level model" src="../../_images/sphx_glr_plot_first_level_details_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/04_glm_first_level/plot_first_level_details.html#sphx-glr-auto-examples-04-glm-first-level-plot-first-level-details-py"><span class="std std-ref">Understanding parameters of the first-level model</span></a></span><a class="headerlink" href="#id10" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip=" Full step-by-step example of fitting a GLM to perform a first and second level analysis in a B..."><div class="figure align-default" id="id11">
<img alt="BIDS dataset first and second level analysis" src="../../_images/sphx_glr_plot_bids_analysis_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/07_advanced/plot_bids_analysis.html#sphx-glr-auto-examples-07-advanced-plot-bids-analysis-py"><span class="std std-ref">BIDS dataset first and second level analysis</span></a></span><a class="headerlink" href="#id11" title="Permalink to this image">Â¶</a></p>
</div>
</div><div style='clear:both'></div></div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">


<h4> Giving credit </h4>
  <ul class="simple">
    <li><p>Please consider <a href="../../authors.html#citing">citing the
                    papers</a>.</p></li>
  </ul>

  <h3><a href="../../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">8.12.15.1. nilearn.glm.first_level.FirstLevelModel</a><ul>
<li><a class="reference internal" href="#examples-using-nilearn-glm-first-level-firstlevelmodel">8.12.15.1.1. Examples using <code class="docutils literal notranslate"><span class="pre">nilearn.glm.first_level.FirstLevelModel</span></code></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="nilearn.glm.threshold_stats_img.html"
                        title="previous chapter"><span class="section-number">8.12.14. </span>nilearn.glm.threshold_stats_img</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="nilearn.glm.first_level.check_design_matrix.html"
                        title="next chapter"><span class="section-number">8.12.15.2. </span>nilearn.glm.first_level.check_design_matrix</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
            &copy; The nilearn developers 2010-2021.
          Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 4.0.2.
        <span style="padding-left: 5ex;">
          <a href="../../_sources/modules/generated/nilearn.glm.first_level.FirstLevelModel.rst.txt"
        	 rel="nofollow">Show this page source</a>
        </span>
    </div>
  </body>
</html>