{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Single-subject data (two runs) in native space\n\nThe example shows the analysis of an :term:`SPM` dataset\nstudying face perception.\nThe analysis is performed in native space.\nRealignment parameters are provided with the input images,\nbut those have not been resampled to a common space.\n\nThe experimental paradigm is simple, with two conditions; viewing a face image\nor a scrambled face image, supposedly with the same low-level statistical\nproperties, to find face-specific responses.\n\nFor details on the data, please see :footcite:t:`Henson2003`.\n\nThis example takes a lot of time because the input are lists of 3D images\nsampled in different positions (encoded by different affine functions).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fetch the :term:`SPM` multimodal_faces data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import fetch_spm_multimodal_fmri\n\nsubject_data = fetch_spm_multimodal_fmri()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify timing and design matrix parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# repetition time, in seconds\nt_r = 2.0\n# Sample at the beginning of each acquisition.\nslice_time_ref = 0.0\n# We use a discrete cosine transform to model signal drifts.\ndrift_model = \"Cosine\"\n# The cutoff for the drift model is 0.01 Hz.\nhigh_pass = 0.01\n# The hemodynamic response function\nhrf_model = \"spm + derivative\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resample the images.\n\nThis is achieved by the concat_imgs function of Nilearn.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\n\nfrom nilearn.image import concat_imgs, mean_img, resample_img\n\n# Avoid getting too many warnings due to resampling\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    fmri_img = [\n        concat_imgs(subject_data.func1, auto_resample=True),\n        concat_imgs(subject_data.func2, auto_resample=True),\n    ]\naffine, shape = fmri_img[0].affine, fmri_img[0].shape\nprint(\"Resampling the second image (this takes time)...\")\nfmri_img[1] = resample_img(\n    fmri_img[1], affine, shape[:3], copy_header=True, force_resample=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create mean image for display purposes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mean_image = mean_img(fmri_img, copy_header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make the design matrices.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\n\nfrom nilearn.glm.first_level import make_first_level_design_matrix\n\ndesign_matrices = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loop over the two runs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for idx, img in enumerate(fmri_img, start=1):\n    # Build experimental paradigm\n    n_scans = img.shape[-1]\n    events = pd.read_table(subject_data[f\"events{idx}\"])\n    # Define the sampling times for the design matrix\n    frame_times = np.arange(n_scans) * t_r\n    # Build design matrix with the reviously defined parameters\n    design_matrix = make_first_level_design_matrix(\n        frame_times,\n        events,\n        hrf_model=hrf_model,\n        drift_model=drift_model,\n        high_pass=high_pass,\n    )\n\n    # put the design matrices in a list\n    design_matrices.append(design_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can specify basic contrasts (to get :term:`beta<Parameter Estimate>`\nmaps).\nWe start by specifying canonical :term:`contrast`\nthat isolate design matrix columns.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "contrast_matrix = np.eye(design_matrix.shape[1])\nbasic_contrasts = {\n    column: contrast_matrix[i]\n    for i, column in enumerate(design_matrix.columns)\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We actually want more interesting contrasts. The simplest contrast\njust makes the difference between the two main conditions.  We\ndefine the two opposite versions to run one-tailed t-tests.  We also\ndefine the effects of interest contrast, a 2-dimensional contrasts\nspanning the two conditions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "contrasts = {\n    \"faces-scrambled\": basic_contrasts[\"faces\"] - basic_contrasts[\"scrambled\"],\n    \"scrambled-faces\": -basic_contrasts[\"faces\"]\n    + basic_contrasts[\"scrambled\"],\n    \"effects_of_interest\": np.vstack(\n        (basic_contrasts[\"faces\"], basic_contrasts[\"scrambled\"])\n    ),\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the :term:`GLM` for the 2 runs\nby specifying a FirstLevelModel and then fitting it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.glm.first_level import FirstLevelModel\n\nprint(\"Fitting a GLM\")\nfmri_glm = FirstLevelModel()\nfmri_glm = fmri_glm.fit(fmri_img, design_matrices=design_matrices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can compute contrast-related statistical maps (in z-scale), and plot\nthem.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn import plotting\n\nprint(\"Computing contrasts\")\n\n# Iterate on contrasts\nfor contrast_id, contrast_val in contrasts.items():\n    print(f\"\\tcontrast id: {contrast_id}\")\n    # compute the contrasts\n    z_map = fmri_glm.compute_contrast(contrast_val, output_type=\"z_score\")\n    # plot the contrasts as soon as they're generated\n    # the display is overlaid on the mean fMRI image\n    # a threshold of 3.0 is used, more sophisticated choices are possible\n    plotting.plot_stat_map(\n        z_map,\n        bg_img=mean_image,\n        threshold=3.0,\n        display_mode=\"z\",\n        cut_coords=3,\n        black_bg=True,\n        title=contrast_id,\n    )\n    plotting.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the resulting maps we observe that the analysis results in\nwide activity for the 'effects of interest' contrast, showing the\nimplications of large portions of the visual cortex in the\nconditions. By contrast, the differential effect between \"faces\" and\n\"scrambled\" involves sparser, more anterior and lateral regions. It\nalso displays some responses in the frontal lobe.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n\n .. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
