{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Working with Surface images\n\nHere we explain how surface images are represented within Nilearn and how you\ncan plot, save and load them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is a surface image?\n\nWithin the context of neuroimaging, a surface image is an alternative way of\nrepresenting MRI data as opposed to a volumetric image.\n\nWhile volumetric images are 3D grids of voxels, surface images consist of\npoints (vertices) in 3D space connected to represent the surface of the\nbrain.\n\nPractically, this means that the main difference between the two is the basic\nunit that holds the data.\nFor volumetric images, that basic unit is a voxel,\nwhile for surface images it is a :term:`vertex`.\n\nThe goal of this tutorial is to show you how to work with surface images in\nNilearn. For more existential questions like why surface images are useful,\nhow they are created etc., [Andy Jahn's blog](https://andysbrainbook.readthedocs.io/en/latest/FreeSurfer/FreeSurfer_Introduction.html)\nis a good starting point.\n\nSurface images have two main components:\n\n1. The :term:`mesh`, which is the geometry of the surface.\n2. The data, which is the information stored at each vertex of the mesh.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mesh\n\nA :term:`mesh` can be defined by two arrays:\n\n1. The coordinates of the vertices.\n2. Which vertices need to be connected to form :term:`faces`.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This representation of a mesh is known as [Face-Vertex](https://en.wikipedia.org/wiki/Polygon_mesh#Face-vertex_meshes)\n          representation.</p></div>\n\nFor brain surfaces we typically have two meshes: one for the left hemisphere\nand one for the right hemisphere.\nNilearn represents this as a\n:class:`~nilearn.surface.PolyMesh` object with two ``parts``:\n``left`` and ``right``.\n\nSo you can define your own :term:`mesh`, say, for the left part a tetrahedron\nand for the right part a pyramid, using numpy arrays and create a\n:class:`~nilearn.surface.PolyMesh` object as follows:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom nilearn.surface import InMemoryMesh, PolyMesh\n\n# for the tetrahedron\nleft_coords = np.asarray(\n    [\n        [0, 0, 0],  # vertex 0\n        [1, 0, 0],  # vertex 1\n        [0, 1, 0],  # vertex 2\n        [0, 0, 1],  # vertex 3\n    ]\n)\nleft_faces = np.asarray(\n    [\n        [1, 0, 2],  # face created by connecting vertices 1, 0, 2\n        [0, 1, 3],  # face created by connecting vertices 0, 1, 3\n        [0, 3, 2],  # face created by connecting vertices 0, 3, 2\n        [1, 2, 3],  # face created by connecting vertices 1, 2, 3\n    ]\n)\n# for the pyramid\nright_coords = (\n    np.asarray(\n        [\n            [0, 0, 0],\n            [1, 0, 0],\n            [1, 1, 0],\n            [0, 1, 0],\n            [0, 0, 1],\n        ]\n    )\n    + 2\n)\nright_faces = np.asarray(\n    [\n        [0, 1, 4],\n        [0, 3, 1],\n        [1, 3, 2],\n        [1, 2, 4],\n        [2, 3, 4],\n        [0, 4, 3],\n    ]\n)\n# put the two parts together\nmesh = PolyMesh(\n    left=InMemoryMesh(left_coords, left_faces),\n    right=InMemoryMesh(right_coords, right_faces),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data\n\nThe data is the information stored at each :term:`vertex`\nof the :term:`mesh`.\nThis can be anything from the thickness of the cortex\nto the activation level at that :term:`vertex`.\n\nFor this example, let's create some random data\nfor the vertices of the :term:`mesh`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rng = np.random.default_rng(0)\nleft_data = rng.random(mesh.parts[\"left\"].n_vertices)\nright_data = rng.random(mesh.parts[\"right\"].n_vertices)\n# put them together in a dictionary\ndata = {\n    \"left\": left_data,\n    \"right\": right_data,\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a surface image\n\nNow we can create a surface image by combining the :term:`mesh` and the data\nusing the :class:`~nilearn.surface.SurfaceImage` class:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.surface import SurfaceImage\n\nsurface_image = SurfaceImage(mesh=mesh, data=data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the surface image\n\nThe surface image can be plotted using the different functions\nfrom the :mod:`nilearn.plotting` module.\nHere we will show how to use the\n:func:`~nilearn.plotting.view_surf` function:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.plotting import view_surf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the left part\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "view_surf(\n    surf_map=surface_image,\n    hemi=\"left\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the right part\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "view_surf(\n    surf_map=surface_image,\n    hemi=\"right\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data format\n\nBrain-related surface data are typically stored in the GIFTI format\n(``.gii`` files) which can be saved to and loaded from via Nilearn.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the surface image\n\nYou can save the :term:`mesh` and the data separately as GIFTI files:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\noutput_dir = Path.cwd() / \"results\" / \"plot_surface_101\"\noutput_dir.mkdir(exist_ok=True, parents=True)\nprint(f\"Output will be saved to: {output_dir}\")\nsurface_image.mesh.to_filename(output_dir / \"surface_image_mesh.gii\")\nsurface_image.data.to_filename(output_dir / \"surface_image_data.gii\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You will see that this creates four files in total -- two for the\n:term:`mesh` and two for the data.\nThe files ending with ``_hemi-L.gii``\ncorrespond to the left part and those ending with ``_hemi-R.gii`` correspond\nto the right part.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the surface image\n\nYou can load the saved files back into Nilearn using the\n:class:`~nilearn.surface.SurfaceImage` object:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mesh = {\n    \"left\": output_dir / \"surface_image_mesh_hemi-L.gii\",\n    \"right\": output_dir / \"surface_image_mesh_hemi-R.gii\",\n}\ndata = {\n    \"left\": output_dir / \"surface_image_data_hemi-L.gii\",\n    \"right\": output_dir / \"surface_image_data_hemi-R.gii\",\n}\n\nsurface_image_loaded = SurfaceImage(\n    mesh=mesh,\n    data=data,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can now plot the loaded surface image:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "view_surf(\n    surf_map=surface_image_loaded,\n    hemi=\"left\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And that's it! Now you know how to create, plot, save and load surface images\nwith Nilearn.\n\n## Further reading\n\nMost things that can be done with volumetric images can also be done with\nsurface images.\nSee following examples for more details:\n\n* For plotting statistical maps on the surface, see\n  `sphx_glr_auto_examples_01_plotting_plot_surf_stat_map.py`\n\n* For performing GLM analysis on surface data organized in BIDS\n  format, see\n  `sphx_glr_auto_examples_07_advanced_plot_surface_bids_analysis.py`\n\n* For performing first-level GLM analysis on surface data, see [this \\\n  example](../04_glm_first_level/plot_localizer_surface_analysis.html).\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
