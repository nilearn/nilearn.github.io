<!doctypehtml><html lang=en xmlns=http://www.w3.org/1999/xhtml><meta content=IE=Edge http-equiv=X-UA-Compatible><meta content="text/html; charset=utf-8"http-equiv=Content-Type><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../_static/nature.css rel=stylesheet><link href=../_static/pygments.css rel=stylesheet><link href=../_static/gallery.css rel=stylesheet><link href=../_static/gallery-binder.css rel=stylesheet><link href=../_static/gallery-dataframe.css rel=stylesheet><script data-url_root=../ id=documentation_options src=../_static/documentation_options.js></script><script src=../_static/jquery.js></script><script src=../_static/underscore.js></script><script src=../_static/doctools.js></script><script src=../_static/language_data.js></script><script src=../_static/copybutton.js></script><link rel="shortcut icon"href=../_static/favicon.ico><link href=../search.html rel=search title=Search><link title="3.4. Region Extraction for better brain parcellations"href=region_extraction.html rel=next><link title="3.2.3.1. Group-sparse covariance estimation"href=../developers/group_sparse_covariance.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script></head><body><div id=logo-banner><div class=logo><a href=../index.html> <img alt="Nilearn logo"border=0 src=../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=parcellating.html>Ward clustering</a></small></li><li><a href=../decoding/searchlight.html>Searchlight</a></li><li><big><a href=#>ICA</a></big></li><li><a href=../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../modules/reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../py-modindex.html>modules</a></li><li class=right><a title="3.4. Region Extraction for better brain parcellations"accesskey=N href=region_extraction.html>next</a> |</li><li class=right><a title="3.2.3.1. Group-sparse covariance estimation"accesskey=P href=../developers/group_sparse_covariance.html>previous</a> |</li><li><a href=../index.html>Nilearn Home</a> | </li><li><a href=../user_guide.html>User Guide</a> | </li><li><a href=../auto_examples/index.html>Examples</a> | </li><li><a href=../modules/reference.html>Reference</a> | </li><li id=navbar-about><a href=../authors.html>About</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=index.html>3. Functional connectivity and resting state</a> »</li></ul></div></div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class=section id=extracting-functional-brain-networks-ica-and-related><span id=extracting-rsn></span><h1>3.3. Extracting functional brain networks: ICA and related<a title="Permalink to this headline"class=headerlink href=#extracting-functional-brain-networks-ica-and-related>¶</a></h1><div class=topic><p class=topic-title><strong>Page summary</strong></p><p>This page demonstrates the use of multi-subject decompositions models to extract brain-networks from fMRI data in a data-driven way. Specifically, we will apply Independent Component Analysis (ICA), which implements a multivariate random effects model across subjects. We will then compare ICA to a newer technique, based on dictionary learning.</p></div><div class=section id=multi-subject-ica-canica><h2>3.3.1. Multi-subject ICA: CanICA<a title="Permalink to this headline"class=headerlink href=#multi-subject-ica-canica>¶</a></h2><div class=topic><p class=topic-title><strong>References</strong></p><ul class=simple><li>G. Varoquaux et al. “A group model for stable multi-subject ICA on fMRI datasets”, <a class="reference external"href=http://www.sciencedirect.com/science/article/pii/S1053811910001618>NeuroImage Vol 51 (2010)</a>, p. 288-299</li></ul></div><div class=section id=objective><h3>3.3.1.1. Objective<a title="Permalink to this headline"class=headerlink href=#objective>¶</a></h3><p>ICA is a useful approach for finding independent sources from fMRI images. ICA and similar techniques can be therefore used to define regions or networks that share similar BOLD signal across time. The CanICA incorporates information both within-subjects and across subjects to arrive at consensus components.</p><div class=topic><p class=topic-title><strong>Nilearn data for examples</strong></p><p>Nilearn provides easy-to-analyze data to explore functional connectivity and resting: the <a class="reference external"href=https://osf.io/5hju4/files/>brain development dataset</a>, which has been preprocessed using <a class="reference external"href=https://osf.io/wjtyq/>FMRIPrep and Nilearn</a> We use nilearn functions to fetch data from Internet and get the filenames (<a class="reference internal"href=../manipulating_images/input_output.html#loading-data><span class="std std-ref">more on data loading</span></a>).</p></div></div><div class=section id=fitting-canica-model-with-nilearn><h3>3.3.1.2. Fitting CanICA model with nilearn<a title="Permalink to this headline"class=headerlink href=#fitting-canica-model-with-nilearn>¶</a></h3><p><a class="reference internal"href=../modules/generated/nilearn.decomposition.CanICA.html#nilearn.decomposition.CanICA title=nilearn.decomposition.CanICA><code class="xref py py-class docutils literal notranslate"><span class=pre>CanICA</span></code></a> is a ready-to-use object that can be applied to multi-subject Nifti data, for instance presented as filenames, and will perform a multi-subject ICA decomposition following the CanICA model. As with every object in nilearn, we give its parameters at construction, and then fit it on the data. For examples of this process, see here: <a class="reference internal"href=../auto_examples/03_connectivity/plot_compare_decomposition.html#sphx-glr-auto-examples-03-connectivity-plot-compare-decomposition-py><span class="std std-ref">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</span></a></p><p>Once an ICA object has been fit to an fMRI dataset, the individual components can be accessed as a 4D Nifti object using the <code class="docutils literal notranslate"><span class=pre>components_img_</span></code> attribute.</p></div><div class=section id=visualizing-results><h3>3.3.1.3. Visualizing results<a title="Permalink to this headline"class=headerlink href=#visualizing-results>¶</a></h3><p>We can visualize each component outlined over the brain:</p><div class="figure align-center"><a class="reference external image-reference"href=../auto_examples/03_connectivity/plot_compare_decomposition.html><img alt=../_images/sphx_glr_plot_compare_decomposition_0011.png src=../_images/sphx_glr_plot_compare_decomposition_0011.png></a></div><p>We can also plot the map for different components separately:</p><p class=centered><strong><a class="reference internal"href=../_images/sphx_glr_plot_compare_decomposition_0021.png><img alt=ic1 src=../_images/sphx_glr_plot_compare_decomposition_0021.png style=width:23%></a> <a class="reference internal"href=../_images/sphx_glr_plot_compare_decomposition_0031.png><img alt=ic2 src=../_images/sphx_glr_plot_compare_decomposition_0031.png style=width:23%></a> <a class="reference internal"href=../_images/sphx_glr_plot_compare_decomposition_0041.png><img alt=ic3 src=../_images/sphx_glr_plot_compare_decomposition_0041.png style=width:23%></a> <a class="reference internal"href=../_images/sphx_glr_plot_compare_decomposition_0051.png><img alt=ic4 src=../_images/sphx_glr_plot_compare_decomposition_0051.png style=width:23%></a></strong></p><div class="admonition seealso"><p class="first admonition-title">See also</p><p class=last>The full code can be found as an example: <a class="reference internal"href=../auto_examples/03_connectivity/plot_compare_decomposition.html#sphx-glr-auto-examples-03-connectivity-plot-compare-decomposition-py><span class="std std-ref">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</span></a></p></div><div class="admonition note"><p class="first admonition-title">Note</p><p class=last>Note that as the ICA components are not ordered, the two components displayed on your computer might not match those of the documentation. For a fair representation, you should display all components and investigate which one resemble those displayed above.</p></div></div><div class=section id=interpreting-such-components><h3>3.3.1.4. Interpreting such components<a title="Permalink to this headline"class=headerlink href=#interpreting-such-components>¶</a></h3><p>ICA, and related algorithms, extract patterns that coactivate in the signal. As a result, it finds functional networks, but also patterns of non neural activity, ie confounding signals. Both are visible in the plots of the components.</p></div></div><div class=section id=an-alternative-to-ica-dictionary-learning><h2>3.3.2. An alternative to ICA: Dictionary learning<a title="Permalink to this headline"class=headerlink href=#an-alternative-to-ica-dictionary-learning>¶</a></h2><p>Recent work has shown that dictionary learning based techniques outperform ICA in term of stability and constitutes a better first step in a statistical analysis pipeline. Dictionary learning in neuro-imaging seeks to extract a few representative temporal elements along with their sparse spatial loadings, which constitute good extracted maps.</p><div class=topic><p class=topic-title><strong>References</strong></p><ul class=simple><li>Arthur Mensch et al. <a class="reference external"href=https://hal.archives-ouvertes.fr/hal-01271033/>Compressed online dictionary learning for fast resting-state fMRI decomposition</a>, ISBI 2016, Lecture Notes in Computer Science</li></ul></div><p><a class="reference internal"href=../modules/generated/nilearn.decomposition.DictLearning.html#nilearn.decomposition.DictLearning title=nilearn.decomposition.DictLearning><code class="xref py py-class docutils literal notranslate"><span class=pre>DictLearning</span></code></a> is a ready-to-use class with the same interface as CanICA. Sparsity of output map is controlled by a parameter alpha: using a larger alpha yields sparser maps.</p><p>We can fit both estimators to compare them. 4D plotting (using <a class="reference internal"href=../modules/generated/nilearn.plotting.plot_prob_atlas.html#nilearn.plotting.plot_prob_atlas title=nilearn.plotting.plot_prob_atlas><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.plotting.plot_prob_atlas</span></code></a>) offers an efficient way to compare both resulting outputs.</p><div class="figure align-center"><a class="reference external image-reference"href=../auto_examples/03_connectivity/plot_compare_decomposition.html><img alt=../_images/sphx_glr_plot_compare_decomposition_0221.png src=../_images/sphx_glr_plot_compare_decomposition_0221.png></a></div><div class="figure align-center"><a class="reference external image-reference"href=../auto_examples/03_connectivity/plot_compare_decomposition.html><img alt=../_images/sphx_glr_plot_compare_decomposition_0011.png src=../_images/sphx_glr_plot_compare_decomposition_0011.png></a></div><p>Maps obtained with dictionary learning are often easier to exploit as they are more contrasted than ICA maps, with blobs usually better defined. Typically, <em>smoothing can be lower than when doing ICA</em>.</p><p class=centered><strong><a class="reference internal"href=../_images/sphx_glr_plot_compare_decomposition_0231.png><img alt=dl1 src=../_images/sphx_glr_plot_compare_decomposition_0231.png style=width:23%></a> <a class="reference internal"href=../_images/sphx_glr_plot_compare_decomposition_0241.png><img alt=dl2 src=../_images/sphx_glr_plot_compare_decomposition_0241.png style=width:23%></a> <a class="reference internal"href=../_images/sphx_glr_plot_compare_decomposition_0251.png><img alt=dl3 src=../_images/sphx_glr_plot_compare_decomposition_0251.png style=width:23%></a> <a class="reference internal"href=../_images/sphx_glr_plot_compare_decomposition_0261.png><img alt=dl4 src=../_images/sphx_glr_plot_compare_decomposition_0261.png style=width:23%></a></strong></p><p>While dictionary learning computation time is comparable to CanICA, obtained atlases have been shown to outperform ICA in a variety of classification tasks.</p><div class="admonition seealso"><p class="first admonition-title">See also</p><p class=last>The full code can be found as an example: <a class="reference internal"href=../auto_examples/03_connectivity/plot_compare_decomposition.html#sphx-glr-auto-examples-03-connectivity-plot-compare-decomposition-py><span class="std std-ref">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</span></a></p></div><div class="admonition seealso"><p class="first admonition-title">See also</p><p class=last>Learn how to extract fMRI data from regions created with dictionary learning with this example: <a class="reference internal"href=../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html#sphx-glr-auto-examples-03-connectivity-plot-extract-regions-dictlearning-maps-py><span class="std std-ref">Regions extraction using Dictionary Learning and functional connectomes</span></a></p></div></div></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>3.3. Extracting functional brain networks: ICA and related</a><ul><li><a class="reference internal"href=#multi-subject-ica-canica>3.3.1. Multi-subject ICA: CanICA</a><ul><li><a class="reference internal"href=#objective>3.3.1.1. Objective</a></li><li><a class="reference internal"href=#fitting-canica-model-with-nilearn>3.3.1.2. Fitting CanICA model with nilearn</a></li><li><a class="reference internal"href=#visualizing-results>3.3.1.3. Visualizing results</a></li><li><a class="reference internal"href=#interpreting-such-components>3.3.1.4. Interpreting such components</a></li></ul></li><li><a class="reference internal"href=#an-alternative-to-ica-dictionary-learning>3.3.2. An alternative to ICA: Dictionary learning</a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=../developers/group_sparse_covariance.html>3.2.3.1. Group-sparse covariance estimation</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=region_extraction.html>3.4. Region Extraction for better brain parcellations</a></p><div id=searchbox role=search style=display:none><h3>Quick search</h3><div class=searchformwrapper><form action=../search.html class=search><input name=q><input type=submit value=Go><input name=check_keywords type=hidden value=yes><input name=area type=hidden value=default></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2020. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 1.8.5. <span style=padding-left:5ex> <a href=../_sources/connectivity/resting_state_networks.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>