<!doctypehtml><html lang=en xmlns=http://www.w3.org/1999/xhtml><meta content=IE=Edge http-equiv=X-UA-Compatible><meta content="text/html; charset=utf-8"http-equiv=Content-Type><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/gallery.css rel=stylesheet><link href=../../_static/gallery-binder.css rel=stylesheet><link href=../../_static/gallery-dataframe.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/language_data.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="8.10.13. nilearn.plotting.plot_connectome_strength"href=nilearn.plotting.plot_connectome_strength.html rel=next><link title="8.10.11. nilearn.plotting.plot_glass_brain"href=nilearn.plotting.plot_glass_brain.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script></head><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="8.10.13. nilearn.plotting.plot_connectome_strength"accesskey=N href=nilearn.plotting.plot_connectome_strength.html>next</a> |</li><li class=right><a title="8.10.11. nilearn.plotting.plot_glass_brain"accesskey=P href=nilearn.plotting.plot_glass_brain.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../../auto_examples/index.html>Examples</a> | </li><li><a href=../reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../reference.html>8. Reference documentation: all nilearn functions</a> »</li></ul></div></div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="admonition note"><p class="first admonition-title">Note</p><p class=last>This page is a reference documentation. It only explains the function signature, and not how to use it. Please refer to the <a class="reference internal"href=../../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for the big picture.</p></div><div class=section id=nilearn-plotting-plot-connectome><h1>8.10.12. nilearn.plotting.plot_connectome<a title="Permalink to this headline"class=headerlink href=#nilearn-plotting-plot-connectome>¶</a></h1><dl class=function><dt id=nilearn.plotting.plot_connectome><code class=descclassname>nilearn.plotting.</code><code class=descname>plot_connectome</code><span class=sig-paren>(</span><em>adjacency_matrix</em>, <em>node_coords</em>, <em>node_color='auto'</em>, <em>node_size=50</em>, <em>edge_cmap=&LTmatplotlib.colors.LinearSegmentedColormap object></em>, <em>edge_vmin=None</em>, <em>edge_vmax=None</em>, <em>edge_threshold=None</em>, <em>output_file=None</em>, <em>display_mode='ortho'</em>, <em>figure=None</em>, <em>axes=None</em>, <em>title=None</em>, <em>annotate=True</em>, <em>black_bg=False</em>, <em>alpha=0.7</em>, <em>edge_kwargs=None</em>, <em>node_kwargs=None</em>, <em>colorbar=False</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.plotting.plot_connectome>¶</a></dt><dd><p>Plot connectome on top of the brain glass schematics.</p> <p>The plotted image should be in MNI space for this function to work properly.</p> <p>In the case of ‘l’ and ‘r’ directions (for hemispheric projections), markers in the coordinate x == 0 are included in both hemispheres.</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>adjacency_matrix</strong> : numpy array of shape (n, n)</p> <blockquote><div><p>represents the link strengths of the graph. Assumed to be a symmetric matrix.</p></div></blockquote> <p><strong>node_coords</strong> : numpy array_like of shape (n, 3)</p> <blockquote><div><p>3d coordinates of the graph nodes in world space.</p></div></blockquote> <p><strong>node_color</strong> : color or sequence of colors</p> <blockquote><div><p>color(s) of the nodes. If string is given, all nodes are plotted with same color given in string.</p></div></blockquote> <p><strong>node_size</strong> : scalar or array_like</p> <blockquote><div><p>size(s) of the nodes in points^2.</p></div></blockquote> <p><strong>edge_cmap</strong> : colormap</p> <blockquote><div><p>colormap used for representing the strength of the edges.</p></div></blockquote> <p><strong>edge_vmin</strong> : float, optional, default: None</p> <p><strong>edge_vmax</strong> : float, optional, default: None</p> <blockquote><div><p>If not None, either or both of these values will be used to as the minimum and maximum values to color edges. If None are supplied the maximum absolute value within the given threshold will be used as minimum (multiplied by -1) and maximum coloring levels.</p></div></blockquote> <p><strong>edge_threshold</strong> : str or number</p> <blockquote><div><p>If it is a number only the edges with a value greater than edge_threshold will be shown. If it is a string it must finish with a percent sign, e.g. “25.3%”, and only the edges with a abs(value) above the given percentile will be shown.</p></div></blockquote> <p><strong>output_file</strong> : string, or None, optional</p> <blockquote><div><p>The name of an image file to export the plot to. Valid extensions are .png, .pdf, .svg. If output_file is not None, the plot is saved to a file, and the display is closed.</p></div></blockquote> <p><strong>display_mode</strong> : string, optional. Default is ‘ortho’.</p> <blockquote><div><p>Choose the direction of the cuts: ‘x’ - sagittal, ‘y’ - coronal, ‘z’ - axial, ‘l’ - sagittal left hemisphere only, ‘r’ - sagittal right hemisphere only, ‘ortho’ - three cuts are performed in orthogonal directions. Possible values are: ‘ortho’, ‘x’, ‘y’, ‘z’, ‘xz’, ‘yx’, ‘yz’, ‘l’, ‘r’, ‘lr’, ‘lzr’, ‘lyr’, ‘lzry’, ‘lyrz’.</p></div></blockquote> <p><strong>figure</strong> : integer or matplotlib figure, optional</p> <blockquote><div><p>Matplotlib figure used or its number. If None is given, a new figure is created.</p></div></blockquote> <p><strong>axes</strong> : matplotlib axes or 4 tuple of float: (xmin, ymin, width, height), optional</p> <blockquote><div><p>The axes, or the coordinates, in matplotlib figure space, of the axes used to display the plot. If None, the complete figure is used.</p></div></blockquote> <p><strong>title</strong> : string, optional</p> <blockquote><div><p>The title displayed on the figure.</p></div></blockquote> <p><strong>annotate</strong> : boolean, optional</p> <blockquote><div><p>If annotate is True, positions and left/right annotation are added to the plot.</p></div></blockquote> <p><strong>black_bg</strong> : boolean, optional</p> <blockquote><div><p>If True, the background of the image is set to be black. If you wish to save figures with a black background, you will need to pass “facecolor=’k’, edgecolor=’k’” to matplotlib.pyplot.savefig.</p></div></blockquote> <p><strong>alpha</strong> : float between 0 and 1</p> <blockquote><div><p>Alpha transparency for the brain schematics.</p></div></blockquote> <p><strong>edge_kwargs</strong> : dict</p> <blockquote><div><p>will be passed as kwargs for each edge matlotlib Line2D.</p></div></blockquote> <p><strong>node_kwargs</strong> : dict</p> <blockquote><div><p>will be passed as kwargs to the plt.scatter call that plots all the nodes in one go</p></div></blockquote> <p><strong>colorbar</strong> : bool, optional</p> <blockquote class=last><div><p>If True, display a colorbar on the right of the plots. By default it is False.</p></div></blockquote></td></tr></tbody></table> <div class="admonition seealso"><p class="first admonition-title">See also</p><dl class="last docutils"><dt><a class="reference internal"href=nilearn.plotting.find_parcellation_cut_coords.html#nilearn.plotting.find_parcellation_cut_coords title=nilearn.plotting.find_parcellation_cut_coords><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.plotting.find_parcellation_cut_coords</span></code></a></dt><dd>Extraction of node coords on brain parcellations.</dd><dt><a class="reference internal"href=nilearn.plotting.find_probabilistic_atlas_cut_coords.html#nilearn.plotting.find_probabilistic_atlas_cut_coords title=nilearn.plotting.find_probabilistic_atlas_cut_coords><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.plotting.find_probabilistic_atlas_cut_coords</span></code></a></dt><dd>Extraction of node coords on brain probabilisitic atlases.</dd></dl></div></dd></dl><div class=section id=examples-using-nilearn-plotting-plot-connectome><h2>8.10.12.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.plotting.plot_connectome</span></code><a title="Permalink to this headline"class=headerlink href=#examples-using-nilearn-plotting-plot-connectome>¶</a></h2><div tooltip="The Destrieux parcellation (Destrieux et al, 2010) in fsaverage5 space as distributed with Free..."class=sphx-glr-thumbcontainer><div class=figure id=id1><img alt="Loading and plotting of a cortical surface atlas"src=../../_images/sphx_glr_plot_surf_atlas_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_surf_atlas.html#sphx-glr-auto-examples-01-plotting-plot-surf-atlas-py><span class="std std-ref">Loading and plotting of a cortical surface atlas</span></a></span></p></div></div><div tooltip="This example extracts the signal on regions defined via a probabilistic atlas, to construct a f..."class=sphx-glr-thumbcontainer><div class=figure id=id2><img alt="Extracting signals of a probabilistic atlas of functional regions"src=../../_images/sphx_glr_plot_probabilistic_atlas_extraction_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_probabilistic_atlas_extraction.html#sphx-glr-auto-examples-03-connectivity-plot-probabilistic-atlas-extraction-py><span class="std std-ref">Extracting signals of a probabilistic atlas of functional regions</span></a></span></p></div></div><div tooltip="This example constructs a functional connectome using the sparse inverse covariance."class=sphx-glr-thumbcontainer><div class=figure id=id3><img alt="Computing a connectome with sparse inverse covariance"src=../../_images/sphx_glr_plot_inverse_covariance_connectome_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_inverse_covariance_connectome.html#sphx-glr-auto-examples-03-connectivity-plot-inverse-covariance-connectome-py><span class="std std-ref">Computing a connectome with sparse inverse covariance</span></a></span></p></div></div><div tooltip="This examples shows how to turn a parcellation into connectome for visualization. This requires..."class=sphx-glr-thumbcontainer><div class=figure id=id4><img alt="Comparing connectomes on different reference atlases"src=../../_images/sphx_glr_plot_atlas_comparison_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_atlas_comparison.html#sphx-glr-auto-examples-03-connectivity-plot-atlas-comparison-py><span class="std std-ref">Comparing connectomes on different reference atlases</span></a></span></p></div></div><div tooltip="This example shows how to estimate a connectome on a group of subjects using the group sparse i..."class=sphx-glr-thumbcontainer><div class=figure id=id5><img alt="Group Sparse inverse covariance for multi-subject connectome"src=../../_images/sphx_glr_plot_multi_subject_connectome_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_multi_subject_connectome.html#sphx-glr-auto-examples-03-connectivity-plot-multi-subject-connectome-py><span class="std std-ref">Group Sparse inverse covariance for multi-subject connectome</span></a></span></p></div></div><div tooltip="This example compares different kinds of functional connectivity between regions of interest : ..."class=sphx-glr-thumbcontainer><div class=figure id=id6><img alt="Classification of age groups using functional connectivity"src=../../_images/sphx_glr_plot_group_level_connectivity_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_group_level_connectivity.html#sphx-glr-auto-examples-03-connectivity-plot-group-level-connectivity-py><span class="std std-ref">Classification of age groups using functional connectivity</span></a></span></p></div></div><div tooltip="This example shows how to use nilearn.regions.RegionExtractor to extract spatially constrained ..."class=sphx-glr-thumbcontainer><div class=figure id=id7><img alt="Regions extraction using Dictionary Learning and functional connectomes"src=../../_images/sphx_glr_plot_extract_regions_dictlearning_maps_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html#sphx-glr-auto-examples-03-connectivity-plot-extract-regions-dictlearning-maps-py><span class="std std-ref">Regions extraction using Dictionary Learning and functional connectomes</span></a></span></p></div></div><div tooltip="This example shows how to extract signals from spherical regions. We show how to build spheres ..."class=sphx-glr-thumbcontainer><div class=figure id=id8><img alt="Extract signals on spheres and plot a connectome"src=../../_images/sphx_glr_plot_sphere_based_connectome_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_sphere_based_connectome.html#sphx-glr-auto-examples-03-connectivity-plot-sphere-based-connectome-py><span class="std std-ref">Extract signals on spheres and plot a connectome</span></a></span></p></div></div><div style=clear:both></div></div></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>8.10.12. nilearn.plotting.plot_connectome</a><ul><li><a class="reference internal"href=#examples-using-nilearn-plotting-plot-connectome>8.10.12.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.plotting.plot_connectome</span></code></a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=nilearn.plotting.plot_glass_brain.html>8.10.11. nilearn.plotting.plot_glass_brain</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=nilearn.plotting.plot_connectome_strength.html>8.10.13. nilearn.plotting.plot_connectome_strength</a></p><div id=searchbox role=search style=display:none><h3>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input name=q><input type=submit value=Go><input name=check_keywords type=hidden value=yes><input name=area type=hidden value=default></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2020. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 1.8.5. <span style=padding-left:5ex> <a href=../../_sources/modules/generated/nilearn.plotting.plot_connectome.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>