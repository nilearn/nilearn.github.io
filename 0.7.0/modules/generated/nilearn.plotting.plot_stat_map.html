<!doctypehtml><html lang=en xmlns=http://www.w3.org/1999/xhtml><meta content=IE=Edge http-equiv=X-UA-Compatible><meta content="text/html; charset=utf-8"http-equiv=Content-Type><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/gallery.css rel=stylesheet><link href=../../_static/gallery-binder.css rel=stylesheet><link href=../../_static/gallery-dataframe.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/language_data.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="8.10.11. nilearn.plotting.plot_glass_brain"href=nilearn.plotting.plot_glass_brain.html rel=next><link title="8.10.9. nilearn.plotting.plot_roi"href=nilearn.plotting.plot_roi.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script></head><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="8.10.11. nilearn.plotting.plot_glass_brain"accesskey=N href=nilearn.plotting.plot_glass_brain.html>next</a> |</li><li class=right><a title="8.10.9. nilearn.plotting.plot_roi"accesskey=P href=nilearn.plotting.plot_roi.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../../auto_examples/index.html>Examples</a> | </li><li><a href=../reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../reference.html>8. Reference documentation: all nilearn functions</a> »</li></ul></div></div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="admonition note"><p class="first admonition-title">Note</p><p class=last>This page is a reference documentation. It only explains the function signature, and not how to use it. Please refer to the <a class="reference internal"href=../../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for the big picture.</p></div><div class=section id=nilearn-plotting-plot-stat-map><h1>8.10.10. nilearn.plotting.plot_stat_map<a title="Permalink to this headline"class=headerlink href=#nilearn-plotting-plot-stat-map>¶</a></h1><dl class=function><dt id=nilearn.plotting.plot_stat_map><code class=descclassname>nilearn.plotting.</code><code class=descname>plot_stat_map</code><span class=sig-paren>(</span><em>stat_map_img</em>, <em>bg_img=&LTMNI152Template></em>, <em>cut_coords=None</em>, <em>output_file=None</em>, <em>display_mode='ortho'</em>, <em>colorbar=True</em>, <em>figure=None</em>, <em>axes=None</em>, <em>title=None</em>, <em>threshold=1e-06</em>, <em>annotate=True</em>, <em>draw_cross=True</em>, <em>black_bg='auto'</em>, <em>cmap=&LTmatplotlib.colors.LinearSegmentedColormap object></em>, <em>symmetric_cbar='auto'</em>, <em>dim='auto'</em>, <em>vmax=None</em>, <em>resampling_interpolation='continuous'</em>, <em>**kwargs</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.plotting.plot_stat_map>¶</a></dt><dd><p>Plot cuts of an ROI/mask image (by default 3 cuts: Frontal, Axial, and Lateral)</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>stat_map_img</strong> : Niimg-like object</p> <blockquote><div><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> The statistical map image</p></div></blockquote> <p><strong>bg_img</strong> : Niimg-like object</p> <blockquote><div><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> The background image that the ROI/mask will be plotted on top of. If nothing is specified, the MNI152 template will be used. To turn off background image, just pass “bg_img=None”.</p></div></blockquote> <p><strong>cut_coords</strong> : None, a tuple of floats, or an integer</p> <blockquote><div><p>The MNI coordinates of the point where the cut is performed If display_mode is ‘ortho’ or ‘tiled’, this should be a 3-tuple: (x, y, z) For display_mode == ‘x’, ‘y’, or ‘z’, then these are the coordinates of each cut in the corresponding direction. If None is given, the cuts is calculated automaticaly. If display_mode is ‘x’, ‘y’ or ‘z’, cut_coords can be an integer, in which case it specifies the number of cuts to perform</p></div></blockquote> <p><strong>output_file</strong> : string, or None, optional</p> <blockquote><div><p>The name of an image file to export the plot to. Valid extensions are .png, .pdf, .svg. If output_file is not None, the plot is saved to a file, and the display is closed.</p></div></blockquote> <p><strong>display_mode</strong> : {‘ortho’, ‘tiled’, ‘x’, ‘y’, ‘z’, ‘yx’, ‘xz’, ‘yz’}</p> <blockquote><div><p>Choose the direction of the cuts: ‘x’ - sagittal, ‘y’ - coronal, ‘z’ - axial, ‘ortho’ - three cuts are performed in orthogonal directions, ‘tiled’ - three cuts are performed and arranged in a 2x2 grid.</p></div></blockquote> <p><strong>colorbar</strong> : boolean, optional</p> <blockquote><div><p>If True, display a colorbar on the right of the plots.</p></div></blockquote> <p><strong>figure</strong> : integer or matplotlib figure, optional</p> <blockquote><div><p>Matplotlib figure used or its number. If None is given, a new figure is created.</p></div></blockquote> <p><strong>axes</strong> : matplotlib axes or 4 tuple of float: (xmin, ymin, width, height), optional</p> <blockquote><div><p>The axes, or the coordinates, in matplotlib figure space, of the axes used to display the plot. If None, the complete figure is used.</p></div></blockquote> <p><strong>title</strong> : string, optional</p> <blockquote><div><p>The title displayed on the figure.</p></div></blockquote> <p><strong>threshold</strong> : a number, None, or ‘auto’</p> <blockquote><div><p>If None is given, the image is not thresholded. If a number is given, it is used to threshold the image: values below the threshold (in absolute value) are plotted as transparent. If auto is given, the threshold is determined magically by analysis of the image.</p></div></blockquote> <p><strong>annotate</strong> : boolean, optional</p> <blockquote><div><p>If annotate is True, positions and left/right annotation are added to the plot.</p></div></blockquote> <p><strong>draw_cross</strong> : boolean, optional</p> <blockquote><div><p>If draw_cross is True, a cross is drawn on the plot to indicate the cut plosition.</p></div></blockquote> <p><strong>black_bg</strong> : boolean, optional</p> <blockquote><div><p>If True, the background of the image is set to be black. If you wish to save figures with a black background, you will need to pass “facecolor=’k’, edgecolor=’k’” to matplotlib.pyplot.savefig.</p></div></blockquote> <p><strong>cmap</strong> : matplotlib colormap, optional</p> <blockquote><div><p>The colormap for specified image. The ccolormap <em>must</em> be symmetrical.</p></div></blockquote> <p><strong>symmetric_cbar</strong> : boolean or ‘auto’, optional, default ‘auto’</p> <blockquote><div><p>Specifies whether the colorbar should range from -vmax to vmax or from vmin to vmax. Setting to ‘auto’ will select the latter if the range of the whole image is either positive or negative. Note: The colormap will always be set to range from -vmax to vmax.</p></div></blockquote> <p><strong>dim</strong> : float, ‘auto’ (by default), optional</p> <blockquote><div><p>Dimming factor applied to background image. By default, automatic heuristics are applied based upon the background image intensity. Accepted float values, where a typical scan is between -2 and 2 (-2 = increase constrast; 2 = decrease contrast), but larger values can be used for a more pronounced effect. 0 means no dimming.</p></div></blockquote> <p><strong>vmax</strong> : float</p> <blockquote><div><p>Upper bound for plotting, passed to matplotlib.pyplot.imshow</p></div></blockquote> <p><strong>resampling_interpolation</strong> : str</p> <blockquote class=last><div><p>Interpolation to use when resampling the image to the destination space. Can be “continuous” (default) to use 3rd-order spline interpolation, or “nearest” to use nearest-neighbor mapping. “nearest” is faster but can be noisier in some cases.</p></div></blockquote></td></tr></tbody></table> <div class="admonition seealso"><p class="first admonition-title">See also</p><dl class="last docutils"><dt><a class="reference internal"href=nilearn.plotting.plot_anat.html#nilearn.plotting.plot_anat title=nilearn.plotting.plot_anat><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.plotting.plot_anat</span></code></a></dt><dd>To simply plot anatomical images</dd><dt><a class="reference internal"href=nilearn.plotting.plot_epi.html#nilearn.plotting.plot_epi title=nilearn.plotting.plot_epi><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.plotting.plot_epi</span></code></a></dt><dd>To simply plot raw EPI images</dd><dt><a class="reference internal"href=nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain title=nilearn.plotting.plot_glass_brain><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.plotting.plot_glass_brain</span></code></a></dt><dd>To plot maps in a glass brain</dd></dl></div> <p class=rubric>Notes</p> <p>Arrays should be passed in numpy convention: (x, y, z) ordered.</p> <p>For visualization, non-finite values found in passed ‘stat_map_img’ or ‘bg_img’ are set to zero.</p></dd></dl><div class=section id=examples-using-nilearn-plotting-plot-stat-map><h2>8.10.10.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.plotting.plot_stat_map</span></code><a title="Permalink to this headline"class=headerlink href=#examples-using-nilearn-plotting-plot-stat-map>¶</a></h2><div tooltip="Here we discover how to work with 3D and 4D niimgs."class=sphx-glr-thumbcontainer><div class=figure id=id1><img alt="3D and 4D niimgs: handling and visualizing"src=../../_images/sphx_glr_plot_3d_and_4d_niimg_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/plot_3d_and_4d_niimg.html#sphx-glr-auto-examples-plot-3d-and-4d-niimg-py><span class="std std-ref">3D and 4D niimgs: handling and visualizing</span></a></span></p></div></div><div tooltip="In this tutorial, we use a General Linear Model (GLM) to compare the fMRI signal during periods..."class=sphx-glr-thumbcontainer><div class=figure id=id2><img alt="Intro to GLM Analysis: a single-session, single-subject fMRI dataset"src=../../_images/sphx_glr_plot_single_subject_single_run_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/plot_single_subject_single_run.html#sphx-glr-auto-examples-plot-single-subject-single-run-py><span class="std std-ref">Intro to GLM Analysis: a single-session, single-subject fMRI dataset</span></a></span></p></div></div><div tooltip="Visualizing a probablistic atlas requires visualizing the different maps that compose it."class=sphx-glr-thumbcontainer><div class=figure id=id3><img alt="Visualizing a probablistic atlas: the default mode in the MSDL atlas"src=../../_images/sphx_glr_plot_overlay_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_overlay.html#sphx-glr-auto-examples-01-plotting-plot-overlay-py><span class="std std-ref">Visualizing a probablistic atlas: the default mode in the MSDL atlas</span></a></span></p></div></div><div tooltip="The dim argument controls the contrast of the background."class=sphx-glr-thumbcontainer><div class=figure id=id4><img alt="Controling the contrast of the background when plotting"src=../../_images/sphx_glr_plot_dim_plotting_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_dim_plotting.html#sphx-glr-auto-examples-01-plotting-plot-dim-plotting-py><span class="std std-ref">Controling the contrast of the background when plotting</span></a></span></p></div></div><div tooltip="Nilearn comes with a set of plotting functions for easy visualization of Nifti-like images such..."class=sphx-glr-thumbcontainer><div class=figure id=id5><img alt="Plotting tools in nilearn"src=../../_images/sphx_glr_plot_demo_plotting_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_demo_plotting.html#sphx-glr-auto-examples-01-plotting-plot-demo-plotting-py><span class="std std-ref">Plotting tools in nilearn</span></a></span></p></div></div><div tooltip="project a 3D statistical map onto a cortical mesh using nilearn.surface.vol_to_surf. Display a ..."class=sphx-glr-thumbcontainer><div class=figure id=id6><img alt="Making a surface plot of a 3D statistical map"src=../../_images/sphx_glr_plot_3d_map_to_surface_projection_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_3d_map_to_surface_projection.html#sphx-glr-auto-examples-01-plotting-plot-3d-map-to-surface-projection-py><span class="std std-ref">Making a surface plot of a 3D statistical map</span></a></span></p></div></div><div tooltip="In this example, we demonstrate how to use plotting options from nilearn essential in visualizi..."class=sphx-glr-thumbcontainer><div class=figure id=id7><img alt="More plotting tools from nilearn"src=../../_images/sphx_glr_plot_demo_more_plotting_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_demo_more_plotting.html#sphx-glr-auto-examples-01-plotting-plot-demo-more-plotting-py><span class="std std-ref">More plotting tools from nilearn</span></a></span></p></div></div><div tooltip="In this example, we use fast ensembling of regularized models (FREM) to solve a regression prob..."class=sphx-glr-thumbcontainer><div class=figure id=id8><img alt='FREM on Jimura et al "mixed gambles" dataset.'src=../../_images/sphx_glr_plot_mixed_gambles_frem_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/02_decoding/plot_mixed_gambles_frem.html#sphx-glr-auto-examples-02-decoding-plot-mixed-gambles-frem-py><span class="std std-ref">FREM on Jimura et al “mixed gambles” dataset.</span></a></span></p></div></div><div tooltip="This example uses fast ensembling of regularized models (FREM) to decode a face vs house discri..."class=sphx-glr-thumbcontainer><div class=figure id=id9><img alt="Decoding with FREM: face vs house object recognition"src=../../_images/sphx_glr_plot_haxby_frem_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/02_decoding/plot_haxby_frem.html#sphx-glr-auto-examples-02-decoding-plot-haxby-frem-py><span class="std std-ref">Decoding with FREM: face vs house object recognition</span></a></span></p></div></div><div tooltip="Predicting age from gray-matter concentration maps from OASIS dataset. Note that age is a conti..."class=sphx-glr-thumbcontainer><div class=figure id=id10><img alt="Voxel-Based Morphometry on Oasis dataset with Space-Net prior"src=../../_images/sphx_glr_plot_oasis_vbm_space_net_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/02_decoding/plot_oasis_vbm_space_net.html#sphx-glr-auto-examples-02-decoding-plot-oasis-vbm-space-net-py><span class="std std-ref">Voxel-Based Morphometry on Oasis dataset with Space-Net prior</span></a></span></p></div></div><div tooltip="This example does a simple but efficient decoding on the Haxby dataset: using a feature selecti..."class=sphx-glr-thumbcontainer><div class=figure id=id11><img alt="Decoding with ANOVA + SVM: face vs house in the Haxby dataset"src=../../_images/sphx_glr_plot_haxby_anova_svm_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/02_decoding/plot_haxby_anova_svm.html#sphx-glr-auto-examples-02-decoding-plot-haxby-anova-svm-py><span class="std std-ref">Decoding with ANOVA + SVM: face vs house in the Haxby dataset</span></a></span></p></div></div><div tooltip="Searchlight analysis requires fitting a classifier a large amount of times. As a result, it is ..."class=sphx-glr-thumbcontainer><div class=figure id=id12><img alt="Searchlight analysis of face vs house recognition"src=../../_images/sphx_glr_plot_haxby_searchlight_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/02_decoding/plot_haxby_searchlight.html#sphx-glr-auto-examples-02-decoding-plot-haxby-searchlight-py><span class="std std-ref">Searchlight analysis of face vs house recognition</span></a></span></p></div></div><div tooltip="Here we compare different classifiers on a visual object recognition decoding task."class=sphx-glr-thumbcontainer><div class=figure id=id13><img alt="Different classifiers in decoding the Haxby dataset"src=../../_images/sphx_glr_plot_haxby_different_estimators_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/02_decoding/plot_haxby_different_estimators.html#sphx-glr-auto-examples-02-decoding-plot-haxby-different-estimators-py><span class="std std-ref">Different classifiers in decoding the Haxby dataset</span></a></span></p></div></div><div tooltip="This example uses Voxel-Based Morphometry (VBM) to study the relationship between aging and gra..."class=sphx-glr-thumbcontainer><div class=figure id=id14><img alt="Voxel-Based Morphometry on Oasis dataset"src=../../_images/sphx_glr_plot_oasis_vbm_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/02_decoding/plot_oasis_vbm.html#sphx-glr-auto-examples-02-decoding-plot-oasis-vbm-py><span class="std std-ref">Voxel-Based Morphometry on Oasis dataset</span></a></span></p></div></div><div tooltip="This example partly reproduces the encoding model presented in     `Visual image reconstruction..."class=sphx-glr-thumbcontainer><div class=figure id=id15><img alt="Encoding models for visual stimuli from Miyawaki et al. 2008"src=../../_images/sphx_glr_plot_miyawaki_encoding_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/02_decoding/plot_miyawaki_encoding.html#sphx-glr-auto-examples-02-decoding-plot-miyawaki-encoding-py><span class="std std-ref">Encoding models for visual stimuli from Miyawaki et al. 2008</span></a></span></p></div></div><div tooltip="Various approaches exist to derive spatial maps or networks from group fmr data. The methods ex..."class=sphx-glr-thumbcontainer><div class=figure id=id16><img alt="Deriving spatial maps from group fMRI data using ICA and Dictionary Learning"src=../../_images/sphx_glr_plot_compare_decomposition_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_compare_decomposition.html#sphx-glr-auto-examples-03-connectivity-plot-compare-decomposition-py><span class="std std-ref">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</span></a></span></p></div></div><div tooltip="This example shows how to produce seed-to-voxel correlation maps for a single subject based on ..."class=sphx-glr-thumbcontainer><div class=figure id=id17><img alt="Producing single subject maps of seed-to-voxel correlation"src=../../_images/sphx_glr_plot_seed_to_voxel_correlation_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html#sphx-glr-auto-examples-03-connectivity-plot-seed-to-voxel-correlation-py><span class="std std-ref">Producing single subject maps of seed-to-voxel correlation</span></a></span></p></div></div><div tooltip="This example shows how to use nilearn.regions.RegionExtractor to extract spatially constrained ..."class=sphx-glr-thumbcontainer><div class=figure id=id18><img alt="Regions extraction using Dictionary Learning and functional connectomes"src=../../_images/sphx_glr_plot_extract_regions_dictlearning_maps_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html#sphx-glr-auto-examples-03-connectivity-plot-extract-regions-dictlearning-maps-py><span class="std std-ref">Regions extraction using Dictionary Learning and functional connectomes</span></a></span></p></div></div><div tooltip="This example illustrates how to run a fixed effects model based on pre-computed statistics. Thi..."class=sphx-glr-thumbcontainer><div class=figure id=id19><img alt="Example of explicit fixed effects fMRI model fitting"src=../../_images/sphx_glr_plot_fixed_effects_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/04_glm_first_level/plot_fixed_effects.html#sphx-glr-auto-examples-04-glm-first-level-plot-fixed-effects-py><span class="std std-ref">Example of explicit fixed effects fMRI model fitting</span></a></span></p></div></div><div tooltip="This example shows a full step-by-step workflow of fitting a GLM to data extracted from a seed ..."class=sphx-glr-thumbcontainer><div class=figure id=id20><img alt="Default Mode Network extraction of AHDH dataset"src=../../_images/sphx_glr_plot_adhd_dmn_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/04_glm_first_level/plot_adhd_dmn.html#sphx-glr-auto-examples-04-glm-first-level-plot-adhd-dmn-py><span class="std std-ref">Default Mode Network extraction of AHDH dataset</span></a></span></p></div></div><div tooltip="FIR models are used to estimate the hemodyamic response non-parametrically. The example below s..."class=sphx-glr-thumbcontainer><div class=figure id=id21><img alt="Analysis of an fMRI dataset with a Finite Impule Response (FIR) model"src=../../_images/sphx_glr_plot_fir_model_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/04_glm_first_level/plot_fir_model.html#sphx-glr-auto-examples-04-glm-first-level-plot-fir-model-py><span class="std std-ref">Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</span></a></span></p></div></div><div tooltip="The example shows the analysis of an SPM dataset studying face perception.  The anaylsis is per..."class=sphx-glr-thumbcontainer><div class=figure id=id22><img alt="Single-subject data (two sessions) in native space"src=../../_images/sphx_glr_plot_spm_multimodal_faces_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/04_glm_first_level/plot_spm_multimodal_faces.html#sphx-glr-auto-examples-04-glm-first-level-plot-spm-multimodal-faces-py><span class="std std-ref">Single-subject data (two sessions) in native space</span></a></span></p></div></div><div tooltip="Here, we will go through a full step-by-step example of fitting a GLM to experimental data and ..."class=sphx-glr-thumbcontainer><div class=figure id=id23><img alt="Simple example of two-session fMRI model fitting"src=../../_images/sphx_glr_plot_fiac_analysis_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/04_glm_first_level/plot_fiac_analysis.html#sphx-glr-auto-examples-04-glm-first-level-plot-fiac-analysis-py><span class="std std-ref">Simple example of two-session fMRI model fitting</span></a></span></p></div></div><div tooltip="Here we fit a First Level GLM with the minimize_memory-argument set to False. By doing so, the ..."class=sphx-glr-thumbcontainer><div class=figure id=id24><img alt="Predicted time series and residuals"src=../../_images/sphx_glr_plot_predictions_residuals_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/04_glm_first_level/plot_predictions_residuals.html#sphx-glr-auto-examples-04-glm-first-level-plot-predictions-residuals-py><span class="std std-ref">Predicted time series and residuals</span></a></span></p></div></div><div tooltip="In this tutorial, we study how first-level models are parametrized for fMRI data analysis and c..."class=sphx-glr-thumbcontainer><div class=figure id=id25><img alt="Understanding parameters of the first-level model"src=../../_images/sphx_glr_plot_first_level_details_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/04_glm_first_level/plot_first_level_details.html#sphx-glr-auto-examples-04-glm-first-level-plot-first-level-details-py><span class="std std-ref">Understanding parameters of the first-level model</span></a></span></p></div></div><div tooltip='This script showcases the so-called "All resolution inference" procedure, in which the proporti...'class=sphx-glr-thumbcontainer><div class=figure id=id26><img alt="Second-level fMRI model: true positive proportion in clusters"src=../../_images/sphx_glr_plot_proportion_activated_voxels_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/05_glm_second_level/plot_proportion_activated_voxels.html#sphx-glr-auto-examples-05-glm-second-level-plot-proportion-activated-voxels-py><span class="std std-ref">Second-level fMRI model: true positive proportion in clusters</span></a></span></p></div></div><div tooltip="Perform a one-sample t-test on a bunch of images (a.k.a. second-level analyis in fMRI) and thre..."class=sphx-glr-thumbcontainer><div class=figure id=id27><img alt="Statistical testing of a second-level analysis"src=../../_images/sphx_glr_plot_thresholding_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/05_glm_second_level/plot_thresholding.html#sphx-glr-auto-examples-05-glm-second-level-plot-thresholding-py><span class="std std-ref">Statistical testing of a second-level analysis</span></a></span></p></div></div><div tooltip="This example uses Voxel-Based Morphometry (VBM) to study the relationship between aging, sex an..."class=sphx-glr-thumbcontainer><div class=figure id=id28><img alt="Voxel-Based Morphometry on Oasis dataset"src=../../_images/sphx_glr_plot_oasis_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/05_glm_second_level/plot_oasis.html#sphx-glr-auto-examples-05-glm-second-level-plot-oasis-py><span class="std std-ref">Voxel-Based Morphometry on Oasis dataset</span></a></span></p></div></div><div tooltip="This example shows the results obtained in a group analysis using a more complex contrast than ..."class=sphx-glr-thumbcontainer><div class=figure id=id29><img alt="Example of generic design in second-level models"src=../../_images/sphx_glr_plot_second_level_association_test_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/05_glm_second_level/plot_second_level_association_test.html#sphx-glr-auto-examples-05-glm-second-level-plot-second-level-association-test-py><span class="std std-ref">Example of generic design in second-level models</span></a></span></p></div></div><div tooltip="The goal of this example is to illustrate the use of the function nilearn.image.math_img on T-m..."class=sphx-glr-thumbcontainer><div class=figure id=id30><img alt="Negating an image with math_img"src=../../_images/sphx_glr_plot_negate_image_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/06_manipulating_images/plot_negate_image.html#sphx-glr-auto-examples-06-manipulating-images-plot-negate-image-py><span class="std std-ref">Negating an image with math_img</span></a></span></p></div></div><div tooltip="The goal of this example is to illustrate the use of the function nilearn.image.math_img with a..."class=sphx-glr-thumbcontainer><div class=figure id=id31><img alt="Comparing the means of 2 images"src=../../_images/sphx_glr_plot_compare_mean_image_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/06_manipulating_images/plot_compare_mean_image.html#sphx-glr-auto-examples-06-manipulating-images-plot-compare-mean-image-py><span class="std std-ref">Comparing the means of 2 images</span></a></span></p></div></div><div tooltip="This simple example shows how to extract regions from Smith atlas resting state networks."class=sphx-glr-thumbcontainer><div class=figure id=id32><img alt="Regions Extraction of Default Mode Networks using Smith Atlas"src=../../_images/sphx_glr_plot_extract_rois_smith_atlas_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/06_manipulating_images/plot_extract_rois_smith_atlas.html#sphx-glr-auto-examples-06-manipulating-images-plot-extract-rois-smith-atlas-py><span class="std std-ref">Regions Extraction of Default Mode Networks using Smith Atlas</span></a></span></p></div></div><div tooltip="The goal of this example is to illustrate the use of the function nilearn.image.resample_to_img..."class=sphx-glr-thumbcontainer><div class=figure id=id33><img alt="Resample an image to a template"src=../../_images/sphx_glr_plot_resample_to_template_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/06_manipulating_images/plot_resample_to_template.html#sphx-glr-auto-examples-06-manipulating-images-plot-resample-to-template-py><span class="std std-ref">Resample an image to a template</span></a></span></p></div></div><div tooltip="Here is a simple example of automatic mask computation using the nifti masker. The mask is comp..."class=sphx-glr-thumbcontainer><div class=figure id=id34><img alt="Simple example of NiftiMasker use"src=../../_images/sphx_glr_plot_nifti_simple_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/06_manipulating_images/plot_nifti_simple.html#sphx-glr-auto-examples-06-manipulating-images-plot-nifti-simple-py><span class="std std-ref">Simple example of NiftiMasker use</span></a></span></p></div></div><div tooltip="This example shows how to extract regions or separate the regions from a statistical map."class=sphx-glr-thumbcontainer><div class=figure id=id35><img alt="Region Extraction using a t-statistical map (3D)"src=../../_images/sphx_glr_plot_extract_rois_statistical_maps_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/06_manipulating_images/plot_extract_rois_statistical_maps.html#sphx-glr-auto-examples-06-manipulating-images-plot-extract-rois-statistical-maps-py><span class="std std-ref">Region Extraction using a t-statistical map (3D)</span></a></span></p></div></div><div tooltip="This example shows manual steps to create and further modify an ROI spatial mask. They represen..."class=sphx-glr-thumbcontainer><div class=figure id=id36><img alt="Computing a Region of Interest (ROI) mask manually"src=../../_images/sphx_glr_plot_roi_extraction_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/06_manipulating_images/plot_roi_extraction.html#sphx-glr-auto-examples-06-manipulating-images-plot-roi-extraction-py><span class="std std-ref">Computing a Region of Interest (ROI) mask manually</span></a></span></p></div></div><div tooltip=" This example is meant to demonstrate nilearn as a low-level tools used to combine feature extr..."class=sphx-glr-thumbcontainer><div class=figure id=id37><img alt="Multivariate decompositions: Independent component analysis of fMRI"src=../../_images/sphx_glr_plot_ica_resting_state_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/07_advanced/plot_ica_resting_state.html#sphx-glr-auto-examples-07-advanced-plot-ica-resting-state-py><span class="std std-ref">Multivariate decompositions: Independent component analysis of fMRI</span></a></span></p></div></div><div tooltip="This example shows how to use the Localizer dataset in a basic analysis. A standard Anova is pe..."class=sphx-glr-thumbcontainer><div class=figure id=id38><img alt="Massively univariate analysis of a calculation task from the Localizer dataset"src=../../_images/sphx_glr_plot_localizer_simple_analysis_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/07_advanced/plot_localizer_simple_analysis.html#sphx-glr-auto-examples-07-advanced-plot-localizer-simple-analysis-py><span class="std std-ref">Massively univariate analysis of a calculation task from the Localizer dataset</span></a></span></p></div></div><div tooltip="This example shows how to download statistical maps from NeuroVault"class=sphx-glr-thumbcontainer><div class=figure id=id39><img alt="NeuroVault meta-analysis of stop-go paradigm studies."src=../../_images/sphx_glr_plot_neurovault_meta_analysis_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/07_advanced/plot_neurovault_meta_analysis.html#sphx-glr-auto-examples-07-advanced-plot-neurovault-meta-analysis-py><span class="std std-ref">NeuroVault meta-analysis of stop-go paradigm studies.</span></a></span></p></div></div><div tooltip="This example shows the results obtained in a massively univariate analysis performed at the int..."class=sphx-glr-thumbcontainer><div class=figure id=id40><img alt="Massively univariate analysis of a motor task from the Localizer dataset"src=../../_images/sphx_glr_plot_localizer_mass_univariate_methods_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/07_advanced/plot_localizer_mass_univariate_methods.html#sphx-glr-auto-examples-07-advanced-plot-localizer-mass-univariate-methods-py><span class="std std-ref">Massively univariate analysis of a motor task from the Localizer dataset</span></a></span></p></div></div><div tooltip="This example shows how to download statistical maps from NeuroVault, label them with NeuroSynth..."class=sphx-glr-thumbcontainer><div class=figure id=id41><img alt="NeuroVault cross-study ICA maps."src=../../_images/sphx_glr_plot_ica_neurovault_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/07_advanced/plot_ica_neurovault.html#sphx-glr-auto-examples-07-advanced-plot-ica-neurovault-py><span class="std std-ref">NeuroVault cross-study ICA maps.</span></a></span></p></div></div><div tooltip="A permuted Ordinary Least Squares algorithm is run at each voxel in order to detemine whether o..."class=sphx-glr-thumbcontainer><div class=figure id=id42><img alt="Massively univariate analysis of face vs house recognition"src=../../_images/sphx_glr_plot_haxby_mass_univariate_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/07_advanced/plot_haxby_mass_univariate.html#sphx-glr-auto-examples-07-advanced-plot-haxby-mass-univariate-py><span class="std std-ref">Massively univariate analysis of face vs house recognition</span></a></span></p></div></div><div tooltip="This tutorial opens the box of decoding pipelines to bridge integrated functionalities provided..."class=sphx-glr-thumbcontainer><div class=figure id=id43><img alt="Advanced decoding using scikit learn"src=../../_images/sphx_glr_plot_advanced_decoding_scikit_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/07_advanced/plot_advanced_decoding_scikit.html#sphx-glr-auto-examples-07-advanced-plot-advanced-decoding-scikit-py><span class="std std-ref">Advanced decoding using scikit learn</span></a></span></p></div></div><div style=clear:both></div></div></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>8.10.10. nilearn.plotting.plot_stat_map</a><ul><li><a class="reference internal"href=#examples-using-nilearn-plotting-plot-stat-map>8.10.10.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.plotting.plot_stat_map</span></code></a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=nilearn.plotting.plot_roi.html>8.10.9. nilearn.plotting.plot_roi</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=nilearn.plotting.plot_glass_brain.html>8.10.11. nilearn.plotting.plot_glass_brain</a></p><div id=searchbox role=search style=display:none><h3>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input name=q><input type=submit value=Go><input name=check_keywords type=hidden value=yes><input name=area type=hidden value=default></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2020. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 1.8.5. <span style=padding-left:5ex> <a href=../../_sources/modules/generated/nilearn.plotting.plot_stat_map.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>