<!doctypehtml><html lang=en xmlns=http://www.w3.org/1999/xhtml><meta content=IE=Edge http-equiv=X-UA-Compatible><meta content="text/html; charset=utf-8"http-equiv=Content-Type><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/gallery.css rel=stylesheet><link href=../../_static/gallery-binder.css rel=stylesheet><link href=../../_static/gallery-dataframe.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/language_data.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="8.6.4. nilearn.input_data.NiftiMapsMasker"href=nilearn.input_data.NiftiMapsMasker.html rel=next><link title="8.6.2. nilearn.input_data.MultiNiftiMasker"href=nilearn.input_data.MultiNiftiMasker.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script></head><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="8.6.4. nilearn.input_data.NiftiMapsMasker"accesskey=N href=nilearn.input_data.NiftiMapsMasker.html>next</a> |</li><li class=right><a title="8.6.2. nilearn.input_data.MultiNiftiMasker"accesskey=P href=nilearn.input_data.MultiNiftiMasker.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../../auto_examples/index.html>Examples</a> | </li><li><a href=../reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../reference.html>8. Reference documentation: all nilearn functions</a> »</li></ul></div></div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="admonition note"><p class="first admonition-title">Note</p><p class=last>This page is a reference documentation. It only explains the class signature, and not how to use it. Please refer to the <a class="reference internal"href=../../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for the big picture.</p></div><div class=section id=nilearn-input-data-niftilabelsmasker><h1>8.6.3. nilearn.input_data.NiftiLabelsMasker<a title="Permalink to this headline"class=headerlink href=#nilearn-input-data-niftilabelsmasker>¶</a></h1><dl class=class><dt id=nilearn.input_data.NiftiLabelsMasker><em class=property>class </em><code class=descclassname>nilearn.input_data.</code><code class=descname>NiftiLabelsMasker</code><span class=sig-paren>(</span><em>labels_img</em>, <em>background_label=0</em>, <em>mask_img=None</em>, <em>smoothing_fwhm=None</em>, <em>standardize=False</em>, <em>detrend=False</em>, <em>low_pass=None</em>, <em>high_pass=None</em>, <em>t_r=None</em>, <em>dtype=None</em>, <em>resampling_target='data'</em>, <em>memory=Memory(location=None)</em>, <em>memory_level=1</em>, <em>verbose=0</em>, <em>strategy='mean'</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.NiftiLabelsMasker>¶</a></dt><dd><p>Class for masking of Niimg-like objects.</p> <p>NiftiLabelsMasker is useful when data from non-overlapping volumes should be extracted (contrarily to NiftiMapsMasker). Use case: Summarize brain signals from clusters that were obtained by prior K-means or Ward clustering.</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>labels_img: Niimg-like object</strong></p> <blockquote><div><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> Region definitions, as one image of labels.</p></div></blockquote> <p><strong>background_label: number, optional</strong></p> <blockquote><div><p>Label used in labels_img to represent background.</p></div></blockquote> <p><strong>mask_img: Niimg-like object, optional</strong></p> <blockquote><div><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> Mask to apply to regions before extracting signals.</p></div></blockquote> <p><strong>smoothing_fwhm: float, optional</strong></p> <blockquote><div><p>If smoothing_fwhm is not None, it gives the full-width half maximum in millimeters of the spatial smoothing to apply to the signal.</p></div></blockquote> <p><strong>standardize: {‘zscore’, ‘psc’, True, False}, default is ‘zscore’</strong></p> <blockquote><div><p>Strategy to standardize the signal. ‘zscore’: the signal is z-scored. Timeseries are shifted to zero mean and scaled to unit variance. ‘psc’: Timeseries are shifted to zero mean value and scaled to percent signal change (as compared to original mean signal). True : the signal is z-scored. Timeseries are shifted to zero mean and scaled to unit variance. False : Do not standardize the data.</p></div></blockquote> <p><strong>detrend: boolean, optional</strong></p> <blockquote><div><p>This parameter is passed to signal.clean. Please see the related documentation for details</p></div></blockquote> <p><strong>low_pass: None or float, optional</strong></p> <blockquote><div><p>This parameter is passed to signal.clean. Please see the related documentation for details</p></div></blockquote> <p><strong>high_pass: None or float, optional</strong></p> <blockquote><div><p>This parameter is passed to signal.clean. Please see the related documentation for details</p></div></blockquote> <p><strong>t_r: float, optional</strong></p> <blockquote><div><p>This parameter is passed to signal.clean. Please see the related documentation for details</p></div></blockquote> <p><strong>dtype: {dtype, “auto”}</strong></p> <blockquote><div><p>Data type toward which the data should be converted. If “auto”, the data will be converted to int32 if dtype is discrete and float32 if it is continuous.</p></div></blockquote> <p><strong>resampling_target: {“data”, “labels”, None}, optional.</strong></p> <blockquote><div><p>Gives which image gives the final shape/size. For example, if <cite>resampling_target</cite> is “data”, the atlas is resampled to the shape of the data if needed. If it is “labels” then mask_img and images provided to fit() are resampled to the shape and affine of maps_img. “None” means no resampling: if shapes and affines do not match, a ValueError is raised. Defaults to “data”.</p></div></blockquote> <p><strong>memory: joblib.Memory or str, optional</strong></p> <blockquote><div><p>Used to cache the region extraction process. By default, no caching is done. If a string is given, it is the path to the caching directory.</p></div></blockquote> <p><strong>memory_level: int, optional</strong></p> <blockquote><div><p>Aggressiveness of memory caching. The higher the number, the higher the number of functions that will be cached. Zero means no caching.</p></div></blockquote> <p><strong>verbose: integer, optional</strong></p> <blockquote><div><p>Indicate the level of verbosity. By default, nothing is printed</p></div></blockquote> <p><strong>strategy: str</strong></p> <blockquote class=last><div><p>The name of a valid function to reduce the region with. Must be one of: sum, mean, median, mininum, maximum, variance, standard_deviation</p></div></blockquote></td></tr></tbody></table> <div class="admonition seealso"><p class="first admonition-title">See also</p><p class=last><a class="reference internal"href=nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker title=nilearn.input_data.NiftiMasker><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.input_data.NiftiMasker</span></code></a></p></div> <dl class=method><dt id=nilearn.input_data.NiftiLabelsMasker.__init__><code class=descname>__init__</code><span class=sig-paren>(</span><em>labels_img</em>, <em>background_label=0</em>, <em>mask_img=None</em>, <em>smoothing_fwhm=None</em>, <em>standardize=False</em>, <em>detrend=False</em>, <em>low_pass=None</em>, <em>high_pass=None</em>, <em>t_r=None</em>, <em>dtype=None</em>, <em>resampling_target='data'</em>, <em>memory=Memory(location=None)</em>, <em>memory_level=1</em>, <em>verbose=0</em>, <em>strategy='mean'</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.NiftiLabelsMasker.__init__>¶</a></dt><dd><p>Initialize self. See help(type(self)) for accurate signature.</p></dd></dl> <dl class=method><dt id=nilearn.input_data.NiftiLabelsMasker.fit><code class=descname>fit</code><span class=sig-paren>(</span><em>X=None</em>, <em>y=None</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.NiftiLabelsMasker.fit>¶</a></dt><dd><p>Prepare signal extraction from regions.</p> <p>All parameters are unused, they are for scikit-learn compatibility.</p></dd></dl> <dl class=method><dt id=nilearn.input_data.NiftiLabelsMasker.fit_transform><code class=descname>fit_transform</code><span class=sig-paren>(</span><em>imgs</em>, <em>confounds=None</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.NiftiLabelsMasker.fit_transform>¶</a></dt><dd><p>Prepare and perform signal extraction from regions.</p></dd></dl> <dl class=method><dt id=nilearn.input_data.NiftiLabelsMasker.get_params><code class=descname>get_params</code><span class=sig-paren>(</span><em>deep=True</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.NiftiLabelsMasker.get_params>¶</a></dt><dd><p>Get parameters for this estimator.</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>deep</strong> : bool, default=True</p> <blockquote><div><p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p></div></blockquote></td></tr><tr class="field-even field"><th class=field-name>Returns:</th><td class=field-body><p class=first><strong>params</strong> : mapping of string to any</p> <blockquote class=last><div><p>Parameter names mapped to their values.</p></div></blockquote></td></tr></tbody></table></dd></dl> <dl class=method><dt id=nilearn.input_data.NiftiLabelsMasker.inverse_transform><code class=descname>inverse_transform</code><span class=sig-paren>(</span><em>signals</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.NiftiLabelsMasker.inverse_transform>¶</a></dt><dd><p>Compute voxel signals from region signals</p> <p>Any mask given at initialization is taken into account.</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>signals (2D numpy.ndarray)</strong></p> <blockquote><div><p>Signal for each region. shape: (number of scans, number of regions)</p></div></blockquote></td></tr><tr class="field-even field"><th class=field-name>Returns:</th><td class=field-body><p class=first>voxel_signals (Nifti1Image)</p> <blockquote class=last><div><p>Signal for each voxel shape: (number of scans, number of voxels)</p></div></blockquote></td></tr></tbody></table></dd></dl> <dl class=method><dt id=nilearn.input_data.NiftiLabelsMasker.set_params><code class=descname>set_params</code><span class=sig-paren>(</span><em>**params</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.NiftiLabelsMasker.set_params>¶</a></dt><dd><p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <code class="docutils literal notranslate"><span class=pre>&LTcomponent>__&LTparameter></span></code> so that it’s possible to update each component of a nested object.</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>**params</strong> : dict</p> <blockquote><div><p>Estimator parameters.</p></div></blockquote></td></tr><tr class="field-even field"><th class=field-name>Returns:</th><td class=field-body><p class=first><strong>self</strong> : object</p> <blockquote class=last><div><p>Estimator instance.</p></div></blockquote></td></tr></tbody></table></dd></dl> <dl class=method><dt id=nilearn.input_data.NiftiLabelsMasker.transform><code class=descname>transform</code><span class=sig-paren>(</span><em>imgs</em>, <em>confounds=None</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.NiftiLabelsMasker.transform>¶</a></dt><dd><p>Apply mask, spatial and temporal preprocessing</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>imgs: 3D/4D Niimg-like object</strong></p> <blockquote><div><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> Images to process. It must boil down to a 4D image with scans number as last dimension.</p></div></blockquote> <p><strong>confounds: CSV file or array-like, optional</strong></p> <blockquote><div><p>This parameter is passed to signal.clean. Please see the related documentation for details. shape: (number of scans, number of confounds)</p></div></blockquote></td></tr><tr class="field-even field"><th class=field-name>Returns:</th><td class=field-body><p class=first>region_signals: 2D numpy.ndarray</p> <blockquote class=last><div><p>Signal for each element. shape: (number of scans, number of elements)</p></div></blockquote></td></tr></tbody></table></dd></dl> <dl class=method><dt id=nilearn.input_data.NiftiLabelsMasker.transform_single_imgs><code class=descname>transform_single_imgs</code><span class=sig-paren>(</span><em>imgs</em>, <em>confounds=None</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.NiftiLabelsMasker.transform_single_imgs>¶</a></dt><dd><p>Extract signals from a single 4D niimg.</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>imgs: 3D/4D Niimg-like object</strong></p> <blockquote><div><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> Images to process. It must boil down to a 4D image with scans number as last dimension.</p></div></blockquote> <p><strong>confounds: CSV file or array-like or pandas DataFrame, optional</strong></p> <blockquote><div><p>This parameter is passed to signal.clean. Please see the related documentation for details. shape: (number of scans, number of confounds)</p></div></blockquote></td></tr><tr class="field-even field"><th class=field-name>Returns:</th><td class=field-body><p class=first>region_signals: 2D numpy.ndarray</p> <blockquote class=last><div><p>Signal for each label. shape: (number of scans, number of labels)</p></div></blockquote></td></tr></tbody></table></dd></dl></dd></dl><div class=section id=examples-using-nilearn-input-data-niftilabelsmasker><h2>8.6.3.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.input_data.NiftiLabelsMasker</span></code><a title="Permalink to this headline"class=headerlink href=#examples-using-nilearn-input-data-niftilabelsmasker>¶</a></h2><div tooltip="Here we show how to extract signals from a brain parcellation and compute a correlation matrix."class=sphx-glr-thumbcontainer><div class=figure id=id1><img alt="Extracting signals from a brain parcellation"src=../../_images/sphx_glr_plot_signal_extraction_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_signal_extraction.html#sphx-glr-auto-examples-03-connectivity-plot-signal-extraction-py><span class="std std-ref">Extracting signals from a brain parcellation</span></a></span></p></div></div><div tooltip="This examples shows how to turn a parcellation into connectome for visualization. This requires..."class=sphx-glr-thumbcontainer><div class=figure id=id2><img alt="Comparing connectomes on different reference atlases"src=../../_images/sphx_glr_plot_atlas_comparison_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/03_connectivity/plot_atlas_comparison.html#sphx-glr-auto-examples-03-connectivity-plot-atlas-comparison-py><span class="std std-ref">Comparing connectomes on different reference atlases</span></a></span></p></div></div><div tooltip="This example shows manual steps to create and further modify an ROI spatial mask. They represen..."class=sphx-glr-thumbcontainer><div class=figure id=id3><img alt="Computing a Region of Interest (ROI) mask manually"src=../../_images/sphx_glr_plot_roi_extraction_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/06_manipulating_images/plot_roi_extraction.html#sphx-glr-auto-examples-06-manipulating-images-plot-roi-extraction-py><span class="std std-ref">Computing a Region of Interest (ROI) mask manually</span></a></span></p></div></div><div style=clear:both></div></div></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>8.6.3. nilearn.input_data.NiftiLabelsMasker</a><ul><li><a class="reference internal"href=#examples-using-nilearn-input-data-niftilabelsmasker>8.6.3.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.input_data.NiftiLabelsMasker</span></code></a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=nilearn.input_data.MultiNiftiMasker.html>8.6.2. nilearn.input_data.MultiNiftiMasker</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=nilearn.input_data.NiftiMapsMasker.html>8.6.4. nilearn.input_data.NiftiMapsMasker</a></p><div id=searchbox role=search style=display:none><h3>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input name=q><input type=submit value=Go><input name=check_keywords type=hidden value=yes><input name=area type=hidden value=default></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2020. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 1.8.5. <span style=padding-left:5ex> <a href=../../_sources/modules/generated/nilearn.input_data.NiftiLabelsMasker.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>