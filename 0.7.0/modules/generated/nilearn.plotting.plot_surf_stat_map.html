<!doctypehtml><html lang=en xmlns=http://www.w3.org/1999/xhtml><meta content=IE=Edge http-equiv=X-UA-Compatible><meta content="text/html; charset=utf-8"http-equiv=Content-Type><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/gallery.css rel=stylesheet><link href=../../_static/gallery-binder.css rel=stylesheet><link href=../../_static/gallery-dataframe.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/language_data.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="8.10.21. nilearn.plotting.plot_img_on_surf"href=nilearn.plotting.plot_img_on_surf.html rel=next><link title="8.10.19. nilearn.plotting.plot_surf_contours"href=nilearn.plotting.plot_surf_contours.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script></head><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="8.10.21. nilearn.plotting.plot_img_on_surf"accesskey=N href=nilearn.plotting.plot_img_on_surf.html>next</a> |</li><li class=right><a title="8.10.19. nilearn.plotting.plot_surf_contours"accesskey=P href=nilearn.plotting.plot_surf_contours.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../../auto_examples/index.html>Examples</a> | </li><li><a href=../reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../reference.html>8. Reference documentation: all nilearn functions</a> »</li></ul></div></div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="admonition note"><p class="first admonition-title">Note</p><p class=last>This page is a reference documentation. It only explains the function signature, and not how to use it. Please refer to the <a class="reference internal"href=../../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for the big picture.</p></div><div class=section id=nilearn-plotting-plot-surf-stat-map><h1>8.10.20. nilearn.plotting.plot_surf_stat_map<a title="Permalink to this headline"class=headerlink href=#nilearn-plotting-plot-surf-stat-map>¶</a></h1><dl class=function><dt id=nilearn.plotting.plot_surf_stat_map><code class=descclassname>nilearn.plotting.</code><code class=descname>plot_surf_stat_map</code><span class=sig-paren>(</span><em>surf_mesh</em>, <em>stat_map</em>, <em>bg_map=None</em>, <em>hemi='left'</em>, <em>view='lateral'</em>, <em>threshold=None</em>, <em>alpha='auto'</em>, <em>vmax=None</em>, <em>cmap='cold_hot'</em>, <em>colorbar=True</em>, <em>symmetric_cbar='auto'</em>, <em>bg_on_data=False</em>, <em>darkness=1</em>, <em>title=None</em>, <em>output_file=None</em>, <em>axes=None</em>, <em>figure=None</em>, <em>**kwargs</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.plotting.plot_surf_stat_map>¶</a></dt><dd><p>Plotting a stats map on a surface mesh with optional background</p> <div class=versionadded><p><span class=versionmodified>New in version 0.3.</span></p></div> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>surf_mesh</strong> : str or list of two numpy.ndarray</p> <blockquote><div><p>Surface mesh geometry, can be a file (valid formats are .gii or Freesurfer specific files such as .orig, .pial, .sphere, .white, .inflated) or a list of two Numpy arrays, the first containing the x-y-z coordinates of the mesh vertices, the second containing the indices (into coords) of the mesh faces</p></div></blockquote> <p><strong>stat_map</strong> : str or numpy.ndarray</p> <blockquote><div><p>Statistical map to be displayed on the surface mesh, can be a file (valid formats are .gii, .mgz, .nii, .nii.gz, or Freesurfer specific files such as .thickness, .curv, .sulc, .annot, .label) or a Numpy array with a value for each vertex of the surf_mesh.</p></div></blockquote> <p><strong>bg_map</strong> : Surface data object (to be defined), optional,</p> <blockquote><div><p>Background image to be plotted on the mesh underneath the stat_map in greyscale, most likely a sulcal depth map for realistic shading.</p></div></blockquote> <p><strong>hemi</strong> : {‘left’, ‘right’}, default is ‘left’</p> <blockquote><div><p>Hemispere to display.</p></div></blockquote> <p><strong>view: {‘lateral’, ‘medial’, ‘dorsal’, ‘ventral’, ‘anterior’, ‘posterior’},</strong></p> <blockquote><div><p>default is ‘lateral’ View of the surface that is rendered.</p></div></blockquote> <p><strong>threshold</strong> : a number or None, default is None</p> <blockquote><div><p>If None is given, the image is not thresholded. If a number is given, it is used to threshold the image, values below the threshold (in absolute value) are plotted as transparent.</p></div></blockquote> <p><strong>cmap</strong> : matplotlib colormap in str or colormap object, default ‘cold_hot’</p> <blockquote><div><p>To use for plotting of the stat_map. Either a string which is a name of a matplotlib colormap, or a matplotlib colormap object.</p></div></blockquote> <p><strong>colorbar</strong> : bool, optional, default is False</p> <blockquote><div><p>If True, a symmetric colorbar of the statistical map is displayed.</p></div></blockquote> <p><strong>alpha</strong> : float, alpha level of the mesh (not the stat_map), default ‘auto’</p> <blockquote><div><p>If ‘auto’ is chosen, alpha will default to .5 when no bg_map is passed and to 1 if a bg_map is passed.</p></div></blockquote> <p><strong>vmax</strong> : upper bound for plotting of stat_map values.</p> <p><strong>symmetric_cbar</strong> : bool or ‘auto’, optional, default ‘auto’</p> <blockquote><div><p>Specifies whether the colorbar should range from -vmax to vmax or from vmin to vmax. Setting to ‘auto’ will select the latter if the range of the whole image is either positive or negative. Note: The colormap will always range from -vmax to vmax.</p></div></blockquote> <p><strong>bg_on_data</strong> : bool, default is False</p> <blockquote><div><p>If True, and a bg_map is specified, the stat_map data is multiplied by the background image, so that e.g. sulcal depth is visible beneath the stat_map. NOTE: that this non-uniformly changes the stat_map values according to e.g the sulcal depth.</p></div></blockquote> <p><strong>darkness: float, between 0 and 1, default 1</strong></p> <blockquote><div><p>Specifying the darkness of the background image. 1 indicates that the original values of the background are used. .5 indicates the background values are reduced by half before being applied.</p></div></blockquote> <p><strong>title</strong> : str, optional</p> <blockquote><div><p>Figure title.</p></div></blockquote> <p><strong>output_file: str, or None, optional</strong></p> <blockquote><div><p>The name of an image file to export plot to. Valid extensions are .png, .pdf, .svg. If output_file is not None, the plot is saved to a file, and the display is closed.</p></div></blockquote> <p><strong>axes: instance of matplotlib axes, None, optional</strong></p> <blockquote><div><p>The axes instance to plot to. The projection must be ‘3d’ (e.g., <cite>figure, axes = plt.subplots(subplot_kw={‘projection’: ‘3d’})</cite>, where axes should be passed.). If None, a new axes is created.</p></div></blockquote> <p><strong>figure: instance of matplotlib figure, None, optional</strong></p> <blockquote class=last><div><p>The figure instance to plot to. If None, a new figure is created.</p></div></blockquote></td></tr></tbody></table> <div class="admonition seealso"><p class="first admonition-title">See also</p><dl class="last docutils"><dt><a class="reference internal"href=nilearn.datasets.fetch_surf_fsaverage.html#nilearn.datasets.fetch_surf_fsaverage title=nilearn.datasets.fetch_surf_fsaverage><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.datasets.fetch_surf_fsaverage</span></code></a></dt><dd>For surface data object to be used as background map for this plotting function.</dd><dt><a class="reference internal"href=nilearn.plotting.plot_surf.html#nilearn.plotting.plot_surf title=nilearn.plotting.plot_surf><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.plotting.plot_surf</span></code></a></dt><dd>For brain surface visualization.</dd></dl></div></dd></dl><div class=section id=examples-using-nilearn-plotting-plot-surf-stat-map><h2>8.10.20.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.plotting.plot_surf_stat_map</span></code><a title="Permalink to this headline"class=headerlink href=#examples-using-nilearn-plotting-plot-surf-stat-map>¶</a></h2><div tooltip="In nilearn, nilearn.surface.vol_to_surf allows us to measure values of a 3d volume at the nodes..."class=sphx-glr-thumbcontainer><div class=figure id=id1><img alt="Technical point: Illustration of the volume to surface sampling schemes"src=../../_images/sphx_glr_plot_surface_projection_strategies_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_surface_projection_strategies.html#sphx-glr-auto-examples-01-plotting-plot-surface-projection-strategies-py><span class="std std-ref">Technical point: Illustration of the volume to surface sampling schemes</span></a></span></p></div></div><div tooltip="project a 3D statistical map onto a cortical mesh using nilearn.surface.vol_to_surf. Display a ..."class=sphx-glr-thumbcontainer><div class=figure id=id2><img alt="Making a surface plot of a 3D statistical map"src=../../_images/sphx_glr_plot_3d_map_to_surface_projection_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_3d_map_to_surface_projection.html#sphx-glr-auto-examples-01-plotting-plot-3d-map-to-surface-projection-py><span class="std std-ref">Making a surface plot of a 3D statistical map</span></a></span></p></div></div><div tooltip="The dataset that is a subset of the enhanced NKI Rockland sample (http://fcon_1000.projects.nit..."class=sphx-glr-thumbcontainer><div class=figure id=id3><img alt="Seed-based connectivity on the surface"src=../../_images/sphx_glr_plot_surf_stat_map_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_surf_stat_map.html#sphx-glr-auto-examples-01-plotting-plot-surf-stat-map-py><span class="std std-ref">Seed-based connectivity on the surface</span></a></span></p></div></div><div tooltip="This is a demo for surface-based searchlight decoding, as described in: Chen, Y., Namburi, P., ..."class=sphx-glr-thumbcontainer><div class=figure id=id4><img alt="Cortical surface-based searchlight decoding"src=../../_images/sphx_glr_plot_haxby_searchlight_surface_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/02_decoding/plot_haxby_searchlight_surface.html#sphx-glr-auto-examples-02-decoding-plot-haxby-searchlight-surface-py><span class="std std-ref">Cortical surface-based searchlight decoding</span></a></span></p></div></div><div tooltip="A full step-by-step example of fitting a GLM to experimental data sampled on the cortical surfa..."class=sphx-glr-thumbcontainer><div class=figure id=id5><img alt="Example of surface-based first-level analysis"src=../../_images/sphx_glr_plot_localizer_surface_analysis_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/04_glm_first_level/plot_localizer_surface_analysis.html#sphx-glr-auto-examples-04-glm-first-level-plot-localizer-surface-analysis-py><span class="std std-ref">Example of surface-based first-level analysis</span></a></span></p></div></div><div tooltip=" Full step-by-step example of fitting a GLM (first and second level analysis) in a 10-subjects ..."class=sphx-glr-thumbcontainer><div class=figure id=id6><img alt="Surface-based dataset first and second level analysis of a dataset"src=../../_images/sphx_glr_plot_surface_bids_analysis_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/07_advanced/plot_surface_bids_analysis.html#sphx-glr-auto-examples-07-advanced-plot-surface-bids-analysis-py><span class="std std-ref">Surface-based dataset first and second level analysis of a dataset</span></a></span></p></div></div><div style=clear:both></div></div></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>8.10.20. nilearn.plotting.plot_surf_stat_map</a><ul><li><a class="reference internal"href=#examples-using-nilearn-plotting-plot-surf-stat-map>8.10.20.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.plotting.plot_surf_stat_map</span></code></a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=nilearn.plotting.plot_surf_contours.html>8.10.19. nilearn.plotting.plot_surf_contours</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=nilearn.plotting.plot_img_on_surf.html>8.10.21. nilearn.plotting.plot_img_on_surf</a></p><div id=searchbox role=search style=display:none><h3>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input name=q><input type=submit value=Go><input name=check_keywords type=hidden value=yes><input name=area type=hidden value=default></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2020. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 1.8.5. <span style=padding-left:5ex> <a href=../../_sources/modules/generated/nilearn.plotting.plot_surf_stat_map.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>