<!doctypehtml><html lang=en xmlns=http://www.w3.org/1999/xhtml><meta content=IE=Edge http-equiv=X-UA-Compatible><meta content="text/html; charset=utf-8"http-equiv=Content-Type><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/gallery.css rel=stylesheet><link href=../../_static/gallery-binder.css rel=stylesheet><link href=../../_static/gallery-dataframe.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/language_data.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="8.10.31. nilearn.plotting.show"href=nilearn.plotting.show.html rel=next><link title="8.10.29. nilearn.plotting.view_markers"href=nilearn.plotting.view_markers.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script></head><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="8.10.31. nilearn.plotting.show"accesskey=N href=nilearn.plotting.show.html>next</a> |</li><li class=right><a title="8.10.29. nilearn.plotting.view_markers"accesskey=P href=nilearn.plotting.view_markers.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../../auto_examples/index.html>Examples</a> | </li><li><a href=../reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../reference.html>8. Reference documentation: all nilearn functions</a> »</li></ul></div></div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="admonition note"><p class="first admonition-title">Note</p><p class=last>This page is a reference documentation. It only explains the function signature, and not how to use it. Please refer to the <a class="reference internal"href=../../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for the big picture.</p></div><div class=section id=nilearn-plotting-view-img><h1>8.10.30. nilearn.plotting.view_img<a title="Permalink to this headline"class=headerlink href=#nilearn-plotting-view-img>¶</a></h1><dl class=function><dt id=nilearn.plotting.view_img><code class=descclassname>nilearn.plotting.</code><code class=descname>view_img</code><span class=sig-paren>(</span><em>stat_map_img</em>, <em>bg_img='MNI152'</em>, <em>cut_coords=None</em>, <em>colorbar=True</em>, <em>title=None</em>, <em>threshold=1e-06</em>, <em>annotate=True</em>, <em>draw_cross=True</em>, <em>black_bg='auto'</em>, <em>cmap=&LTmatplotlib.colors.LinearSegmentedColormap object></em>, <em>symmetric_cmap=True</em>, <em>dim='auto'</em>, <em>vmax=None</em>, <em>vmin=None</em>, <em>resampling_interpolation='continuous'</em>, <em>opacity=1</em>, <em>**kwargs</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.plotting.view_img>¶</a></dt><dd><p>Interactive html viewer of a statistical map, with optional background</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>stat_map_img</strong> : Niimg-like object</p> <blockquote><div><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> The statistical map image. Can be either a 3D volume or a 4D volume with exactly one time point.</p></div></blockquote> <p><strong>bg_img</strong> : Niimg-like object (default=’MNI152’)</p> <blockquote><div><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> The background image that the stat map will be plotted on top of. If nothing is specified, the MNI152 template will be used. To turn off background image, just pass “bg_img=False”.</p></div></blockquote> <p><strong>cut_coords</strong> : None, or a tuple of floats (default None)</p> <blockquote><div><p>The MNI coordinates of the point where the cut is performed as a 3-tuple: (x, y, z). If None is given, the cuts are calculated automaticaly.</p></div></blockquote> <p><strong>colorbar</strong> : boolean, optional (default True)</p> <blockquote><div><p>If True, display a colorbar on top of the plots.</p></div></blockquote> <p><strong>title</strong> : string or None (default=None)</p> <blockquote><div><p>The title displayed on the figure (or None: no title).</p></div></blockquote> <p><strong>threshold</strong> : string, number or None (default=1e-6)</p> <blockquote><div><p>If None is given, the image is not thresholded. If a string of the form “90%” is given, use the 90-th percentile of the absolute value in the image. If a number is given, it is used to threshold the image: values below the threshold (in absolute value) are plotted as transparent. If auto is given, the threshold is determined automatically.</p></div></blockquote> <p><strong>annotate</strong> : boolean (default=True)</p> <blockquote><div><p>If annotate is True, current cuts are added to the viewer.</p></div></blockquote> <p><strong>draw_cross</strong> : boolean (default=True)</p> <blockquote><div><p>If draw_cross is True, a cross is drawn on the plot to indicate the cuts.</p></div></blockquote> <p><strong>black_bg</strong> : boolean (default=’auto’)</p> <blockquote><div><p>If True, the background of the image is set to be black. Otherwise, a white background is used. If set to auto, an educated guess is made to find if the background is white or black.</p></div></blockquote> <p><strong>cmap</strong> : matplotlib colormap, optional</p> <blockquote><div><p>The colormap for specified image.</p></div></blockquote> <p><strong>symmetric_cmap</strong> : bool, optional (default=True)</p> <blockquote><div><p>True: make colormap symmetric (ranging from -vmax to vmax). False: the colormap will go from the minimum of the volume to vmax. Set it to False if you are plotting a positive volume, e.g. an atlas or an anatomical image.</p></div></blockquote> <p><strong>dim</strong> : float, ‘auto’ (default=’auto’)</p> <blockquote><div><p>Dimming factor applied to background image. By default, automatic heuristics are applied based upon the background image intensity. Accepted float values, where a typical scan is between -2 and 2 (-2 = increase constrast; 2 = decrease contrast), but larger values can be used for a more pronounced effect. 0 means no dimming.</p></div></blockquote> <p><strong>vmax</strong> : float, or None (default=None)</p> <blockquote><div><p>max value for mapping colors. If vmax is None and symmetric_cmap is True, vmax is the max absolute value of the volume. If vmax is None and symmetric_cmap is False, vmax is the max value of the volume.</p></div></blockquote> <p><strong>vmin</strong> : float, or None (default=None)</p> <blockquote><div><p>min value for mapping colors. If <cite>symmetric_cmap</cite> is <cite>True</cite>, <cite>vmin</cite> is always equal to <cite>-vmax</cite> and cannot be chosen. If <cite>symmetric_cmap</cite> is <cite>False</cite>, <cite>vmin</cite> defaults to the min of the image, or 0 when a threshold is used.</p></div></blockquote> <p><strong>resampling_interpolation</strong> : string, optional (default continuous)</p> <blockquote><div><p>The interpolation method for resampling. Can be ‘continuous’, ‘linear’, or ‘nearest’. See nilearn.image.resample_img</p></div></blockquote> <p><strong>opacity</strong> : float in [0,1] (default 1)</p> <blockquote><div><p>The level of opacity of the overlay (0: transparent, 1: opaque)</p></div></blockquote></td></tr><tr class="field-even field"><th class=field-name>Returns:</th><td class=field-body><p class=first><strong>html_view</strong> : the html viewer object.</p> <blockquote class=last><div><p>It can be saved as an html page <cite>html_view.save_as_html(‘test.html’)</cite>, or opened in a browser <cite>html_view.open_in_browser()</cite>. If the output is not requested and the current environment is a Jupyter notebook, the viewer will be inserted in the notebook.</p></div></blockquote></td></tr></tbody></table> <div class="admonition seealso"><p class="first admonition-title">See also</p><dl class=docutils><dt><a class="reference internal"href=nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map title=nilearn.plotting.plot_stat_map><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.plotting.plot_stat_map</span></code></a></dt><dd>static plot of brain volume, on a single or multiple planes.</dd><dt><a class="reference internal"href=nilearn.plotting.view_connectome.html#nilearn.plotting.view_connectome title=nilearn.plotting.view_connectome><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.plotting.view_connectome</span></code></a></dt><dd>interactive 3d view of a connectome.</dd><dt><a class="reference internal"href=nilearn.plotting.view_markers.html#nilearn.plotting.view_markers title=nilearn.plotting.view_markers><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.plotting.view_markers</span></code></a></dt><dd>interactive plot of colored markers.</dd></dl><p class=last><a class="reference internal"href=nilearn.plotting.view_surf.html#nilearn.plotting.view_surf title=nilearn.plotting.view_surf><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.plotting.view_surf</span></code></a>, <a class="reference internal"href=nilearn.plotting.view_img_on_surf.html#nilearn.plotting.view_img_on_surf title=nilearn.plotting.view_img_on_surf><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.plotting.view_img_on_surf</span></code></a></p></div></dd></dl><div class=section id=examples-using-nilearn-plotting-view-img><h2>8.10.30.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.plotting.view_img</span></code><a title="Permalink to this headline"class=headerlink href=#examples-using-nilearn-plotting-view-img>¶</a></h2><div tooltip="Here is a simple tutorial on decoding with nilearn. It reproduces the Haxby 2001 study on a fac..."class=sphx-glr-thumbcontainer><div class=figure id=id1><img alt="A introduction tutorial to fMRI decoding"src=../../_images/sphx_glr_plot_decoding_tutorial_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/plot_decoding_tutorial.html#sphx-glr-auto-examples-plot-decoding-tutorial-py><span class="std std-ref">A introduction tutorial to fMRI decoding</span></a></span></p></div></div><div tooltip="Nilearn comes with a set of plotting functions for easy visualization of Nifti-like images such..."class=sphx-glr-thumbcontainer><div class=figure id=id2><img alt="Plotting tools in nilearn"src=../../_images/sphx_glr_plot_demo_plotting_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/01_plotting/plot_demo_plotting.html#sphx-glr-auto-examples-01-plotting-plot-demo-plotting-py><span class="std std-ref">Plotting tools in nilearn</span></a></span></p></div></div><div tooltip="This example does a simple but efficient decoding on the Haxby dataset: using a feature selecti..."class=sphx-glr-thumbcontainer><div class=figure id=id3><img alt="Decoding with ANOVA + SVM: face vs house in the Haxby dataset"src=../../_images/sphx_glr_plot_haxby_anova_svm_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/02_decoding/plot_haxby_anova_svm.html#sphx-glr-auto-examples-02-decoding-plot-haxby-anova-svm-py><span class="std std-ref">Decoding with ANOVA + SVM: face vs house in the Haxby dataset</span></a></span></p></div></div><div style=clear:both></div></div></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>8.10.30. nilearn.plotting.view_img</a><ul><li><a class="reference internal"href=#examples-using-nilearn-plotting-view-img>8.10.30.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.plotting.view_img</span></code></a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=nilearn.plotting.view_markers.html>8.10.29. nilearn.plotting.view_markers</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=nilearn.plotting.show.html>8.10.31. nilearn.plotting.show</a></p><div id=searchbox role=search style=display:none><h3>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input name=q><input type=submit value=Go><input name=check_keywords type=hidden value=yes><input name=area type=hidden value=default></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2020. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 1.8.5. <span style=padding-left:5ex> <a href=../../_sources/modules/generated/nilearn.plotting.view_img.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>