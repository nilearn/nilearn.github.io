<!doctypehtml><html lang=en xmlns=http://www.w3.org/1999/xhtml><meta content=IE=Edge http-equiv=X-UA-Compatible><meta content="text/html; charset=utf-8"http-equiv=Content-Type><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/gallery.css rel=stylesheet><link href=../../_static/gallery-binder.css rel=stylesheet><link href=../../_static/gallery-dataframe.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/language_data.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="8.6.3. nilearn.input_data.NiftiLabelsMasker"href=nilearn.input_data.NiftiLabelsMasker.html rel=next><link title="8.6.1. nilearn.input_data.NiftiMasker"href=nilearn.input_data.NiftiMasker.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script></head><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="8.6.3. nilearn.input_data.NiftiLabelsMasker"accesskey=N href=nilearn.input_data.NiftiLabelsMasker.html>next</a> |</li><li class=right><a title="8.6.1. nilearn.input_data.NiftiMasker"accesskey=P href=nilearn.input_data.NiftiMasker.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../../auto_examples/index.html>Examples</a> | </li><li><a href=../reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../reference.html>8. Reference documentation: all nilearn functions</a> »</li></ul></div></div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="admonition note"><p class="first admonition-title">Note</p><p class=last>This page is a reference documentation. It only explains the class signature, and not how to use it. Please refer to the <a class="reference internal"href=../../user_guide.html#user-guide><span class="std std-ref">user guide</span></a> for the big picture.</p></div><div class=section id=nilearn-input-data-multiniftimasker><h1>8.6.2. nilearn.input_data.MultiNiftiMasker<a title="Permalink to this headline"class=headerlink href=#nilearn-input-data-multiniftimasker>¶</a></h1><dl class=class><dt id=nilearn.input_data.MultiNiftiMasker><em class=property>class </em><code class=descclassname>nilearn.input_data.</code><code class=descname>MultiNiftiMasker</code><span class=sig-paren>(</span><em>mask_img=None</em>, <em>smoothing_fwhm=None</em>, <em>standardize=False</em>, <em>detrend=False</em>, <em>low_pass=None</em>, <em>high_pass=None</em>, <em>t_r=None</em>, <em>target_affine=None</em>, <em>target_shape=None</em>, <em>mask_strategy='background'</em>, <em>mask_args=None</em>, <em>dtype=None</em>, <em>memory=Memory(location=None)</em>, <em>memory_level=0</em>, <em>n_jobs=1</em>, <em>verbose=0</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.MultiNiftiMasker>¶</a></dt><dd><p>Class for masking of Niimg-like objects.</p> <p>MultiNiftiMasker is useful when dealing with image sets from multiple subjects. Use case: integrates well with decomposition by MultiPCA and CanICA (multi-subject models)</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>mask_img: Niimg-like object</strong></p> <blockquote><div><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> Mask of the data. If not given, a mask is computed in the fit step. Optional parameters can be set using mask_args and mask_strategy to fine tune the mask extraction.</p></div></blockquote> <p><strong>smoothing_fwhm: float, optional</strong></p> <blockquote><div><p>If smoothing_fwhm is not None, it gives the size in millimeters of the spatial smoothing to apply to the signal.</p></div></blockquote> <p><strong>standardize: {‘zscore’, ‘psc’, True, False}, default is ‘zscore’</strong></p> <blockquote><div><p>Strategy to standardize the signal. ‘zscore’: the signal is z-scored. Timeseries are shifted to zero mean and scaled to unit variance. ‘psc’: Timeseries are shifted to zero mean value and scaled to percent signal change (as compared to original mean signal). True : the signal is z-scored. Timeseries are shifted to zero mean and scaled to unit variance. False : Do not standardize the data.</p></div></blockquote> <p><strong>detrend: boolean, optional</strong></p> <blockquote><div><p>This parameter is passed to signal.clean. Please see the related documentation for details</p></div></blockquote> <p><strong>low_pass: None or float, optional</strong></p> <blockquote><div><p>This parameter is passed to signal.clean. Please see the related documentation for details</p></div></blockquote> <p><strong>high_pass: None or float, optional</strong></p> <blockquote><div><p>This parameter is passed to signal.clean. Please see the related documentation for details</p></div></blockquote> <p><strong>t_r: float, optional</strong></p> <blockquote><div><p>This parameter is passed to signal.clean. Please see the related documentation for details</p></div></blockquote> <p><strong>target_affine: 3x3 or 4x4 matrix, optional</strong></p> <blockquote><div><p>This parameter is passed to image.resample_img. Please see the related documentation for details.</p></div></blockquote> <p><strong>target_shape: 3-tuple of integers, optional</strong></p> <blockquote><div><p>This parameter is passed to image.resample_img. Please see the related documentation for details.</p></div></blockquote> <p><strong>mask_strategy: {‘background’, ‘epi’ or ‘template’}, optional</strong></p> <blockquote><div><p>The strategy used to compute the mask: use ‘background’ if your images present a clear homogeneous background, ‘epi’ if they are raw EPI images, or you could use ‘template’ which will extract the gray matter part of your data by resampling the MNI152 brain mask for your data’s field of view. Depending on this value, the mask will be computed from masking.compute_background_mask, masking.compute_epi_mask or masking.compute_brain_mask. Default is ‘background’.</p></div></blockquote> <p><strong>mask_args</strong> : dict, optional</p> <blockquote><div><p>If mask is None, these are additional parameters passed to masking.compute_background_mask or masking.compute_epi_mask to fine-tune mask computation. Please see the related documentation for details.</p></div></blockquote> <p><strong>dtype: {dtype, “auto”}</strong></p> <blockquote><div><p>Data type toward which the data should be converted. If “auto”, the data will be converted to int32 if dtype is discrete and float32 if it is continuous.</p></div></blockquote> <p><strong>memory: instance of joblib.Memory or string</strong></p> <blockquote><div><p>Used to cache the masking process. By default, no caching is done. If a string is given, it is the path to the caching directory.</p></div></blockquote> <p><strong>memory_level: integer, optional</strong></p> <blockquote><div><p>Rough estimator of the amount of memory used by caching. Higher value means more memory for caching.</p></div></blockquote> <p><strong>n_jobs: integer, optional</strong></p> <blockquote><div><p>The number of CPUs to use to do the computation. -1 means ‘all CPUs’, -2 ‘all CPUs but one’, and so on.</p></div></blockquote> <p><strong>verbose: integer, optional</strong></p> <blockquote class=last><div><p>Indicate the level of verbosity. By default, nothing is printed</p></div></blockquote></td></tr></tbody></table> <div class="admonition seealso"><p class="first admonition-title">See also</p><dl class="last docutils"><dt><a class="reference internal"href=nilearn.image.resample_img.html#nilearn.image.resample_img title=nilearn.image.resample_img><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.image.resample_img</span></code></a></dt><dd>image resampling</dd><dt><a class="reference internal"href=nilearn.masking.compute_epi_mask.html#nilearn.masking.compute_epi_mask title=nilearn.masking.compute_epi_mask><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.masking.compute_epi_mask</span></code></a></dt><dd>mask computation</dd><dt><a class="reference internal"href=nilearn.masking.apply_mask.html#nilearn.masking.apply_mask title=nilearn.masking.apply_mask><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.masking.apply_mask</span></code></a></dt><dd>mask application on image</dd><dt><a class="reference internal"href=nilearn.signal.clean.html#nilearn.signal.clean title=nilearn.signal.clean><code class="xref py py-obj docutils literal notranslate"><span class=pre>nilearn.signal.clean</span></code></a></dt><dd>confounds removal and general filtering of signals</dd></dl></div> <p class=rubric>Attributes</p> <table border=1 class=docutils><colgroup><col width=22%><col width=78%></colgroup><tbody valign=top><tr class=row-odd><td><strong>`mask_img_`</strong></td><td>(nibabel.Nifti1Image object) The mask of the data.</td></tr><tr class=row-even><td><strong>`affine_`</strong></td><td>(4x4 numpy.ndarray) Affine of the transformed image.</td></tr></tbody></table> <dl class=method><dt id=nilearn.input_data.MultiNiftiMasker.__init__><code class=descname>__init__</code><span class=sig-paren>(</span><em>mask_img=None</em>, <em>smoothing_fwhm=None</em>, <em>standardize=False</em>, <em>detrend=False</em>, <em>low_pass=None</em>, <em>high_pass=None</em>, <em>t_r=None</em>, <em>target_affine=None</em>, <em>target_shape=None</em>, <em>mask_strategy='background'</em>, <em>mask_args=None</em>, <em>dtype=None</em>, <em>memory=Memory(location=None)</em>, <em>memory_level=0</em>, <em>n_jobs=1</em>, <em>verbose=0</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.MultiNiftiMasker.__init__>¶</a></dt><dd><p>Initialize self. See help(type(self)) for accurate signature.</p></dd></dl> <dl class=method><dt id=nilearn.input_data.MultiNiftiMasker.fit><code class=descname>fit</code><span class=sig-paren>(</span><em>imgs=None</em>, <em>y=None</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.MultiNiftiMasker.fit>¶</a></dt><dd><p>Compute the mask corresponding to the data</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>imgs: list of Niimg-like objects</strong></p> <blockquote class=last><div><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> Data on which the mask must be calculated. If this is a list, the affine is considered the same for all.</p></div></blockquote></td></tr></tbody></table></dd></dl> <dl class=method><dt id=nilearn.input_data.MultiNiftiMasker.fit_transform><code class=descname>fit_transform</code><span class=sig-paren>(</span><em>X</em>, <em>y=None</em>, <em>confounds=None</em>, <em>**fit_params</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.MultiNiftiMasker.fit_transform>¶</a></dt><dd><p>Fit to data, then transform it</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>X</strong> : Niimg-like object</p> <blockquote><div><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a></p></div></blockquote> <p><strong>y</strong> : numpy array of shape [n_samples]</p> <blockquote><div><p>Target values.</p></div></blockquote> <p><strong>confounds: list of confounds, optional</strong></p> <blockquote><div><p>List of confounds (2D arrays or filenames pointing to CSV files). Must be of same length than imgs_list.</p></div></blockquote></td></tr><tr class="field-even field"><th class=field-name>Returns:</th><td class=field-body><p class=first><strong>X_new</strong> : numpy array of shape [n_samples, n_features_new]</p> <blockquote class=last><div><p>Transformed array.</p></div></blockquote></td></tr></tbody></table></dd></dl> <dl class=method><dt id=nilearn.input_data.MultiNiftiMasker.generate_report><code class=descname>generate_report</code><span class=sig-paren>(</span><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.MultiNiftiMasker.generate_report>¶</a></dt><dd></dd></dl> <dl class=method><dt id=nilearn.input_data.MultiNiftiMasker.get_params><code class=descname>get_params</code><span class=sig-paren>(</span><em>deep=True</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.MultiNiftiMasker.get_params>¶</a></dt><dd><p>Get parameters for this estimator.</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>deep</strong> : bool, default=True</p> <blockquote><div><p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p></div></blockquote></td></tr><tr class="field-even field"><th class=field-name>Returns:</th><td class=field-body><p class=first><strong>params</strong> : mapping of string to any</p> <blockquote class=last><div><p>Parameter names mapped to their values.</p></div></blockquote></td></tr></tbody></table></dd></dl> <dl class=method><dt id=nilearn.input_data.MultiNiftiMasker.inverse_transform><code class=descname>inverse_transform</code><span class=sig-paren>(</span><em>X</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.MultiNiftiMasker.inverse_transform>¶</a></dt><dd><p>Transform the 2D data matrix back to an image in brain space.</p></dd></dl> <dl class=method><dt id=nilearn.input_data.MultiNiftiMasker.set_params><code class=descname>set_params</code><span class=sig-paren>(</span><em>**params</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.MultiNiftiMasker.set_params>¶</a></dt><dd><p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as pipelines). The latter have parameters of the form <code class="docutils literal notranslate"><span class=pre>&LTcomponent>__&LTparameter></span></code> so that it’s possible to update each component of a nested object.</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>**params</strong> : dict</p> <blockquote><div><p>Estimator parameters.</p></div></blockquote></td></tr><tr class="field-even field"><th class=field-name>Returns:</th><td class=field-body><p class=first><strong>self</strong> : object</p> <blockquote class=last><div><p>Estimator instance.</p></div></blockquote></td></tr></tbody></table></dd></dl> <dl class=method><dt id=nilearn.input_data.MultiNiftiMasker.transform><code class=descname>transform</code><span class=sig-paren>(</span><em>imgs</em>, <em>confounds=None</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.MultiNiftiMasker.transform>¶</a></dt><dd><p>Apply mask, spatial and temporal preprocessing</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>imgs: list of Niimg-like objects</strong></p> <blockquote><div><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> Data to be preprocessed</p></div></blockquote> <p><strong>confounds: CSV file path or 2D array or pandas DataFrame</strong></p> <blockquote><div><p>This parameter is passed to signal.clean. Please see the corresponding documentation for details.</p></div></blockquote></td></tr><tr class="field-even field"><th class=field-name>Returns:</th><td class=field-body><p class=first>data: {list of numpy arrays}</p> <blockquote class=last><div><p>preprocessed images</p></div></blockquote></td></tr></tbody></table></dd></dl> <dl class=method><dt id=nilearn.input_data.MultiNiftiMasker.transform_imgs><code class=descname>transform_imgs</code><span class=sig-paren>(</span><em>imgs_list</em>, <em>confounds=None</em>, <em>copy=True</em>, <em>n_jobs=1</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.MultiNiftiMasker.transform_imgs>¶</a></dt><dd><p>Prepare multi subject data in parallel</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>imgs_list: list of Niimg-like objects</strong></p> <blockquote><div><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> List of imgs file to prepare. One item per subject.</p></div></blockquote> <p><strong>confounds: list of confounds, optional</strong></p> <blockquote><div><p>List of confounds (2D arrays or filenames pointing to CSV files or pandas DataFrames). Must be of same length than imgs_list.</p></div></blockquote> <p><strong>copy: boolean, optional</strong></p> <blockquote><div><p>If True, guarantees that output array has no memory in common with input array.</p></div></blockquote> <p><strong>n_jobs: integer, optional</strong></p> <blockquote><div><p>The number of cpus to use to do the computation. -1 means ‘all cpus’.</p></div></blockquote></td></tr><tr class="field-even field"><th class=field-name>Returns:</th><td class=field-body><p class=first>region_signals: list of 2D numpy.ndarray</p> <blockquote class=last><div><p>List of signal for each element per subject. shape: list of (number of scans, number of elements)</p></div></blockquote></td></tr></tbody></table></dd></dl> <dl class=method><dt id=nilearn.input_data.MultiNiftiMasker.transform_single_imgs><code class=descname>transform_single_imgs</code><span class=sig-paren>(</span><em>imgs</em>, <em>confounds=None</em>, <em>copy=True</em><span class=sig-paren>)</span><a title="Permalink to this definition"class=headerlink href=#nilearn.input_data.MultiNiftiMasker.transform_single_imgs>¶</a></dt><dd><p>Apply mask, spatial and temporal preprocessing</p> <table class="docutils field-list"frame=void rules=none><col class=field-name><col class=field-body><tbody valign=top><tr class="field-odd field"><th class=field-name>Parameters:</th><td class=field-body><p class=first><strong>imgs: 3D/4D Niimg-like object</strong></p> <blockquote><div><p>See <a class="reference external"href=http://nilearn.github.io/manipulating_images/input_output.html>http://nilearn.github.io/manipulating_images/input_output.html</a> Images to process. It must boil down to a 4D image with scans number as last dimension.</p></div></blockquote> <p><strong>confounds: CSV file or array-like or pandas DataFrame, optional</strong></p> <blockquote><div><p>This parameter is passed to signal.clean. Please see the related documentation for details: <a class="reference internal"href=nilearn.signal.clean.html#nilearn.signal.clean title=nilearn.signal.clean><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.signal.clean</span></code></a>. shape: (number of scans, number of confounds)</p></div></blockquote></td></tr><tr class="field-even field"><th class=field-name>Returns:</th><td class=field-body><p class=first>region_signals: 2D numpy.ndarray</p> <blockquote class=last><div><p>Signal for each voxel inside the mask. shape: (number of scans, number of voxels)</p></div></blockquote></td></tr></tbody></table></dd></dl></dd></dl><div class=section id=examples-using-nilearn-input-data-multiniftimasker><h2>8.6.2.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.input_data.MultiNiftiMasker</span></code><a title="Permalink to this headline"class=headerlink href=#examples-using-nilearn-input-data-multiniftimasker>¶</a></h2><div tooltip="This example partly reproduces the encoding model presented in     `Visual image reconstruction..."class=sphx-glr-thumbcontainer><div class=figure id=id1><img alt="Encoding models for visual stimuli from Miyawaki et al. 2008"src=../../_images/sphx_glr_plot_miyawaki_encoding_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/02_decoding/plot_miyawaki_encoding.html#sphx-glr-auto-examples-02-decoding-plot-miyawaki-encoding-py><span class="std std-ref">Encoding models for visual stimuli from Miyawaki et al. 2008</span></a></span></p></div></div><div tooltip="This example reproduces the experiment presented in     `Visual image reconstruction from human..."class=sphx-glr-thumbcontainer><div class=figure id=id2><img alt="Reconstruction of visual stimuli from Miyawaki et al. 2008"src=../../_images/sphx_glr_plot_miyawaki_reconstruction_thumb.png><p class=caption><span class=caption-text><a class="reference internal"href=../../auto_examples/02_decoding/plot_miyawaki_reconstruction.html#sphx-glr-auto-examples-02-decoding-plot-miyawaki-reconstruction-py><span class="std std-ref">Reconstruction of visual stimuli from Miyawaki et al. 2008</span></a></span></p></div></div><div style=clear:both></div></div></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>8.6.2. nilearn.input_data.MultiNiftiMasker</a><ul><li><a class="reference internal"href=#examples-using-nilearn-input-data-multiniftimasker>8.6.2.1. Examples using <code class="docutils literal notranslate"><span class=pre>nilearn.input_data.MultiNiftiMasker</span></code></a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=nilearn.input_data.NiftiMasker.html>8.6.1. nilearn.input_data.NiftiMasker</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=nilearn.input_data.NiftiLabelsMasker.html>8.6.3. nilearn.input_data.NiftiLabelsMasker</a></p><div id=searchbox role=search style=display:none><h3>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input name=q><input type=submit value=Go><input name=check_keywords type=hidden value=yes><input name=area type=hidden value=default></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2020. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 1.8.5. <span style=padding-left:5ex> <a href=../../_sources/modules/generated/nilearn.input_data.MultiNiftiMasker.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>