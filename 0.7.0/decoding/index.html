<!doctypehtml><html lang=en xmlns=http://www.w3.org/1999/xhtml><meta content=IE=Edge http-equiv=X-UA-Compatible><meta content="text/html; charset=utf-8"http-equiv=Content-Type><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../_static/nature.css rel=stylesheet><link href=../_static/pygments.css rel=stylesheet><link href=../_static/gallery.css rel=stylesheet><link href=../_static/gallery-binder.css rel=stylesheet><link href=../_static/gallery-dataframe.css rel=stylesheet><script data-url_root=../ id=documentation_options src=../_static/documentation_options.js></script><script src=../_static/jquery.js></script><script src=../_static/underscore.js></script><script src=../_static/doctools.js></script><script src=../_static/language_data.js></script><script src=../_static/copybutton.js></script><link rel="shortcut icon"href=../_static/favicon.ico><link href=../search.html rel=search title=Search><link title="2.1. An introduction to decoding"href=decoding_intro.html rel=next><link title="1. Introduction: nilearn in a nutshell"href=../introduction.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script></head><body><div id=logo-banner><div class=logo><a href=../index.html> <img alt="Nilearn logo"border=0 src=../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=searchlight.html>Searchlight</a></li><li><big><a href=../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../modules/reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../py-modindex.html>modules</a></li><li class=right><a title="2.1. An introduction to decoding"accesskey=N href=decoding_intro.html>next</a> |</li><li class=right><a title="1. Introduction: nilearn in a nutshell"accesskey=P href=../introduction.html>previous</a> |</li><li><a href=../index.html>Nilearn Home</a> | </li><li><a href=../user_guide.html>User Guide</a> | </li><li><a href=../auto_examples/index.html>Examples</a> | </li><li><a href=../modules/reference.html>Reference</a> | </li><li id=navbar-about><a href=../authors.html>About</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a accesskey=U href=../user_guide.html>User guide: table of contents</a> »</li></ul></div></div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><script>//Function to make the index toctree collapsible
 $(function () {
     $('.toctree-l2')
         .click(function(event){
             if (event.target.tagName.toLowerCase() != "a") {
                 if ($(this).children('ul').length > 0) {
                      $(this).attr('data-content',
                          (!$(this).children('ul').is(':hidden')) ? '\u25ba' : '\u25bc');
                     $(this).children('ul').toggle();
                 }
                 return true; //Makes links clickable
             }
         })
         .mousedown(function(event){ return false; }) //Firefox highlighting fix
         .children('ul').hide();
     // Initialize the values
     $('li.toctree-l2:not(:has(ul))').attr('data-content', '-');
     $('li.toctree-l2:has(ul)').attr('data-content', '\u25ba');
     $('li.toctree-l2:has(ul)').css('cursor', 'pointer');

     $('.toctree-l2').hover(
         function () {
             if ($(this).children('ul').length > 0) {
                 $(this).css('background-color', '#D0D0D0').children('ul').css('background-color', '#F0F0F0');
                 $(this).attr('data-content',
                     (!$(this).children('ul').is(':hidden')) ? '\u25bc' : '\u25ba');
             }
             else {
                 $(this).css('background-color', '#F9F9F9');
             }
         },
         function () {
             $(this).css('background-color', 'white').children('ul').css('background-color', 'white');
             if ($(this).children('ul').length > 0) {
                 $(this).attr('data-content',
                     (!$(this).children('ul').is(':hidden')) ? '\u25bc' : '\u25ba');
             }
         }
     );
 });</script><style>div.bodywrapper blockquote{margin:0}div.toctree-wrapper ul{margin:0;padding-left:0}li,ul{transition-duration:.2s}li.toctree-l1{color:#20435c;background-color:#f2f2f2;margin-bottom:1.2em;margin-left:0;padding:5px 0 0;font-family:Arial,sans-serif;font-size:150%;font-weight:700;list-style-type:none}li.toctree-l1 a{color:#314f64;padding:0 0 0 10px}li.toctree-l2{background-color:#fff;padding:.25em 0;font-size:85%;font-weight:400;list-style-type:none}li.toctree-l2 ul{padding-left:40px}li.toctree-l2:before{content:attr(data-content);color:#777;width:10px;font-size:85%;display:inline-block}li.toctree-l3{font-size:88%;font-weight:400;list-style-type:square}li.toctree-l4{font-size:93%;font-weight:400;list-style-type:circle}div.topic li.toctree-l1{background-color:#0000;margin-bottom:0;margin-left:1.5em;font-size:100%;font-weight:700;display:inline}div.topic p{margin:.4ex;font-size:90%}div.topic p.topic-title{margin-bottom:0;font-size:100%;display:inline}div.sidebar{width:25ex}</style><div class=section id=decoding-and-mvpa-predicting-from-brain-images><span id=decoding></span><h1>2. Decoding and MVPA: predicting from brain images<a title="Permalink to this headline"class=headerlink href=#decoding-and-mvpa-predicting-from-brain-images>¶</a></h1><p>Decoding consists in predicting external variables such as behavioral or phenotypic variables from brain image. It can be useful for diagnostic of prognosis, or to probe the information content of brain activity images.</p><p>These are <a class="reference external"href=http://en.wikipedia.org/wiki/Supervised_learning>Supervised learning</a> tasks, focused on predicting an output value.</p><div class=line-block><div class=line><br></div></div><style>div.bodywrapper blockquote{margin:0}div.toctree-wrapper ul{margin-top:0;margin-bottom:0;padding-left:10px}li.toctree-l1{padding:0 0 .5em;font-size:150%;font-weight:700;list-style-type:none}li.toctree-l1 ul{padding-left:40px}li.toctree-l2{font-size:75%;font-weight:400;list-style-type:square}li.toctree-l3{font-size:85%;font-weight:400;list-style-type:circle}</style><div class="toctree-wrapper compound"><ul><li class=toctree-l1><a class="reference internal"href=decoding_intro.html>2.1. An introduction to decoding</a><ul><li class=toctree-l2><a class="reference internal"href=decoding_intro.html#loading-and-preparing-the-data>2.1.1. Loading and preparing the data</a><ul><li class=toctree-l3><a class="reference internal"href=decoding_intro.html#the-haxby-2001-experiment>2.1.1.1. The Haxby 2001 experiment</a></li><li class=toctree-l3><a class="reference internal"href=decoding_intro.html#loading-the-data-into-nilearn>2.1.1.2. Loading the data into nilearn</a></li></ul></li><li class=toctree-l2><a class="reference internal"href=decoding_intro.html#performing-a-simple-decoding-analysis>2.1.2. Performing a simple decoding analysis</a><ul><li class=toctree-l3><a class="reference internal"href=decoding_intro.html#a-few-definitions>2.1.2.1. A few definitions</a></li><li class=toctree-l3><a class="reference internal"href=decoding_intro.html#a-first-estimator>2.1.2.2. A first estimator</a></li><li class=toctree-l3><a class="reference internal"href=decoding_intro.html#decoding-made-easy>2.1.2.3. Decoding made easy</a></li><li class=toctree-l3><a class="reference internal"href=decoding_intro.html#measuring-prediction-performance>2.1.2.4. Measuring prediction performance</a><ul><li class=toctree-l4><a class="reference internal"href=decoding_intro.html#cross-validation>2.1.2.4.1. Cross-validation</a></li><li class=toctree-l4><a class="reference internal"href=decoding_intro.html#choosing-a-good-cross-validation-strategy>2.1.2.4.2. Choosing a good cross-validation strategy</a></li><li class=toctree-l4><a class="reference internal"href=decoding_intro.html#choice-of-the-prediction-accuracy-measure>2.1.2.4.3. Choice of the prediction accuracy measure</a></li></ul></li><li class=toctree-l3><a class="reference internal"href=decoding_intro.html#visualizing-the-decoder-s-weights>2.1.2.5. Visualizing the decoder’s weights</a></li></ul></li><li class=toctree-l2><a class="reference internal"href=decoding_intro.html#decoding-without-a-mask-anova-svm>2.1.3. Decoding without a mask: Anova-SVM</a><ul><li class=toctree-l3><a class="reference internal"href=decoding_intro.html#dimension-reduction-with-feature-selection>2.1.3.1. Dimension reduction with feature selection</a></li><li class=toctree-l3><a class="reference internal"href=decoding_intro.html#visualizing-the-results>2.1.3.2. Visualizing the results</a></li></ul></li></ul></li><li class=toctree-l1><a class="reference internal"href=estimator_choice.html>2.2. Choosing the right predictive model for neuroimaging</a><ul><li class=toctree-l2><a class="reference internal"href=estimator_choice.html#predictions-regression-classification-and-multi-class>2.2.1. Predictions: regression, classification and multi-class</a><ul><li class=toctree-l3><a class="reference internal"href=estimator_choice.html#regression>2.2.1.1. Regression</a></li><li class=toctree-l3><a class="reference internal"href=estimator_choice.html#classification-two-classes-or-multi-class>2.2.1.2. Classification: two classes or multi-class</a></li></ul></li><li class=toctree-l2><a class="reference internal"href=estimator_choice.html#different-linear-models>2.2.2. Different linear models</a></li><li class=toctree-l2><a class="reference internal"href=estimator_choice.html#setting-estimator-parameters>2.2.3. Setting estimator parameters</a></li><li class=toctree-l2><a class="reference internal"href=estimator_choice.html#bagging-several-models>2.2.4. Bagging several models</a></li></ul></li><li class=toctree-l1><a class="reference internal"href=frem.html>2.3. FREM: fast ensembling of regularized models for robust decoding</a><ul><li class=toctree-l2><a class="reference internal"href=frem.html#frem-pipeline>2.3.1. FREM pipeline</a></li><li class=toctree-l2><a class="reference internal"href=frem.html#empirical-comparisons>2.3.2. Empirical comparisons</a><ul><li class=toctree-l3><a class="reference internal"href=frem.html#decoding-performance-increase-on-haxby-dataset>2.3.2.1. Decoding performance increase on Haxby dataset</a></li><li class=toctree-l3><a class="reference internal"href=frem.html#spatial-regularization-of-decoding-maps-on-mixed-gambles-study>2.3.2.2. Spatial regularization of decoding maps on mixed gambles study</a></li></ul></li></ul></li><li class=toctree-l1><a class="reference internal"href=space_net.html>2.4. SpaceNet: decoding with spatial structure for better maps</a><ul><li class=toctree-l2><a class="reference internal"href=space_net.html#the-spacenet-decoder>2.4.1. The SpaceNet decoder</a></li><li class=toctree-l2><a class="reference internal"href=space_net.html#related-example>2.4.2. Related example</a></li></ul></li><li class=toctree-l1><a class="reference internal"href=searchlight.html>2.5. Searchlight : finding voxels containing information</a><ul><li class=toctree-l2><a class="reference internal"href=searchlight.html#principle-of-the-searchlight>2.5.1. Principle of the Searchlight</a></li><li class=toctree-l2><a class="reference internal"href=searchlight.html#preparing-the-data>2.5.2. Preparing the data</a><ul><li class=toctree-l3><a class="reference internal"href=searchlight.html#masking>2.5.2.1. Masking</a></li></ul></li><li class=toctree-l2><a class="reference internal"href=searchlight.html#setting-up-the-searchlight>2.5.3. Setting up the searchlight</a><ul><li class=toctree-l3><a class="reference internal"href=searchlight.html#classifier>2.5.3.1. Classifier</a></li><li class=toctree-l3><a class="reference internal"href=searchlight.html#score-function>2.5.3.2. Score function</a></li><li class=toctree-l3><a class="reference internal"href=searchlight.html#cross-validation>2.5.3.3. Cross validation</a></li><li class=toctree-l3><a class="reference internal"href=searchlight.html#sphere-radius>2.5.3.4. Sphere radius</a></li></ul></li><li class=toctree-l2><a class="reference internal"href=searchlight.html#visualization>2.5.4. Visualization</a><ul><li class=toctree-l3><a class="reference internal"href=searchlight.html#id1>2.5.4.1. Searchlight</a></li><li class=toctree-l3><a class="reference internal"href=searchlight.html#comparing-to-massively-univariate-analysis-f-score-or-spm>2.5.4.2. Comparing to massively univariate analysis: F_score or SPM</a></li></ul></li></ul></li><li class=toctree-l1><a class="reference internal"href=going_further.html>2.6. Running scikit-learn functions for more control on the analysis</a><ul><li class=toctree-l2><a class="reference internal"href=going_further.html#performing-decoding-with-scikit-learn>2.6.1. Performing decoding with scikit-learn</a><ul><li class=toctree-l3><a class="reference internal"href=going_further.html#using-scikit-learn-estimators>2.6.1.1. Using scikit-learn estimators</a></li><li class=toctree-l3><a class="reference internal"href=going_further.html#cross-validation-with-scikit-learn>2.6.1.2. Cross-validation with scikit-learn</a></li><li class=toctree-l3><a class="reference internal"href=going_further.html#measuring-the-chance-level>2.6.1.3. Measuring the chance level</a></li></ul></li><li class=toctree-l2><a class="reference internal"href=going_further.html#going-further-with-scikit-learn>2.6.2. Going further with scikit-learn</a><ul><li class=toctree-l3><a class="reference internal"href=going_further.html#decoding-without-a-mask-anova-svm-using-scikit-learn>2.6.2.1. Decoding without a mask: Anova-SVM using scikit-learn</a></li><li class=toctree-l3><a class="reference internal"href=going_further.html#using-any-other-model-in-the-pipeline>2.6.2.2. Using any other model in the pipeline</a></li></ul></li><li class=toctree-l2><a class="reference internal"href=going_further.html#setting-estimator-parameters>2.6.3. Setting estimator parameters</a></li></ul></li></ul></div></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../authors.html#citing>citing the papers</a>.</p></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=../introduction.html>1. Introduction: nilearn in a nutshell</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=decoding_intro.html>2.1. An introduction to decoding</a></p><div id=searchbox role=search style=display:none><h3>Quick search</h3><div class=searchformwrapper><form action=../search.html class=search><input name=q><input type=submit value=Go><input name=check_keywords type=hidden value=yes><input name=area type=hidden value=default></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2020. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 1.8.5. <span style=padding-left:5ex> <a href=../_sources/decoding/index.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>