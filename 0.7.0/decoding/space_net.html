<!doctypehtml><html lang=en xmlns=http://www.w3.org/1999/xhtml><meta content=IE=Edge http-equiv=X-UA-Compatible><meta content="text/html; charset=utf-8"http-equiv=Content-Type><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../_static/nature.css rel=stylesheet><link href=../_static/pygments.css rel=stylesheet><link href=../_static/gallery.css rel=stylesheet><link href=../_static/gallery-binder.css rel=stylesheet><link href=../_static/gallery-dataframe.css rel=stylesheet><script data-url_root=../ id=documentation_options src=../_static/documentation_options.js></script><script src=../_static/jquery.js></script><script src=../_static/underscore.js></script><script src=../_static/doctools.js></script><script src=../_static/language_data.js></script><script src=../_static/copybutton.js></script><link rel="shortcut icon"href=../_static/favicon.ico><link href=../search.html rel=search title=Search><link title="2.5. Searchlight : finding voxels containing information"href=searchlight.html rel=next><link title="2.3. FREM: fast ensembling of regularized models for robust decoding"href=frem.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script></head><body><div id=logo-banner><div class=logo><a href=../index.html> <img alt="Nilearn logo"border=0 src=../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../auto_examples/decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=searchlight.html>Searchlight</a></li><li><big><a href=../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../modules/reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../py-modindex.html>modules</a></li><li class=right><a title="2.5. Searchlight : finding voxels containing information"accesskey=N href=searchlight.html>next</a> |</li><li class=right><a title="2.3. FREM: fast ensembling of regularized models for robust decoding"accesskey=P href=frem.html>previous</a> |</li><li><a href=../index.html>Nilearn Home</a> | </li><li><a href=../user_guide.html>User Guide</a> | </li><li><a href=../auto_examples/index.html>Examples</a> | </li><li><a href=../modules/reference.html>Reference</a> | </li><li id=navbar-about><a href=../authors.html>About</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=index.html>2. Decoding and MVPA: predicting from brain images</a> »</li></ul></div></div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class=section id=spacenet-decoding-with-spatial-structure-for-better-maps><span id=space-net></span><h1>2.4. SpaceNet: decoding with spatial structure for better maps<a title="Permalink to this headline"class=headerlink href=#spacenet-decoding-with-spatial-structure-for-better-maps>¶</a></h1><div class=section id=the-spacenet-decoder><h2>2.4.1. The SpaceNet decoder<a title="Permalink to this headline"class=headerlink href=#the-spacenet-decoder>¶</a></h2><p>SpaceNet implements spatial penalties which improve brain decoding power as well as decoder maps:</p><ul class=simple><li>penalty=”tvl1”: priors inspired from TV (Total Variation) <a class="reference external"href=https://hal.inria.fr/inria-00563468/document>[Michel et al. 2011]</a>, TV-L1 <a class="reference external"href=http://www0.cs.ucl.ac.uk/staff/M.Pontil/reading/neurosparse_prni.pdf>[Baldassarre et al. 2012]</a>, <a class="reference external"href=https://hal.inria.fr/hal-00839984>[Gramfort et al. 2013]</a>,</li><li>penalty=”graph-net”: GraphNet prior <a class="reference external"href=https://www.ncbi.nlm.nih.gov/pubmed/23298747>[Grosenick et al. 2013]</a>)</li></ul><p>These regularize classification and regression problems in brain imaging. The results are brain maps which are both sparse (i.e regression coefficients are zero everywhere, except at predictive voxels) and structured (blobby). The superiority of TV-L1 over methods without structured priors like the Lasso, SVM, ANOVA, Ridge, etc. for yielding more interpretable maps and improved prediction scores is now well established <a class="reference external"href=http://www0.cs.ucl.ac.uk/staff/M.Pontil/reading/neurosparse_prni.pdf>[Baldassarre et al. 2012]</a>, <a class="reference external"href=https://hal.inria.fr/hal-00839984>[Gramfort et al. 2013]</a>, <a class="reference external"href=https://www.ncbi.nlm.nih.gov/pubmed/23298747>[Grosenick et al. 2013]</a>.</p><p>Note that TV-L1 prior leads to a difficult optimization problem, and so can be slow to run. Under the hood, a few heuristics are used to make things a bit faster. These include:</p><ul class=simple><li>Feature preprocessing, where an F-test is used to eliminate non-predictive voxels, thus reducing the size of the brain mask in a principled way.</li><li>Continuation is used along the regularization path, where the solution of the optimization problem for a given value of the regularization parameter <cite>alpha</cite> is used as initialization for the next regularization (smaller) value on the regularization grid.</li></ul><p><strong>Implementation:</strong> See <a class="reference external"href=https://hal.inria.fr/hal-01147731>[Dohmatob et al. 2015 (PRNI)]</a> and <a class="reference external"href=https://hal.inria.fr/hal-00991743>[Dohmatob et al. 2014 (PRNI)]</a> for technical details regarding the implementation of SpaceNet.</p></div><div class=section id=related-example><h2>2.4.2. Related example<a title="Permalink to this headline"class=headerlink href=#related-example>¶</a></h2><p><a class="reference internal"href=../auto_examples/02_decoding/plot_oasis_vbm_space_net.html#sphx-glr-auto-examples-02-decoding-plot-oasis-vbm-space-net-py><span class="std std-ref">Age prediction on OASIS dataset with SpaceNet</span></a>.</p><div class=figure><img alt=../_images/sphx_glr_plot_oasis_vbm_space_net_0021.png src=../_images/sphx_glr_plot_oasis_vbm_space_net_0021.png></div><div class="admonition note"><p class="first admonition-title">Note</p><p class=last>Empirical comparisons using this method have been removed from documentation in version 0.7 to keep its computational cost low. You can easily try SpaceNet instead of FREM in <a class="reference internal"href=../auto_examples/02_decoding/plot_mixed_gambles_frem.html#sphx-glr-auto-examples-02-decoding-plot-mixed-gambles-frem-py><span class="std std-ref">mixed gambles study</span></a> or <a class="reference internal"href=../auto_examples/02_decoding/plot_haxby_frem.html#sphx-glr-auto-examples-02-decoding-plot-haxby-frem-py><span class="std std-ref">Haxby study</span></a>.</p></div><div class="admonition seealso"><p class="first admonition-title">See also</p><p class=last><a class="reference internal"href=frem.html#frem><span class="std std-ref">FREM</span></a>, a pipeline ensembling many models that yields very good decoding performance at a lower computational cost.</p></div></div></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>2.4. SpaceNet: decoding with spatial structure for better maps</a><ul><li><a class="reference internal"href=#the-spacenet-decoder>2.4.1. The SpaceNet decoder</a></li><li><a class="reference internal"href=#related-example>2.4.2. Related example</a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=frem.html>2.3. FREM: fast ensembling of regularized models for robust decoding</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=searchlight.html>2.5. Searchlight : finding voxels containing information</a></p><div id=searchbox role=search style=display:none><h3>Quick search</h3><div class=searchformwrapper><form action=../search.html class=search><input name=q><input type=submit value=Go><input name=check_keywords type=hidden value=yes><input name=area type=hidden value=default></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2020. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 1.8.5. <span style=padding-left:5ex> <a href=../_sources/decoding/space_net.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>