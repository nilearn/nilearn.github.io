<!doctypehtml><html lang=en xmlns=http://www.w3.org/1999/xhtml><meta content=IE=Edge http-equiv=X-UA-Compatible><meta content="text/html; charset=utf-8"http-equiv=Content-Type><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/gallery.css rel=stylesheet><link href=../../_static/gallery-binder.css rel=stylesheet><link href=../../_static/gallery-dataframe.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/language_data.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="9.4.12. Extract signals on spheres and plot a connectome"href=plot_sphere_based_connectome.html rel=next><link title="9.4.10. Regions extraction using Dictionary Learning and functional connectomes"href=plot_extract_regions_dictlearning_maps.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script></head><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../../modules/reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="9.4.12. Extract signals on spheres and plot a connectome"accesskey=N href=plot_sphere_based_connectome.html>next</a> |</li><li class=right><a title="9.4.10. Regions extraction using Dictionary Learning and functional connectomes"accesskey=P href=plot_extract_regions_dictlearning_maps.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../index.html>Examples</a> | </li><li><a href=../../modules/reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../index.html>9. Nilearn usage examples</a> »</li></ul></div></div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="sphx-glr-download-link-note admonition note"><p class="first admonition-title">Note</p><p class=last>Click <a class="reference internal"href=#sphx-glr-download-auto-examples-03-connectivity-plot-data-driven-parcellations-py><span class="std std-ref">here</span></a> to download the full example code or to run this example in your browser via Binder</p></div><div class="sphx-glr-example-title section"id=clustering-methods-to-learn-a-brain-parcellation-from-fmri><span id=sphx-glr-auto-examples-03-connectivity-plot-data-driven-parcellations-py></span><h1>9.4.11. Clustering methods to learn a brain parcellation from fMRI<a title="Permalink to this headline"class=headerlink href=#clustering-methods-to-learn-a-brain-parcellation-from-fmri>¶</a></h1><p>We use spatially-constrained Ward-clustering, KMeans, and Recursive Neighbor Agglomeration (ReNA) to create a set of parcels.</p><p>In a high dimensional regime, these methods can be interesting to create a ‘compressed’ representation of the data, replacing the data in the fMRI images by mean signals on the parcellation, which can subsequently be used for statistical analysis or machine learning.</p><p>Also, these methods can be used to learn functional connectomes and subsequently for classification tasks.</p><div class=section id=references><h2>9.4.11.1. References<a title="Permalink to this headline"class=headerlink href=#references>¶</a></h2><p>Which clustering method to use, an empirical comparison can be found in this paper</p><blockquote><div><ul class=simple><li>Bertrand Thirion, Gael Varoquaux, Elvis Dohmatob, Jean-Baptiste Poline. <a class="reference external"href=https://doi.org/10.3389/fnins.2014.00167>Which fMRI clustering gives good brain parcellations ?</a> Frontiers in Neuroscience, 2014.</li></ul></div></blockquote><p>This parcellation may be useful in a supervised learning, see for instance</p><blockquote><div><ul class=simple><li>Vincent Michel, Alexandre Gramfort, Gael Varoquaux, Evelyn Eger, Christine Keribin, Bertrand Thirion. <a class="reference external"href=http://dx.doi.org/10.1016/j.patcog.2011.04.006>A supervised clustering approach for fMRI-based inference of brain states.</a>. Pattern Recognition, Elsevier, 2011.</li></ul></div></blockquote><p>The big picture discussion corresponding to this example can be found in the documentation section <a class="reference internal"href=../../connectivity/parcellating.html#parcellating-brain><span class="std std-ref">Clustering to parcellate the brain in regions</span></a>.</p></div><div class=section id=download-a-brain-development-fmri-dataset-and-turn-it-to-a-data-matrix><h2>9.4.11.2. Download a brain development fmri dataset and turn it to a data matrix<a title="Permalink to this headline"class=headerlink href=#download-a-brain-development-fmri-dataset-and-turn-it-to-a-data-matrix>¶</a></h2><p>We download one subject of the movie watching dataset from Internet</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn</span> <span class=k>import</span> <span class=n>datasets</span>
<a class="sphx-glr-backref-module-sklearn-utils sphx-glr-backref-type-py-function"href=https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch title=sklearn.utils.Bunch><span class=n>dataset</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-datasets sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.datasets.fetch_development_fmri.html#nilearn.datasets.fetch_development_fmri title=nilearn.datasets.fetch_development_fmri><span class=n>datasets</span><span class=o>.</span><span class=n>fetch_development_fmri</span></a><span class=p>(</span><span class=n>n_subjects</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=c1># print basic information on the dataset</span>
<span class=nb>print</span><span class=p>(</span><span class=s1>'First subject functional nifti image (4D) is at: </span><span class=si>%s</span><span class=s1>'</span> <span class=o>%</span>
      <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>dataset</span><span class=o>.</span><span class=n>func</span></a><span class=p>[</span><span class=mi>0</span><span class=p>])</span>  <span class=c1># 4D data</span>
</pre></div></div><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>First subject functional nifti image (4D) is at: /home/varoquau/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz
</pre></div></div></div><div class=section id=brain-parcellations-with-ward-clustering><h2>9.4.11.3. Brain parcellations with Ward Clustering<a title="Permalink to this headline"class=headerlink href=#brain-parcellations-with-ward-clustering>¶</a></h2><p>Transforming list of images to data matrix and build brain parcellations, all can be done at once using <cite>Parcellations</cite> object.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn.regions</span> <span class=k>import</span> <a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-class"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations title=nilearn.regions.Parcellations><span class=n>Parcellations</span></a>

<span class=c1># Computing ward for the first time, will be long... This can be seen by</span>
<span class=c1># measuring using time</span>
<span class=kn>import</span> <span class=nn>time</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#float title=builtins.float><span class=n>start</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"href=https://docs.python.org/3.6/library/time.html#time.time title=time.time><span class=n>time</span><span class=o>.</span><span class=n>time</span></a><span class=p>()</span>

<span class=c1># Agglomerative Clustering: ward</span>

<span class=c1># We build parameters of our own for this object. Parameters related to</span>
<span class=c1># masking, caching and defining number of clusters and specific parcellations</span>
<span class=c1># method.</span>
<a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations title=nilearn.regions.Parcellations><span class=n>ward</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-class"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations title=nilearn.regions.Parcellations><span class=n>Parcellations</span></a><span class=p>(</span><span class=n>method</span><span class=o>=</span><span class=s1>'ward'</span><span class=p>,</span> <span class=n>n_parcels</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span>
                     <span class=n>standardize</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>smoothing_fwhm</span><span class=o>=</span><span class=mf>2.</span><span class=p>,</span>
                     <span class=n>memory</span><span class=o>=</span><span class=s1>'nilearn_cache'</span><span class=p>,</span> <span class=n>memory_level</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
                     <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
<span class=c1># Call fit on functional dataset: single subject (less samples).</span>
<a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations.fit title=nilearn.regions.Parcellations.fit><span class=n>ward</span><span class=o>.</span><span class=n>fit</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>dataset</span><span class=o>.</span><span class=n>func</span></a><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>"Ward agglomeration 1000 clusters: </span><span class=si>%.2f</span><span class=s2>s"</span> <span class=o>%</span> <span class=p>(</span><a class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"href=https://docs.python.org/3.6/library/time.html#time.time title=time.time><span class=n>time</span><span class=o>.</span><span class=n>time</span></a><span class=p>()</span> <span class=o>-</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#float title=builtins.float><span class=n>start</span></a><span class=p>))</span>

<span class=c1># We compute now ward clustering with 2000 clusters and compare</span>
<span class=c1># time with 1000 clusters. To see the benefits of caching for second time.</span>

<span class=c1># We initialize class again with n_parcels=2000 this time.</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#float title=builtins.float><span class=n>start</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"href=https://docs.python.org/3.6/library/time.html#time.time title=time.time><span class=n>time</span><span class=o>.</span><span class=n>time</span></a><span class=p>()</span>
<a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations title=nilearn.regions.Parcellations><span class=n>ward</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-class"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations title=nilearn.regions.Parcellations><span class=n>Parcellations</span></a><span class=p>(</span><span class=n>method</span><span class=o>=</span><span class=s1>'ward'</span><span class=p>,</span> <span class=n>n_parcels</span><span class=o>=</span><span class=mi>2000</span><span class=p>,</span>
                     <span class=n>standardize</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>smoothing_fwhm</span><span class=o>=</span><span class=mf>2.</span><span class=p>,</span>
                     <span class=n>memory</span><span class=o>=</span><span class=s1>'nilearn_cache'</span><span class=p>,</span> <span class=n>memory_level</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
                     <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
<a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations.fit title=nilearn.regions.Parcellations.fit><span class=n>ward</span><span class=o>.</span><span class=n>fit</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>dataset</span><span class=o>.</span><span class=n>func</span></a><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>"Ward agglomeration 2000 clusters: </span><span class=si>%.2f</span><span class=s2>s"</span> <span class=o>%</span> <span class=p>(</span><a class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"href=https://docs.python.org/3.6/library/time.html#time.time title=time.time><span class=n>time</span><span class=o>.</span><span class=n>time</span></a><span class=p>()</span> <span class=o>-</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#float title=builtins.float><span class=n>start</span></a><span class=p>))</span>
</pre></div></div><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>[MultiNiftiMasker.fit] Loading data from [/home/varoquau/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz]
[MultiNiftiMasker.fit] Computing mask
/home/varoquau/dev/nilearn/nilearn/_utils/cache_mixin.py:295: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.
  warnings.warn("memory_level is currently set to 0 but "
[MultiNiftiMasker.transform] Resampling mask
[Parcellations] Loading data
[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/varoquau/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz')
[MultiNiftiMasker.transform_single_imgs] Smoothing images
[MultiNiftiMasker.transform_single_imgs] Extracting region signals
[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals
[Parcellations] computing ward
________________________________________________________________________________
[Memory] Calling nilearn.regions.parcellations._estimator_fit...
_estimator_fit(array([[-0.01289 , ...,  0.005973],
       ...,
       [-0.00842 , ...,  0.000342]]),
AgglomerativeClustering(connectivity=&LT24256x24256 sparse matrix of type '&LTclass 'numpy.int64'>'
        with 162682 stored elements in COOrdinate format>,
                        memory=Memory(location=nilearn_cache/joblib),
                        n_clusters=1000))
________________________________________________________________________________
[Memory] Calling sklearn.cluster._agglomerative.ward_tree...
ward_tree(array([[-0.01289 , ..., -0.00842 ],
       ...,
       [ 0.005973, ...,  0.000342]]), connectivity=&LT24256x24256 sparse matrix of type '&LTclass 'numpy.int64'>'
        with 162682 stored elements in COOrdinate format>, n_clusters=1000, return_distance=False)
________________________________________________________ward_tree - 6.4s, 0.1min
____________________________________________________estimator_fit - 6.6s, 0.1min
Ward agglomeration 1000 clusters: 18.12s
[MultiNiftiMasker.fit] Loading data from [/home/varoquau/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz]
[MultiNiftiMasker.fit] Computing mask
/home/varoquau/dev/nilearn/nilearn/_utils/cache_mixin.py:295: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.
  warnings.warn("memory_level is currently set to 0 but "
[MultiNiftiMasker.transform] Resampling mask
[Parcellations] Loading data
[Parcellations] computing ward
________________________________________________________________________________
[Memory] Calling nilearn.regions.parcellations._estimator_fit...
_estimator_fit(array([[-0.01289 , ...,  0.005973],
       ...,
       [-0.00842 , ...,  0.000342]]),
AgglomerativeClustering(connectivity=&LT24256x24256 sparse matrix of type '&LTclass 'numpy.int64'>'
        with 162682 stored elements in COOrdinate format>,
                        memory=Memory(location=nilearn_cache/joblib),
                        n_clusters=2000))
________________________________________________________________________________
[Memory] Calling sklearn.cluster._agglomerative.ward_tree...
ward_tree(array([[-0.01289 , ..., -0.00842 ],
       ...,
       [ 0.005973, ...,  0.000342]]), connectivity=&LT24256x24256 sparse matrix of type '&LTclass 'numpy.int64'>'
        with 162682 stored elements in COOrdinate format>, n_clusters=2000, return_distance=False)
________________________________________________________ward_tree - 6.6s, 0.1min
____________________________________________________estimator_fit - 6.9s, 0.1min
Ward agglomeration 2000 clusters: 14.99s
</pre></div></div><div class=section id=visualize-brain-parcellations-ward><h3>9.4.11.3.1. Visualize: Brain parcellations (Ward)<a title="Permalink to this headline"class=headerlink href=#visualize-brain-parcellations-ward>¶</a></h3><p>First, we display the parcellations of the brain image stored in attribute <cite>labels_img_</cite></p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>ward_labels_img</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>ward</span><span class=o>.</span><span class=n>labels_img_</span></a>

<span class=c1># Now, ward_labels_img are Nifti1Image object, it can be saved to file</span>
<span class=c1># with the following code:</span>
<a class="sphx-glr-backref-module-nibabel-filebasedimages sphx-glr-backref-type-py-method"href=https://nipy.org/nibabel/reference/nibabel.filebasedimages.html#nibabel.filebasedimages.FileBasedImage.to_filename title=nibabel.filebasedimages.FileBasedImage.to_filename><span class=n>ward_labels_img</span><span class=o>.</span><span class=n>to_filename</span></a><span class=p>(</span><span class=s1>'ward_parcellation.nii.gz'</span><span class=p>)</span>

<span class=kn>from</span> <span class=nn>nilearn</span> <span class=k>import</span> <span class=n>plotting</span>
<span class=kn>from</span> <span class=nn>nilearn.image</span> <span class=k>import</span> <a class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.image.mean_img.html#nilearn.image.mean_img title=nilearn.image.mean_img><span class=n>mean_img</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.image.index_img.html#nilearn.image.index_img title=nilearn.image.index_img><span class=n>index_img</span></a>

<span class=n>first_plot</span> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.plot_roi.html#nilearn.plotting.plot_roi title=nilearn.plotting.plot_roi><span class=n>plotting</span><span class=o>.</span><span class=n>plot_roi</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>ward_labels_img</span></a><span class=p>,</span> <span class=n>title</span><span class=o>=</span><span class=s2>"Ward parcellation"</span><span class=p>,</span>
                               <span class=n>display_mode</span><span class=o>=</span><span class=s1>'xz'</span><span class=p>)</span>

<span class=c1># Grab cut coordinates from this plot to use as a common for all plots</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>cut_coords</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>first_plot</span><span class=o>.</span><span class=n>cut_coords</span></a>
</pre></div></div><img alt="plot data driven parcellations"class=sphx-glr-single-img src=../../_images/sphx_glr_plot_data_driven_parcellations_001.png></div><div class=section id=compressed-representation-of-ward-clustering><h3>9.4.11.3.2. Compressed representation of Ward clustering<a title="Permalink to this headline"class=headerlink href=#compressed-representation-of-ward-clustering>¶</a></h3><p>Second, we illustrate the effect that the clustering has on the signal. We show the original data, and the approximation provided by the clustering by averaging the signal on each parcel.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=c1># Grab number of voxels from attribute mask image (mask_img_).</span>
<span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
<span class=kn>from</span> <span class=nn>nilearn.image</span> <span class=k>import</span> <a class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.image.get_data.html#nilearn.image.get_data title=nilearn.image.get_data><span class=n>get_data</span></a>
<span class=n>original_voxels</span> <span class=o>=</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"href=https://numpy.org/doc/stable/reference/generated/numpy.sum.html#numpy.sum title=numpy.sum><span class=n>np</span><span class=o>.</span><span class=n>sum</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.image.get_data.html#nilearn.image.get_data title=nilearn.image.get_data><span class=n>get_data</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>ward</span><span class=o>.</span><span class=n>mask_img_</span></a><span class=p>))</span>

<span class=c1># Compute mean over time on the functional image to use the mean</span>
<span class=c1># image for compressed representation comparisons</span>
<a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>mean_func_img</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.image.mean_img.html#nilearn.image.mean_img title=nilearn.image.mean_img><span class=n>mean_img</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>dataset</span><span class=o>.</span><span class=n>func</span></a><span class=p>[</span><span class=mi>0</span><span class=p>])</span>

<span class=c1># Compute common vmin and vmax</span>
<span class=n>vmin</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>min</span><span class=p>(</span><a class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.image.get_data.html#nilearn.image.get_data title=nilearn.image.get_data><span class=n>get_data</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>mean_func_img</span></a><span class=p>))</span>
<span class=n>vmax</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><a class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.image.get_data.html#nilearn.image.get_data title=nilearn.image.get_data><span class=n>get_data</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>mean_func_img</span></a><span class=p>))</span>

<a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.plot_epi.html#nilearn.plotting.plot_epi title=nilearn.plotting.plot_epi><span class=n>plotting</span><span class=o>.</span><span class=n>plot_epi</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>mean_func_img</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>cut_coords</span></a><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>cut_coords</span></a><span class=p>,</span>
                  <span class=n>title</span><span class=o>=</span><span class=s1>'Original (</span><span class=si>%i</span><span class=s1> voxels)'</span> <span class=o>%</span> <span class=n>original_voxels</span><span class=p>,</span>
                  <span class=n>vmax</span><span class=o>=</span><span class=n>vmax</span><span class=p>,</span> <span class=n>vmin</span><span class=o>=</span><span class=n>vmin</span><span class=p>,</span> <span class=n>display_mode</span><span class=o>=</span><span class=s1>'xz'</span><span class=p>)</span>

<span class=c1># A reduced dataset can be created by taking the parcel-level average:</span>
<span class=c1># Note that Parcellation objects with any method have the opportunity to</span>
<span class=c1># use a `transform` call that modifies input features. Here it reduces their</span>
<span class=c1># dimension. Note that we `fit` before calling a `transform` so that average</span>
<span class=c1># signals can be created on the brain parcellations with fit call.</span>
<a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>fmri_reduced</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations.transform title=nilearn.regions.Parcellations.transform><span class=n>ward</span><span class=o>.</span><span class=n>transform</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>dataset</span><span class=o>.</span><span class=n>func</span></a><span class=p>)</span>

<span class=c1># Display the corresponding data compressed using the parcellation using</span>
<span class=c1># parcels=2000.</span>
<a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>fmri_compressed</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations.inverse_transform title=nilearn.regions.Parcellations.inverse_transform><span class=n>ward</span><span class=o>.</span><span class=n>inverse_transform</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>fmri_reduced</span></a><span class=p>)</span>

<a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.plot_epi.html#nilearn.plotting.plot_epi title=nilearn.plotting.plot_epi><span class=n>plotting</span><span class=o>.</span><span class=n>plot_epi</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.image.index_img.html#nilearn.image.index_img title=nilearn.image.index_img><span class=n>index_img</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>fmri_compressed</span></a><span class=p>,</span> <span class=mi>0</span><span class=p>),</span>
                  <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>cut_coords</span></a><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>cut_coords</span></a><span class=p>,</span>
                  <span class=n>title</span><span class=o>=</span><span class=s1>'Ward compressed representation (2000 parcels)'</span><span class=p>,</span>
                  <span class=n>vmin</span><span class=o>=</span><span class=n>vmin</span><span class=p>,</span> <span class=n>vmax</span><span class=o>=</span><span class=n>vmax</span><span class=p>,</span> <span class=n>display_mode</span><span class=o>=</span><span class=s1>'xz'</span><span class=p>)</span>
<span class=c1># As you can see below, this approximation is almost good, although there</span>
<span class=c1># are only 2000 parcels, instead of the original 60000 voxels</span>
</pre></div></div><ul class=sphx-glr-horizontal><li><img alt="plot data driven parcellations"class="sphx-glr-multi-img first"src=../../_images/sphx_glr_plot_data_driven_parcellations_002.png></li><li><img alt="plot data driven parcellations"class="sphx-glr-multi-img first"src=../../_images/sphx_glr_plot_data_driven_parcellations_003.png></li></ul><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>[Parcellations.transform] loading data from Nifti1Image('ward_parcellation.nii.gz')
[Parcellations.transform] loading data from Nifti1Image(
shape=(50, 59, 50),
affine=array([[   4.,    0.,    0.,  -96.],
       [   0.,    4.,    0., -132.],
       [   0.,    0.,    4.,  -78.],
       [   0.,    0.,    0.,    1.]])
)
________________________________________________________________________________
[Memory] Calling nilearn.input_data.base_masker.filter_and_extract...
filter_and_extract(&LTnibabel.nifti1.Nifti1Image object at 0x7f8bfb472520>, &LTnilearn.input_data.nifti_labels_masker._ExtractionFunctor object at 0x7f8bfb472790>,
{ 'background_label': 0,
  'detrend': False,
  'dtype': None,
  'high_pass': None,
  'labels_img': &LTnibabel.nifti1.Nifti1Image object at 0x7f8bfb11f910>,
  'low_pass': None,
  'mask_img': &LTnibabel.nifti1.Nifti1Image object at 0x7f8bfb11fa90>,
  'smoothing_fwhm': 2.0,
  'standardize': False,
  'strategy': 'mean',
  't_r': None,
  'target_affine': None,
  'target_shape': None}, confounds=None, dtype=None, memory=Memory(location=nilearn_cache/joblib), memory_level=1, verbose=1)
[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/varoquau/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz')
[NiftiLabelsMasker.transform_single_imgs] Smoothing images
[NiftiLabelsMasker.transform_single_imgs] Extracting region signals
[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals
/home/varoquau/dev/nilearn/nilearn/input_data/nifti_labels_masker.py:299: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems
(results will be correct in all cases).
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  region_signals, labels_ = self._cache(
_______________________________________________filter_and_extract - 7.7s, 0.1min

&LTnilearn.plotting.displays.XZSlicer object at 0x7f8bf8d6d490>
</pre></div></div></div></div><div class=section id=brain-parcellations-with-kmeans-clustering><h2>9.4.11.4. Brain parcellations with KMeans Clustering<a title="Permalink to this headline"class=headerlink href=#brain-parcellations-with-kmeans-clustering>¶</a></h2><p>We use the same approach as with building parcellations using Ward clustering. But, in the range of a small number of clusters, it is most likely that we want to use standardization. Indeed with standardization and smoothing, the clusters will form as regions.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=c1># class/functions can be used here as they are already imported above.</span>

<span class=c1># This object uses method='kmeans' for KMeans clustering with 10mm smoothing</span>
<span class=c1># and standardization ON</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#float title=builtins.float><span class=n>start</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"href=https://docs.python.org/3.6/library/time.html#time.time title=time.time><span class=n>time</span><span class=o>.</span><span class=n>time</span></a><span class=p>()</span>
<a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations title=nilearn.regions.Parcellations><span class=n>kmeans</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-class"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations title=nilearn.regions.Parcellations><span class=n>Parcellations</span></a><span class=p>(</span><span class=n>method</span><span class=o>=</span><span class=s1>'kmeans'</span><span class=p>,</span> <span class=n>n_parcels</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span>
                       <span class=n>standardize</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>smoothing_fwhm</span><span class=o>=</span><span class=mf>10.</span><span class=p>,</span>
                       <span class=n>memory</span><span class=o>=</span><span class=s1>'nilearn_cache'</span><span class=p>,</span> <span class=n>memory_level</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
                       <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
<span class=c1># Call fit on functional dataset: single subject (less samples)</span>
<a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations.fit title=nilearn.regions.Parcellations.fit><span class=n>kmeans</span><span class=o>.</span><span class=n>fit</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>dataset</span><span class=o>.</span><span class=n>func</span></a><span class=p>)</span>
</pre></div></div><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>[MultiNiftiMasker.fit] Loading data from [/home/varoquau/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz]
[MultiNiftiMasker.fit] Computing mask
/home/varoquau/dev/nilearn/nilearn/_utils/cache_mixin.py:295: UserWarning: memory_level is currently set to 0 but a Memory object has been provided. Setting memory_level to 1.
  warnings.warn("memory_level is currently set to 0 but "
[MultiNiftiMasker.transform] Resampling mask
[Parcellations] Loading data
[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/varoquau/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz')
[MultiNiftiMasker.transform_single_imgs] Smoothing images
[MultiNiftiMasker.transform_single_imgs] Extracting region signals
[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals
[Parcellations] computing kmeans
________________________________________________________________________________
[Memory] Calling nilearn.regions.parcellations._estimator_fit...
_estimator_fit(array([[-0.006091, ...,  0.003879],
       ...,
       [-0.010654, ...,  0.01386 ]]),
MiniBatchKMeans(n_clusters=50, random_state=0))
____________________________________________________estimator_fit - 1.3s, 0.0min

Parcellations(memory=Memory(location=nilearn_cache/joblib), memory_level=1,
              method='kmeans', smoothing_fwhm=10.0, standardize=True)
</pre></div></div><div class=section id=visualize-brain-parcellations-kmeans><h3>9.4.11.4.1. Visualize: Brain parcellations (KMeans)<a title="Permalink to this headline"class=headerlink href=#visualize-brain-parcellations-kmeans>¶</a></h3><p>Grab parcellations of brain image stored in attribute <cite>labels_img_</cite></p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>kmeans_labels_img</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>kmeans</span><span class=o>.</span><span class=n>labels_img_</span></a>

<a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.plot_roi.html#nilearn.plotting.plot_roi title=nilearn.plotting.plot_roi><span class=n>plotting</span><span class=o>.</span><span class=n>plot_roi</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>kmeans_labels_img</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>mean_func_img</span></a><span class=p>,</span>
                  <span class=n>title</span><span class=o>=</span><span class=s2>"KMeans parcellation"</span><span class=p>,</span>
                  <span class=n>display_mode</span><span class=o>=</span><span class=s1>'xz'</span><span class=p>)</span>

<span class=c1># kmeans_labels_img is a Nifti1Image object, it can be saved to file with</span>
<span class=c1># the following code:</span>
<a class="sphx-glr-backref-module-nibabel-filebasedimages sphx-glr-backref-type-py-method"href=https://nipy.org/nibabel/reference/nibabel.filebasedimages.html#nibabel.filebasedimages.FileBasedImage.to_filename title=nibabel.filebasedimages.FileBasedImage.to_filename><span class=n>kmeans_labels_img</span><span class=o>.</span><span class=n>to_filename</span></a><span class=p>(</span><span class=s1>'kmeans_parcellation.nii.gz'</span><span class=p>)</span>
</pre></div></div><img alt="plot data driven parcellations"class=sphx-glr-single-img src=../../_images/sphx_glr_plot_data_driven_parcellations_004.png></div></div><div class=section id=brain-parcellations-with-rena-clustering><h2>9.4.11.5. Brain parcellations with ReNA Clustering<a title="Permalink to this headline"class=headerlink href=#brain-parcellations-with-rena-clustering>¶</a></h2><p>One interesting algorithmic property of ReNA (see References) is that it is very fast for a large number of parcels (notably faster than Ward). As before, the parcellation is done with a Parcellations object. The spatial constraints are implemented inside the Parcellations object.</p><div class=section id=id1><h3>9.4.11.5.1. References<a title="Permalink to this headline"class=headerlink href=#id1>¶</a></h3><p>More about ReNA clustering algorithm in the original paper</p><blockquote><div><ul class=simple><li>A. Hoyos-Idrobo, G. Varoquaux, J. Kahn and B. Thirion, “Recursive Nearest Agglomeration (ReNA): Fast Clustering for Approximation of Structured Signals,” in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 41, no. 3, pp. 669-681, 1 March 2019. <a class="reference external"href=https://hal.archives-ouvertes.fr/hal-01366651/>https://hal.archives-ouvertes.fr/hal-01366651/</a></li></ul></div></blockquote><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#float title=builtins.float><span class=n>start</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"href=https://docs.python.org/3.6/library/time.html#time.time title=time.time><span class=n>time</span><span class=o>.</span><span class=n>time</span></a><span class=p>()</span>
<a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations title=nilearn.regions.Parcellations><span class=n>rena</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-class"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations title=nilearn.regions.Parcellations><span class=n>Parcellations</span></a><span class=p>(</span><span class=n>method</span><span class=o>=</span><span class=s1>'rena'</span><span class=p>,</span> <span class=n>n_parcels</span><span class=o>=</span><span class=mi>5000</span><span class=p>,</span> <span class=n>standardize</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
                     <span class=n>smoothing_fwhm</span><span class=o>=</span><span class=mf>2.</span><span class=p>,</span> <span class=n>scaling</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations.fit_transform title=nilearn.regions.Parcellations.fit_transform><span class=n>rena</span><span class=o>.</span><span class=n>fit_transform</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>dataset</span><span class=o>.</span><span class=n>func</span></a><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>"ReNA 5000 clusters: </span><span class=si>%.2f</span><span class=s2>s"</span> <span class=o>%</span> <span class=p>(</span><a class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"href=https://docs.python.org/3.6/library/time.html#time.time title=time.time><span class=n>time</span><span class=o>.</span><span class=n>time</span></a><span class=p>()</span> <span class=o>-</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#float title=builtins.float><span class=n>start</span></a><span class=p>))</span>
</pre></div></div><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>[MultiNiftiMasker.fit] Loading data from [/home/varoquau/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz]
[MultiNiftiMasker.fit] Computing mask
[MultiNiftiMasker.transform] Resampling mask
[Parcellations] Loading data
[MultiNiftiMasker.transform_single_imgs] Loading data from Nifti1Image('/home/varoquau/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz')
[MultiNiftiMasker.transform_single_imgs] Smoothing images
[MultiNiftiMasker.transform_single_imgs] Extracting region signals
[MultiNiftiMasker.transform_single_imgs] Cleaning extracted signals
[Parcellations] computing rena
[Parcellations.fit_transform] loading data from Nifti1Image(
shape=(50, 59, 50),
affine=array([[   4.,    0.,    0.,  -96.],
       [   0.,    4.,    0., -132.],
       [   0.,    0.,    4.,  -78.],
       [   0.,    0.,    0.,    1.]])
)
[Parcellations.fit_transform] loading data from Nifti1Image(
shape=(50, 59, 50),
affine=array([[   4.,    0.,    0.,  -96.],
       [   0.,    4.,    0., -132.],
       [   0.,    0.,    4.,  -78.],
       [   0.,    0.,    0.,    1.]])
)
[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/varoquau/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz')
[NiftiLabelsMasker.transform_single_imgs] Smoothing images
[NiftiLabelsMasker.transform_single_imgs] Extracting region signals
[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals
ReNA 5000 clusters: 36.64s
</pre></div></div></div><div class=section id=visualize-brain-parcellations-rena><h3>9.4.11.5.2. Visualize: Brain parcellations (ReNA)<a title="Permalink to this headline"class=headerlink href=#visualize-brain-parcellations-rena>¶</a></h3><p>First, we display the parcellations of the brain image stored in attribute <cite>labels_img_</cite></p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>rena_labels_img</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>rena</span><span class=o>.</span><span class=n>labels_img_</span></a>

<span class=c1># Now, rena_labels_img are Nifti1Image object, it can be saved to file</span>
<span class=c1># with the following code:</span>
<a class="sphx-glr-backref-module-nibabel-filebasedimages sphx-glr-backref-type-py-method"href=https://nipy.org/nibabel/reference/nibabel.filebasedimages.html#nibabel.filebasedimages.FileBasedImage.to_filename title=nibabel.filebasedimages.FileBasedImage.to_filename><span class=n>rena_labels_img</span><span class=o>.</span><span class=n>to_filename</span></a><span class=p>(</span><span class=s1>'rena_parcellation.nii.gz'</span><span class=p>)</span>

<a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.plot_roi.html#nilearn.plotting.plot_roi title=nilearn.plotting.plot_roi><span class=n>plotting</span><span class=o>.</span><span class=n>plot_roi</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>ward_labels_img</span></a><span class=p>,</span> <span class=n>title</span><span class=o>=</span><span class=s2>"ReNA parcellation"</span><span class=p>,</span>
                  <span class=n>display_mode</span><span class=o>=</span><span class=s1>'xz'</span><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>cut_coords</span></a><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>cut_coords</span></a><span class=p>)</span>
</pre></div></div><img alt="plot data driven parcellations"class=sphx-glr-single-img src=../../_images/sphx_glr_plot_data_driven_parcellations_005.png><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>&LTnilearn.plotting.displays.XZSlicer object at 0x7f8bfc2f3b50>
</pre></div></div></div><div class=section id=compressed-representation-of-rena-clustering><h3>9.4.11.5.3. Compressed representation of ReNA clustering<a title="Permalink to this headline"class=headerlink href=#compressed-representation-of-rena-clustering>¶</a></h3><p>We illustrate the effect that the clustering has on the signal. We show the original data, and the approximation provided by the clustering by averaging the signal on each parcel.</p><p>We can then compare the results with the compressed representation obtained with Ward.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=c1># Display the original data</span>
<a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.plot_epi.html#nilearn.plotting.plot_epi title=nilearn.plotting.plot_epi><span class=n>plotting</span><span class=o>.</span><span class=n>plot_epi</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>mean_func_img</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>cut_coords</span></a><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>cut_coords</span></a><span class=p>,</span>
                  <span class=n>title</span><span class=o>=</span><span class=s1>'Original (</span><span class=si>%i</span><span class=s1> voxels)'</span> <span class=o>%</span> <span class=n>original_voxels</span><span class=p>,</span>
                  <span class=n>vmax</span><span class=o>=</span><span class=n>vmax</span><span class=p>,</span> <span class=n>vmin</span><span class=o>=</span><span class=n>vmin</span><span class=p>,</span> <span class=n>display_mode</span><span class=o>=</span><span class=s1>'xz'</span><span class=p>)</span>

<span class=c1># A reduced data can be created by taking the parcel-level average:</span>
<span class=c1># Note that, as many scikit-learn objects, the ReNA object exposes</span>
<span class=c1># a transform method that modifies input features. Here it reduces their</span>
<span class=c1># dimension.</span>
<span class=c1># However, the data are in one single large 4D image, we need to use</span>
<span class=c1># index_img to do the split easily:</span>
<a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>fmri_reduced_rena</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations.transform title=nilearn.regions.Parcellations.transform><span class=n>rena</span><span class=o>.</span><span class=n>transform</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>dataset</span><span class=o>.</span><span class=n>func</span></a><span class=p>)</span>

<span class=c1># Display the corresponding data compression using the parcellation</span>
<a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>compressed_img_rena</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-regions sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations.inverse_transform title=nilearn.regions.Parcellations.inverse_transform><span class=n>rena</span><span class=o>.</span><span class=n>inverse_transform</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>fmri_reduced_rena</span></a><span class=p>)</span>

<a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.plot_epi.html#nilearn.plotting.plot_epi title=nilearn.plotting.plot_epi><span class=n>plotting</span><span class=o>.</span><span class=n>plot_epi</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.image.index_img.html#nilearn.image.index_img title=nilearn.image.index_img><span class=n>index_img</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>compressed_img_rena</span></a><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>cut_coords</span></a><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>cut_coords</span></a><span class=p>,</span>
                  <span class=n>title</span><span class=o>=</span><span class=s1>'ReNA compressed representation (5000 parcels)'</span><span class=p>,</span>
                  <span class=n>vmin</span><span class=o>=</span><span class=n>vmin</span><span class=p>,</span> <span class=n>vmax</span><span class=o>=</span><span class=n>vmax</span><span class=p>,</span> <span class=n>display_mode</span><span class=o>=</span><span class=s1>'xz'</span><span class=p>)</span>
</pre></div></div><ul class=sphx-glr-horizontal><li><img alt="plot data driven parcellations"class="sphx-glr-multi-img first"src=../../_images/sphx_glr_plot_data_driven_parcellations_006.png></li><li><img alt="plot data driven parcellations"class="sphx-glr-multi-img first"src=../../_images/sphx_glr_plot_data_driven_parcellations_007.png></li></ul><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>[Parcellations.transform] loading data from Nifti1Image('rena_parcellation.nii.gz')
[Parcellations.transform] loading data from Nifti1Image(
shape=(50, 59, 50),
affine=array([[   4.,    0.,    0.,  -96.],
       [   0.,    4.,    0., -132.],
       [   0.,    0.,    4.,  -78.],
       [   0.,    0.,    0.,    1.]])
)
[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/varoquau/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz')
[NiftiLabelsMasker.transform_single_imgs] Smoothing images
[NiftiLabelsMasker.transform_single_imgs] Extracting region signals
[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals

&LTnilearn.plotting.displays.XZSlicer object at 0x7f8bfb44bd90>
</pre></div></div><p>Even if the compressed signal is relatively close to the original signal, we can notice that Ward Clustering gives a slightly more accurate compressed representation. However, as said in the previous section, the computation time is reduced which could still make ReNA more relevant than Ward in some cases.</p><p class=sphx-glr-timing><strong>Total running time of the script:</strong> ( 1 minutes 54.212 seconds)</p><div class="sphx-glr-footer class sphx-glr-footer-example docutils container"id=sphx-glr-download-auto-examples-03-connectivity-plot-data-driven-parcellations-py><div class="binder-badge docutils container"><a class="reference external image-reference"href=https://mybinder.org/v2/gh/nilearn/nilearn.github.io/master?filepath=examples/auto_examples/03_connectivity/plot_data_driven_parcellations.ipynb><img alt=https://mybinder.org/badge_logo.svg src=https://mybinder.org/badge_logo.svg width=150px></a></div><div class="sphx-glr-download sphx-glr-download-python docutils container"><a class="reference download internal"download href=../../_downloads/386459a6054ce7cb5a9328ff8bd14379/plot_data_driven_parcellations.py><code class="xref download docutils literal notranslate"><span class=pre>Download</span> <span class=pre>Python</span> <span class=pre>source</span> <span class=pre>code:</span> <span class=pre>plot_data_driven_parcellations.py</span></code></a></div><div class="sphx-glr-download sphx-glr-download-jupyter docutils container"><a class="reference download internal"download href=../../_downloads/34fef91c90f36da995898e159cc3d8e6/plot_data_driven_parcellations.ipynb><code class="xref download docutils literal notranslate"><span class=pre>Download</span> <span class=pre>Jupyter</span> <span class=pre>notebook:</span> <span class=pre>plot_data_driven_parcellations.ipynb</span></code></a></div></div><p class=sphx-glr-signature><a class="reference external"href=https://sphinx-gallery.github.io>Gallery generated by Sphinx-Gallery</a></p></div></div></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>9.4.11. Clustering methods to learn a brain parcellation from fMRI</a><ul><li><a class="reference internal"href=#references>9.4.11.1. References</a></li><li><a class="reference internal"href=#download-a-brain-development-fmri-dataset-and-turn-it-to-a-data-matrix>9.4.11.2. Download a brain development fmri dataset and turn it to a data matrix</a></li><li><a class="reference internal"href=#brain-parcellations-with-ward-clustering>9.4.11.3. Brain parcellations with Ward Clustering</a><ul><li><a class="reference internal"href=#visualize-brain-parcellations-ward>9.4.11.3.1. Visualize: Brain parcellations (Ward)</a></li><li><a class="reference internal"href=#compressed-representation-of-ward-clustering>9.4.11.3.2. Compressed representation of Ward clustering</a></li></ul></li><li><a class="reference internal"href=#brain-parcellations-with-kmeans-clustering>9.4.11.4. Brain parcellations with KMeans Clustering</a><ul><li><a class="reference internal"href=#visualize-brain-parcellations-kmeans>9.4.11.4.1. Visualize: Brain parcellations (KMeans)</a></li></ul></li><li><a class="reference internal"href=#brain-parcellations-with-rena-clustering>9.4.11.5. Brain parcellations with ReNA Clustering</a><ul><li><a class="reference internal"href=#id1>9.4.11.5.1. References</a></li><li><a class="reference internal"href=#visualize-brain-parcellations-rena>9.4.11.5.2. Visualize: Brain parcellations (ReNA)</a></li><li><a class="reference internal"href=#compressed-representation-of-rena-clustering>9.4.11.5.3. Compressed representation of ReNA clustering</a></li></ul></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=plot_extract_regions_dictlearning_maps.html>9.4.10. Regions extraction using Dictionary Learning and functional connectomes</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=plot_sphere_based_connectome.html>9.4.12. Extract signals on spheres and plot a connectome</a></p><div id=searchbox role=search style=display:none><h3>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input name=q><input type=submit value=Go><input name=check_keywords type=hidden value=yes><input name=area type=hidden value=default></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2020. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 1.8.5. <span style=padding-left:5ex> <a href=../../_sources/auto_examples/03_connectivity/plot_data_driven_parcellations.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>