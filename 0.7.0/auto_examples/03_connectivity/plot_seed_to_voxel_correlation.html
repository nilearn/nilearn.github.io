<!doctypehtml><html lang=en xmlns=http://www.w3.org/1999/xhtml><meta content=IE=Edge http-equiv=X-UA-Compatible><meta content="text/html; charset=utf-8"http-equiv=Content-Type><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/gallery.css rel=stylesheet><link href=../../_static/gallery-binder.css rel=stylesheet><link href=../../_static/gallery-dataframe.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/language_data.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="9.4.8. Group Sparse inverse covariance for multi-subject connectome"href=plot_multi_subject_connectome.html rel=next><link title="9.4.6. Comparing connectomes on different reference atlases"href=plot_atlas_comparison.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script></head><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../../modules/reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="9.4.8. Group Sparse inverse covariance for multi-subject connectome"accesskey=N href=plot_multi_subject_connectome.html>next</a> |</li><li class=right><a title="9.4.6. Comparing connectomes on different reference atlases"accesskey=P href=plot_atlas_comparison.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../index.html>Examples</a> | </li><li><a href=../../modules/reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../index.html>9. Nilearn usage examples</a> »</li></ul></div></div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="sphx-glr-download-link-note admonition note"><p class="first admonition-title">Note</p><p class=last>Click <a class="reference internal"href=#sphx-glr-download-auto-examples-03-connectivity-plot-seed-to-voxel-correlation-py><span class="std std-ref">here</span></a> to download the full example code or to run this example in your browser via Binder</p></div><div class="sphx-glr-example-title section"id=producing-single-subject-maps-of-seed-to-voxel-correlation><span id=sphx-glr-auto-examples-03-connectivity-plot-seed-to-voxel-correlation-py></span><h1>9.4.7. Producing single subject maps of seed-to-voxel correlation<a title="Permalink to this headline"class=headerlink href=#producing-single-subject-maps-of-seed-to-voxel-correlation>¶</a></h1><p>This example shows how to produce seed-to-voxel correlation maps for a single subject based on movie-watching fMRI scans. These maps depict the temporal correlation of a <strong>seed region</strong> with the <strong>rest of the brain</strong>.</p><p>This example is an advanced one that requires manipulating the data with numpy. Note the difference between images, that lie in brain space, and the numpy array, corresponding to the data inside the mask.</p><p>See also <a class="reference internal"href=../01_plotting/plot_surf_stat_map.html#sphx-glr-auto-examples-01-plotting-plot-surf-stat-map-py><span class="std std-ref">for a similar example using cortical surface input data</span></a>.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=c1># author: Franz Liem</span>
</pre></div></div><div class=section id=getting-the-data><h2>9.4.7.1. Getting the data<a title="Permalink to this headline"class=headerlink href=#getting-the-data>¶</a></h2><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=c1># We will work with the first subject of the brain development fmri data set.</span>
<span class=c1># dataset.func is a list of filenames. We select the 1st (0-based)</span>
<span class=c1># subject by indexing with [0]).</span>
<span class=kn>from</span> <span class=nn>nilearn</span> <span class=k>import</span> <span class=n>datasets</span>

<a class="sphx-glr-backref-module-sklearn-utils sphx-glr-backref-type-py-function"href=https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch title=sklearn.utils.Bunch><span class=n>dataset</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-datasets sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.datasets.fetch_development_fmri.html#nilearn.datasets.fetch_development_fmri title=nilearn.datasets.fetch_development_fmri><span class=n>datasets</span><span class=o>.</span><span class=n>fetch_development_fmri</span></a><span class=p>(</span><span class=n>n_subjects</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#str title=builtins.str><span class=n>func_filename</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>dataset</span><span class=o>.</span><span class=n>func</span></a><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#str title=builtins.str><span class=n>confound_filename</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>dataset</span><span class=o>.</span><span class=n>confounds</span></a><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</pre></div></div><p>Note that func_filename and confound_filename are strings pointing to files on your hard drive.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=nb>print</span><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#str title=builtins.str><span class=n>func_filename</span></a><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#str title=builtins.str><span class=n>confound_filename</span></a><span class=p>)</span>
</pre></div></div><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>/home/varoquau/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz
/home/varoquau/nilearn_data/development_fmri/development_fmri/sub-pixar123_task-pixar_desc-reducedConfounds_regressors.tsv
</pre></div></div></div><div class=section id=time-series-extraction><h2>9.4.7.2. Time series extraction<a title="Permalink to this headline"class=headerlink href=#time-series-extraction>¶</a></h2><p>We are going to extract signals from the functional time series in two steps. First we will extract the mean signal within the <strong>seed region of interest</strong>. Second, we will extract the <strong>brain-wide voxel-wise time series</strong>.</p><p>We will be working with one seed sphere in the Posterior Cingulate Cortex (PCC), considered part of the Default Mode Network.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>pcc_coords</span></a> <span class=o>=</span> <span class=p>[(</span><span class=mi>0</span><span class=p>,</span> <span class=o>-</span><span class=mi>52</span><span class=p>,</span> <span class=mi>18</span><span class=p>)]</span>
</pre></div></div><p>We use <a class="reference internal"href=../../modules/generated/nilearn.input_data.NiftiSpheresMasker.html#nilearn.input_data.NiftiSpheresMasker title=nilearn.input_data.NiftiSpheresMasker><code class="xref py py-class docutils literal notranslate"><span class=pre>nilearn.input_data.NiftiSpheresMasker</span></code></a> to extract the <strong>time series from the functional imaging within the sphere</strong>. The sphere is centered at pcc_coords and will have the radius we pass the NiftiSpheresMasker function (here 8 mm).</p><p>The extraction will also detrend, standardize, and bandpass filter the data. This will create a NiftiSpheresMasker object.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn</span> <span class=k>import</span> <span class=n>input_data</span>

<a class="sphx-glr-backref-module-nilearn-input_data sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=../../modules/generated/nilearn.input_data.NiftiSpheresMasker.html#nilearn.input_data.NiftiSpheresMasker title=nilearn.input_data.NiftiSpheresMasker><span class=n>seed_masker</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-input_data sphx-glr-backref-type-py-class"href=../../modules/generated/nilearn.input_data.NiftiSpheresMasker.html#nilearn.input_data.NiftiSpheresMasker title=nilearn.input_data.NiftiSpheresMasker><span class=n>input_data</span><span class=o>.</span><span class=n>NiftiSpheresMasker</span></a><span class=p>(</span>
    <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>pcc_coords</span></a><span class=p>,</span> <span class=n>radius</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
    <span class=n>detrend</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>standardize</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
    <span class=n>low_pass</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>high_pass</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span> <span class=n>t_r</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
    <span class=n>memory</span><span class=o>=</span><span class=s1>'nilearn_cache'</span><span class=p>,</span> <span class=n>memory_level</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</pre></div></div><p>Then we extract the mean time series within the seed region while regressing out the confounds that can be found in the dataset’s csv file</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>seed_time_series</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-input_data sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.input_data.NiftiSpheresMasker.html#nilearn.input_data.NiftiSpheresMasker.fit_transform title=nilearn.input_data.NiftiSpheresMasker.fit_transform><span class=n>seed_masker</span><span class=o>.</span><span class=n>fit_transform</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#str title=builtins.str><span class=n>func_filename</span></a><span class=p>,</span>
                                             <span class=n>confounds</span><span class=o>=</span><span class=p>[</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#str title=builtins.str><span class=n>confound_filename</span></a><span class=p>])</span>
</pre></div></div><p>Next, we can proceed similarly for the <strong>brain-wide voxel-wise time series</strong>, using <a class="reference internal"href=../../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker title=nilearn.input_data.NiftiMasker><code class="xref py py-class docutils literal notranslate"><span class=pre>nilearn.input_data.NiftiMasker</span></code></a> with the same input arguments as in the seed_masker in addition to smoothing with a 6 mm kernel</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-nilearn-input_data sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=../../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker title=nilearn.input_data.NiftiMasker><span class=n>brain_masker</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-input_data sphx-glr-backref-type-py-class"href=../../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker title=nilearn.input_data.NiftiMasker><span class=n>input_data</span><span class=o>.</span><span class=n>NiftiMasker</span></a><span class=p>(</span>
    <span class=n>smoothing_fwhm</span><span class=o>=</span><span class=mi>6</span><span class=p>,</span>
    <span class=n>detrend</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>standardize</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
    <span class=n>low_pass</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>high_pass</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span> <span class=n>t_r</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
    <span class=n>memory</span><span class=o>=</span><span class=s1>'nilearn_cache'</span><span class=p>,</span> <span class=n>memory_level</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</pre></div></div><p>Then we extract the brain-wide voxel-wise time series while regressing out the confounds as before</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>brain_time_series</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-input_data sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker.fit_transform title=nilearn.input_data.NiftiMasker.fit_transform><span class=n>brain_masker</span><span class=o>.</span><span class=n>fit_transform</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#str title=builtins.str><span class=n>func_filename</span></a><span class=p>,</span>
                                               <span class=n>confounds</span><span class=o>=</span><span class=p>[</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#str title=builtins.str><span class=n>confound_filename</span></a><span class=p>])</span>
</pre></div></div><p>We can now inspect the extracted time series. Note that the <strong>seed time series</strong> is an array with shape n_volumes, 1), while the <strong>brain time series</strong> is an array with shape (n_volumes, n_voxels).</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=nb>print</span><span class=p>(</span><span class=s2>"Seed time series shape: (</span><span class=si>%s</span><span class=s2>, </span><span class=si>%s</span><span class=s2>)"</span> <span class=o>%</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#tuple title=builtins.tuple><span class=n>seed_time_series</span><span class=o>.</span><span class=n>shape</span></a><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>"Brain time series shape: (</span><span class=si>%s</span><span class=s2>, </span><span class=si>%s</span><span class=s2>)"</span> <span class=o>%</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#tuple title=builtins.tuple><span class=n>brain_time_series</span><span class=o>.</span><span class=n>shape</span></a><span class=p>)</span>
</pre></div></div><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>Seed time series shape: (168, 1)
Brain time series shape: (168, 32504)
</pre></div></div><p>We can plot the <strong>seed time series</strong>.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>

<a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"href=https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot title=matplotlib.pyplot.plot><span class=n>plt</span><span class=o>.</span><span class=n>plot</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>seed_time_series</span></a><span class=p>)</span>
<a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"href=https://matplotlib.org/api/_as_gen/matplotlib.pyplot.title.html#matplotlib.pyplot.title title=matplotlib.pyplot.title><span class=n>plt</span><span class=o>.</span><span class=n>title</span></a><span class=p>(</span><span class=s1>'Seed time series (Posterior cingulate cortex)'</span><span class=p>)</span>
<a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"href=https://matplotlib.org/api/_as_gen/matplotlib.pyplot.xlabel.html#matplotlib.pyplot.xlabel title=matplotlib.pyplot.xlabel><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span></a><span class=p>(</span><span class=s1>'Scan number'</span><span class=p>)</span>
<a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"href=https://matplotlib.org/api/_as_gen/matplotlib.pyplot.ylabel.html#matplotlib.pyplot.ylabel title=matplotlib.pyplot.ylabel><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span></a><span class=p>(</span><span class=s1>'Normalized signal'</span><span class=p>)</span>
<a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"href=https://matplotlib.org/api/_as_gen/matplotlib.pyplot.tight_layout.html#matplotlib.pyplot.tight_layout title=matplotlib.pyplot.tight_layout><span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span></a><span class=p>()</span>
</pre></div></div><img alt="Seed time series (Posterior cingulate cortex)"class=sphx-glr-single-img src=../../_images/sphx_glr_plot_seed_to_voxel_correlation_001.png><p>Exemplarily, we can also select 5 random voxels from the <strong>brain-wide data</strong> and plot the time series from.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"href=https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot title=matplotlib.pyplot.plot><span class=n>plt</span><span class=o>.</span><span class=n>plot</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>brain_time_series</span></a><span class=p>[:,</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>45</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>5000</span><span class=p>,</span> <span class=mi>10000</span><span class=p>]])</span>
<a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"href=https://matplotlib.org/api/_as_gen/matplotlib.pyplot.title.html#matplotlib.pyplot.title title=matplotlib.pyplot.title><span class=n>plt</span><span class=o>.</span><span class=n>title</span></a><span class=p>(</span><span class=s1>'Time series from 5 random voxels'</span><span class=p>)</span>
<a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"href=https://matplotlib.org/api/_as_gen/matplotlib.pyplot.xlabel.html#matplotlib.pyplot.xlabel title=matplotlib.pyplot.xlabel><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span></a><span class=p>(</span><span class=s1>'Scan number'</span><span class=p>)</span>
<a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"href=https://matplotlib.org/api/_as_gen/matplotlib.pyplot.ylabel.html#matplotlib.pyplot.ylabel title=matplotlib.pyplot.ylabel><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span></a><span class=p>(</span><span class=s1>'Normalized signal'</span><span class=p>)</span>
<a class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"href=https://matplotlib.org/api/_as_gen/matplotlib.pyplot.tight_layout.html#matplotlib.pyplot.tight_layout title=matplotlib.pyplot.tight_layout><span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span></a><span class=p>()</span>
</pre></div></div><img alt="Time series from 5 random voxels"class=sphx-glr-single-img src=../../_images/sphx_glr_plot_seed_to_voxel_correlation_002.png></div><div class=section id=performing-the-seed-to-voxel-correlation-analysis><h2>9.4.7.3. Performing the seed-to-voxel correlation analysis<a title="Permalink to this headline"class=headerlink href=#performing-the-seed-to-voxel-correlation-analysis>¶</a></h2><p>Now that we have two arrays (<strong>sphere signal</strong>: (n_volumes, 1), <strong>brain-wide voxel-wise signal</strong> (n_volumes, n_voxels)), we can correlate the <strong>seed signal</strong> with the <strong>signal of each voxel</strong>. The dot product of the two arrays will give us this correlation. Note that the signals have been variance-standardized during extraction. To have them standardized to norm unit, we further have to divide the result by the length of the time series.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>

<a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>seed_to_voxel_correlations</span></a> <span class=o>=</span> <span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"href=https://numpy.org/doc/stable/reference/generated/numpy.dot.html#numpy.dot title=numpy.dot><span class=n>np</span><span class=o>.</span><span class=n>dot</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>brain_time_series</span><span class=o>.</span><span class=n>T</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>seed_time_series</span></a><span class=p>)</span> <span class=o>/</span>
                              <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#tuple title=builtins.tuple><span class=n>seed_time_series</span><span class=o>.</span><span class=n>shape</span></a><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
                              <span class=p>)</span>
</pre></div></div><p>The resulting array will contain a value representing the correlation values between the signal in the <strong>seed region</strong> of interest and <strong>each voxel’s signal</strong>, and will be of shape (n_voxels, 1). The correlation values can potentially range between -1 and 1.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=nb>print</span><span class=p>(</span><span class=s2>"Seed-to-voxel correlation shape: (</span><span class=si>%s</span><span class=s2>, </span><span class=si>%s</span><span class=s2>)"</span> <span class=o>%</span>
      <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#tuple title=builtins.tuple><span class=n>seed_to_voxel_correlations</span><span class=o>.</span><span class=n>shape</span></a><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>"Seed-to-voxel correlation: min = </span><span class=si>%.3f</span><span class=s2>; max = </span><span class=si>%.3f</span><span class=s2>"</span> <span class=o>%</span> <span class=p>(</span>
    <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>seed_to_voxel_correlations</span></a><span class=o>.</span><span class=n>min</span><span class=p>(),</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>seed_to_voxel_correlations</span></a><span class=o>.</span><span class=n>max</span><span class=p>()))</span>
</pre></div></div><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>Seed-to-voxel correlation shape: (32504, 1)
Seed-to-voxel correlation: min = -0.624; max = 0.958
</pre></div></div></div><div class=section id=plotting-the-seed-to-voxel-correlation-map><h2>9.4.7.4. Plotting the seed-to-voxel correlation map<a title="Permalink to this headline"class=headerlink href=#plotting-the-seed-to-voxel-correlation-map>¶</a></h2><p>We can now plot the seed-to-voxel correlation map and perform thresholding to only show values more extreme than +/- 0.5. Before displaying, we need to create an in memory Nifti image object. Furthermore, we can display the location of the seed with a sphere and set the cross to the center of the seed region of interest.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn</span> <span class=k>import</span> <span class=n>plotting</span>

<a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>seed_to_voxel_correlations_img</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-input_data sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker.inverse_transform title=nilearn.input_data.NiftiMasker.inverse_transform><span class=n>brain_masker</span><span class=o>.</span><span class=n>inverse_transform</span></a><span class=p>(</span>
    <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>seed_to_voxel_correlations</span><span class=o>.</span><span class=n>T</span></a><span class=p>)</span>
<a class="sphx-glr-backref-module-nilearn-plotting-displays sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=../../modules/generated/nilearn.plotting.displays.OrthoSlicer.html#nilearn.plotting.displays.OrthoSlicer title=nilearn.plotting.displays.OrthoSlicer><span class=n>display</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map title=nilearn.plotting.plot_stat_map><span class=n>plotting</span><span class=o>.</span><span class=n>plot_stat_map</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>seed_to_voxel_correlations_img</span></a><span class=p>,</span>
                                 <span class=n>threshold</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>vmax</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
                                 <span class=n>cut_coords</span><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>pcc_coords</span></a><span class=p>[</span><span class=mi>0</span><span class=p>],</span>
                                 <span class=n>title</span><span class=o>=</span><span class=s2>"Seed-to-voxel correlation (PCC seed)"</span>
                                 <span class=p>)</span>
<a class="sphx-glr-backref-module-nilearn-plotting-displays sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.plotting.displays.OrthoSlicer.html#nilearn.plotting.displays.OrthoSlicer.add_markers title=nilearn.plotting.displays.OrthoSlicer.add_markers><span class=n>display</span><span class=o>.</span><span class=n>add_markers</span></a><span class=p>(</span><span class=n>marker_coords</span><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>pcc_coords</span></a><span class=p>,</span> <span class=n>marker_color</span><span class=o>=</span><span class=s1>'g'</span><span class=p>,</span>
                    <span class=n>marker_size</span><span class=o>=</span><span class=mi>300</span><span class=p>)</span>
<span class=c1># At last, we save the plot as pdf.</span>
<a class="sphx-glr-backref-module-nilearn-plotting-displays sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.plotting.displays.OrthoSlicer.html#nilearn.plotting.displays.OrthoSlicer.savefig title=nilearn.plotting.displays.OrthoSlicer.savefig><span class=n>display</span><span class=o>.</span><span class=n>savefig</span></a><span class=p>(</span><span class=s1>'pcc_seed_correlation.pdf'</span><span class=p>)</span>
</pre></div></div><img alt="plot seed to voxel correlation"class=sphx-glr-single-img src=../../_images/sphx_glr_plot_seed_to_voxel_correlation_003.png></div><div class=section id=fisher-z-transformation-and-save-nifti><h2>9.4.7.5. Fisher-z transformation and save nifti<a title="Permalink to this headline"class=headerlink href=#fisher-z-transformation-and-save-nifti>¶</a></h2><p>Finally, we can Fisher-z transform the data to achieve a normal distribution. The transformed array can now have values more extreme than +/- 1.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>seed_to_voxel_correlations_fisher_z</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-data"href=https://numpy.org/doc/stable/reference/generated/numpy.arctanh.html#numpy.arctanh title=numpy.arctanh><span class=n>np</span><span class=o>.</span><span class=n>arctanh</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>seed_to_voxel_correlations</span></a><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>"Seed-to-voxel correlation Fisher-z transformed: min = </span><span class=si>%.3f</span><span class=s2>; max = </span><span class=si>%.3f</span><span class=s2>"</span>
      <span class=o>%</span> <span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>seed_to_voxel_correlations_fisher_z</span></a><span class=o>.</span><span class=n>min</span><span class=p>(),</span>
         <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>seed_to_voxel_correlations_fisher_z</span></a><span class=o>.</span><span class=n>max</span><span class=p>()</span>
         <span class=p>)</span>
      <span class=p>)</span>

<span class=c1># Finally, we can tranform the correlation array back to a Nifti image</span>
<span class=c1># object, that we can save.</span>
<a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>seed_to_voxel_correlations_fisher_z_img</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-input_data sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker.inverse_transform title=nilearn.input_data.NiftiMasker.inverse_transform><span class=n>brain_masker</span><span class=o>.</span><span class=n>inverse_transform</span></a><span class=p>(</span>
    <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>seed_to_voxel_correlations_fisher_z</span><span class=o>.</span><span class=n>T</span></a><span class=p>)</span>
<a class="sphx-glr-backref-module-nibabel-filebasedimages sphx-glr-backref-type-py-method"href=https://nipy.org/nibabel/reference/nibabel.filebasedimages.html#nibabel.filebasedimages.FileBasedImage.to_filename title=nibabel.filebasedimages.FileBasedImage.to_filename><span class=n>seed_to_voxel_correlations_fisher_z_img</span><span class=o>.</span><span class=n>to_filename</span></a><span class=p>(</span>
    <span class=s1>'pcc_seed_correlation_z.nii.gz'</span><span class=p>)</span>
</pre></div></div><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>Seed-to-voxel correlation Fisher-z transformed: min = -0.731; max = 1.927
</pre></div></div><p class=sphx-glr-timing><strong>Total running time of the script:</strong> ( 0 minutes 7.274 seconds)</p><div class="sphx-glr-footer class sphx-glr-footer-example docutils container"id=sphx-glr-download-auto-examples-03-connectivity-plot-seed-to-voxel-correlation-py><div class="binder-badge docutils container"><a class="reference external image-reference"href=https://mybinder.org/v2/gh/nilearn/nilearn.github.io/master?filepath=examples/auto_examples/03_connectivity/plot_seed_to_voxel_correlation.ipynb><img alt=https://mybinder.org/badge_logo.svg src=https://mybinder.org/badge_logo.svg width=150px></a></div><div class="sphx-glr-download sphx-glr-download-python docutils container"><a class="reference download internal"download href=../../_downloads/5859e27565d0ef43eebc0277c2bc6627/plot_seed_to_voxel_correlation.py><code class="xref download docutils literal notranslate"><span class=pre>Download</span> <span class=pre>Python</span> <span class=pre>source</span> <span class=pre>code:</span> <span class=pre>plot_seed_to_voxel_correlation.py</span></code></a></div><div class="sphx-glr-download sphx-glr-download-jupyter docutils container"><a class="reference download internal"download href=../../_downloads/2903f993fa9c6a304844c3539d88fd0c/plot_seed_to_voxel_correlation.ipynb><code class="xref download docutils literal notranslate"><span class=pre>Download</span> <span class=pre>Jupyter</span> <span class=pre>notebook:</span> <span class=pre>plot_seed_to_voxel_correlation.ipynb</span></code></a></div></div><p class=sphx-glr-signature><a class="reference external"href=https://sphinx-gallery.github.io>Gallery generated by Sphinx-Gallery</a></p></div></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>9.4.7. Producing single subject maps of seed-to-voxel correlation</a><ul><li><a class="reference internal"href=#getting-the-data>9.4.7.1. Getting the data</a></li><li><a class="reference internal"href=#time-series-extraction>9.4.7.2. Time series extraction</a></li><li><a class="reference internal"href=#performing-the-seed-to-voxel-correlation-analysis>9.4.7.3. Performing the seed-to-voxel correlation analysis</a></li><li><a class="reference internal"href=#plotting-the-seed-to-voxel-correlation-map>9.4.7.4. Plotting the seed-to-voxel correlation map</a></li><li><a class="reference internal"href=#fisher-z-transformation-and-save-nifti>9.4.7.5. Fisher-z transformation and save nifti</a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=plot_atlas_comparison.html>9.4.6. Comparing connectomes on different reference atlases</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=plot_multi_subject_connectome.html>9.4.8. Group Sparse inverse covariance for multi-subject connectome</a></p><div id=searchbox role=search style=display:none><h3>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input name=q><input type=submit value=Go><input name=check_keywords type=hidden value=yes><input name=area type=hidden value=default></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2020. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 1.8.5. <span style=padding-left:5ex> <a href=../../_sources/auto_examples/03_connectivity/plot_seed_to_voxel_correlation.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>