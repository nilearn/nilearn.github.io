<!doctypehtml><html lang=en xmlns=http://www.w3.org/1999/xhtml><meta content=IE=Edge http-equiv=X-UA-Compatible><meta content="text/html; charset=utf-8"http-equiv=Content-Type><title>Nilearn: Statistical Analysis for NeuroImaging in Python — Machine learning for NeuroImaging</title><link href=../../_static/nature.css rel=stylesheet><link href=../../_static/pygments.css rel=stylesheet><link href=../../_static/gallery.css rel=stylesheet><link href=../../_static/gallery-binder.css rel=stylesheet><link href=../../_static/gallery-dataframe.css rel=stylesheet><script data-url_root=../../ id=documentation_options src=../../_static/documentation_options.js></script><script src=../../_static/jquery.js></script><script src=../../_static/underscore.js></script><script src=../../_static/doctools.js></script><script src=../../_static/language_data.js></script><script src=../../_static/copybutton.js></script><link rel="shortcut icon"href=../../_static/favicon.ico><link href=../../search.html rel=search title=Search><link title="9.3.16. Reconstruction of visual stimuli from Miyawaki et al. 2008"href=plot_miyawaki_reconstruction.html rel=next><link title="9.3.14. Example of pattern recognition on simulated data"href=plot_simulated_data.html rel=prev><meta content=True name=HandheldFriendly><meta content=width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0 name=viewport><meta content="nilearn, neuroimaging, python, neuroscience, machinelearning"name=keywords><script>function updateTopMenuPosition(height, width) {
    if($(window).scrollTop() > height && $(window).outerWidth() > 1024) {
        //begin to scroll
        $('.related-wrapper').css("z-index", 1000);
        $('.related-wrapper').css("position", "sticky");
        $('.related-wrapper').css("top", 0);
        $('.related-wrapper').css("width", width)
    } else {
        //lock it back into place
        $('.related-wrapper').css("position", "relative");
        $('.related-wrapper').css("top", 0)
    }
}

$(function() {
    var banner_height = $('#logo-banner').outerHeight();
    var banner_width = $('#logo-banner').outerWidth();
    var width = $('.related-wrapper').css("height", $('.related').outerHeight());

    updateTopMenuPosition(banner_height, width);

    $(window).scroll(function(event) {
        updateTopMenuPosition(banner_height, width)
    });

    $(window).resize(function(event) {
        var banner_width = $('#logo-banner').outerWidth();
        var menu_height = $('.related').outerHeight();
        $('.related').css("width", banner_width);
        $('.related-wrapper').css("height", menu_height);
        updateTopMenuPosition(banner_height, width)
    })
});</script><script>function updateSideBarPosition(top, offset, sections) {
    var pos = $(window).scrollTop();
    // Lock the table of content to a fixed position once we scroll enough
    var topShift = 2 * offset;
    if(pos > top + topShift + 1) {
        // begin to scroll with sticky menu bar
        var topShift = -topShift + 1;
        if ($(window).outerWidth() < 1024) {
            // compensate top menu that disappears
            topShift -= offset + 1
        }
        $('.sphinxsidebarwrapper').css("position", "fixed");
        $('.sphinxsidebarwrapper').css("top", topShift)
    }
    else {
        //lock it back into place
        $('.sphinxsidebarwrapper').css("position", "relative");
        $('.sphinxsidebarwrapper').css("top",0)
    }

    // Highlight the current section
    i = 0;
    current_section = 0;
    $('a.internal').removeClass('active');
    for(i in sections) {
        if(sections[i] > pos) {
            break
        }
        if($('a.internal[href$="' + i + '"]').is(':visible')){
            current_section = i
        }
    }
    $('a.internal[href$="' + current_section + '"]').addClass('active');
    $('a.internal[href$="' + current_section + '"]').parent().addClass('active')
}

$(function () {
    // Lock the table of content to a fixed position once we scroll enough
    var tocOffset = $('.related-wrapper').outerHeight();
    var marginTop = parseFloat($('.sphinxsidebarwrapper').css('margin-top').replace(/auto/, 0));
    var top = $('.sphinxsidebarwrapper').offset().top - marginTop;
    sections = {};
    url = document.URL.replace(/#.*$/, "");

    // Grab positions of our sections
    $('.headerlink').each(function(){
        sections[this.href.replace(url, '')] = $(this).offset().top - 50
    });

    updateSideBarPosition(top, tocOffset, sections);

    $(window).scroll(function(event) {
        updateSideBarPosition(top, tocOffset, sections)
    });

    $(window).resize(function(event) {
        tocOffset = $('.related-wrapper').outerHeight();
        updateSideBarPosition(top, tocOffset, sections)
    });
});</script><script>var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-41920728-1']);
        _gaq.push(['_trackPageview']);

        (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();</script></head><body><div id=logo-banner><div class=logo><a href=../../index.html> <img alt="Nilearn logo"border=0 src=../../_static/nilearn-logo.png> </a></div><div class=tags><ul><li><big><a href=../decoding/plot_haxby_anova_svm.html>SVM</a></big></li><li><small><a href=../../connectivity/parcellating.html>Ward clustering</a></small></li><li><a href=../../decoding/searchlight.html>Searchlight</a></li><li><big><a href=../../connectivity/resting_state_networks.html>ICA</a></big></li><li><a href=../../manipulating_images/data_preparation.html>Nifti IO</a></li><li><a href=../../modules/reference.html#module-nilearn.datasets>Datasets</a></li></ul></div><div class=banner><h1>Nilearn:</h1><h2>Statistics for NeuroImaging in Python</h2></div><div class=search_form><div class=gcse-search id=cse style=width:100%></div><script>(function() {
        var cx = '017289614950330089114:elrt9qoutrq';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();</script></div></div><div class=related-wrapper><div aria-label="related navigation"class=related role=navigation><h3>Navigation</h3><ul><li class=right style=margin-right:10px><a title="Python Module Index"href=../../py-modindex.html>modules</a></li><li class=right><a title="9.3.16. Reconstruction of visual stimuli from Miyawaki et al. 2008"accesskey=N href=plot_miyawaki_reconstruction.html>next</a> |</li><li class=right><a title="9.3.14. Example of pattern recognition on simulated data"accesskey=P href=plot_simulated_data.html>previous</a> |</li><li><a href=../../index.html>Nilearn Home</a> | </li><li><a href=../../user_guide.html>User Guide</a> | </li><li><a href=../index.html>Examples</a> | </li><li><a href=../../modules/reference.html>Reference</a> | </li><li id=navbar-about><a href=../../authors.html>About</a>| </li><li id=navbar-ecosystem><a href=http://www.nipy.org/>Nipy ecosystem</a></li><li class="nav-item nav-item-1"><a href=../../user_guide.html>User guide: table of contents</a> »</li><li class="nav-item nav-item-2"><a accesskey=U href=../index.html>9. Nilearn usage examples</a> »</li></ul></div></div><div class=document><div class=documentwrapper><div class=bodywrapper><div class=body role=main><div class="sphx-glr-download-link-note admonition note"><p class="first admonition-title">Note</p><p class=last>Click <a class="reference internal"href=#sphx-glr-download-auto-examples-02-decoding-plot-miyawaki-encoding-py><span class="std std-ref">here</span></a> to download the full example code or to run this example in your browser via Binder</p></div><div class="sphx-glr-example-title section"id=encoding-models-for-visual-stimuli-from-miyawaki-et-al-2008><span id=sphx-glr-auto-examples-02-decoding-plot-miyawaki-encoding-py></span><h1>9.3.15. Encoding models for visual stimuli from Miyawaki et al. 2008<a title="Permalink to this headline"class=headerlink href=#encoding-models-for-visual-stimuli-from-miyawaki-et-al-2008>¶</a></h1><dl class=docutils><dt>This example partly reproduces the encoding model presented in</dt><dd><a class="reference external"href=http://www.cell.com/neuron/abstract/S0896-6273%2808%2900958-6>Visual image reconstruction from human brain activity using a combination of multiscale local image decoders</a>, Miyawaki, Y., Uchida, H., Yamashita, O., Sato, M. A., Morito, Y., Tanabe, H. C., … & Kamitani, Y. (2008). Neuron, 60(5), 915-929.</dd></dl><p>Encoding models try to predict neuronal activity using information from presented stimuli, like an image or sound. Where decoding goes from brain data to real-world stimulus, encoding goes the other direction.</p><p>We demonstrate how to build such an <strong>encoding model</strong> in nilearn, predicting <strong>fMRI data</strong> from <strong>visual stimuli</strong>, using the dataset from <a class="reference external"href=http://www.cell.com/neuron/abstract/S0896-6273%2808%2900958-6>Miyawaki et al., 2008</a>.</p><p>Participants were shown images, which consisted of random 10x10 binary (either black or white) pixels, and the corresponding fMRI activity was recorded. We will try to predict the activity in each voxel from the binary pixel-values of the presented images. Then we extract the receptive fields for a set of voxels to see which pixel location a voxel is most sensitive to.</p><p>See also <a class="reference internal"href=plot_miyawaki_reconstruction.html><span class=doc>Reconstruction of visual stimuli from Miyawaki et al. 2008</span></a> for a decoding approach for the same dataset.</p><div class=section id=loading-the-data><h2>9.3.15.1. Loading the data<a title="Permalink to this headline"class=headerlink href=#loading-the-data>¶</a></h2><p>Now we can load the data set:</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn.datasets</span> <span class=k>import</span> <a class="sphx-glr-backref-module-nilearn-datasets sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.datasets.fetch_miyawaki2008.html#nilearn.datasets.fetch_miyawaki2008 title=nilearn.datasets.fetch_miyawaki2008><span class=n>fetch_miyawaki2008</span></a>

<a class="sphx-glr-backref-module-sklearn-utils sphx-glr-backref-type-py-function"href=https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch title=sklearn.utils.Bunch><span class=n>dataset</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-datasets sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.datasets.fetch_miyawaki2008.html#nilearn.datasets.fetch_miyawaki2008 title=nilearn.datasets.fetch_miyawaki2008><span class=n>fetch_miyawaki2008</span></a><span class=p>()</span>
</pre></div></div><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>Dataset created in /home/varoquau/nilearn_data/miyawaki2008

Downloading data from https://www.nitrc.org/frs/download.php/8486/miyawaki2008.tgz ...

Downloaded 114688 of 161069109 bytes (0.1%, 26.5min remaining)
Downloaded 278528 of 161069109 bytes (0.2%, 21.1min remaining)
Downloaded 581632 of 161069109 bytes (0.4%, 15.7min remaining)
Downloaded 991232 of 161069109 bytes (0.6%, 12.5min remaining)
Downloaded 1523712 of 161069109 bytes (0.9%, 10.3min remaining)
Downloaded 2220032 of 161069109 bytes (1.4%,  8.5min remaining)
Downloaded 3055616 of 161069109 bytes (1.9%,  7.1min remaining)
Downloaded 3858432 of 161069109 bytes (2.4%,  6.3min remaining)
Downloaded 5029888 of 161069109 bytes (3.1%,  5.4min remaining)
Downloaded 6021120 of 161069109 bytes (3.7%,  5.0min remaining)
Downloaded 7356416 of 161069109 bytes (4.6%,  4.4min remaining)
Downloaded 8790016 of 161069109 bytes (5.5%,  4.0min remaining)
Downloaded 10330112 of 161069109 bytes (6.4%,  3.7min remaining)
Downloaded 12009472 of 161069109 bytes (7.5%,  3.4min remaining)
Downloaded 13803520 of 161069109 bytes (8.6%,  3.1min remaining)
Downloaded 15335424 of 161069109 bytes (9.5%,  3.0min remaining)
Downloaded 16777216 of 161069109 bytes (10.4%,  2.9min remaining)
Downloaded 18333696 of 161069109 bytes (11.4%,  2.8min remaining)
Downloaded 20013056 of 161069109 bytes (12.4%,  2.7min remaining)
Downloaded 21815296 of 161069109 bytes (13.5%,  2.6min remaining)
Downloaded 23814144 of 161069109 bytes (14.8%,  2.4min remaining)
Downloaded 25305088 of 161069109 bytes (15.7%,  2.4min remaining)
Downloaded 26877952 of 161069109 bytes (16.7%,  2.3min remaining)
Downloaded 28483584 of 161069109 bytes (17.7%,  2.2min remaining)
Downloaded 30081024 of 161069109 bytes (18.7%,  2.2min remaining)
Downloaded 31694848 of 161069109 bytes (19.7%,  2.1min remaining)
Downloaded 33366016 of 161069109 bytes (20.7%,  2.1min remaining)
Downloaded 34775040 of 161069109 bytes (21.6%,  2.0min remaining)
Downloaded 36249600 of 161069109 bytes (22.5%,  2.0min remaining)
Downloaded 37863424 of 161069109 bytes (23.5%,  2.0min remaining)
Downloaded 39346176 of 161069109 bytes (24.4%,  1.9min remaining)
Downloaded 40902656 of 161069109 bytes (25.4%,  1.9min remaining)
Downloaded 42565632 of 161069109 bytes (26.4%,  1.8min remaining)
Downloaded 44351488 of 161069109 bytes (27.5%,  1.8min remaining)
Downloaded 45883392 of 161069109 bytes (28.5%,  1.8min remaining)
Downloaded 47267840 of 161069109 bytes (29.3%,  1.7min remaining)
Downloaded 48758784 of 161069109 bytes (30.3%,  1.7min remaining)
Downloaded 50339840 of 161069109 bytes (31.3%,  1.7min remaining)
Downloaded 51929088 of 161069109 bytes (32.2%,  1.6min remaining)
Downloaded 53526528 of 161069109 bytes (33.2%,  1.6min remaining)
Downloaded 55156736 of 161069109 bytes (34.2%,  1.6min remaining)
Downloaded 56164352 of 161069109 bytes (34.9%,  1.6min remaining)
Downloaded 56270848 of 161069109 bytes (34.9%,  1.6min remaining)
Downloaded 56434688 of 161069109 bytes (35.0%,  1.6min remaining)
Downloaded 56696832 of 161069109 bytes (35.2%,  1.7min remaining)
Downloaded 57065472 of 161069109 bytes (35.4%,  1.7min remaining)
Downloaded 57565184 of 161069109 bytes (35.7%,  1.7min remaining)
Downloaded 58171392 of 161069109 bytes (36.1%,  1.7min remaining)
Downloaded 58744832 of 161069109 bytes (36.5%,  1.7min remaining)
Downloaded 59555840 of 161069109 bytes (37.0%,  1.7min remaining)
Downloaded 60522496 of 161069109 bytes (37.6%,  1.7min remaining)
Downloaded 61685760 of 161069109 bytes (38.3%,  1.7min remaining)
Downloaded 62963712 of 161069109 bytes (39.1%,  1.7min remaining)
Downloaded 64348160 of 161069109 bytes (40.0%,  1.6min remaining)
Downloaded 65527808 of 161069109 bytes (40.7%,  1.6min remaining)
Downloaded 67092480 of 161069109 bytes (41.7%,  1.6min remaining)
Downloaded 68763648 of 161069109 bytes (42.7%,  1.5min remaining)
Downloaded 70451200 of 161069109 bytes (43.7%,  1.5min remaining)
Downloaded 72187904 of 161069109 bytes (44.8%,  1.5min remaining)
Downloaded 73637888 of 161069109 bytes (45.7%,  1.4min remaining)
Downloaded 75333632 of 161069109 bytes (46.8%,  1.4min remaining)
Downloaded 76775424 of 161069109 bytes (47.7%,  1.4min remaining)
Downloaded 78323712 of 161069109 bytes (48.6%,  1.3min remaining)
Downloaded 79962112 of 161069109 bytes (49.6%,  1.3min remaining)
Downloaded 81690624 of 161069109 bytes (50.7%,  1.3min remaining)
Downloaded 83156992 of 161069109 bytes (51.6%,  1.2min remaining)
Downloaded 84762624 of 161069109 bytes (52.6%,  1.2min remaining)
Downloaded 86204416 of 161069109 bytes (53.5%,  1.2min remaining)
Downloaded 87769088 of 161069109 bytes (54.5%,  1.2min remaining)
Downloaded 89350144 of 161069109 bytes (55.5%,  1.1min remaining)
Downloaded 90595328 of 161069109 bytes (56.2%,  1.1min remaining)
Downloaded 91840512 of 161069109 bytes (57.0%,  1.1min remaining)
Downloaded 93200384 of 161069109 bytes (57.9%,  1.1min remaining)
Downloaded 94666752 of 161069109 bytes (58.8%,  1.0min remaining)
Downloaded 95920128 of 161069109 bytes (59.6%,  1.0min remaining)
Downloaded 95993856 of 161069109 bytes (59.6%,  1.0min remaining)
Downloaded 96133120 of 161069109 bytes (59.7%,  1.0min remaining)
Downloaded 96321536 of 161069109 bytes (59.8%,  1.1min remaining)
Downloaded 96583680 of 161069109 bytes (60.0%,  1.1min remaining)
Downloaded 96935936 of 161069109 bytes (60.2%,  1.1min remaining)
Downloaded 97386496 of 161069109 bytes (60.5%,  1.1min remaining)
Downloaded 97959936 of 161069109 bytes (60.8%,  1.1min remaining)
Downloaded 98639872 of 161069109 bytes (61.2%,  1.1min remaining)
Downloaded 99418112 of 161069109 bytes (61.7%,  1.0min remaining)
Downloaded 100319232 of 161069109 bytes (62.3%,  1.0min remaining)
Downloaded 101384192 of 161069109 bytes (62.9%,  1.0min remaining)
Downloaded 102555648 of 161069109 bytes (63.7%,   59.9s remaining)
Downloaded 103833600 of 161069109 bytes (64.5%,   58.5s remaining)
Downloaded 105168896 of 161069109 bytes (65.3%,   57.1s remaining)
Downloaded 106512384 of 161069109 bytes (66.1%,   55.6s remaining)
Downloaded 107855872 of 161069109 bytes (67.0%,   54.2s remaining)
Downloaded 109248512 of 161069109 bytes (67.8%,   52.7s remaining)
Downloaded 110723072 of 161069109 bytes (68.7%,   51.1s remaining)
Downloaded 112320512 of 161069109 bytes (69.7%,   49.3s remaining)
Downloaded 114024448 of 161069109 bytes (70.8%,   47.3s remaining)
Downloaded 115482624 of 161069109 bytes (71.7%,   45.7s remaining)
Downloaded 117194752 of 161069109 bytes (72.8%,   43.8s remaining)
Downloaded 118636544 of 161069109 bytes (73.7%,   42.3s remaining)
Downloaded 120496128 of 161069109 bytes (74.8%,   40.2s remaining)
Downloaded 121831424 of 161069109 bytes (75.6%,   38.8s remaining)
Downloaded 123600896 of 161069109 bytes (76.7%,   36.9s remaining)
Downloaded 125116416 of 161069109 bytes (77.7%,   35.3s remaining)
Downloaded 126484480 of 161069109 bytes (78.5%,   33.9s remaining)
Downloaded 127975424 of 161069109 bytes (79.5%,   32.4s remaining)
Downloaded 129400832 of 161069109 bytes (80.3%,   31.0s remaining)
Downloaded 130572288 of 161069109 bytes (81.1%,   29.8s remaining)
Downloaded 131825664 of 161069109 bytes (81.8%,   28.6s remaining)
Downloaded 133169152 of 161069109 bytes (82.7%,   27.2s remaining)
Downloaded 134619136 of 161069109 bytes (83.6%,   25.8s remaining)
Downloaded 136175616 of 161069109 bytes (84.5%,   24.2s remaining)
Downloaded 138076160 of 161069109 bytes (85.7%,   22.2s remaining)
Downloaded 139354112 of 161069109 bytes (86.5%,   20.9s remaining)
Downloaded 141025280 of 161069109 bytes (87.6%,   19.3s remaining)
Downloaded 142819328 of 161069109 bytes (88.7%,   17.5s remaining)
Downloaded 144351232 of 161069109 bytes (89.6%,   16.0s remaining)
Downloaded 145760256 of 161069109 bytes (90.5%,   14.6s remaining)
Downloaded 147275776 of 161069109 bytes (91.4%,   13.2s remaining)
Downloaded 148905984 of 161069109 bytes (92.4%,   11.6s remaining)
Downloaded 150650880 of 161069109 bytes (93.5%,    9.9s remaining)
Downloaded 152272896 of 161069109 bytes (94.5%,    8.3s remaining)
Downloaded 153632768 of 161069109 bytes (95.4%,    7.0s remaining)
Downloaded 155107328 of 161069109 bytes (96.3%,    5.6s remaining)
Downloaded 156672000 of 161069109 bytes (97.3%,    4.1s remaining)
Downloaded 158253056 of 161069109 bytes (98.3%,    2.6s remaining)
Downloaded 159834112 of 161069109 bytes (99.2%,    1.2s remaining) ...done. (153 seconds, 2 min)
Extracting data from /home/varoquau/nilearn_data/miyawaki2008/18b67c55cebe5e71427c5ffdcfafd948/miyawaki2008.tgz..... done.
</pre></div></div><p>We only use the training data of this study, where random binary images were shown.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=c1># training data starts after the first 12 files</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>fmri_random_runs_filenames</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>dataset</span><span class=o>.</span><span class=n>func</span></a><span class=p>[</span><span class=mi>12</span><span class=p>:]</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>stimuli_random_runs_filenames</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>dataset</span><span class=o>.</span><span class=n>label</span></a><span class=p>[</span><span class=mi>12</span><span class=p>:]</span>
</pre></div></div><p>We can use <a class="reference internal"href=../../modules/generated/nilearn.input_data.MultiNiftiMasker.html#nilearn.input_data.MultiNiftiMasker title=nilearn.input_data.MultiNiftiMasker><code class="xref py py-func docutils literal notranslate"><span class=pre>nilearn.input_data.MultiNiftiMasker</span></code></a> to load the fMRI data, clean and mask it.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
<span class=kn>from</span> <span class=nn>nilearn.input_data</span> <span class=k>import</span> <a class="sphx-glr-backref-module-nilearn-input_data sphx-glr-backref-type-py-class"href=../../modules/generated/nilearn.input_data.MultiNiftiMasker.html#nilearn.input_data.MultiNiftiMasker title=nilearn.input_data.MultiNiftiMasker><span class=n>MultiNiftiMasker</span></a>

<a class="sphx-glr-backref-module-nilearn-input_data sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=../../modules/generated/nilearn.input_data.MultiNiftiMasker.html#nilearn.input_data.MultiNiftiMasker title=nilearn.input_data.MultiNiftiMasker><span class=n>masker</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-input_data sphx-glr-backref-type-py-class"href=../../modules/generated/nilearn.input_data.MultiNiftiMasker.html#nilearn.input_data.MultiNiftiMasker title=nilearn.input_data.MultiNiftiMasker><span class=n>MultiNiftiMasker</span></a><span class=p>(</span><span class=n>mask_img</span><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#str title=builtins.str><span class=n>dataset</span><span class=o>.</span><span class=n>mask</span></a><span class=p>,</span> <span class=n>detrend</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
                          <span class=n>standardize</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<a class="sphx-glr-backref-module-nilearn-input_data sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.input_data.MultiNiftiMasker.html#nilearn.input_data.MultiNiftiMasker.fit title=nilearn.input_data.MultiNiftiMasker.fit><span class=n>masker</span><span class=o>.</span><span class=n>fit</span></a><span class=p>()</span>
<a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>fmri_data</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-input_data sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.input_data.MultiNiftiMasker.html#nilearn.input_data.MultiNiftiMasker.transform title=nilearn.input_data.MultiNiftiMasker.transform><span class=n>masker</span><span class=o>.</span><span class=n>transform</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>fmri_random_runs_filenames</span></a><span class=p>)</span>

<span class=c1># shape of the binary (i.e. black and wihte values) image in pixels</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#tuple title=builtins.tuple><span class=n>stimulus_shape</span></a> <span class=o>=</span> <span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>

<span class=c1># We load the visual stimuli from csv files</span>
<a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>stimuli</span></a> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#str title=builtins.str><span class=n>stimulus_run</span></a> <span class=ow>in</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>stimuli_random_runs_filenames</span></a><span class=p>:</span>
    <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>stimuli</span><span class=o>.</span><span class=n>append</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"href=https://numpy.org/doc/stable/reference/generated/numpy.reshape.html#numpy.reshape title=numpy.reshape><span class=n>np</span><span class=o>.</span><span class=n>reshape</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"href=https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html#numpy.loadtxt title=numpy.loadtxt><span class=n>np</span><span class=o>.</span><span class=n>loadtxt</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#str title=builtins.str><span class=n>stimulus_run</span></a><span class=p>,</span>
                              <span class=n>dtype</span><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class"href=https://docs.python.org/3.6/library/functions.html#int title=builtins.int><span class=n>np</span><span class=o>.</span><span class=n>int</span></a><span class=p>,</span> <span class=n>delimiter</span><span class=o>=</span><span class=s1>','</span><span class=p>),</span>
                              <span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,)</span> <span class=o>+</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#tuple title=builtins.tuple><span class=n>stimulus_shape</span></a><span class=p>,</span> <span class=n>order</span><span class=o>=</span><span class=s1>'F'</span><span class=p>))</span>
</pre></div></div><p>Let’s take a look at some of these binary images:</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>import</span> <span class=nn>pylab</span> <span class=k>as</span> <span class=nn>plt</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>stimuli</span></a><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=mi>124</span><span class=p>],</span> <span class=n>interpolation</span><span class=o>=</span><span class=s1>'nearest'</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>'gray'</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>'off'</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>'Run </span><span class=si>{}</span><span class=s1>, Stimulus </span><span class=si>{}</span><span class=s1>'</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>125</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>stimuli</span></a><span class=p>[</span><span class=mi>2</span><span class=p>][</span><span class=mi>101</span><span class=p>],</span> <span class=n>interpolation</span><span class=o>=</span><span class=s1>'nearest'</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>'gray'</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>'off'</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>'Run </span><span class=si>{}</span><span class=s1>, Stimulus </span><span class=si>{}</span><span class=s1>'</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>102</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>subplots_adjust</span><span class=p>(</span><span class=n>wspace</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
</pre></div></div><img alt="Run 1, Stimulus 125, Run 3, Stimulus 102"class=sphx-glr-single-img src=../../_images/sphx_glr_plot_miyawaki_encoding_001.png><p>We now stack the fmri and stimulus data and remove an offset in the beginning/end.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>fmri_data</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"href=https://numpy.org/doc/stable/reference/generated/numpy.vstack.html#numpy.vstack title=numpy.vstack><span class=n>np</span><span class=o>.</span><span class=n>vstack</span></a><span class=p>([</span><span class=n>fmri_run</span><span class=p>[</span><span class=mi>2</span><span class=p>:]</span> <span class=k>for</span> <span class=n>fmri_run</span> <span class=ow>in</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>fmri_data</span></a><span class=p>])</span>
<a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>stimuli</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"href=https://numpy.org/doc/stable/reference/generated/numpy.vstack.html#numpy.vstack title=numpy.vstack><span class=n>np</span><span class=o>.</span><span class=n>vstack</span></a><span class=p>([</span><span class=n>stimuli_run</span><span class=p>[:</span><span class=o>-</span><span class=mi>2</span><span class=p>]</span> <span class=k>for</span> <span class=n>stimuli_run</span> <span class=ow>in</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>stimuli</span></a><span class=p>])</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>float</span><span class=p>)</span>
</pre></div></div><p>fmri_data is a matrix of <em>samples</em> x <em>voxels</em></p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=nb>print</span><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#tuple title=builtins.tuple><span class=n>fmri_data</span><span class=o>.</span><span class=n>shape</span></a><span class=p>)</span>
</pre></div></div><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>(2860, 5438)
</pre></div></div><p>We flatten the last two dimensions of stimuli so it is a matrix of <em>samples</em> x <em>pixels</em>.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=c1># Flatten the stimuli</span>
<a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>stimuli</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"href=https://numpy.org/doc/stable/reference/generated/numpy.reshape.html#numpy.reshape title=numpy.reshape><span class=n>np</span><span class=o>.</span><span class=n>reshape</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>stimuli</span></a><span class=p>,</span> <span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#tuple title=builtins.tuple><span class=n>stimulus_shape</span></a><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#tuple title=builtins.tuple><span class=n>stimulus_shape</span></a><span class=p>[</span><span class=mi>1</span><span class=p>]))</span>

<span class=nb>print</span><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#tuple title=builtins.tuple><span class=n>stimuli</span><span class=o>.</span><span class=n>shape</span></a><span class=p>)</span>
</pre></div></div><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>(2860, 100)
</pre></div></div></div><div class=section id=building-the-encoding-models><h2>9.3.15.2. Building the encoding models<a title="Permalink to this headline"class=headerlink href=#building-the-encoding-models>¶</a></h2><p>We can now proceed to build a simple <strong>voxel-wise encoding model</strong> using <a class="reference external"href=http://en.wikipedia.org/wiki/Tikhonov_regularization>Ridge regression</a>. For each voxel we fit an independent regression model, using the pixel-values of the visual stimuli to predict the neuronal activity in this voxel.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>sklearn.linear_model</span> <span class=k>import</span> <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"href=https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge title=sklearn.linear_model.Ridge><span class=n>Ridge</span></a>
<span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=k>import</span> <a class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-class"href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold title=sklearn.model_selection.KFold><span class=n>KFold</span></a>
</pre></div></div><p>Using 10-fold cross-validation, we partition the data into 10 ‘folds’. We hold out each fold of the data for testing, then fit a ridge regression to the remaining 9/10 of the data, using stimuli as predictors and fmri_data as targets, and create predictions for the held-out 10th.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=k>import</span> <a class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"href=https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score title=sklearn.metrics.r2_score><span class=n>r2_score</span></a>

<a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge title=sklearn.linear_model.Ridge><span class=n>estimator</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"href=https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge title=sklearn.linear_model.Ridge><span class=n>Ridge</span></a><span class=p>(</span><span class=n>alpha</span><span class=o>=</span><span class=mf>100.</span><span class=p>)</span>
<a class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold title=sklearn.model_selection.KFold><span class=n>cv</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-class"href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold title=sklearn.model_selection.KFold><span class=n>KFold</span></a><span class=p>(</span><span class=n>n_splits</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>

<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>scores</span></a> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>train</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>test</span></a> <span class=ow>in</span> <a class="sphx-glr-backref-module-sklearn-model_selection sphx-glr-backref-type-py-method"href=https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold.split title=sklearn.model_selection.KFold.split><span class=n>cv</span><span class=o>.</span><span class=n>split</span></a><span class=p>(</span><span class=n>X</span><span class=o>=</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>stimuli</span></a><span class=p>):</span>
    <span class=c1># we train the Ridge estimator on the training set</span>
    <span class=c1># and predict the fMRI activity for the test set</span>
    <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>predictions</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"href=https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge title=sklearn.linear_model.Ridge><span class=n>Ridge</span></a><span class=p>(</span><span class=n>alpha</span><span class=o>=</span><span class=mf>100.</span><span class=p>)</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span>
    <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>stimuli</span></a><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>100</span><span class=p>)[</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>train</span></a><span class=p>],</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>fmri_data</span></a><span class=p>[</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>train</span></a><span class=p>])</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span>
        <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>stimuli</span></a><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>100</span><span class=p>)[</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>test</span></a><span class=p>])</span>
    <span class=c1># we compute how much variance our encoding model explains in each voxel</span>
    <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>scores</span></a><span class=o>.</span><span class=n>append</span><span class=p>(</span><a class="sphx-glr-backref-module-sklearn-metrics sphx-glr-backref-type-py-function"href=https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score title=sklearn.metrics.r2_score><span class=n>r2_score</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>fmri_data</span></a><span class=p>[</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>test</span></a><span class=p>],</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>predictions</span></a><span class=p>,</span>
                           <span class=n>multioutput</span><span class=o>=</span><span class=s1>'raw_values'</span><span class=p>))</span>
</pre></div></div></div><div class=section id=mapping-the-encoding-scores-on-the-brain><h2>9.3.15.3. Mapping the encoding scores on the brain<a title="Permalink to this headline"class=headerlink href=#mapping-the-encoding-scores-on-the-brain>¶</a></h2><p>To plot the scores onto the brain, we create a Nifti1Image containing the scores and then threshold it:</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn.image</span> <span class=k>import</span> <a class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.image.threshold_img.html#nilearn.image.threshold_img title=nilearn.image.threshold_img><span class=n>threshold_img</span></a>
<a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>cut_score</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"href=https://numpy.org/doc/stable/reference/generated/numpy.mean.html#numpy.mean title=numpy.mean><span class=n>np</span><span class=o>.</span><span class=n>mean</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>scores</span></a><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
<a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>cut_score</span></a><span class=p>[</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>cut_score</span></a> <span class=o><</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>

<span class=c1># bring the scores into the shape of the background brain</span>
<a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>score_map_img</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-input_data sphx-glr-backref-type-py-method"href=../../modules/generated/nilearn.input_data.MultiNiftiMasker.html#nilearn.input_data.MultiNiftiMasker.inverse_transform title=nilearn.input_data.MultiNiftiMasker.inverse_transform><span class=n>masker</span><span class=o>.</span><span class=n>inverse_transform</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>cut_score</span></a><span class=p>)</span>

<a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>thresholded_score_map_img</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.image.threshold_img.html#nilearn.image.threshold_img title=nilearn.image.threshold_img><span class=n>threshold_img</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>score_map_img</span></a><span class=p>,</span> <span class=n>threshold</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>,</span> <span class=n>copy</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</pre></div></div><p>Plotting the statistical map on a background brain, we mark four voxels which we will inspect more closely later on.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>nilearn.plotting</span> <span class=k>import</span> <a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map title=nilearn.plotting.plot_stat_map><span class=n>plot_stat_map</span></a>
<span class=kn>from</span> <span class=nn>nilearn.image</span> <span class=k>import</span> <a class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.image.coord_transform.html#nilearn.image.coord_transform title=nilearn.image.coord_transform><span class=n>coord_transform</span></a>

<span class=k>def</span> <span class=nf>index_to_xy_coord</span><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#int title=builtins.int><span class=n>x</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#int title=builtins.int><span class=n>y</span></a><span class=p>,</span> <span class=n>z</span><span class=o>=</span><span class=mi>10</span><span class=p>):</span>
    <span class=sd>'''Transforms data index to coordinates of the background + offset'''</span>
    <span class=n>coords</span> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-image sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.image.coord_transform.html#nilearn.image.coord_transform title=nilearn.image.coord_transform><span class=n>coord_transform</span></a><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#int title=builtins.int><span class=n>x</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#int title=builtins.int><span class=n>y</span></a><span class=p>,</span> <span class=n>z</span><span class=p>,</span>
                             <span class=n>affine</span><span class=o>=</span><a class="sphx-glr-backref-module-nibabel-spatialimages sphx-glr-backref-type-py-method"href=https://nipy.org/nibabel/reference/nibabel.spatialimages.html#nibabel.spatialimages.SpatialImage.affine title=nibabel.spatialimages.SpatialImage.affine><span class=n>thresholded_score_map_img</span><span class=o>.</span><span class=n>affine</span></a><span class=p>)</span>
    <span class=k>return</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"href=https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array title=numpy.array><span class=n>np</span><span class=o>.</span><span class=n>array</span></a><span class=p>(</span><span class=n>coords</span><span class=p>)[</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-data"href=https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis title=numpy.newaxis><span class=n>np</span><span class=o>.</span><span class=n>newaxis</span></a><span class=p>,</span> <span class=p>:]</span> <span class=o>+</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"href=https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array title=numpy.array><span class=n>np</span><span class=o>.</span><span class=n>array</span></a><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>])</span>


<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>xy_indices_of_special_voxels</span></a> <span class=o>=</span> <span class=p>[(</span><span class=mi>30</span><span class=p>,</span> <span class=mi>10</span><span class=p>),</span> <span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=mi>10</span><span class=p>),</span> <span class=p>(</span><span class=mi>31</span><span class=p>,</span> <span class=mi>9</span><span class=p>),</span> <span class=p>(</span><span class=mi>31</span><span class=p>,</span> <span class=mi>10</span><span class=p>)]</span>

<span class=n>display</span> <span class=o>=</span> <a class="sphx-glr-backref-module-nilearn-plotting sphx-glr-backref-type-py-function"href=../../modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map title=nilearn.plotting.plot_stat_map><span class=n>plot_stat_map</span></a><span class=p>(</span><a class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image title=nibabel.nifti1.Nifti1Image><span class=n>thresholded_score_map_img</span></a><span class=p>,</span> <span class=n>bg_img</span><span class=o>=</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#str title=builtins.str><span class=n>dataset</span><span class=o>.</span><span class=n>background</span></a><span class=p>,</span>
                        <span class=n>cut_coords</span><span class=o>=</span><span class=p>[</span><span class=o>-</span><span class=mi>8</span><span class=p>],</span> <span class=n>display_mode</span><span class=o>=</span><span class=s1>'z'</span><span class=p>,</span> <span class=n>aspect</span><span class=o>=</span><span class=mf>1.25</span><span class=p>,</span>
                        <span class=n>title</span><span class=o>=</span><span class=s1>'Explained variance per voxel'</span><span class=p>)</span>

<span class=c1># creating a marker for each voxel and adding it to the statistical map</span>

<span class=k>for</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#int title=builtins.int><span class=n>i</span></a><span class=p>,</span> <span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#int title=builtins.int><span class=n>x</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#int title=builtins.int><span class=n>y</span></a><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#list title=builtins.list><span class=n>xy_indices_of_special_voxels</span></a><span class=p>):</span>
    <span class=n>display</span><span class=o>.</span><span class=n>add_markers</span><span class=p>(</span><span class=n>index_to_xy_coord</span><span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#int title=builtins.int><span class=n>x</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#int title=builtins.int><span class=n>y</span></a><span class=p>),</span> <span class=n>marker_color</span><span class=o>=</span><span class=s1>'none'</span><span class=p>,</span>
                        <span class=n>edgecolor</span><span class=o>=</span><span class=p>[</span><span class=s1>'b'</span><span class=p>,</span> <span class=s1>'r'</span><span class=p>,</span> <span class=s1>'magenta'</span><span class=p>,</span> <span class=s1>'g'</span><span class=p>][</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#int title=builtins.int><span class=n>i</span></a><span class=p>],</span>
                        <span class=n>marker_size</span><span class=o>=</span><span class=mi>140</span><span class=p>,</span> <span class=n>marker</span><span class=o>=</span><span class=s1>'s'</span><span class=p>,</span>
                        <span class=n>facecolor</span><span class=o>=</span><span class=s1>'none'</span><span class=p>,</span> <span class=n>lw</span><span class=o>=</span><span class=mf>4.5</span><span class=p>)</span>


<span class=c1># re-set figure size after construction so colorbar gets rescaled too</span>
<a class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://matplotlib.org/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure title=matplotlib.figure.Figure><span class=n>fig</span></a> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>gcf</span><span class=p>()</span>
<a class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-method"href=https://matplotlib.org/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure.set_size_inches title=matplotlib.figure.Figure.set_size_inches><span class=n>fig</span><span class=o>.</span><span class=n>set_size_inches</span></a><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>12</span><span class=p>)</span>
</pre></div></div><img alt="plot miyawaki encoding"class=sphx-glr-single-img src=../../_images/sphx_glr_plot_miyawaki_encoding_002.png><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>/home/varoquau/dev/nilearn/nilearn/plotting/displays.py:1608: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.
  ax = fh.add_axes([fraction * index * (x1 - x0) + x0, y0,
</pre></div></div></div><div class=section id=estimating-receptive-fields><h2>9.3.15.4. Estimating receptive fields<a title="Permalink to this headline"class=headerlink href=#estimating-receptive-fields>¶</a></h2><p>Now we take a closer look at the receptive fields of the four marked voxels. A voxel’s <a class="reference external"href=http://en.wikipedia.org/wiki/Receptive_field>receptive field</a> is the region of a stimulus (like an image) where the presence of an object, like a white instead of a black pixel, results in a change in activity in the voxel. In our case the receptive field is just the vector of 100 regression coefficients (one for each pixel) reshaped into the 10x10 form of the original images. Some voxels are receptive to only very few pixels, so we use <a class="reference external"href=http://en.wikipedia.org/wiki/Lasso_(statistics)>Lasso regression</a> to estimate a sparse set of regression coefficients.</p><div class="highlight-default notranslate"><div class=highlight><pre><span></span><span class=kn>from</span> <span class=nn>sklearn.linear_model</span> <span class=k>import</span> <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"href=https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV title=sklearn.linear_model.LassoLarsCV><span class=n>LassoLarsCV</span></a>

<span class=c1># automatically estimate the sparsity by cross-validation</span>
<a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV title=sklearn.linear_model.LassoLarsCV><span class=n>lasso</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-class"href=https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV title=sklearn.linear_model.LassoLarsCV><span class=n>LassoLarsCV</span></a><span class=p>(</span><span class=n>max_iter</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>

<span class=c1># Mark the same pixel in each receptive field</span>
<a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#tuple title=builtins.tuple><span class=n>marked_pixel</span></a> <span class=o>=</span> <span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>

<span class=kn>from</span> <span class=nn>matplotlib</span> <span class=k>import</span> <span class=n>gridspec</span>
<span class=kn>from</span> <span class=nn>matplotlib.patches</span> <span class=k>import</span> <a class="sphx-glr-backref-module-matplotlib-patches sphx-glr-backref-type-py-class"href=https://matplotlib.org/api/_as_gen/matplotlib.patches.Rectangle.html#matplotlib.patches.Rectangle title=matplotlib.patches.Rectangle><span class=n>Rectangle</span></a>

<a class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://matplotlib.org/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure title=matplotlib.figure.Figure><span class=n>fig</span></a> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>))</span>
<a class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-method"href=https://matplotlib.org/api/_as_gen/matplotlib.figure.Figure.html#matplotlib.figure.Figure.suptitle title=matplotlib.figure.Figure.suptitle><span class=n>fig</span><span class=o>.</span><span class=n>suptitle</span></a><span class=p>(</span><span class=s1>'Receptive fields of the marked voxels'</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>25</span><span class=p>)</span>

<span class=c1># GridSpec allows us to do subplots with more control of the spacing</span>
<a class="sphx-glr-backref-module-matplotlib-gridspec sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://matplotlib.org/api/_as_gen/matplotlib.gridspec.GridSpec.html#matplotlib.gridspec.GridSpec title=matplotlib.gridspec.GridSpec><span class=n>gs1</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-matplotlib-gridspec sphx-glr-backref-type-py-class"href=https://matplotlib.org/api/_as_gen/matplotlib.gridspec.GridSpec.html#matplotlib.gridspec.GridSpec title=matplotlib.gridspec.GridSpec><span class=n>gridspec</span><span class=o>.</span><span class=n>GridSpec</span></a><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>

<span class=c1># we fit the Lasso for each of the three voxels of the upper row</span>
<span class=k>for</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#int title=builtins.int><span class=n>i</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#int title=builtins.int><span class=n>index</span></a> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>([</span><span class=mi>1780</span><span class=p>,</span> <span class=mi>1951</span><span class=p>,</span> <span class=mi>2131</span><span class=p>]):</span>
    <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><a class="sphx-glr-backref-module-matplotlib-gridspec sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://matplotlib.org/api/_as_gen/matplotlib.gridspec.GridSpec.html#matplotlib.gridspec.GridSpec title=matplotlib.gridspec.GridSpec><span class=n>gs1</span></a><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#int title=builtins.int><span class=n>i</span></a><span class=p>])</span>
    <span class=c1># we reshape the coefficients into the form of the original images</span>
    <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>rf</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-method"href=https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV.fit title=sklearn.linear_model.LassoLarsCV.fit><span class=n>lasso</span><span class=o>.</span><span class=n>fit</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>stimuli</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>fmri_data</span></a><span class=p>[:,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#int title=builtins.int><span class=n>index</span></a><span class=p>])</span><span class=o>.</span><span class=n>coef_</span><span class=o>.</span><span class=n>reshape</span><span class=p>((</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>
    <span class=c1># add a black background</span>
    <a class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"href=https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.imshow.html#matplotlib.axes.Axes.imshow title=matplotlib.axes.Axes.imshow><span class=n>ax</span><span class=o>.</span><span class=n>imshow</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"href=https://numpy.org/doc/stable/reference/generated/numpy.zeros_like.html#numpy.zeros_like title=numpy.zeros_like><span class=n>np</span><span class=o>.</span><span class=n>zeros_like</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>rf</span></a><span class=p>),</span> <span class=n>vmin</span><span class=o>=</span><span class=mf>0.</span><span class=p>,</span> <span class=n>vmax</span><span class=o>=</span><span class=mf>1.</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>'gray'</span><span class=p>)</span>
    <a class="sphx-glr-backref-module-matplotlib-image sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://matplotlib.org/api/image_api.html#matplotlib.image.AxesImage title=matplotlib.image.AxesImage><span class=n>ax_im</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"href=https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.imshow.html#matplotlib.axes.Axes.imshow title=matplotlib.axes.Axes.imshow><span class=n>ax</span><span class=o>.</span><span class=n>imshow</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy-ma sphx-glr-backref-type-py-function"href=https://numpy.org/doc/stable/reference/generated/numpy.ma.masked_less.html#numpy.ma.masked_less title=numpy.ma.masked_less><span class=n>np</span><span class=o>.</span><span class=n>ma</span><span class=o>.</span><span class=n>masked_less</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>rf</span></a><span class=p>,</span> <span class=mf>0.1</span><span class=p>),</span> <span class=n>interpolation</span><span class=o>=</span><span class=s2>"nearest"</span><span class=p>,</span>
                      <span class=n>cmap</span><span class=o>=</span><span class=p>[</span><span class=s1>'Blues'</span><span class=p>,</span> <span class=s1>'Greens'</span><span class=p>,</span> <span class=s1>'Reds'</span><span class=p>][</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/functions.html#int title=builtins.int><span class=n>i</span></a><span class=p>],</span> <span class=n>vmin</span><span class=o>=</span><span class=mf>0.</span><span class=p>,</span> <span class=n>vmax</span><span class=o>=</span><span class=mf>0.75</span><span class=p>)</span>
    <span class=c1># add the marked pixel</span>
    <a class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"href=https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.add_patch.html#matplotlib.axes.Axes.add_patch title=matplotlib.axes.Axes.add_patch><span class=n>ax</span><span class=o>.</span><span class=n>add_patch</span></a><span class=p>(</span><a class="sphx-glr-backref-module-matplotlib-patches sphx-glr-backref-type-py-class"href=https://matplotlib.org/api/_as_gen/matplotlib.patches.Rectangle.html#matplotlib.patches.Rectangle title=matplotlib.patches.Rectangle><span class=n>Rectangle</span></a><span class=p>(</span>
        <span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#tuple title=builtins.tuple><span class=n>marked_pixel</span></a><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>-</span> <span class=o>.</span><span class=mi>5</span><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#tuple title=builtins.tuple><span class=n>marked_pixel</span></a><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=o>.</span><span class=mi>5</span><span class=p>),</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span>
        <span class=n>facecolor</span><span class=o>=</span><span class=s1>'none'</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>'r'</span><span class=p>,</span> <span class=n>lw</span><span class=o>=</span><span class=mi>4</span><span class=p>))</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>'off'</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>colorbar</span><span class=p>(</span><a class="sphx-glr-backref-module-matplotlib-image sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://matplotlib.org/api/image_api.html#matplotlib.image.AxesImage title=matplotlib.image.AxesImage><span class=n>ax_im</span></a><span class=p>,</span> <span class=n>ax</span><span class=o>=</span><span class=n>ax</span><span class=p>)</span>

<span class=c1># and then for the voxel at the bottom</span>

<a class="sphx-glr-backref-module-matplotlib-gridspec sphx-glr-backref-type-py-method"href=https://matplotlib.org/api/_as_gen/matplotlib.gridspec.GridSpec.html#matplotlib.gridspec.GridSpec.update title=matplotlib.gridspec.GridSpec.update><span class=n>gs1</span><span class=o>.</span><span class=n>update</span></a><span class=p>(</span><span class=n>left</span><span class=o>=</span><span class=mf>0.</span><span class=p>,</span> <span class=n>right</span><span class=o>=</span><span class=mf>1.</span><span class=p>,</span> <span class=n>wspace</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
<span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><a class="sphx-glr-backref-module-matplotlib-gridspec sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://matplotlib.org/api/_as_gen/matplotlib.gridspec.GridSpec.html#matplotlib.gridspec.GridSpec title=matplotlib.gridspec.GridSpec><span class=n>gs1</span></a><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
<span class=c1># we reshape the coefficients into the form of the original images</span>
<a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>rf</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-sklearn-linear_model sphx-glr-backref-type-py-method"href=https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV.fit title=sklearn.linear_model.LassoLarsCV.fit><span class=n>lasso</span><span class=o>.</span><span class=n>fit</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>stimuli</span></a><span class=p>,</span> <a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>fmri_data</span></a><span class=p>[:,</span> <span class=mi>1935</span><span class=p>])</span><span class=o>.</span><span class=n>coef_</span><span class=o>.</span><span class=n>reshape</span><span class=p>((</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>
<a class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"href=https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.imshow.html#matplotlib.axes.Axes.imshow title=matplotlib.axes.Axes.imshow><span class=n>ax</span><span class=o>.</span><span class=n>imshow</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"href=https://numpy.org/doc/stable/reference/generated/numpy.zeros_like.html#numpy.zeros_like title=numpy.zeros_like><span class=n>np</span><span class=o>.</span><span class=n>zeros_like</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>rf</span></a><span class=p>),</span> <span class=n>vmin</span><span class=o>=</span><span class=mf>0.</span><span class=p>,</span> <span class=n>vmax</span><span class=o>=</span><span class=mf>1.</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>'gray'</span><span class=p>)</span>
<a class="sphx-glr-backref-module-matplotlib-image sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://matplotlib.org/api/image_api.html#matplotlib.image.AxesImage title=matplotlib.image.AxesImage><span class=n>ax_im</span></a> <span class=o>=</span> <a class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"href=https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.imshow.html#matplotlib.axes.Axes.imshow title=matplotlib.axes.Axes.imshow><span class=n>ax</span><span class=o>.</span><span class=n>imshow</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy-ma sphx-glr-backref-type-py-function"href=https://numpy.org/doc/stable/reference/generated/numpy.ma.masked_less.html#numpy.ma.masked_less title=numpy.ma.masked_less><span class=n>np</span><span class=o>.</span><span class=n>ma</span><span class=o>.</span><span class=n>masked_less</span></a><span class=p>(</span><a class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray title=numpy.ndarray><span class=n>rf</span></a><span class=p>,</span> <span class=mf>0.1</span><span class=p>),</span> <span class=n>interpolation</span><span class=o>=</span><span class=s2>"nearest"</span><span class=p>,</span>
                  <span class=n>cmap</span><span class=o>=</span><span class=s1>'RdPu'</span><span class=p>,</span> <span class=n>vmin</span><span class=o>=</span><span class=mf>0.</span><span class=p>,</span> <span class=n>vmax</span><span class=o>=</span><span class=mf>0.75</span><span class=p>)</span>

<span class=c1># add the marked pixel</span>
<a class="sphx-glr-backref-module-matplotlib-axes sphx-glr-backref-type-py-method"href=https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.add_patch.html#matplotlib.axes.Axes.add_patch title=matplotlib.axes.Axes.add_patch><span class=n>ax</span><span class=o>.</span><span class=n>add_patch</span></a><span class=p>(</span><a class="sphx-glr-backref-module-matplotlib-patches sphx-glr-backref-type-py-class"href=https://matplotlib.org/api/_as_gen/matplotlib.patches.Rectangle.html#matplotlib.patches.Rectangle title=matplotlib.patches.Rectangle><span class=n>Rectangle</span></a><span class=p>(</span>
    <span class=p>(</span><a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#tuple title=builtins.tuple><span class=n>marked_pixel</span></a><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>-</span> <span class=o>.</span><span class=mi>5</span><span class=p>,</span> <a class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://docs.python.org/3.6/library/stdtypes.html#tuple title=builtins.tuple><span class=n>marked_pixel</span></a><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=o>.</span><span class=mi>5</span><span class=p>),</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span>
    <span class=n>facecolor</span><span class=o>=</span><span class=s1>'none'</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>'r'</span><span class=p>,</span> <span class=n>lw</span><span class=o>=</span><span class=mi>4</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>'off'</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>colorbar</span><span class=p>(</span><a class="sphx-glr-backref-module-matplotlib-image sphx-glr-backref-type-py-class sphx-glr-backref-instance"href=https://matplotlib.org/api/image_api.html#matplotlib.image.AxesImage title=matplotlib.image.AxesImage><span class=n>ax_im</span></a><span class=p>,</span> <span class=n>ax</span><span class=o>=</span><span class=n>ax</span><span class=p>)</span>
</pre></div></div><img alt="Receptive fields of the marked voxels"class=sphx-glr-single-img src=../../_images/sphx_glr_plot_miyawaki_encoding_003.png><p class=sphx-glr-script-out>Out:</p><div class="sphx-glr-script-out highlight-none notranslate"><div class=highlight><pre><span></span>&LTmatplotlib.colorbar.Colorbar object at 0x7f8bfbb6faf0>
</pre></div></div><p>The receptive fields of the four voxels are not only close to each other, the relative location of the pixel each voxel is most sensitive to roughly maps to the relative location of the voxels to each other. We can see a relationship between some voxel’s receptive field and its location in the brain.</p><p class=sphx-glr-timing><strong>Total running time of the script:</strong> ( 3 minutes 2.472 seconds)</p><div class="sphx-glr-footer class sphx-glr-footer-example docutils container"id=sphx-glr-download-auto-examples-02-decoding-plot-miyawaki-encoding-py><div class="binder-badge docutils container"><a class="reference external image-reference"href=https://mybinder.org/v2/gh/nilearn/nilearn.github.io/master?filepath=examples/auto_examples/02_decoding/plot_miyawaki_encoding.ipynb><img alt=https://mybinder.org/badge_logo.svg src=https://mybinder.org/badge_logo.svg width=150px></a></div><div class="sphx-glr-download sphx-glr-download-python docutils container"><a class="reference download internal"download href=../../_downloads/d099d812c675252215124fcd76e33012/plot_miyawaki_encoding.py><code class="xref download docutils literal notranslate"><span class=pre>Download</span> <span class=pre>Python</span> <span class=pre>source</span> <span class=pre>code:</span> <span class=pre>plot_miyawaki_encoding.py</span></code></a></div><div class="sphx-glr-download sphx-glr-download-jupyter docutils container"><a class="reference download internal"download href=../../_downloads/b561a583ccd86c26f183f50901baf411/plot_miyawaki_encoding.ipynb><code class="xref download docutils literal notranslate"><span class=pre>Download</span> <span class=pre>Jupyter</span> <span class=pre>notebook:</span> <span class=pre>plot_miyawaki_encoding.ipynb</span></code></a></div></div><p class=sphx-glr-signature><a class="reference external"href=https://sphinx-gallery.github.io>Gallery generated by Sphinx-Gallery</a></p></div></div></div></div></div><div aria-label="main navigation"class=sphinxsidebar role=navigation><div class=sphinxsidebarwrapper><h4>Giving credit</h4><ul class=simple><li><p>Please consider <a href=../../authors.html#citing>citing the papers</a>.</p></li></ul><h3><a href=../../index.html>Table of Contents</a></h3><ul><li><a class="reference internal"href=#>9.3.15. Encoding models for visual stimuli from Miyawaki et al. 2008</a><ul><li><a class="reference internal"href=#loading-the-data>9.3.15.1. Loading the data</a></li><li><a class="reference internal"href=#building-the-encoding-models>9.3.15.2. Building the encoding models</a></li><li><a class="reference internal"href=#mapping-the-encoding-scores-on-the-brain>9.3.15.3. Mapping the encoding scores on the brain</a></li><li><a class="reference internal"href=#estimating-receptive-fields>9.3.15.4. Estimating receptive fields</a></li></ul></li></ul><h4>Previous topic</h4><p class=topless><a title="previous chapter"href=plot_simulated_data.html>9.3.14. Example of pattern recognition on simulated data</a></p><h4>Next topic</h4><p class=topless><a title="next chapter"href=plot_miyawaki_reconstruction.html>9.3.16. Reconstruction of visual stimuli from Miyawaki et al. 2008</a></p><div id=searchbox role=search style=display:none><h3>Quick search</h3><div class=searchformwrapper><form action=../../search.html class=search><input name=q><input type=submit value=Go><input name=check_keywords type=hidden value=yes><input name=area type=hidden value=default></form></div></div><script>$('#searchbox').show(0);</script></div></div><div class=clearer></div></div><div class=footer>© The nilearn developers 2010-2020. Created using <a href=http://sphinx.pocoo.org/>Sphinx</a> 1.8.5. <span style=padding-left:5ex> <a href=../../_sources/auto_examples/02_decoding/plot_miyawaki_encoding.rst.txt rel=nofollow>Show this page source</a> </span></div></body></html>