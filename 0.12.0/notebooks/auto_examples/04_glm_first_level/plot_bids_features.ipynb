{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# First level analysis of a complete BIDS dataset from openneuro\n\nFull step-by-step example of fitting a :term:`GLM`\nto perform a first level analysis in an openneuro :term:`BIDS` dataset.\nWe demonstrate how :term:`BIDS`\nderivatives can be exploited to perform a simple one subject analysis with\nminimal code. Details about the :term:`BIDS` standard are available at\n[https://bids.neuroimaging.io/](https://bids.neuroimaging.io/).\nWe also demonstrate how to download individual groups of files from the\nOpenneuro s3 bucket.\n\nMore specifically:\n\n1. Download an :term:`fMRI` :term:`BIDS` dataset\n   with derivatives from openneuro.\n2. Extract first level model objects automatically\n   from the :term:`BIDS` dataset.\n3. Demonstrate Quality assurance of Nilearn estimation against available FSL.\n   estimation in the openneuro dataset.\n4. Display contrast plot and uncorrected first level statistics table report.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetch openneuro :term:`BIDS` dataset\nWe download one subject from the stopsignal task\nin the ds000030 V4 :term:`BIDS` dataset available in openneuro.\nThis dataset contains the necessary information to run a statistical analysis\nusing Nilearn. The dataset also contains statistical results from a previous\nFSL analysis that we can employ for comparison with the Nilearn estimation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.datasets import (\n    fetch_ds000030_urls,\n    fetch_openneuro_dataset,\n    select_from_index,\n)\n\n_, urls = fetch_ds000030_urls()\n\nexclusion_patterns = [\n    \"*group*\",\n    \"*phenotype*\",\n    \"*mriqc*\",\n    \"*parameter_plots*\",\n    \"*physio_plots*\",\n    \"*space-fsaverage*\",\n    \"*space-T1w*\",\n    \"*dwi*\",\n    \"*beh*\",\n    \"*task-bart*\",\n    \"*task-rest*\",\n    \"*task-scap*\",\n    \"*task-task*\",\n]\nurls = select_from_index(\n    urls, exclusion_filters=exclusion_patterns, n_subjects=1\n)\n\ndata_dir, _ = fetch_openneuro_dataset(urls=urls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Obtain FirstLevelModel objects automatically and fit arguments\nFrom the dataset directory we automatically obtain FirstLevelModel objects\nwith their subject_id filled from the :term:`BIDS` dataset.\nMoreover we obtain,\nfor each model, the list of run images and their respective events and\nconfound regressors. Those are inferred from the confounds.tsv files\navailable in the :term:`BIDS` dataset.\nTo get the first level models we have to specify the dataset directory,\nthe task_label and the space_label as specified in the file names.\nWe also have to provide the folder with the desired derivatives, that in this\ncase were produced by the :term:`fMRIPrep` :term:`BIDS` app.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.glm.first_level import first_level_from_bids\n\ntask_label = \"stopsignal\"\nspace_label = \"MNI152NLin2009cAsym\"\nderivatives_folder = \"derivatives/fmriprep\"\n(\n    models,\n    models_run_imgs,\n    models_events,\n    models_confounds,\n) = first_level_from_bids(\n    data_dir,\n    task_label,\n    space_label,\n    smoothing_fwhm=5.0,\n    derivatives_folder=derivatives_folder,\n    n_jobs=2,\n    verbose=1,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Access the model and model arguments of the subject and process events.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model, imgs, events, confounds = (\n    models[0],\n    models_run_imgs[0],\n    models_events[0],\n    models_confounds[0],\n)\nsubject = f\"sub-{model.subject_label}\"\nmodel.minimize_memory = False  # override default\n\nfrom pathlib import Path\n\nfrom nilearn.interfaces.fsl import get_design_from_fslmat\n\nfsl_design_matrix_path = (\n    Path(data_dir)\n    / \"derivatives\"\n    / \"task\"\n    / subject\n    / \"stopsignal.feat\"\n    / \"design.mat\"\n)\ndesign_matrix = get_design_from_fslmat(\n    fsl_design_matrix_path, column_names=None\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We identify the columns of the Go and StopSuccess conditions of the\ndesign matrix inferred from the FSL file, to use them later for contrast\ndefinition.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "design_columns = [\n    f\"cond_{int(i):02}\" for i in range(len(design_matrix.columns))\n]\ndesign_columns[0] = \"Go\"\ndesign_columns[4] = \"StopSuccess\"\ndesign_matrix.columns = design_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## First level model estimation (one subject)\nWe fit the first level model for one subject.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model.fit(imgs, design_matrices=[design_matrix])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we compute the StopSuccess - Go contrast. We can use the column names\nof the design matrix.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z_map = model.compute_contrast(\"StopSuccess - Go\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize results\nLet's have a look at the Nilearn estimation\nand the FSL estimation available in the dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport nibabel as nib\nfrom scipy.stats import norm\n\nfrom nilearn.plotting import plot_glass_brain, show\n\nfsl_z_map = nib.load(\n    Path(data_dir)\n    / \"derivatives\"\n    / \"task\"\n    / subject\n    / \"stopsignal.feat\"\n    / \"stats\"\n    / \"zstat12.nii.gz\"\n)\n\nplot_glass_brain(\n    z_map,\n    threshold=norm.isf(0.001),\n    title='Nilearn Z map of \"StopSuccess - Go\" (unc p<0.001)',\n    plot_abs=False,\n    display_mode=\"ortho\",\n)\nplot_glass_brain(\n    fsl_z_map,\n    threshold=norm.isf(0.001),\n    title='FSL Z map of \"StopSuccess - Go\" (unc p<0.001)',\n    plot_abs=False,\n    display_mode=\"ortho\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We show the agreement between the 2 estimations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.plotting import plot_bland_altman, plot_img_comparison\n\nplot_img_comparison(\n    z_map, fsl_z_map, model.masker_, ref_label=\"Nilearn\", src_label=\"FSL\"\n)\n\nplot_bland_altman(\n    z_map, fsl_z_map, model.masker_, ref_label=\"Nilearn\", src_label=\"FSL\"\n)\n\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving model outputs to disk\n\nWe can now easily save the main results,\nthe model metadata and an HTML report to the disk.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.interfaces.bids import save_glm_to_bids\n\noutput_dir = Path.cwd() / \"results\" / \"plot_bids_features\"\noutput_dir.mkdir(exist_ok=True, parents=True)\n\nstat_threshold = norm.isf(0.001)\n\nsave_glm_to_bids(\n    model,\n    contrasts=\"StopSuccess - Go\",\n    contrast_types={\"StopSuccess - Go\": \"t\"},\n    out_dir=output_dir / \"derivatives\" / \"nilearn_glm\",\n    threshold=stat_threshold,\n    cluster_threshold=10,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View the generated files\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "files = sorted((output_dir / \"derivatives\" / \"nilearn_glm\").glob(\"**/*\"))\nprint(\"\\n\".join([str(x.relative_to(output_dir)) for x in files]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple statistical report of thresholded contrast\nWe display the :term:`contrast` plot and table with cluster information.\n\nHere we will the image directly from the results saved to disk.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.plotting import plot_contrast_matrix\n\nplot_contrast_matrix(\"StopSuccess - Go\", design_matrix)\n\nz_map = (\n    output_dir\n    / \"derivatives\"\n    / \"nilearn_glm\"\n    / \"sub-10159\"\n    / (\n        \"sub-10159_task-stopsignal_space-MNI152NLin2009cAsym_\"\n        \"contrast-stopsuccessMinusGo_stat-z_statmap.nii.gz\"\n    )\n)\n\nplot_glass_brain(\n    z_map,\n    threshold=stat_threshold,\n    plot_abs=False,\n    display_mode=\"z\",\n    figure=plt.figure(figsize=(4, 4)),\n)\nshow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The saved results include a table of activated clusters.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This table can also be generated by using the function\n    :func:`nilearn.reporting.get_clusters_table`.\n\n```python\nfrom nilearn.reporting import get_clusters_table\n\ntable = get_clusters_table(\n    z_map,\n    stat_threshold=norm.isf(0.001),\n    cluster_threshold=10\n)</p></div>\n```\n.. seealso::\n\n    The restults saved to disk and the output of get_clusters_table\n    do not contain the anatomical location of the clusters.\n    To get the names of the location of the clusters\n    according to one or several atlases,\n    we recommend using\n    the [atlasreader package](https://github.com/miykael/atlasreader).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\ntable_file = (\n    output_dir\n    / \"derivatives\"\n    / \"nilearn_glm\"\n    / \"sub-10159\"\n    / (\n        \"sub-10159_task-stopsignal_space-MNI152NLin2009cAsym_\"\n        \"contrast-stopsuccessMinusGo_clusters.tsv\"\n    )\n)\n\ntable = pd.read_csv(table_file, sep=\"\\t\")\n\ntable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can get a latex table from a Pandas Dataframe\nfor display and publication purposes.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>This requires to have jinja2 installed:\n\n```bash\npip install jinja2</p></div>\n```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(table.to_latex())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also print the output to markdown,\nif you have the `tabulate` dependencies installed.\n\n```bash\npip install tabulate\n```\n```python\ntable.to_markdown()\n```\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}