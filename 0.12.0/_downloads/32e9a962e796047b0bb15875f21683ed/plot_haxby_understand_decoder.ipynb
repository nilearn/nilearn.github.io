{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Understanding :class:`~nilearn.decoding.Decoder`\n\nNilearn's :class:`~nilearn.decoding.Decoder` object is a composite estimator\nthat does several things under the hood and can hence be a bit difficult to\nunderstand at first.\n\nThis example aims to provide a clear understanding of the\n:class:`~nilearn.decoding.Decoder` object by demonstrating these steps via a\nScikit-Learn pipeline.\n\nWe will use the :footcite:t:`Haxby2001` dataset where the participants were\nshown images of 8 different types as described in the\n`sphx_glr_auto_examples_02_decoding_plot_haxby_anova_svm.py` example.\nWe will train a classifier to predict the label of the object in the stimulus\nimage based on the subject's fMRI data from the Ventral Temporal cortex.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the Haxby dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn import datasets\n\n# By default 2nd subject data will be fetched on which we run our analysis\nhaxby_dataset = datasets.fetch_haxby()\nfmri_img = haxby_dataset.func[0]\n# Pick the mask that we will use to extract the data from Ventral Temporal\n# cortex\nmask_vt = haxby_dataset.mask_vt[0]\n\n# Load the behavioral data\nimport pandas as pd\n\nfrom nilearn.image import index_img\n\nbehavioral_data = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\nlabels = behavioral_data[\"labels\"]\n# Keep the trials corresponding to all the labels except the ``rest`` ones\nlabels_mask = labels != \"rest\"\ny = labels[labels_mask]\ny = y.to_numpy()\n\n# Load run information\nrun = behavioral_data[\"chunks\"][labels_mask]\nrun = run.to_numpy()\n\n# Also keep the fmri data corresponding to these labels\nfmri_img = index_img(fmri_img, labels_mask)\n\n# Overview of the input data\nimport numpy as np\n\nn_labels = len(np.unique(y))\n\nprint(f\"{n_labels} labels to predict (y): {np.unique(y)}\")\nprint(f\"fMRI data shape (X): {fmri_img.shape}\")\nprint(f\"Runs (groups): {np.unique(run)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing\n\nAs we can see, the fMRI data is a 4D image with shape (40, 64, 64, 864).\nHere 40x64x64 are the dimensions of the 3D brain image and 864 is the number\nof brain volumes acquired while visual stimuli were presented, each\ncorresponding to one of the 8 labels we selected above.\n\n:class:`~nilearn.decoding.Decoder` can convert this 4D image to a 2D numpy\narray where each row corresponds to a trial and each column corresponds to a\nvoxel. In addition, it can also do several other things like masking,\nsmoothing, standardizing the data etc. depending on your requirements.\n\nUnder the hood, :class:`~nilearn.decoding.Decoder` uses\n:class:`~nilearn.maskers.NiftiMasker` to do all these operations. So here we\nwill demonstrate this by directly using the\n:class:`~nilearn.maskers.NiftiMasker`. Specifically, we will use it to:\n\n1. only keep the data from the Ventral Temporal cortex by providing the\nmask image (in :class:`~nilearn.decoding.Decoder` this is done by\nproviding the mask image in the ``mask`` parameter).\n\n2. standardize the data by z-scoring it such that the data is scaled to\nhave zero mean and unit variance across trials (in\n:class:`~nilearn.decoding.Decoder`\nthis is done by setting the ``standardize``\nparameter to ``\"zscore_sample\"``).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.maskers import NiftiMasker\n\nmasker = NiftiMasker(mask_img=mask_vt, standardize=\"zscore_sample\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert the multi-class labels to binary labels\n\nThe :class:`~nilearn.decoding.Decoder` converts multi-class classification\nproblem to N one-vs-others binary classification problems by default (where N\nis the number of unique labels)\n\nThe advantage of this approach is its interpretability. Once we are done with\ntraining and cross-validating, we will have N area-under receiver operating\ncharacteristic curve (AU-:term:`ROC`) scores, one for each\nlabel. This will give us an insight into which labels (and the corresponding\ncognitive domains) are easier to predict and are hence well differentiated\nrelative to the others in the brain.\n\nIn addition, we will also have access to the classifier coefficients for each\nlabel. These can be further used to understand the importance of each voxel\nfor each corresponding cognitive domain.\n\nIn this example we have N = 8 unique labels and we will use Scikit-Learn's\n:class:`~sklearn.preprocessing.LabelBinarizer` to do this conversion.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\nfrom sklearn.preprocessing import LabelBinarizer\n\nlabel_binarizer = LabelBinarizer(pos_label=1, neg_label=-1)\ny_binary = label_binarizer.fit_transform(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the labels to understand the conversion\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib.colors import ListedColormap\nfrom sklearn.preprocessing import LabelEncoder\n\n# create a copy of y_binary and manipulate it just for plotting\ny_binary_ = y_binary.copy()\nfor col in range(y_binary_.shape[1]):\n    y_binary_[np.where(y_binary_[:, col] == 1), col] = col\n\nfig, (ax_binary, ax_multi) = plt.subplots(\n    2, gridspec_kw={\"height_ratios\": [10, 1.5]}, figsize=(12, 2)\n)\ncmap = ListedColormap([\"white\"] + list(plt.cm.tab10.colors)[:n_labels])\nbinary_plt = ax_binary.imshow(\n    y_binary_.T,\n    aspect=\"auto\",\n    cmap=cmap,\n    interpolation=\"nearest\",\n    origin=\"lower\",\n)\nax_binary.set_xticks([])\nax_binary.set_yticks([])\nax_binary.set_ylabel(\"One-vs-Others\")\n\n# encode the original labels for plotting\nlabel_multi = LabelEncoder()\ny_multi = label_multi.fit_transform(y)\ny_multi = y_multi.reshape(1, -1)\ncmap = ListedColormap(list(plt.cm.tab10.colors)[:n_labels])\nmulti_plt = ax_multi.imshow(\n    y_multi,\n    aspect=\"auto\",\n    interpolation=\"nearest\",\n    cmap=cmap,\n)\nax_multi.set_yticks([])\nax_multi.set_xlabel(\"Original trial sequence\")\ncbar = fig.colorbar(multi_plt, ax=[ax_binary, ax_multi])\ncbar.set_ticks(np.arange(1 + len(label_multi.classes_)))\ncbar.set_ticklabels([*label_multi.classes_, \"all others\"])\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So at the bottom we have the original presentation sequence of the selected\ntrials and at the top we have the labels in the one-vs-others format.\n\nEach row corresponds to a one-vs-others binary classification problem.\nFor example, the first row from the bottom corresponds to the binary\nclassification problem of predicting the label \"bottle\" vs. all other labels\nand so on. Later we will train a classifier for each row and calculate the\nAU-ROC score for each row.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature selection\n\nAfter preprocessing the provided fMRI data, the\n:class:`~nilearn.decoding.Decoder` performs a univariate feature selection on\nthe voxels of the brain volume. It uses Scikit-Learn's\n:class:`~sklearn.feature_selection.SelectPercentile` with\n:func:`~sklearn.feature_selection.f_classif` to calculate ANOVA F-scores for\neach voxel and to only keep the ones that have highest 20 percentile scores,\nby default. This selection threshold can be changed using the\n``screening_percentile`` parameter.\n\nThese 20 percentile voxels are with respect to the volume of the standard\nMNI152 brain template. Furthermore, if the provided mask image has less\nvoxels than the selected percentile, all voxels in the mask are used.\n\nAlso note that these top 20 percentile voxels are selected based on training\nset and then these selected voxels are picked for the test set too for each\ntrain-test split.\n\nFor simplicity we will just keep all (100 percentile) voxels in this example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectPercentile, f_classif\n\nscreening_percentile = 100\nfeature_selector = SelectPercentile(f_classif, percentile=screening_percentile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter optimization\n\nThe :class:`~nilearn.decoding.Decoder` also performs hyperparameter tuning.\nHow this is done depends on the estimator used.\n\nFor the support vector classifiers (known as SVC, and used by setting\n``estimator=\"svc\"`` or ``\"svc_l1\"`` or ``\"svc_l2\"``), the score from the\nbest performing regularization hyperparameter (``C``) for each train-test\nsplit is picked.\n\nFor all classifiers other than SVC, the hyperparameter tuning is done using\nthe ``<estimator_name>CV`` classes from Scikit-Learn. This essentially means\nthat the hyperparameters are optimized using an internal cross-validation on\nthe training data.\n\nIn addition, the parameter grids that are used for hyperparameter tuning\nby :class:`~nilearn.decoding.Decoder` are also different from the default\nScikit-Learn parameter grids for the corresponding ``<estimator_name>CV``\nobjects.\n\nFor simplicity, let's use Scikit-Learn's\n:class:`~sklearn.linear_model.LogisticRegressionCV` with custom parameter\ngrid (via ``Cs`` parameter) as used in Nilearn's\n:class:`~nilearn.decoding.Decoder`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n\nclassifier = LogisticRegressionCV(\n    penalty=\"l2\",\n    solver=\"liblinear\",\n    Cs=np.geomspace(1e-3, 1e4, 8),\n    refit=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train and cross-validate via an Scikit-Learn pipeline\n\nNow let's put all the pieces together to train and cross-validate. The\n:class:`~nilearn.decoding.Decoder` uses a leave-one-group-out\ncross-validation scheme by default in cases where groups are defined. In our\nexample a group is a run, so we will use Scikit-Learn's\n:class:`~sklearn.model_selection.LeaveOneGroupOut`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import LeaveOneGroupOut\n\nlogo_cv = LeaveOneGroupOut()\n\n# Transform fMRI data into a 2D numpy array and standardize it with the masker\nX = masker.fit_transform(fmri_img)\nprint(f\"fMRI data shape after masking: {X.shape}\")\n# So now we have a 2D numpy array of shape (864, 464) where each row\n# corresponds to a trial and each column corresponds to a feature\n# (voxel in the Ventral Temporal cortex).\n\n# Loop over each CV split and each class vs. rest binary classification\n# problems (number of classification problems = n_labels)\nscores_sklearn = []\nfor klass in range(n_labels):\n    for train, test in logo_cv.split(X, y, groups=run):\n        # separate train and test events in the data\n        X_train, X_test = X[train], X[test]\n        # separate labels for train and test events for a given class vs. rest\n        # problem\n        y_train, y_test = y_binary[train, klass], y_binary[test, klass]\n\n        # select the voxels by fitting feature selector on training data\n        X_train = feature_selector.fit_transform(X_train, y_train)\n        # pick the same voxels in the test data\n        X_test = feature_selector.transform(X_test)\n\n        # fit the classifier on the training data\n        classifier.fit(X_train, y_train)\n        # predict the labels on the test data\n        pred = classifier.predict_proba(X_test)\n\n        # calculate the ROC AUC score\n        score = roc_auc_score(y_test, pred[:, 1])\n        scores_sklearn.append(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Decode via the :class:`~nilearn.decoding.Decoder`\n\nAll these steps can be done in a few lines and made faster via parallel\nprocessing using the ``n_jobs`` parameter in\n:class:`~nilearn.decoding.Decoder`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nilearn.decoding import Decoder\n\ndecoder = Decoder(\n    estimator=\"logistic_l2\",\n    mask=mask_vt,\n    standardize=\"zscore_sample\",\n    n_jobs=n_labels,\n    cv=logo_cv,\n    screening_percentile=screening_percentile,\n    scoring=\"roc_auc_ovr\",\n)\ndecoder.fit(fmri_img, y, groups=run)\nscores_nilearn = np.concatenate(list(decoder.cv_scores_.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare the results\n\nLet's compare the results from the Scikit-Learn pipeline and the Nilearn\ndecoder.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Nilearn mean AU-ROC score\", np.mean(scores_nilearn))\nprint(\"Scikit-Learn mean AU-ROC score\", np.mean(scores_sklearn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, the mean AU-ROC scores from the Scikit-Learn pipeline and\nNilearn's :class:`~nilearn.decoding.Decoder` are identical.\n\nThe advantage of using Nilearn's :class:`~nilearn.decoding.Decoder` is\nthat it does all these steps under the hood and provides a simple interface\nto train, cross-validate and predict on new data, while also parallelizing\nthe computations to make the cross-validation faster. It also organizes the\nresults in a structured way that can be easily accessed and analyzed.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}